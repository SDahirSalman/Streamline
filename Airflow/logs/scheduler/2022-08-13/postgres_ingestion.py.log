[2022-08-13 00:00:29,748] {processor.py:163} INFO - Started process (PID=96753) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:00:29,750] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:00:29,753] {logging_mixin.py:109} INFO - [2022-08-13 00:00:29,752] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:00:29,774] {logging_mixin.py:109} INFO - [2022-08-13 00:00:29,772] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:00:29,815] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:00:29,832] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.089 seconds
[2022-08-13 00:01:00,309] {processor.py:163} INFO - Started process (PID=96814) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:01:00,311] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:01:00,313] {logging_mixin.py:109} INFO - [2022-08-13 00:01:00,313] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:01:00,325] {logging_mixin.py:109} INFO - [2022-08-13 00:01:00,323] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:01:00,357] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:01:00,373] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.069 seconds
[2022-08-13 00:01:30,443] {processor.py:163} INFO - Started process (PID=96884) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:01:30,446] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:01:30,448] {logging_mixin.py:109} INFO - [2022-08-13 00:01:30,448] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:01:30,458] {logging_mixin.py:109} INFO - [2022-08-13 00:01:30,457] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:01:30,481] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:01:30,494] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.058 seconds
[2022-08-13 00:02:00,899] {processor.py:163} INFO - Started process (PID=96945) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:02:00,901] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:02:00,904] {logging_mixin.py:109} INFO - [2022-08-13 00:02:00,903] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:02:00,912] {logging_mixin.py:109} INFO - [2022-08-13 00:02:00,911] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:02:00,934] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:02:00,947] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.055 seconds
[2022-08-13 00:02:31,029] {processor.py:163} INFO - Started process (PID=97006) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:02:31,031] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:02:31,032] {logging_mixin.py:109} INFO - [2022-08-13 00:02:31,032] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:02:31,045] {logging_mixin.py:109} INFO - [2022-08-13 00:02:31,043] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:02:31,067] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:02:31,082] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.058 seconds
[2022-08-13 00:03:01,519] {processor.py:163} INFO - Started process (PID=97077) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:03:01,521] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:03:01,523] {logging_mixin.py:109} INFO - [2022-08-13 00:03:01,522] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:03:01,532] {logging_mixin.py:109} INFO - [2022-08-13 00:03:01,531] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:03:01,556] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:03:01,568] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.054 seconds
[2022-08-13 00:03:32,352] {processor.py:163} INFO - Started process (PID=97138) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:03:32,355] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:03:32,357] {logging_mixin.py:109} INFO - [2022-08-13 00:03:32,357] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:03:32,366] {logging_mixin.py:109} INFO - [2022-08-13 00:03:32,365] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:03:32,388] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:03:32,400] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.052 seconds
[2022-08-13 00:04:02,828] {processor.py:163} INFO - Started process (PID=97207) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:04:02,830] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:04:02,833] {logging_mixin.py:109} INFO - [2022-08-13 00:04:02,832] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:04:02,857] {logging_mixin.py:109} INFO - [2022-08-13 00:04:02,849] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:04:02,888] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:04:02,903] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.081 seconds
[2022-08-13 00:04:33,878] {processor.py:163} INFO - Started process (PID=97271) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:04:33,881] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:04:33,883] {logging_mixin.py:109} INFO - [2022-08-13 00:04:33,883] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:04:33,896] {logging_mixin.py:109} INFO - [2022-08-13 00:04:33,895] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:04:33,924] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:04:33,941] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.068 seconds
[2022-08-13 00:05:04,536] {processor.py:163} INFO - Started process (PID=97332) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:05:04,543] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:05:04,546] {logging_mixin.py:109} INFO - [2022-08-13 00:05:04,545] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:05:04,579] {logging_mixin.py:109} INFO - [2022-08-13 00:05:04,577] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:05:04,604] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:05:04,621] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.094 seconds
[2022-08-13 00:05:34,658] {processor.py:163} INFO - Started process (PID=97402) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:05:34,661] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:05:34,663] {logging_mixin.py:109} INFO - [2022-08-13 00:05:34,662] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:05:34,674] {logging_mixin.py:109} INFO - [2022-08-13 00:05:34,672] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:05:34,702] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:05:34,746] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.092 seconds
[2022-08-13 00:06:05,112] {processor.py:163} INFO - Started process (PID=97463) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:06:05,116] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:06:05,120] {logging_mixin.py:109} INFO - [2022-08-13 00:06:05,120] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:06:05,132] {logging_mixin.py:109} INFO - [2022-08-13 00:06:05,131] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:06:05,158] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:06:05,172] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.067 seconds
[2022-08-13 00:06:35,462] {processor.py:163} INFO - Started process (PID=97526) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:06:35,467] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:06:35,471] {logging_mixin.py:109} INFO - [2022-08-13 00:06:35,470] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:06:35,488] {logging_mixin.py:109} INFO - [2022-08-13 00:06:35,486] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:06:35,516] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:06:35,537] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.079 seconds
[2022-08-13 00:07:05,626] {processor.py:163} INFO - Started process (PID=97595) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:07:05,628] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:07:05,630] {logging_mixin.py:109} INFO - [2022-08-13 00:07:05,630] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:07:05,643] {logging_mixin.py:109} INFO - [2022-08-13 00:07:05,642] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:07:05,673] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:07:05,690] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.070 seconds
[2022-08-13 00:07:35,757] {processor.py:163} INFO - Started process (PID=97655) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:07:35,760] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:07:35,761] {logging_mixin.py:109} INFO - [2022-08-13 00:07:35,761] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:07:35,774] {logging_mixin.py:109} INFO - [2022-08-13 00:07:35,773] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:07:35,796] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:07:35,810] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.058 seconds
[2022-08-13 00:08:05,999] {processor.py:163} INFO - Started process (PID=97707) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:08:06,002] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:08:06,004] {logging_mixin.py:109} INFO - [2022-08-13 00:08:06,004] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:08:06,018] {logging_mixin.py:109} INFO - [2022-08-13 00:08:06,014] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:08:06,045] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:08:06,068] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.076 seconds
[2022-08-13 00:08:36,585] {processor.py:163} INFO - Started process (PID=97778) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:08:36,588] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:08:36,590] {logging_mixin.py:109} INFO - [2022-08-13 00:08:36,590] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:08:36,602] {logging_mixin.py:109} INFO - [2022-08-13 00:08:36,601] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:08:36,630] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:08:36,644] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.065 seconds
[2022-08-13 00:09:07,019] {processor.py:163} INFO - Started process (PID=97839) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:09:07,022] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:09:07,024] {logging_mixin.py:109} INFO - [2022-08-13 00:09:07,024] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:09:07,034] {logging_mixin.py:109} INFO - [2022-08-13 00:09:07,033] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:09:07,055] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:09:07,065] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.051 seconds
[2022-08-13 00:09:37,217] {processor.py:163} INFO - Started process (PID=97901) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:09:37,220] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:09:37,223] {logging_mixin.py:109} INFO - [2022-08-13 00:09:37,222] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:09:37,236] {logging_mixin.py:109} INFO - [2022-08-13 00:09:37,233] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:09:37,270] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:09:37,295] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.088 seconds
[2022-08-13 00:10:07,894] {processor.py:163} INFO - Started process (PID=97963) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:10:07,898] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:10:07,900] {logging_mixin.py:109} INFO - [2022-08-13 00:10:07,900] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:10:07,910] {logging_mixin.py:109} INFO - [2022-08-13 00:10:07,909] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:10:07,939] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:10:07,953] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.064 seconds
[2022-08-13 00:10:38,299] {processor.py:163} INFO - Started process (PID=98024) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:10:38,302] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:10:38,305] {logging_mixin.py:109} INFO - [2022-08-13 00:10:38,304] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:10:38,316] {logging_mixin.py:109} INFO - [2022-08-13 00:10:38,315] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:10:38,343] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:10:38,357] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.063 seconds
[2022-08-13 00:11:08,775] {processor.py:163} INFO - Started process (PID=98094) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:11:08,779] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:11:08,781] {logging_mixin.py:109} INFO - [2022-08-13 00:11:08,781] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:11:08,793] {logging_mixin.py:109} INFO - [2022-08-13 00:11:08,791] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:11:08,821] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:11:08,843] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.072 seconds
[2022-08-13 00:11:39,331] {processor.py:163} INFO - Started process (PID=98158) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:11:39,335] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:11:39,337] {logging_mixin.py:109} INFO - [2022-08-13 00:11:39,337] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:11:39,352] {logging_mixin.py:109} INFO - [2022-08-13 00:11:39,349] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:11:39,381] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:11:39,399] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.077 seconds
[2022-08-13 00:12:09,700] {processor.py:163} INFO - Started process (PID=98218) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:12:09,704] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:12:09,706] {logging_mixin.py:109} INFO - [2022-08-13 00:12:09,706] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:12:09,717] {logging_mixin.py:109} INFO - [2022-08-13 00:12:09,715] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:12:09,740] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:12:09,752] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.056 seconds
[2022-08-13 00:12:40,118] {processor.py:163} INFO - Started process (PID=98287) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:12:40,121] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:12:40,128] {logging_mixin.py:109} INFO - [2022-08-13 00:12:40,128] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:12:40,139] {logging_mixin.py:109} INFO - [2022-08-13 00:12:40,137] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:12:40,182] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:12:40,208] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.095 seconds
[2022-08-13 00:13:10,501] {processor.py:163} INFO - Started process (PID=98349) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:13:10,503] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:13:10,506] {logging_mixin.py:109} INFO - [2022-08-13 00:13:10,506] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:13:10,517] {logging_mixin.py:109} INFO - [2022-08-13 00:13:10,516] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:13:10,543] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:13:10,556] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.061 seconds
[2022-08-13 00:13:40,647] {processor.py:163} INFO - Started process (PID=98411) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:13:40,651] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:13:40,652] {logging_mixin.py:109} INFO - [2022-08-13 00:13:40,652] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:13:40,663] {logging_mixin.py:109} INFO - [2022-08-13 00:13:40,662] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:13:40,692] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:13:40,707] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.065 seconds
[2022-08-13 00:14:10,899] {processor.py:163} INFO - Started process (PID=98480) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:14:10,902] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:14:10,903] {logging_mixin.py:109} INFO - [2022-08-13 00:14:10,903] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:14:10,919] {logging_mixin.py:109} INFO - [2022-08-13 00:14:10,917] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:14:10,962] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:14:10,986] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.092 seconds
[2022-08-13 00:14:41,119] {processor.py:163} INFO - Started process (PID=98544) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:14:41,123] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:14:41,125] {logging_mixin.py:109} INFO - [2022-08-13 00:14:41,125] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:14:41,135] {logging_mixin.py:109} INFO - [2022-08-13 00:14:41,133] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:14:41,160] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:14:41,173] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.058 seconds
[2022-08-13 00:15:11,608] {processor.py:163} INFO - Started process (PID=98601) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:15:11,611] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:15:11,613] {logging_mixin.py:109} INFO - [2022-08-13 00:15:11,612] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:15:11,624] {logging_mixin.py:109} INFO - [2022-08-13 00:15:11,622] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:15:11,648] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:15:11,664] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.064 seconds
[2022-08-13 00:15:42,160] {processor.py:163} INFO - Started process (PID=98672) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:15:42,163] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:15:42,165] {logging_mixin.py:109} INFO - [2022-08-13 00:15:42,164] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:15:42,175] {logging_mixin.py:109} INFO - [2022-08-13 00:15:42,174] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:15:42,204] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:15:42,225] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.070 seconds
[2022-08-13 00:16:12,414] {processor.py:163} INFO - Started process (PID=98734) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:16:12,416] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:16:12,417] {logging_mixin.py:109} INFO - [2022-08-13 00:16:12,417] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:16:12,428] {logging_mixin.py:109} INFO - [2022-08-13 00:16:12,426] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:16:12,456] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:16:12,470] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.061 seconds
[2022-08-13 00:16:42,979] {processor.py:163} INFO - Started process (PID=98796) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:16:42,982] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:16:42,983] {logging_mixin.py:109} INFO - [2022-08-13 00:16:42,983] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:16:42,999] {logging_mixin.py:109} INFO - [2022-08-13 00:16:42,997] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:16:43,028] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:16:43,046] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.077 seconds
[2022-08-13 00:17:13,636] {processor.py:163} INFO - Started process (PID=98868) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:17:13,638] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:17:13,640] {logging_mixin.py:109} INFO - [2022-08-13 00:17:13,640] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:17:13,657] {logging_mixin.py:109} INFO - [2022-08-13 00:17:13,655] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:17:13,695] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:17:13,708] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.078 seconds
[2022-08-13 00:17:43,804] {processor.py:163} INFO - Started process (PID=98931) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:17:43,806] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:17:43,808] {logging_mixin.py:109} INFO - [2022-08-13 00:17:43,808] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:17:43,818] {logging_mixin.py:109} INFO - [2022-08-13 00:17:43,816] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:17:43,839] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:17:43,851] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.054 seconds
[2022-08-13 00:18:14,125] {processor.py:163} INFO - Started process (PID=98991) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:18:14,128] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:18:14,130] {logging_mixin.py:109} INFO - [2022-08-13 00:18:14,130] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:18:14,145] {logging_mixin.py:109} INFO - [2022-08-13 00:18:14,144] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:18:14,172] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:18:14,189] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.072 seconds
[2022-08-13 00:18:44,791] {processor.py:163} INFO - Started process (PID=99061) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:18:44,794] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:18:44,795] {logging_mixin.py:109} INFO - [2022-08-13 00:18:44,795] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:18:44,805] {logging_mixin.py:109} INFO - [2022-08-13 00:18:44,804] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:18:44,829] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:18:44,843] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.058 seconds
[2022-08-13 00:19:15,165] {processor.py:163} INFO - Started process (PID=99121) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:19:15,168] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:19:15,170] {logging_mixin.py:109} INFO - [2022-08-13 00:19:15,170] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:19:15,180] {logging_mixin.py:109} INFO - [2022-08-13 00:19:15,179] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:19:15,204] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:19:15,219] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.060 seconds
[2022-08-13 00:19:45,762] {processor.py:163} INFO - Started process (PID=99183) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:19:45,768] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:19:45,772] {logging_mixin.py:109} INFO - [2022-08-13 00:19:45,771] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:19:45,792] {logging_mixin.py:109} INFO - [2022-08-13 00:19:45,790] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:19:45,830] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:19:45,866] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.109 seconds
[2022-08-13 00:20:16,611] {processor.py:163} INFO - Started process (PID=99253) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:20:16,615] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:20:16,620] {logging_mixin.py:109} INFO - [2022-08-13 00:20:16,619] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:20:16,633] {logging_mixin.py:109} INFO - [2022-08-13 00:20:16,632] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:20:16,659] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:20:16,682] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.076 seconds
[2022-08-13 00:20:46,849] {processor.py:163} INFO - Started process (PID=99314) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:20:46,853] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:20:46,856] {logging_mixin.py:109} INFO - [2022-08-13 00:20:46,856] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:20:46,867] {logging_mixin.py:109} INFO - [2022-08-13 00:20:46,866] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:20:46,897] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:20:46,910] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.066 seconds
[2022-08-13 00:21:17,348] {processor.py:163} INFO - Started process (PID=99375) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:21:17,353] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:21:17,356] {logging_mixin.py:109} INFO - [2022-08-13 00:21:17,356] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:21:17,386] {logging_mixin.py:109} INFO - [2022-08-13 00:21:17,384] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:21:17,424] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:21:17,442] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.101 seconds
[2022-08-13 00:21:48,183] {processor.py:163} INFO - Started process (PID=99446) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:21:48,185] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:21:48,187] {logging_mixin.py:109} INFO - [2022-08-13 00:21:48,187] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:21:48,197] {logging_mixin.py:109} INFO - [2022-08-13 00:21:48,196] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:21:48,221] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:21:48,237] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.060 seconds
[2022-08-13 00:22:18,929] {processor.py:163} INFO - Started process (PID=99507) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:22:18,933] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:22:18,936] {logging_mixin.py:109} INFO - [2022-08-13 00:22:18,936] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:22:18,951] {logging_mixin.py:109} INFO - [2022-08-13 00:22:18,949] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:22:18,983] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:22:19,000] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.081 seconds
[2022-08-13 00:22:49,336] {processor.py:163} INFO - Started process (PID=99577) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:22:49,339] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:22:49,341] {logging_mixin.py:109} INFO - [2022-08-13 00:22:49,340] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:22:49,351] {logging_mixin.py:109} INFO - [2022-08-13 00:22:49,350] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:22:49,383] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:22:49,408] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.076 seconds
[2022-08-13 00:23:19,784] {processor.py:163} INFO - Started process (PID=99639) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:23:19,788] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:23:19,790] {logging_mixin.py:109} INFO - [2022-08-13 00:23:19,790] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:23:19,800] {logging_mixin.py:109} INFO - [2022-08-13 00:23:19,798] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:23:19,824] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:23:19,839] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.061 seconds
[2022-08-13 00:23:50,158] {processor.py:163} INFO - Started process (PID=99701) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:23:50,163] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:23:50,165] {logging_mixin.py:109} INFO - [2022-08-13 00:23:50,165] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:23:50,179] {logging_mixin.py:109} INFO - [2022-08-13 00:23:50,177] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:23:50,222] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:23:50,237] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.090 seconds
[2022-08-13 00:24:20,332] {processor.py:163} INFO - Started process (PID=99773) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:24:20,338] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:24:20,340] {logging_mixin.py:109} INFO - [2022-08-13 00:24:20,340] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:24:20,355] {logging_mixin.py:109} INFO - [2022-08-13 00:24:20,354] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:24:20,381] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:24:20,396] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.067 seconds
[2022-08-13 00:24:50,806] {processor.py:163} INFO - Started process (PID=99835) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:24:50,809] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:24:50,811] {logging_mixin.py:109} INFO - [2022-08-13 00:24:50,811] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:24:50,821] {logging_mixin.py:109} INFO - [2022-08-13 00:24:50,819] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:24:50,845] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:24:50,858] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.059 seconds
[2022-08-13 00:25:21,248] {processor.py:163} INFO - Started process (PID=99897) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:25:21,251] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:25:21,254] {logging_mixin.py:109} INFO - [2022-08-13 00:25:21,253] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:25:21,265] {logging_mixin.py:109} INFO - [2022-08-13 00:25:21,264] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:25:21,296] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:25:21,314] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.073 seconds
[2022-08-13 00:25:51,639] {processor.py:163} INFO - Started process (PID=99967) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:25:51,641] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:25:51,643] {logging_mixin.py:109} INFO - [2022-08-13 00:25:51,643] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:25:51,656] {logging_mixin.py:109} INFO - [2022-08-13 00:25:51,654] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:25:51,682] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:25:51,696] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.064 seconds
[2022-08-13 00:26:21,789] {processor.py:163} INFO - Started process (PID=330) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:26:21,792] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:26:21,794] {logging_mixin.py:109} INFO - [2022-08-13 00:26:21,794] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:26:21,802] {logging_mixin.py:109} INFO - [2022-08-13 00:26:21,801] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:26:21,829] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:26:21,846] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.061 seconds
[2022-08-13 00:26:52,288] {processor.py:163} INFO - Started process (PID=391) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:26:52,292] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:26:52,293] {logging_mixin.py:109} INFO - [2022-08-13 00:26:52,293] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:26:52,307] {logging_mixin.py:109} INFO - [2022-08-13 00:26:52,306] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:26:52,341] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:26:52,370] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.092 seconds
[2022-08-13 00:27:22,595] {processor.py:163} INFO - Started process (PID=462) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:27:22,597] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:27:22,599] {logging_mixin.py:109} INFO - [2022-08-13 00:27:22,599] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:27:22,611] {logging_mixin.py:109} INFO - [2022-08-13 00:27:22,610] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:27:22,636] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:27:22,651] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.063 seconds
[2022-08-13 00:27:53,033] {processor.py:163} INFO - Started process (PID=523) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:27:53,037] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:27:53,039] {logging_mixin.py:109} INFO - [2022-08-13 00:27:53,039] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:27:53,050] {logging_mixin.py:109} INFO - [2022-08-13 00:27:53,049] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:27:53,082] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:27:53,097] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.068 seconds
[2022-08-13 00:28:23,260] {processor.py:163} INFO - Started process (PID=584) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:28:23,264] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:28:23,265] {logging_mixin.py:109} INFO - [2022-08-13 00:28:23,265] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:28:23,279] {logging_mixin.py:109} INFO - [2022-08-13 00:28:23,277] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:28:23,343] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:28:23,399] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.145 seconds
[2022-08-13 00:28:54,083] {processor.py:163} INFO - Started process (PID=654) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:28:54,087] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:28:54,088] {logging_mixin.py:109} INFO - [2022-08-13 00:28:54,088] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:28:54,104] {logging_mixin.py:109} INFO - [2022-08-13 00:28:54,101] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:28:54,133] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:28:54,149] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.072 seconds
[2022-08-13 00:29:24,463] {processor.py:163} INFO - Started process (PID=715) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:29:24,465] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:29:24,466] {logging_mixin.py:109} INFO - [2022-08-13 00:29:24,466] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:29:24,477] {logging_mixin.py:109} INFO - [2022-08-13 00:29:24,476] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:29:24,500] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:29:24,513] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.058 seconds
[2022-08-13 00:29:54,893] {processor.py:163} INFO - Started process (PID=786) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:29:54,896] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:29:54,899] {logging_mixin.py:109} INFO - [2022-08-13 00:29:54,898] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:29:54,915] {logging_mixin.py:109} INFO - [2022-08-13 00:29:54,913] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:29:54,943] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:29:54,961] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.075 seconds
[2022-08-13 00:30:25,364] {processor.py:163} INFO - Started process (PID=847) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:30:25,366] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:30:25,369] {logging_mixin.py:109} INFO - [2022-08-13 00:30:25,369] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:30:25,379] {logging_mixin.py:109} INFO - [2022-08-13 00:30:25,377] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:30:25,402] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:30:25,415] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.058 seconds
[2022-08-13 00:30:55,774] {processor.py:163} INFO - Started process (PID=908) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:30:55,778] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:30:55,780] {logging_mixin.py:109} INFO - [2022-08-13 00:30:55,780] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:30:55,791] {logging_mixin.py:109} INFO - [2022-08-13 00:30:55,789] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:30:55,820] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:30:55,838] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.068 seconds
[2022-08-13 00:31:26,139] {processor.py:163} INFO - Started process (PID=979) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:31:26,143] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:31:26,145] {logging_mixin.py:109} INFO - [2022-08-13 00:31:26,145] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:31:26,156] {logging_mixin.py:109} INFO - [2022-08-13 00:31:26,155] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:31:26,181] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:31:26,194] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.059 seconds
[2022-08-13 00:31:56,454] {processor.py:163} INFO - Started process (PID=1041) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:31:56,456] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:31:56,459] {logging_mixin.py:109} INFO - [2022-08-13 00:31:56,459] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:31:56,471] {logging_mixin.py:109} INFO - [2022-08-13 00:31:56,470] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:31:56,497] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:31:56,518] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.070 seconds
[2022-08-13 00:32:26,790] {processor.py:163} INFO - Started process (PID=1102) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:32:26,793] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:32:26,794] {logging_mixin.py:109} INFO - [2022-08-13 00:32:26,794] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:32:26,805] {logging_mixin.py:109} INFO - [2022-08-13 00:32:26,804] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:32:26,832] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:32:26,845] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.061 seconds
[2022-08-13 00:32:56,912] {processor.py:163} INFO - Started process (PID=1172) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:32:56,914] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:32:56,916] {logging_mixin.py:109} INFO - [2022-08-13 00:32:56,916] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:32:56,930] {logging_mixin.py:109} INFO - [2022-08-13 00:32:56,929] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:32:56,955] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:32:56,968] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.062 seconds
[2022-08-13 00:33:27,130] {processor.py:163} INFO - Started process (PID=1233) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:33:27,133] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:33:27,135] {logging_mixin.py:109} INFO - [2022-08-13 00:33:27,135] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:33:27,144] {logging_mixin.py:109} INFO - [2022-08-13 00:33:27,143] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:33:27,166] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:33:27,177] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.053 seconds
[2022-08-13 00:33:57,367] {processor.py:163} INFO - Started process (PID=1294) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:33:57,370] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:33:57,372] {logging_mixin.py:109} INFO - [2022-08-13 00:33:57,372] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:33:57,385] {logging_mixin.py:109} INFO - [2022-08-13 00:33:57,384] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:33:57,409] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:33:57,422] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.059 seconds
[2022-08-13 00:34:27,973] {processor.py:163} INFO - Started process (PID=1360) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:34:27,978] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:34:27,979] {logging_mixin.py:109} INFO - [2022-08-13 00:34:27,979] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:34:27,989] {logging_mixin.py:109} INFO - [2022-08-13 00:34:27,988] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:34:28,015] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:34:28,029] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.061 seconds
[2022-08-13 00:34:58,418] {processor.py:163} INFO - Started process (PID=1421) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:34:58,420] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:34:58,423] {logging_mixin.py:109} INFO - [2022-08-13 00:34:58,422] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:34:58,434] {logging_mixin.py:109} INFO - [2022-08-13 00:34:58,433] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:34:58,459] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:34:58,473] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.060 seconds
[2022-08-13 00:35:29,029] {processor.py:163} INFO - Started process (PID=1482) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:35:29,032] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:35:29,034] {logging_mixin.py:109} INFO - [2022-08-13 00:35:29,033] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:35:29,047] {logging_mixin.py:109} INFO - [2022-08-13 00:35:29,045] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:35:29,074] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:35:29,092] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.069 seconds
[2022-08-13 00:35:59,615] {processor.py:163} INFO - Started process (PID=1552) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:35:59,617] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:35:59,619] {logging_mixin.py:109} INFO - [2022-08-13 00:35:59,618] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:35:59,630] {logging_mixin.py:109} INFO - [2022-08-13 00:35:59,629] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:35:59,658] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:35:59,675] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.066 seconds
[2022-08-13 00:36:30,238] {processor.py:163} INFO - Started process (PID=1614) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:36:30,240] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:36:30,242] {logging_mixin.py:109} INFO - [2022-08-13 00:36:30,242] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:36:30,252] {logging_mixin.py:109} INFO - [2022-08-13 00:36:30,251] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:36:30,275] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:36:30,289] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.057 seconds
[2022-08-13 00:37:00,823] {processor.py:163} INFO - Started process (PID=1685) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:37:00,826] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:37:00,831] {logging_mixin.py:109} INFO - [2022-08-13 00:37:00,830] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:37:00,852] {logging_mixin.py:109} INFO - [2022-08-13 00:37:00,851] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:37:00,879] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:37:00,891] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.076 seconds
[2022-08-13 00:37:31,320] {processor.py:163} INFO - Started process (PID=1747) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:37:31,325] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:37:31,329] {logging_mixin.py:109} INFO - [2022-08-13 00:37:31,328] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:37:31,344] {logging_mixin.py:109} INFO - [2022-08-13 00:37:31,342] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:37:31,374] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:37:31,393] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.080 seconds
[2022-08-13 00:38:02,047] {processor.py:163} INFO - Started process (PID=1808) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:38:02,050] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:38:02,051] {logging_mixin.py:109} INFO - [2022-08-13 00:38:02,051] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:38:02,065] {logging_mixin.py:109} INFO - [2022-08-13 00:38:02,064] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:38:02,101] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:38:02,119] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.079 seconds
[2022-08-13 00:38:32,396] {processor.py:163} INFO - Started process (PID=1878) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:38:32,399] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:38:32,401] {logging_mixin.py:109} INFO - [2022-08-13 00:38:32,400] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:38:32,412] {logging_mixin.py:109} INFO - [2022-08-13 00:38:32,410] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:38:32,440] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:38:32,453] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.060 seconds
[2022-08-13 00:39:02,957] {processor.py:163} INFO - Started process (PID=1940) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:39:02,960] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:39:02,963] {logging_mixin.py:109} INFO - [2022-08-13 00:39:02,962] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:39:02,975] {logging_mixin.py:109} INFO - [2022-08-13 00:39:02,973] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:39:03,002] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:39:03,019] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.070 seconds
[2022-08-13 00:39:33,208] {processor.py:163} INFO - Started process (PID=2002) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:39:33,210] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:39:33,212] {logging_mixin.py:109} INFO - [2022-08-13 00:39:33,212] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:39:33,222] {logging_mixin.py:109} INFO - [2022-08-13 00:39:33,220] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:39:33,264] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:39:33,281] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.079 seconds
[2022-08-13 00:40:03,818] {processor.py:163} INFO - Started process (PID=2074) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:40:03,820] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:40:03,823] {logging_mixin.py:109} INFO - [2022-08-13 00:40:03,822] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:40:03,836] {logging_mixin.py:109} INFO - [2022-08-13 00:40:03,835] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:40:03,866] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:40:03,885] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.074 seconds
[2022-08-13 00:40:34,311] {processor.py:163} INFO - Started process (PID=2136) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:40:34,314] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:40:34,315] {logging_mixin.py:109} INFO - [2022-08-13 00:40:34,315] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:40:34,326] {logging_mixin.py:109} INFO - [2022-08-13 00:40:34,325] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:40:34,349] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:40:34,361] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.058 seconds
[2022-08-13 00:41:04,688] {processor.py:163} INFO - Started process (PID=2197) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:41:04,693] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:41:04,696] {logging_mixin.py:109} INFO - [2022-08-13 00:41:04,696] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:41:04,711] {logging_mixin.py:109} INFO - [2022-08-13 00:41:04,709] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:41:04,742] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:41:04,761] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.082 seconds
[2022-08-13 00:41:35,228] {processor.py:163} INFO - Started process (PID=2267) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:41:35,232] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:41:35,234] {logging_mixin.py:109} INFO - [2022-08-13 00:41:35,234] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:41:35,247] {logging_mixin.py:109} INFO - [2022-08-13 00:41:35,244] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:41:35,270] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:41:35,292] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.068 seconds
[2022-08-13 00:42:05,784] {processor.py:163} INFO - Started process (PID=2329) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:42:05,786] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:42:05,790] {logging_mixin.py:109} INFO - [2022-08-13 00:42:05,789] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:42:05,799] {logging_mixin.py:109} INFO - [2022-08-13 00:42:05,798] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:42:05,821] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:42:05,851] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.074 seconds
[2022-08-13 00:42:36,238] {processor.py:163} INFO - Started process (PID=2400) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:42:36,242] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:42:36,246] {logging_mixin.py:109} INFO - [2022-08-13 00:42:36,246] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:42:36,267] {logging_mixin.py:109} INFO - [2022-08-13 00:42:36,266] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:42:36,302] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:42:36,323] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.096 seconds
[2022-08-13 00:43:06,916] {processor.py:163} INFO - Started process (PID=2462) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:43:06,918] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:43:06,919] {logging_mixin.py:109} INFO - [2022-08-13 00:43:06,919] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:43:06,933] {logging_mixin.py:109} INFO - [2022-08-13 00:43:06,931] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:43:06,961] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:43:06,975] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.068 seconds
[2022-08-13 00:43:37,405] {processor.py:163} INFO - Started process (PID=2524) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:43:37,409] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:43:37,411] {logging_mixin.py:109} INFO - [2022-08-13 00:43:37,411] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:43:37,422] {logging_mixin.py:109} INFO - [2022-08-13 00:43:37,420] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:43:37,449] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:43:37,461] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.060 seconds
[2022-08-13 00:44:07,858] {processor.py:163} INFO - Started process (PID=2595) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:44:07,860] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:44:07,862] {logging_mixin.py:109} INFO - [2022-08-13 00:44:07,862] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:44:07,874] {logging_mixin.py:109} INFO - [2022-08-13 00:44:07,871] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:44:07,902] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:44:07,923] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.072 seconds
[2022-08-13 00:44:38,086] {processor.py:163} INFO - Started process (PID=2656) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:44:38,088] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:44:38,091] {logging_mixin.py:109} INFO - [2022-08-13 00:44:38,090] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:44:38,100] {logging_mixin.py:109} INFO - [2022-08-13 00:44:38,099] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:44:38,125] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:44:38,136] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.055 seconds
[2022-08-13 00:45:08,775] {processor.py:163} INFO - Started process (PID=2717) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:45:08,778] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:45:08,780] {logging_mixin.py:109} INFO - [2022-08-13 00:45:08,780] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:45:08,794] {logging_mixin.py:109} INFO - [2022-08-13 00:45:08,793] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:45:08,820] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:45:08,837] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.071 seconds
[2022-08-13 00:45:39,249] {processor.py:163} INFO - Started process (PID=2789) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:45:39,252] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:45:39,254] {logging_mixin.py:109} INFO - [2022-08-13 00:45:39,254] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:45:39,265] {logging_mixin.py:109} INFO - [2022-08-13 00:45:39,263] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:45:39,291] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:45:39,308] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.065 seconds
[2022-08-13 00:46:09,875] {processor.py:163} INFO - Started process (PID=2850) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:46:09,877] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:46:09,879] {logging_mixin.py:109} INFO - [2022-08-13 00:46:09,879] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:46:09,889] {logging_mixin.py:109} INFO - [2022-08-13 00:46:09,887] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:46:09,914] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:46:09,944] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.076 seconds
[2022-08-13 00:46:40,097] {processor.py:163} INFO - Started process (PID=2912) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:46:40,099] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:46:40,101] {logging_mixin.py:109} INFO - [2022-08-13 00:46:40,101] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:46:40,113] {logging_mixin.py:109} INFO - [2022-08-13 00:46:40,111] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:46:40,141] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:46:40,155] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.063 seconds
[2022-08-13 00:47:10,652] {processor.py:163} INFO - Started process (PID=2983) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:47:10,656] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:47:10,658] {logging_mixin.py:109} INFO - [2022-08-13 00:47:10,658] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:47:10,682] {logging_mixin.py:109} INFO - [2022-08-13 00:47:10,677] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:47:10,717] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:47:10,734] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.086 seconds
[2022-08-13 00:47:41,597] {processor.py:163} INFO - Started process (PID=3043) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:47:41,601] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:47:41,602] {logging_mixin.py:109} INFO - [2022-08-13 00:47:41,602] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:47:41,612] {logging_mixin.py:109} INFO - [2022-08-13 00:47:41,611] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:47:41,637] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:47:41,652] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.059 seconds
[2022-08-13 00:48:12,162] {processor.py:163} INFO - Started process (PID=3114) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:48:12,164] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:48:12,166] {logging_mixin.py:109} INFO - [2022-08-13 00:48:12,166] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:48:12,176] {logging_mixin.py:109} INFO - [2022-08-13 00:48:12,174] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:48:12,209] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:48:12,231] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.086 seconds
[2022-08-13 00:48:42,391] {processor.py:163} INFO - Started process (PID=3175) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:48:42,395] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:48:42,398] {logging_mixin.py:109} INFO - [2022-08-13 00:48:42,398] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:48:42,409] {logging_mixin.py:109} INFO - [2022-08-13 00:48:42,407] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:48:42,443] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:48:42,465] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.086 seconds
[2022-08-13 00:49:12,767] {processor.py:163} INFO - Started process (PID=3236) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:49:12,769] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:49:12,771] {logging_mixin.py:109} INFO - [2022-08-13 00:49:12,771] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:49:12,785] {logging_mixin.py:109} INFO - [2022-08-13 00:49:12,784] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:49:12,829] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:49:12,847] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.086 seconds
[2022-08-13 00:49:43,071] {processor.py:163} INFO - Started process (PID=3306) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:49:43,076] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:49:43,078] {logging_mixin.py:109} INFO - [2022-08-13 00:49:43,078] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:49:43,091] {logging_mixin.py:109} INFO - [2022-08-13 00:49:43,088] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:49:43,120] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:49:43,146] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.080 seconds
[2022-08-13 00:50:13,281] {processor.py:163} INFO - Started process (PID=3367) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:50:13,285] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:50:13,287] {logging_mixin.py:109} INFO - [2022-08-13 00:50:13,287] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:50:13,302] {logging_mixin.py:109} INFO - [2022-08-13 00:50:13,299] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:50:13,325] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:50:13,341] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.067 seconds
[2022-08-13 00:50:44,088] {processor.py:163} INFO - Started process (PID=3428) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:50:44,090] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:50:44,092] {logging_mixin.py:109} INFO - [2022-08-13 00:50:44,091] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:50:44,104] {logging_mixin.py:109} INFO - [2022-08-13 00:50:44,103] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:50:44,130] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:50:44,151] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.067 seconds
[2022-08-13 00:51:14,700] {processor.py:163} INFO - Started process (PID=3498) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:51:14,705] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:51:14,707] {logging_mixin.py:109} INFO - [2022-08-13 00:51:14,707] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:51:14,727] {logging_mixin.py:109} INFO - [2022-08-13 00:51:14,725] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:51:14,757] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:51:14,773] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.084 seconds
[2022-08-13 00:51:45,304] {processor.py:163} INFO - Started process (PID=3559) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:51:45,308] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:51:45,309] {logging_mixin.py:109} INFO - [2022-08-13 00:51:45,309] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:51:45,320] {logging_mixin.py:109} INFO - [2022-08-13 00:51:45,318] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:51:45,346] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:51:45,365] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.067 seconds
[2022-08-13 00:52:15,788] {processor.py:163} INFO - Started process (PID=3621) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:52:15,792] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:52:15,793] {logging_mixin.py:109} INFO - [2022-08-13 00:52:15,793] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:52:15,805] {logging_mixin.py:109} INFO - [2022-08-13 00:52:15,803] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:52:15,833] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:52:15,850] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.070 seconds
[2022-08-13 00:52:46,279] {processor.py:163} INFO - Started process (PID=3691) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:52:46,282] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:52:46,285] {logging_mixin.py:109} INFO - [2022-08-13 00:52:46,285] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:52:46,295] {logging_mixin.py:109} INFO - [2022-08-13 00:52:46,294] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:52:46,320] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:52:46,337] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.068 seconds
[2022-08-13 00:53:16,839] {processor.py:163} INFO - Started process (PID=3752) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:53:16,842] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:53:16,843] {logging_mixin.py:109} INFO - [2022-08-13 00:53:16,843] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:53:16,856] {logging_mixin.py:109} INFO - [2022-08-13 00:53:16,854] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:53:16,882] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:53:16,895] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.060 seconds
[2022-08-13 00:53:47,560] {processor.py:163} INFO - Started process (PID=3816) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:53:47,563] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:53:47,566] {logging_mixin.py:109} INFO - [2022-08-13 00:53:47,566] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:53:47,581] {logging_mixin.py:109} INFO - [2022-08-13 00:53:47,579] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:53:47,611] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:53:47,630] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.079 seconds
[2022-08-13 00:54:18,044] {processor.py:163} INFO - Started process (PID=3879) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:54:18,046] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:54:18,048] {logging_mixin.py:109} INFO - [2022-08-13 00:54:18,048] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:54:18,058] {logging_mixin.py:109} INFO - [2022-08-13 00:54:18,057] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:54:18,082] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:54:18,103] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.065 seconds
[2022-08-13 00:54:48,536] {processor.py:163} INFO - Started process (PID=3940) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:54:48,539] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:54:48,542] {logging_mixin.py:109} INFO - [2022-08-13 00:54:48,542] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:54:48,558] {logging_mixin.py:109} INFO - [2022-08-13 00:54:48,556] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:54:48,593] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:54:48,613] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.086 seconds
[2022-08-13 00:55:18,767] {processor.py:163} INFO - Started process (PID=4010) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:55:18,772] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:55:18,774] {logging_mixin.py:109} INFO - [2022-08-13 00:55:18,774] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:55:18,789] {logging_mixin.py:109} INFO - [2022-08-13 00:55:18,787] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:55:18,821] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:55:18,839] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.078 seconds
[2022-08-13 00:55:49,327] {processor.py:163} INFO - Started process (PID=4071) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:55:49,330] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:55:49,331] {logging_mixin.py:109} INFO - [2022-08-13 00:55:49,331] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:55:49,344] {logging_mixin.py:109} INFO - [2022-08-13 00:55:49,342] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:55:49,370] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:55:49,386] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.066 seconds
[2022-08-13 00:56:19,487] {processor.py:163} INFO - Started process (PID=4132) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:56:19,489] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:56:19,491] {logging_mixin.py:109} INFO - [2022-08-13 00:56:19,490] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:56:19,503] {logging_mixin.py:109} INFO - [2022-08-13 00:56:19,500] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:56:19,528] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:56:19,541] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.069 seconds
[2022-08-13 00:56:50,382] {processor.py:163} INFO - Started process (PID=4202) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:56:50,384] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:56:50,387] {logging_mixin.py:109} INFO - [2022-08-13 00:56:50,387] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:56:50,399] {logging_mixin.py:109} INFO - [2022-08-13 00:56:50,398] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:56:50,429] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:56:50,445] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.067 seconds
[2022-08-13 00:57:21,226] {processor.py:163} INFO - Started process (PID=4263) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:57:21,229] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:57:21,231] {logging_mixin.py:109} INFO - [2022-08-13 00:57:21,231] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:57:21,243] {logging_mixin.py:109} INFO - [2022-08-13 00:57:21,241] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:57:21,272] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:57:21,285] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.065 seconds
[2022-08-13 00:57:51,341] {processor.py:163} INFO - Started process (PID=4325) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:57:51,344] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:57:51,349] {logging_mixin.py:109} INFO - [2022-08-13 00:57:51,349] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:57:51,362] {logging_mixin.py:109} INFO - [2022-08-13 00:57:51,361] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:57:51,385] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:57:51,400] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.066 seconds
[2022-08-13 00:58:22,022] {processor.py:163} INFO - Started process (PID=4396) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:58:22,024] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:58:22,026] {logging_mixin.py:109} INFO - [2022-08-13 00:58:22,026] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:58:22,035] {logging_mixin.py:109} INFO - [2022-08-13 00:58:22,034] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:58:22,060] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:58:22,075] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.060 seconds
[2022-08-13 00:58:52,154] {processor.py:163} INFO - Started process (PID=4458) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:58:52,157] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:58:52,159] {logging_mixin.py:109} INFO - [2022-08-13 00:58:52,159] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:58:52,168] {logging_mixin.py:109} INFO - [2022-08-13 00:58:52,167] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:58:52,194] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:58:52,208] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.058 seconds
[2022-08-13 00:59:22,789] {processor.py:163} INFO - Started process (PID=4519) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:59:22,792] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:59:22,793] {logging_mixin.py:109} INFO - [2022-08-13 00:59:22,793] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:59:22,806] {logging_mixin.py:109} INFO - [2022-08-13 00:59:22,805] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:59:22,832] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:59:22,844] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.061 seconds
[2022-08-13 00:59:53,182] {processor.py:163} INFO - Started process (PID=4589) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:59:53,184] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 00:59:53,186] {logging_mixin.py:109} INFO - [2022-08-13 00:59:53,186] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:59:53,198] {logging_mixin.py:109} INFO - [2022-08-13 00:59:53,196] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 00:59:53,221] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 00:59:53,240] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.065 seconds
[2022-08-13 01:00:23,467] {processor.py:163} INFO - Started process (PID=4650) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:00:23,487] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:00:23,492] {logging_mixin.py:109} INFO - [2022-08-13 01:00:23,491] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:00:23,509] {logging_mixin.py:109} INFO - [2022-08-13 01:00:23,508] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:00:23,536] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:00:23,552] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.092 seconds
[2022-08-13 01:00:53,780] {processor.py:163} INFO - Started process (PID=4720) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:00:53,782] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:00:53,784] {logging_mixin.py:109} INFO - [2022-08-13 01:00:53,784] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:00:53,801] {logging_mixin.py:109} INFO - [2022-08-13 01:00:53,800] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:00:53,846] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:00:53,862] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.087 seconds
[2022-08-13 01:01:24,465] {processor.py:163} INFO - Started process (PID=4781) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:01:24,468] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:01:24,469] {logging_mixin.py:109} INFO - [2022-08-13 01:01:24,469] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:01:24,482] {logging_mixin.py:109} INFO - [2022-08-13 01:01:24,480] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:01:24,504] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:01:24,518] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.059 seconds
[2022-08-13 01:01:54,954] {processor.py:163} INFO - Started process (PID=4844) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:01:54,957] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:01:54,959] {logging_mixin.py:109} INFO - [2022-08-13 01:01:54,959] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:01:54,968] {logging_mixin.py:109} INFO - [2022-08-13 01:01:54,967] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:01:55,000] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:01:55,025] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.074 seconds
[2022-08-13 01:02:25,606] {processor.py:163} INFO - Started process (PID=4914) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:02:25,609] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:02:25,611] {logging_mixin.py:109} INFO - [2022-08-13 01:02:25,611] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:02:25,620] {logging_mixin.py:109} INFO - [2022-08-13 01:02:25,619] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:02:25,644] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:02:25,665] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.063 seconds
[2022-08-13 01:02:56,269] {processor.py:163} INFO - Started process (PID=4975) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:02:56,271] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:02:56,274] {logging_mixin.py:109} INFO - [2022-08-13 01:02:56,273] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:02:56,284] {logging_mixin.py:109} INFO - [2022-08-13 01:02:56,283] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:02:56,305] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:02:56,321] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.058 seconds
[2022-08-13 01:03:26,819] {processor.py:163} INFO - Started process (PID=5036) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:03:26,821] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:03:26,824] {logging_mixin.py:109} INFO - [2022-08-13 01:03:26,824] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:03:26,835] {logging_mixin.py:109} INFO - [2022-08-13 01:03:26,833] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:03:26,863] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:03:26,884] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.069 seconds
[2022-08-13 01:03:57,410] {processor.py:163} INFO - Started process (PID=5107) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:03:57,413] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:03:57,416] {logging_mixin.py:109} INFO - [2022-08-13 01:03:57,416] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:03:57,429] {logging_mixin.py:109} INFO - [2022-08-13 01:03:57,428] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:03:57,456] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:03:57,471] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.065 seconds
[2022-08-13 01:04:27,556] {processor.py:163} INFO - Started process (PID=5168) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:04:27,559] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:04:27,561] {logging_mixin.py:109} INFO - [2022-08-13 01:04:27,561] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:04:27,570] {logging_mixin.py:109} INFO - [2022-08-13 01:04:27,569] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:04:27,594] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:04:27,610] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.057 seconds
[2022-08-13 01:04:58,283] {processor.py:163} INFO - Started process (PID=5230) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:04:58,285] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:04:58,287] {logging_mixin.py:109} INFO - [2022-08-13 01:04:58,286] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:04:58,298] {logging_mixin.py:109} INFO - [2022-08-13 01:04:58,297] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:04:58,321] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:04:58,334] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.058 seconds
[2022-08-13 01:05:28,770] {processor.py:163} INFO - Started process (PID=5300) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:05:28,772] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:05:28,774] {logging_mixin.py:109} INFO - [2022-08-13 01:05:28,774] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:05:28,784] {logging_mixin.py:109} INFO - [2022-08-13 01:05:28,783] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:05:28,813] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:05:28,826] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.061 seconds
[2022-08-13 01:05:59,633] {processor.py:163} INFO - Started process (PID=5361) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:05:59,638] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:05:59,640] {logging_mixin.py:109} INFO - [2022-08-13 01:05:59,640] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:05:59,655] {logging_mixin.py:109} INFO - [2022-08-13 01:05:59,653] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:05:59,684] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:05:59,700] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.077 seconds
[2022-08-13 01:06:29,961] {processor.py:163} INFO - Started process (PID=5422) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:06:29,972] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:06:29,974] {logging_mixin.py:109} INFO - [2022-08-13 01:06:29,974] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:06:29,990] {logging_mixin.py:109} INFO - [2022-08-13 01:06:29,989] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:06:30,044] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:06:30,061] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.104 seconds
[2022-08-13 01:07:00,363] {processor.py:163} INFO - Started process (PID=5493) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:07:00,366] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:07:00,368] {logging_mixin.py:109} INFO - [2022-08-13 01:07:00,368] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:07:00,377] {logging_mixin.py:109} INFO - [2022-08-13 01:07:00,376] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:07:00,401] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:07:00,414] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.056 seconds
[2022-08-13 01:07:30,463] {processor.py:163} INFO - Started process (PID=5553) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:07:30,467] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:07:30,470] {logging_mixin.py:109} INFO - [2022-08-13 01:07:30,470] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:07:30,485] {logging_mixin.py:109} INFO - [2022-08-13 01:07:30,483] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:07:30,523] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:07:30,537] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.083 seconds
[2022-08-13 01:08:00,930] {processor.py:163} INFO - Started process (PID=5624) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:08:00,934] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:08:00,936] {logging_mixin.py:109} INFO - [2022-08-13 01:08:00,935] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:08:00,946] {logging_mixin.py:109} INFO - [2022-08-13 01:08:00,945] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:08:00,971] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:08:00,984] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.057 seconds
[2022-08-13 01:08:31,610] {processor.py:163} INFO - Started process (PID=5685) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:08:31,613] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:08:31,614] {logging_mixin.py:109} INFO - [2022-08-13 01:08:31,614] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:08:31,626] {logging_mixin.py:109} INFO - [2022-08-13 01:08:31,624] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:08:31,653] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:08:31,673] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.068 seconds
[2022-08-13 01:09:02,370] {processor.py:163} INFO - Started process (PID=5746) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:09:02,373] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:09:02,376] {logging_mixin.py:109} INFO - [2022-08-13 01:09:02,375] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:09:02,389] {logging_mixin.py:109} INFO - [2022-08-13 01:09:02,388] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:09:02,418] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:09:02,438] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.076 seconds
[2022-08-13 01:09:32,513] {processor.py:163} INFO - Started process (PID=5818) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:09:32,515] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:09:32,518] {logging_mixin.py:109} INFO - [2022-08-13 01:09:32,518] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:09:32,528] {logging_mixin.py:109} INFO - [2022-08-13 01:09:32,527] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:09:32,550] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:09:32,563] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.054 seconds
[2022-08-13 01:10:02,614] {processor.py:163} INFO - Started process (PID=5873) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:10:02,618] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:10:02,621] {logging_mixin.py:109} INFO - [2022-08-13 01:10:02,620] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:10:02,635] {logging_mixin.py:109} INFO - [2022-08-13 01:10:02,632] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:10:02,669] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:10:02,687] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.082 seconds
[2022-08-13 01:10:33,363] {processor.py:163} INFO - Started process (PID=5934) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:10:33,366] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:10:33,369] {logging_mixin.py:109} INFO - [2022-08-13 01:10:33,369] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:10:33,379] {logging_mixin.py:109} INFO - [2022-08-13 01:10:33,377] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:10:33,401] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:10:33,415] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.057 seconds
[2022-08-13 01:11:03,702] {processor.py:163} INFO - Started process (PID=6004) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:11:03,706] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:11:03,708] {logging_mixin.py:109} INFO - [2022-08-13 01:11:03,707] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:11:03,723] {logging_mixin.py:109} INFO - [2022-08-13 01:11:03,721] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:11:03,750] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:11:03,763] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.065 seconds
[2022-08-13 01:11:34,052] {processor.py:163} INFO - Started process (PID=6065) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:11:34,055] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:11:34,057] {logging_mixin.py:109} INFO - [2022-08-13 01:11:34,056] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:11:34,067] {logging_mixin.py:109} INFO - [2022-08-13 01:11:34,066] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:11:34,089] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:11:34,101] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.054 seconds
[2022-08-13 01:12:04,701] {processor.py:163} INFO - Started process (PID=6123) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:12:04,705] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:12:04,707] {logging_mixin.py:109} INFO - [2022-08-13 01:12:04,706] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:12:04,720] {logging_mixin.py:109} INFO - [2022-08-13 01:12:04,718] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:12:04,767] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:12:04,789] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.097 seconds
[2022-08-13 01:12:35,116] {processor.py:163} INFO - Started process (PID=6193) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:12:35,118] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:12:35,120] {logging_mixin.py:109} INFO - [2022-08-13 01:12:35,120] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:12:35,131] {logging_mixin.py:109} INFO - [2022-08-13 01:12:35,128] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:12:35,156] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:12:35,168] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.059 seconds
[2022-08-13 01:13:05,512] {processor.py:163} INFO - Started process (PID=6254) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:13:05,515] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:13:05,517] {logging_mixin.py:109} INFO - [2022-08-13 01:13:05,517] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:13:05,525] {logging_mixin.py:109} INFO - [2022-08-13 01:13:05,524] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:13:05,558] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:13:05,575] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.067 seconds
[2022-08-13 01:13:36,282] {processor.py:163} INFO - Started process (PID=6325) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:13:36,284] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:13:36,286] {logging_mixin.py:109} INFO - [2022-08-13 01:13:36,285] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:13:36,295] {logging_mixin.py:109} INFO - [2022-08-13 01:13:36,294] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:13:36,318] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:13:36,332] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.054 seconds
[2022-08-13 01:14:06,750] {processor.py:163} INFO - Started process (PID=6386) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:14:06,752] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:14:06,754] {logging_mixin.py:109} INFO - [2022-08-13 01:14:06,754] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:14:06,763] {logging_mixin.py:109} INFO - [2022-08-13 01:14:06,762] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:14:06,787] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:14:06,804] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.058 seconds
[2022-08-13 01:14:37,063] {processor.py:163} INFO - Started process (PID=6447) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:14:37,067] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:14:37,068] {logging_mixin.py:109} INFO - [2022-08-13 01:14:37,068] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:14:37,079] {logging_mixin.py:109} INFO - [2022-08-13 01:14:37,078] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:14:37,107] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:14:37,118] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.059 seconds
[2022-08-13 01:15:07,416] {processor.py:163} INFO - Started process (PID=6519) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:15:07,419] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:15:07,421] {logging_mixin.py:109} INFO - [2022-08-13 01:15:07,421] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:15:07,431] {logging_mixin.py:109} INFO - [2022-08-13 01:15:07,430] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:15:07,454] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:15:07,466] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.055 seconds
[2022-08-13 01:15:37,693] {processor.py:163} INFO - Started process (PID=6581) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:15:37,695] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:15:37,697] {logging_mixin.py:109} INFO - [2022-08-13 01:15:37,697] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:15:37,709] {logging_mixin.py:109} INFO - [2022-08-13 01:15:37,707] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:15:37,730] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:15:37,745] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.060 seconds
[2022-08-13 01:16:08,294] {processor.py:163} INFO - Started process (PID=6642) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:16:08,297] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:16:08,301] {logging_mixin.py:109} INFO - [2022-08-13 01:16:08,301] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:16:08,318] {logging_mixin.py:109} INFO - [2022-08-13 01:16:08,314] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:16:08,347] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:16:08,368] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.083 seconds
[2022-08-13 01:16:38,857] {processor.py:163} INFO - Started process (PID=6713) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:16:38,860] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:16:38,862] {logging_mixin.py:109} INFO - [2022-08-13 01:16:38,862] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:16:38,873] {logging_mixin.py:109} INFO - [2022-08-13 01:16:38,872] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:16:38,895] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:16:38,908] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.056 seconds
[2022-08-13 01:17:09,097] {processor.py:163} INFO - Started process (PID=6774) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:17:09,099] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:17:09,102] {logging_mixin.py:109} INFO - [2022-08-13 01:17:09,101] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:17:09,112] {logging_mixin.py:109} INFO - [2022-08-13 01:17:09,111] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:17:09,134] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:17:09,147] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.054 seconds
[2022-08-13 01:17:39,466] {processor.py:163} INFO - Started process (PID=6834) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:17:39,470] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:17:39,471] {logging_mixin.py:109} INFO - [2022-08-13 01:17:39,471] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:17:39,481] {logging_mixin.py:109} INFO - [2022-08-13 01:17:39,480] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:17:39,509] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:17:39,524] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.062 seconds
[2022-08-13 01:18:09,965] {processor.py:163} INFO - Started process (PID=6905) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:18:09,972] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:18:09,974] {logging_mixin.py:109} INFO - [2022-08-13 01:18:09,973] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:18:09,989] {logging_mixin.py:109} INFO - [2022-08-13 01:18:09,988] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:18:10,018] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:18:10,035] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.077 seconds
[2022-08-13 01:18:40,583] {processor.py:163} INFO - Started process (PID=6966) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:18:40,585] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:18:40,587] {logging_mixin.py:109} INFO - [2022-08-13 01:18:40,587] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:18:40,597] {logging_mixin.py:109} INFO - [2022-08-13 01:18:40,596] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:18:40,628] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:18:40,644] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.065 seconds
[2022-08-13 01:19:11,316] {processor.py:163} INFO - Started process (PID=7038) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:19:11,319] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:19:11,322] {logging_mixin.py:109} INFO - [2022-08-13 01:19:11,322] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:19:11,334] {logging_mixin.py:109} INFO - [2022-08-13 01:19:11,333] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:19:11,364] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:19:11,379] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.070 seconds
[2022-08-13 01:19:41,780] {processor.py:163} INFO - Started process (PID=7100) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:19:41,783] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:19:41,784] {logging_mixin.py:109} INFO - [2022-08-13 01:19:41,784] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:19:41,797] {logging_mixin.py:109} INFO - [2022-08-13 01:19:41,795] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:19:41,825] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:19:41,840] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.065 seconds
[2022-08-13 01:20:11,989] {processor.py:163} INFO - Started process (PID=7161) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:20:11,991] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:20:11,993] {logging_mixin.py:109} INFO - [2022-08-13 01:20:11,993] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:20:12,004] {logging_mixin.py:109} INFO - [2022-08-13 01:20:12,002] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:20:12,026] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:20:12,039] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.054 seconds
[2022-08-13 01:20:42,454] {processor.py:163} INFO - Started process (PID=7231) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:20:42,456] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:20:42,458] {logging_mixin.py:109} INFO - [2022-08-13 01:20:42,458] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:20:42,473] {logging_mixin.py:109} INFO - [2022-08-13 01:20:42,471] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:20:42,500] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:20:42,516] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.069 seconds
[2022-08-13 01:21:12,934] {processor.py:163} INFO - Started process (PID=7293) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:21:12,937] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:21:12,938] {logging_mixin.py:109} INFO - [2022-08-13 01:21:12,938] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:21:12,949] {logging_mixin.py:109} INFO - [2022-08-13 01:21:12,947] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:21:12,975] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:21:12,987] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.058 seconds
[2022-08-13 01:21:43,662] {processor.py:163} INFO - Started process (PID=7354) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:21:43,665] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:21:43,667] {logging_mixin.py:109} INFO - [2022-08-13 01:21:43,667] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:21:43,682] {logging_mixin.py:109} INFO - [2022-08-13 01:21:43,679] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:21:43,709] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:21:43,731] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.076 seconds
[2022-08-13 01:22:13,867] {processor.py:163} INFO - Started process (PID=7425) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:22:13,871] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:22:13,872] {logging_mixin.py:109} INFO - [2022-08-13 01:22:13,872] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:22:13,882] {logging_mixin.py:109} INFO - [2022-08-13 01:22:13,881] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:22:13,908] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:22:13,921] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.058 seconds
[2022-08-13 01:22:44,108] {processor.py:163} INFO - Started process (PID=7486) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:22:44,111] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:22:44,114] {logging_mixin.py:109} INFO - [2022-08-13 01:22:44,113] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:22:44,128] {logging_mixin.py:109} INFO - [2022-08-13 01:22:44,125] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:22:44,155] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:22:44,170] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.069 seconds
[2022-08-13 01:23:14,714] {processor.py:163} INFO - Started process (PID=7548) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:23:14,718] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:23:14,721] {logging_mixin.py:109} INFO - [2022-08-13 01:23:14,720] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:23:14,732] {logging_mixin.py:109} INFO - [2022-08-13 01:23:14,731] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:23:14,758] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:23:14,771] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.063 seconds
[2022-08-13 01:23:45,334] {processor.py:163} INFO - Started process (PID=7618) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:23:45,336] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:23:45,338] {logging_mixin.py:109} INFO - [2022-08-13 01:23:45,338] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:23:45,348] {logging_mixin.py:109} INFO - [2022-08-13 01:23:45,346] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:23:45,370] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:23:45,383] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.053 seconds
[2022-08-13 01:24:16,186] {processor.py:163} INFO - Started process (PID=7679) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:24:16,189] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:24:16,191] {logging_mixin.py:109} INFO - [2022-08-13 01:24:16,190] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:24:16,202] {logging_mixin.py:109} INFO - [2022-08-13 01:24:16,201] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:24:16,234] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:24:16,259] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.078 seconds
[2022-08-13 01:24:47,175] {processor.py:163} INFO - Started process (PID=7749) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:24:47,177] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:24:47,179] {logging_mixin.py:109} INFO - [2022-08-13 01:24:47,178] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:24:47,189] {logging_mixin.py:109} INFO - [2022-08-13 01:24:47,187] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:24:47,213] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:24:47,227] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.057 seconds
[2022-08-13 01:25:18,084] {processor.py:163} INFO - Started process (PID=7810) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:25:18,086] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:25:18,087] {logging_mixin.py:109} INFO - [2022-08-13 01:25:18,087] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:25:18,101] {logging_mixin.py:109} INFO - [2022-08-13 01:25:18,099] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:25:18,125] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:25:18,139] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.060 seconds
[2022-08-13 01:25:48,224] {processor.py:163} INFO - Started process (PID=7872) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:25:48,227] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:25:48,228] {logging_mixin.py:109} INFO - [2022-08-13 01:25:48,228] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:25:48,241] {logging_mixin.py:109} INFO - [2022-08-13 01:25:48,238] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:25:48,287] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:25:48,304] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.085 seconds
[2022-08-13 01:26:18,677] {processor.py:163} INFO - Started process (PID=7941) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:26:18,681] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:26:18,683] {logging_mixin.py:109} INFO - [2022-08-13 01:26:18,683] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:26:18,694] {logging_mixin.py:109} INFO - [2022-08-13 01:26:18,693] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:26:18,722] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:26:18,735] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.063 seconds
[2022-08-13 01:26:49,481] {processor.py:163} INFO - Started process (PID=7998) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:26:49,485] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:26:49,487] {logging_mixin.py:109} INFO - [2022-08-13 01:26:49,486] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:26:49,498] {logging_mixin.py:109} INFO - [2022-08-13 01:26:49,496] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:26:49,524] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:26:49,541] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.066 seconds
[2022-08-13 01:27:19,860] {processor.py:163} INFO - Started process (PID=8059) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:27:19,864] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:27:19,865] {logging_mixin.py:109} INFO - [2022-08-13 01:27:19,865] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:27:19,874] {logging_mixin.py:109} INFO - [2022-08-13 01:27:19,873] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:27:19,901] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:27:19,915] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.059 seconds
[2022-08-13 01:27:50,256] {processor.py:163} INFO - Started process (PID=8128) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:27:50,261] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:27:50,265] {logging_mixin.py:109} INFO - [2022-08-13 01:27:50,265] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:27:50,289] {logging_mixin.py:109} INFO - [2022-08-13 01:27:50,287] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:27:50,315] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:27:50,330] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.080 seconds
[2022-08-13 01:28:21,209] {processor.py:163} INFO - Started process (PID=8189) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:28:21,213] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:28:21,215] {logging_mixin.py:109} INFO - [2022-08-13 01:28:21,215] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:28:21,224] {logging_mixin.py:109} INFO - [2022-08-13 01:28:21,223] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:28:21,246] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:28:21,258] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.054 seconds
[2022-08-13 01:28:51,411] {processor.py:163} INFO - Started process (PID=8250) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:28:51,414] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:28:51,416] {logging_mixin.py:109} INFO - [2022-08-13 01:28:51,416] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:28:51,425] {logging_mixin.py:109} INFO - [2022-08-13 01:28:51,424] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:28:51,447] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:28:51,460] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.053 seconds
[2022-08-13 01:29:21,516] {processor.py:163} INFO - Started process (PID=8319) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:29:21,520] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:29:21,522] {logging_mixin.py:109} INFO - [2022-08-13 01:29:21,522] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:29:21,535] {logging_mixin.py:109} INFO - [2022-08-13 01:29:21,534] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:29:21,563] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:29:21,583] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.075 seconds
[2022-08-13 01:29:51,892] {processor.py:163} INFO - Started process (PID=8379) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:29:51,895] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:29:51,897] {logging_mixin.py:109} INFO - [2022-08-13 01:29:51,897] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:29:51,909] {logging_mixin.py:109} INFO - [2022-08-13 01:29:51,908] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:29:51,938] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:29:51,957] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.069 seconds
[2022-08-13 01:30:22,240] {processor.py:163} INFO - Started process (PID=8441) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:30:22,242] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:30:22,243] {logging_mixin.py:109} INFO - [2022-08-13 01:30:22,243] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:30:22,259] {logging_mixin.py:109} INFO - [2022-08-13 01:30:22,258] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:30:22,286] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:30:22,298] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.067 seconds
[2022-08-13 01:30:52,463] {processor.py:163} INFO - Started process (PID=8513) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:30:52,465] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:30:52,468] {logging_mixin.py:109} INFO - [2022-08-13 01:30:52,468] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:30:52,478] {logging_mixin.py:109} INFO - [2022-08-13 01:30:52,477] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:30:52,502] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:30:52,518] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.059 seconds
[2022-08-13 01:31:23,152] {processor.py:163} INFO - Started process (PID=8575) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:31:23,155] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:31:23,157] {logging_mixin.py:109} INFO - [2022-08-13 01:31:23,157] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:31:23,166] {logging_mixin.py:109} INFO - [2022-08-13 01:31:23,164] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:31:23,191] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:31:23,203] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.056 seconds
[2022-08-13 01:31:53,237] {processor.py:163} INFO - Started process (PID=8632) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:31:53,239] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:31:53,241] {logging_mixin.py:109} INFO - [2022-08-13 01:31:53,241] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:31:53,253] {logging_mixin.py:109} INFO - [2022-08-13 01:31:53,251] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:31:53,284] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:31:53,303] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.072 seconds
[2022-08-13 01:32:23,788] {processor.py:163} INFO - Started process (PID=8701) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:32:23,791] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:32:23,793] {logging_mixin.py:109} INFO - [2022-08-13 01:32:23,793] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:32:23,804] {logging_mixin.py:109} INFO - [2022-08-13 01:32:23,803] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:32:23,830] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:32:23,845] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.063 seconds
[2022-08-13 01:32:54,330] {processor.py:163} INFO - Started process (PID=8762) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:32:54,332] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:32:54,335] {logging_mixin.py:109} INFO - [2022-08-13 01:32:54,335] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:32:54,345] {logging_mixin.py:109} INFO - [2022-08-13 01:32:54,344] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:32:54,366] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:32:54,380] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.055 seconds
[2022-08-13 01:33:24,565] {processor.py:163} INFO - Started process (PID=8823) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:33:24,568] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:33:24,571] {logging_mixin.py:109} INFO - [2022-08-13 01:33:24,570] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:33:24,581] {logging_mixin.py:109} INFO - [2022-08-13 01:33:24,580] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:33:24,601] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:33:24,615] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.055 seconds
[2022-08-13 01:33:55,074] {processor.py:163} INFO - Started process (PID=8893) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:33:55,077] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:33:55,078] {logging_mixin.py:109} INFO - [2022-08-13 01:33:55,078] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:33:55,087] {logging_mixin.py:109} INFO - [2022-08-13 01:33:55,086] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:33:55,113] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:33:55,127] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.057 seconds
[2022-08-13 01:34:25,605] {processor.py:163} INFO - Started process (PID=8955) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:34:25,607] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 01:34:25,608] {logging_mixin.py:109} INFO - [2022-08-13 01:34:25,608] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:34:25,616] {logging_mixin.py:109} INFO - [2022-08-13 01:34:25,615] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 01:34:25,635] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 01:34:25,646] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.044 seconds
[2022-08-13 02:04:28,985] {processor.py:163} INFO - Started process (PID=8991) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 02:04:28,989] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 02:04:28,999] {logging_mixin.py:109} INFO - [2022-08-13 02:04:28,998] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 02:04:29,015] {logging_mixin.py:109} INFO - [2022-08-13 02:04:29,013] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 02:04:29,055] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 02:04:29,079] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.101 seconds
[2022-08-13 02:05:02,922] {processor.py:163} INFO - Started process (PID=9043) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 02:05:03,246] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 02:05:03,365] {logging_mixin.py:109} INFO - [2022-08-13 02:05:03,359] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 02:05:03,910] {logging_mixin.py:109} INFO - [2022-08-13 02:05:03,833] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 02:05:05,617] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 02:05:07,426] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 5.683 seconds
[2022-08-13 02:07:43,114] {processor.py:163} INFO - Started process (PID=9134) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 02:07:43,175] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 02:07:43,221] {logging_mixin.py:109} INFO - [2022-08-13 02:07:43,221] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 02:07:43,464] {logging_mixin.py:109} INFO - [2022-08-13 02:07:43,382] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 02:07:44,265] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 02:07:44,697] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.819 seconds
[2022-08-13 02:11:00,651] {processor.py:163} INFO - Started process (PID=9226) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 02:11:02,514] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 02:11:03,306] {logging_mixin.py:109} INFO - [2022-08-13 02:11:03,086] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 02:11:06,696] {logging_mixin.py:109} INFO - [2022-08-13 02:11:05,132] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 02:11:31,364] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 02:45:56,448] {processor.py:163} INFO - Started process (PID=9373) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 02:45:56,740] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 02:45:56,854] {logging_mixin.py:109} INFO - [2022-08-13 02:45:56,853] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 02:45:57,587] {logging_mixin.py:109} INFO - [2022-08-13 02:45:57,476] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 02:47:46,479] {processor.py:163} INFO - Started process (PID=9417) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 02:47:50,249] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 02:47:52,110] {logging_mixin.py:109} INFO - [2022-08-13 02:47:52,099] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 02:48:00,760] {logging_mixin.py:109} INFO - [2022-08-13 02:47:57,179] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 02:48:15,849] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 02:48:17,238] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 31.547 seconds
[2022-08-13 06:27:38,881] {processor.py:163} INFO - Started process (PID=10083) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:27:38,904] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:27:38,911] {logging_mixin.py:109} INFO - [2022-08-13 06:27:38,910] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:27:38,953] {logging_mixin.py:109} INFO - [2022-08-13 06:27:38,942] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 06:27:39,065] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:27:39,151] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.290 seconds
[2022-08-13 06:29:02,012] {processor.py:163} INFO - Started process (PID=10127) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:29:02,436] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:29:02,496] {logging_mixin.py:109} INFO - [2022-08-13 06:29:02,496] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:29:03,240] {logging_mixin.py:109} INFO - [2022-08-13 06:29:02,859] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 06:29:06,499] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:29:07,722] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 6.386 seconds
[2022-08-13 06:31:14,646] {processor.py:163} INFO - Started process (PID=10232) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:31:14,654] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:31:14,673] {logging_mixin.py:109} INFO - [2022-08-13 06:31:14,673] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:31:14,712] {logging_mixin.py:109} INFO - [2022-08-13 06:31:14,702] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 06:31:14,859] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:31:14,913] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.286 seconds
[2022-08-13 06:31:45,868] {processor.py:163} INFO - Started process (PID=10303) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:31:45,875] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:31:45,877] {logging_mixin.py:109} INFO - [2022-08-13 06:31:45,877] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:31:45,891] {logging_mixin.py:109} INFO - [2022-08-13 06:31:45,890] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 06:31:45,916] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:31:45,934] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.073 seconds
[2022-08-13 06:32:16,035] {processor.py:163} INFO - Started process (PID=10364) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:32:16,038] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:32:16,039] {logging_mixin.py:109} INFO - [2022-08-13 06:32:16,039] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:32:16,055] {logging_mixin.py:109} INFO - [2022-08-13 06:32:16,051] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 06:32:16,076] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:32:16,090] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.060 seconds
[2022-08-13 06:32:46,273] {processor.py:163} INFO - Started process (PID=10426) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:32:46,276] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:32:46,278] {logging_mixin.py:109} INFO - [2022-08-13 06:32:46,278] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:32:46,289] {logging_mixin.py:109} INFO - [2022-08-13 06:32:46,288] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 26
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 06:32:46,309] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:32:46,325] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.063 seconds
[2022-08-13 06:32:57,794] {processor.py:163} INFO - Started process (PID=10462) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:32:57,797] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:32:57,798] {logging_mixin.py:109} INFO - [2022-08-13 06:32:57,798] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:32:57,809] {logging_mixin.py:109} INFO - [2022-08-13 06:32:57,808] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 27
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 06:32:57,828] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:32:57,841] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.052 seconds
[2022-08-13 06:32:59,906] {processor.py:163} INFO - Started process (PID=10464) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:32:59,908] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:32:59,910] {logging_mixin.py:109} INFO - [2022-08-13 06:32:59,910] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:32:59,921] {logging_mixin.py:109} INFO - [2022-08-13 06:32:59,920] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 28
    schedule_interval = None,
    ^
SyntaxError: keyword argument repeated
[2022-08-13 06:32:59,945] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:32:59,957] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.055 seconds
[2022-08-13 06:33:21,134] {processor.py:163} INFO - Started process (PID=10502) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:33:21,138] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:33:21,139] {logging_mixin.py:109} INFO - [2022-08-13 06:33:21,139] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:33:21,812] {logging_mixin.py:109} INFO - [2022-08-13 06:33:21,809] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:33:21,832] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:33:21,846] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.717 seconds
[2022-08-13 06:33:32,088] {processor.py:163} INFO - Started process (PID=10539) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:33:32,090] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:33:32,093] {logging_mixin.py:109} INFO - [2022-08-13 06:33:32,093] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:33:32,738] {logging_mixin.py:109} INFO - [2022-08-13 06:33:32,734] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:33:32,758] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:33:32,771] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.688 seconds
[2022-08-13 06:34:02,849] {processor.py:163} INFO - Started process (PID=10605) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:34:02,851] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:34:02,852] {logging_mixin.py:109} INFO - [2022-08-13 06:34:02,852] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:34:03,366] {logging_mixin.py:109} INFO - [2022-08-13 06:34:03,364] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:34:03,387] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:34:03,404] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.561 seconds
[2022-08-13 06:34:34,458] {processor.py:163} INFO - Started process (PID=10681) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:34:34,461] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:34:34,463] {logging_mixin.py:109} INFO - [2022-08-13 06:34:34,462] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:34:35,074] {logging_mixin.py:109} INFO - [2022-08-13 06:34:35,070] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:34:35,093] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:34:35,103] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.650 seconds
[2022-08-13 06:35:05,678] {processor.py:163} INFO - Started process (PID=10747) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:35:05,681] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:35:05,682] {logging_mixin.py:109} INFO - [2022-08-13 06:35:05,682] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:35:06,282] {logging_mixin.py:109} INFO - [2022-08-13 06:35:06,279] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:35:06,301] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:35:06,314] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.640 seconds
[2022-08-13 06:35:36,934] {processor.py:163} INFO - Started process (PID=10822) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:35:36,937] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:35:36,939] {logging_mixin.py:109} INFO - [2022-08-13 06:35:36,939] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:35:37,541] {logging_mixin.py:109} INFO - [2022-08-13 06:35:37,538] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:35:37,560] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:35:37,570] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.641 seconds
[2022-08-13 06:36:08,320] {processor.py:163} INFO - Started process (PID=10889) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:36:08,323] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:36:08,325] {logging_mixin.py:109} INFO - [2022-08-13 06:36:08,325] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:36:08,931] {logging_mixin.py:109} INFO - [2022-08-13 06:36:08,928] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:36:08,950] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:36:08,974] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.657 seconds
[2022-08-13 06:36:39,469] {processor.py:163} INFO - Started process (PID=10961) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:36:39,472] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:36:39,474] {logging_mixin.py:109} INFO - [2022-08-13 06:36:39,474] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:36:40,030] {logging_mixin.py:109} INFO - [2022-08-13 06:36:40,025] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:36:40,048] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:36:40,057] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.596 seconds
[2022-08-13 06:37:10,687] {processor.py:163} INFO - Started process (PID=11029) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:37:10,689] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:37:10,691] {logging_mixin.py:109} INFO - [2022-08-13 06:37:10,691] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:37:11,268] {logging_mixin.py:109} INFO - [2022-08-13 06:37:11,265] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:37:11,295] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:37:11,307] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.624 seconds
[2022-08-13 06:37:41,380] {processor.py:163} INFO - Started process (PID=11094) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:37:41,383] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:37:41,385] {logging_mixin.py:109} INFO - [2022-08-13 06:37:41,385] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:37:41,984] {logging_mixin.py:109} INFO - [2022-08-13 06:37:41,981] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:37:42,005] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:37:42,017] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.644 seconds
[2022-08-13 06:38:12,605] {processor.py:163} INFO - Started process (PID=11169) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:38:12,608] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:38:12,610] {logging_mixin.py:109} INFO - [2022-08-13 06:38:12,610] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:38:13,220] {logging_mixin.py:109} INFO - [2022-08-13 06:38:13,217] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:38:13,240] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:38:13,253] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.654 seconds
[2022-08-13 06:38:43,811] {processor.py:163} INFO - Started process (PID=11235) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:38:43,814] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:38:43,816] {logging_mixin.py:109} INFO - [2022-08-13 06:38:43,816] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:38:44,355] {logging_mixin.py:109} INFO - [2022-08-13 06:38:44,353] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:38:44,374] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:38:44,387] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.581 seconds
[2022-08-13 06:39:14,607] {processor.py:163} INFO - Started process (PID=11309) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:39:14,610] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:39:14,611] {logging_mixin.py:109} INFO - [2022-08-13 06:39:14,611] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:39:15,149] {logging_mixin.py:109} INFO - [2022-08-13 06:39:15,146] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:39:15,168] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:39:15,180] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.576 seconds
[2022-08-13 06:39:45,611] {processor.py:163} INFO - Started process (PID=11374) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:39:45,615] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:39:45,617] {logging_mixin.py:109} INFO - [2022-08-13 06:39:45,617] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:39:46,180] {logging_mixin.py:109} INFO - [2022-08-13 06:39:46,175] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:39:46,209] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:39:46,217] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.615 seconds
[2022-08-13 06:40:16,342] {processor.py:163} INFO - Started process (PID=11448) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:40:16,345] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:40:16,346] {logging_mixin.py:109} INFO - [2022-08-13 06:40:16,346] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:40:16,883] {logging_mixin.py:109} INFO - [2022-08-13 06:40:16,880] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:40:16,899] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:40:16,909] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.572 seconds
[2022-08-13 06:40:47,096] {processor.py:163} INFO - Started process (PID=11513) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:40:47,100] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:40:47,102] {logging_mixin.py:109} INFO - [2022-08-13 06:40:47,102] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:40:47,602] {logging_mixin.py:109} INFO - [2022-08-13 06:40:47,600] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:40:47,619] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:40:47,628] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.537 seconds
[2022-08-13 06:41:18,025] {processor.py:163} INFO - Started process (PID=11578) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:41:18,027] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:41:18,029] {logging_mixin.py:109} INFO - [2022-08-13 06:41:18,029] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:41:18,595] {logging_mixin.py:109} INFO - [2022-08-13 06:41:18,592] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:41:18,613] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:41:18,625] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.605 seconds
[2022-08-13 06:41:48,829] {processor.py:163} INFO - Started process (PID=11652) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:41:48,831] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:41:48,833] {logging_mixin.py:109} INFO - [2022-08-13 06:41:48,833] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:41:49,386] {logging_mixin.py:109} INFO - [2022-08-13 06:41:49,383] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:41:49,404] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:41:49,415] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.590 seconds
[2022-08-13 06:42:19,502] {processor.py:163} INFO - Started process (PID=11717) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:42:19,506] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:42:19,508] {logging_mixin.py:109} INFO - [2022-08-13 06:42:19,508] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:42:20,140] {logging_mixin.py:109} INFO - [2022-08-13 06:42:20,136] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:42:20,166] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:42:20,184] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.689 seconds
[2022-08-13 06:42:50,407] {processor.py:163} INFO - Started process (PID=11792) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:42:50,410] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:42:50,411] {logging_mixin.py:109} INFO - [2022-08-13 06:42:50,411] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:42:51,053] {logging_mixin.py:109} INFO - [2022-08-13 06:42:51,047] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:42:51,071] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:42:51,090] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.687 seconds
[2022-08-13 06:43:21,460] {processor.py:163} INFO - Started process (PID=11857) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:43:21,464] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:43:21,465] {logging_mixin.py:109} INFO - [2022-08-13 06:43:21,465] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:43:22,051] {logging_mixin.py:109} INFO - [2022-08-13 06:43:22,048] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:43:22,068] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:43:22,077] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.620 seconds
[2022-08-13 06:43:52,336] {processor.py:163} INFO - Started process (PID=11924) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:43:52,339] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:43:52,340] {logging_mixin.py:109} INFO - [2022-08-13 06:43:52,340] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:43:52,955] {logging_mixin.py:109} INFO - [2022-08-13 06:43:52,952] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:43:52,971] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:43:52,981] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.652 seconds
[2022-08-13 06:44:23,829] {processor.py:163} INFO - Started process (PID=11999) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:44:23,832] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:44:23,834] {logging_mixin.py:109} INFO - [2022-08-13 06:44:23,834] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:44:24,492] {logging_mixin.py:109} INFO - [2022-08-13 06:44:24,490] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:44:24,514] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:44:24,534] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.709 seconds
[2022-08-13 06:44:54,983] {processor.py:163} INFO - Started process (PID=12064) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:44:54,986] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:44:54,988] {logging_mixin.py:109} INFO - [2022-08-13 06:44:54,988] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:44:55,508] {logging_mixin.py:109} INFO - [2022-08-13 06:44:55,505] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:44:55,524] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:44:55,534] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.555 seconds
[2022-08-13 06:45:25,871] {processor.py:163} INFO - Started process (PID=12133) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:45:25,874] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:45:25,876] {logging_mixin.py:109} INFO - [2022-08-13 06:45:25,875] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:45:26,470] {logging_mixin.py:109} INFO - [2022-08-13 06:45:26,467] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:45:26,488] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:45:26,501] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.635 seconds
[2022-08-13 06:45:57,197] {processor.py:163} INFO - Started process (PID=12198) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:45:57,201] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:45:57,203] {logging_mixin.py:109} INFO - [2022-08-13 06:45:57,203] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:45:57,842] {logging_mixin.py:109} INFO - [2022-08-13 06:45:57,839] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:45:57,862] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:45:57,876] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.683 seconds
[2022-08-13 06:46:28,684] {processor.py:163} INFO - Started process (PID=12272) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:46:28,686] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:46:28,687] {logging_mixin.py:109} INFO - [2022-08-13 06:46:28,687] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:46:29,343] {logging_mixin.py:109} INFO - [2022-08-13 06:46:29,341] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:46:29,361] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:46:29,373] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.694 seconds
[2022-08-13 06:46:59,871] {processor.py:163} INFO - Started process (PID=12336) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:46:59,874] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:46:59,875] {logging_mixin.py:109} INFO - [2022-08-13 06:46:59,875] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:47:00,485] {logging_mixin.py:109} INFO - [2022-08-13 06:47:00,482] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:47:00,505] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:47:00,516] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.652 seconds
[2022-08-13 06:47:31,228] {processor.py:163} INFO - Started process (PID=12409) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:47:31,230] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:47:31,233] {logging_mixin.py:109} INFO - [2022-08-13 06:47:31,232] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:47:31,811] {logging_mixin.py:109} INFO - [2022-08-13 06:47:31,807] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:47:31,833] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:47:31,848] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.626 seconds
[2022-08-13 06:48:02,586] {processor.py:163} INFO - Started process (PID=12475) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:48:02,588] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:48:02,591] {logging_mixin.py:109} INFO - [2022-08-13 06:48:02,591] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:48:03,256] {logging_mixin.py:109} INFO - [2022-08-13 06:48:03,253] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:48:03,279] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:48:03,294] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.712 seconds
[2022-08-13 06:48:34,031] {processor.py:163} INFO - Started process (PID=12550) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:48:34,036] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:48:34,038] {logging_mixin.py:109} INFO - [2022-08-13 06:48:34,038] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:48:34,632] {logging_mixin.py:109} INFO - [2022-08-13 06:48:34,629] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:48:34,649] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:48:34,661] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.634 seconds
[2022-08-13 06:49:05,293] {processor.py:163} INFO - Started process (PID=12615) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:49:05,297] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:49:05,299] {logging_mixin.py:109} INFO - [2022-08-13 06:49:05,299] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:49:05,995] {logging_mixin.py:109} INFO - [2022-08-13 06:49:05,991] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:49:06,018] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:49:06,032] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.743 seconds
[2022-08-13 06:49:36,893] {processor.py:163} INFO - Started process (PID=12682) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:49:36,897] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:49:36,898] {logging_mixin.py:109} INFO - [2022-08-13 06:49:36,898] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:49:37,522] {logging_mixin.py:109} INFO - [2022-08-13 06:49:37,519] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:49:37,541] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:49:37,553] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.667 seconds
[2022-08-13 06:50:08,209] {processor.py:163} INFO - Started process (PID=12756) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:50:08,211] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:50:08,213] {logging_mixin.py:109} INFO - [2022-08-13 06:50:08,213] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:50:08,928] {logging_mixin.py:109} INFO - [2022-08-13 06:50:08,924] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:50:08,953] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:50:08,996] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.792 seconds
[2022-08-13 06:50:39,821] {processor.py:163} INFO - Started process (PID=12821) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:50:39,823] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:50:39,824] {logging_mixin.py:109} INFO - [2022-08-13 06:50:39,824] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:50:40,451] {logging_mixin.py:109} INFO - [2022-08-13 06:50:40,449] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:50:40,470] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:50:40,482] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.667 seconds
[2022-08-13 06:51:11,322] {processor.py:163} INFO - Started process (PID=12895) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:51:11,324] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:51:11,325] {logging_mixin.py:109} INFO - [2022-08-13 06:51:11,325] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:51:11,924] {logging_mixin.py:109} INFO - [2022-08-13 06:51:11,922] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:51:11,944] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:51:11,956] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.640 seconds
[2022-08-13 06:51:42,744] {processor.py:163} INFO - Started process (PID=12960) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:51:42,746] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:51:42,749] {logging_mixin.py:109} INFO - [2022-08-13 06:51:42,748] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:51:43,477] {logging_mixin.py:109} INFO - [2022-08-13 06:51:43,475] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:51:43,495] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:51:43,517] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.779 seconds
[2022-08-13 06:52:14,169] {processor.py:163} INFO - Started process (PID=13034) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:52:14,172] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:52:14,174] {logging_mixin.py:109} INFO - [2022-08-13 06:52:14,174] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:52:14,829] {logging_mixin.py:109} INFO - [2022-08-13 06:52:14,825] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:52:14,849] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:52:14,860] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.700 seconds
[2022-08-13 06:52:45,521] {processor.py:163} INFO - Started process (PID=13099) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:52:45,524] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:52:45,525] {logging_mixin.py:109} INFO - [2022-08-13 06:52:45,525] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:52:46,130] {logging_mixin.py:109} INFO - [2022-08-13 06:52:46,127] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:52:46,151] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:52:46,164] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.648 seconds
[2022-08-13 06:53:16,975] {processor.py:163} INFO - Started process (PID=13175) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:53:16,979] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:53:16,981] {logging_mixin.py:109} INFO - [2022-08-13 06:53:16,981] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:53:17,578] {logging_mixin.py:109} INFO - [2022-08-13 06:53:17,575] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:53:17,596] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:53:17,608] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.639 seconds
[2022-08-13 06:53:48,382] {processor.py:163} INFO - Started process (PID=13241) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:53:48,385] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:53:48,387] {logging_mixin.py:109} INFO - [2022-08-13 06:53:48,386] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:53:49,014] {logging_mixin.py:109} INFO - [2022-08-13 06:53:49,012] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:53:49,034] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:53:49,047] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.673 seconds
[2022-08-13 06:54:19,838] {processor.py:163} INFO - Started process (PID=13316) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:54:19,841] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:54:19,842] {logging_mixin.py:109} INFO - [2022-08-13 06:54:19,842] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:54:20,593] {logging_mixin.py:109} INFO - [2022-08-13 06:54:20,590] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:54:20,615] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:54:20,629] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.802 seconds
[2022-08-13 06:54:51,475] {processor.py:163} INFO - Started process (PID=13381) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:54:51,479] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:54:51,481] {logging_mixin.py:109} INFO - [2022-08-13 06:54:51,481] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:54:52,151] {logging_mixin.py:109} INFO - [2022-08-13 06:54:52,148] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:54:52,174] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:54:52,190] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.721 seconds
[2022-08-13 06:55:22,675] {processor.py:163} INFO - Started process (PID=13455) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:55:22,678] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:55:22,680] {logging_mixin.py:109} INFO - [2022-08-13 06:55:22,680] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:55:23,217] {logging_mixin.py:109} INFO - [2022-08-13 06:55:23,213] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:55:23,231] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:55:23,242] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.574 seconds
[2022-08-13 06:55:53,941] {processor.py:163} INFO - Started process (PID=13521) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:55:53,944] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:55:53,945] {logging_mixin.py:109} INFO - [2022-08-13 06:55:53,945] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:55:54,645] {logging_mixin.py:109} INFO - [2022-08-13 06:55:54,641] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:55:54,683] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:55:54,697] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.765 seconds
[2022-08-13 06:56:25,725] {processor.py:163} INFO - Started process (PID=13586) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:56:25,729] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:56:25,736] {logging_mixin.py:109} INFO - [2022-08-13 06:56:25,735] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:56:26,346] {logging_mixin.py:109} INFO - [2022-08-13 06:56:26,343] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:56:26,362] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:56:26,375] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.658 seconds
[2022-08-13 06:56:57,304] {processor.py:163} INFO - Started process (PID=13661) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:56:57,306] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:56:57,307] {logging_mixin.py:109} INFO - [2022-08-13 06:56:57,307] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:56:57,951] {logging_mixin.py:109} INFO - [2022-08-13 06:56:57,949] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:56:57,973] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:56:57,986] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.689 seconds
[2022-08-13 06:57:28,459] {processor.py:163} INFO - Started process (PID=13727) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:57:28,462] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:57:28,465] {logging_mixin.py:109} INFO - [2022-08-13 06:57:28,464] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:57:29,093] {logging_mixin.py:109} INFO - [2022-08-13 06:57:29,091] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:57:29,117] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:57:29,132] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.678 seconds
[2022-08-13 06:57:59,207] {processor.py:163} INFO - Started process (PID=13801) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:57:59,210] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:57:59,212] {logging_mixin.py:109} INFO - [2022-08-13 06:57:59,212] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:57:59,717] {logging_mixin.py:109} INFO - [2022-08-13 06:57:59,714] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:57:59,733] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:57:59,744] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.543 seconds
[2022-08-13 06:58:30,768] {processor.py:163} INFO - Started process (PID=13866) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:58:30,771] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:58:30,773] {logging_mixin.py:109} INFO - [2022-08-13 06:58:30,772] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:58:31,366] {logging_mixin.py:109} INFO - [2022-08-13 06:58:31,364] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:58:31,384] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:58:31,395] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.632 seconds
[2022-08-13 06:59:02,019] {processor.py:163} INFO - Started process (PID=13939) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:59:02,023] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:59:02,026] {logging_mixin.py:109} INFO - [2022-08-13 06:59:02,025] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:59:02,718] {logging_mixin.py:109} INFO - [2022-08-13 06:59:02,715] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:59:02,738] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:59:02,749] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.736 seconds
[2022-08-13 06:59:33,428] {processor.py:163} INFO - Started process (PID=14005) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:59:33,431] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 06:59:33,432] {logging_mixin.py:109} INFO - [2022-08-13 06:59:33,432] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:59:34,065] {logging_mixin.py:109} INFO - [2022-08-13 06:59:34,063] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 06:59:34,086] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 06:59:34,097] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.674 seconds
[2022-08-13 07:00:04,583] {processor.py:163} INFO - Started process (PID=14080) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:00:04,587] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:00:04,588] {logging_mixin.py:109} INFO - [2022-08-13 07:00:04,588] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:00:05,221] {logging_mixin.py:109} INFO - [2022-08-13 07:00:05,219] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 07:00:05,241] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:00:05,256] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.678 seconds
[2022-08-13 07:00:35,625] {processor.py:163} INFO - Started process (PID=14146) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:00:35,629] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:00:35,630] {logging_mixin.py:109} INFO - [2022-08-13 07:00:35,630] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:00:36,240] {logging_mixin.py:109} INFO - [2022-08-13 07:00:36,238] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 07:00:36,263] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:00:36,273] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.652 seconds
[2022-08-13 07:01:07,111] {processor.py:163} INFO - Started process (PID=14218) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:01:07,115] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:01:07,117] {logging_mixin.py:109} INFO - [2022-08-13 07:01:07,117] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:01:07,722] {logging_mixin.py:109} INFO - [2022-08-13 07:01:07,720] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 07:01:07,742] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:01:07,761] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.656 seconds
[2022-08-13 07:01:37,974] {processor.py:163} INFO - Started process (PID=14285) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:01:37,992] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:01:37,995] {logging_mixin.py:109} INFO - [2022-08-13 07:01:37,995] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:01:38,728] {logging_mixin.py:109} INFO - [2022-08-13 07:01:38,724] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 07:01:38,760] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:01:38,778] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.814 seconds
[2022-08-13 07:02:08,906] {processor.py:163} INFO - Started process (PID=14351) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:02:08,908] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:02:08,911] {logging_mixin.py:109} INFO - [2022-08-13 07:02:08,910] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:02:09,571] {logging_mixin.py:109} INFO - [2022-08-13 07:02:09,568] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 07:02:09,591] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:02:09,604] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.705 seconds
[2022-08-13 07:02:39,890] {processor.py:163} INFO - Started process (PID=14426) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:02:39,893] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:02:39,894] {logging_mixin.py:109} INFO - [2022-08-13 07:02:39,894] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:02:40,481] {logging_mixin.py:109} INFO - [2022-08-13 07:02:40,478] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 07:02:40,502] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:02:40,513] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.628 seconds
[2022-08-13 07:03:10,634] {processor.py:163} INFO - Started process (PID=14492) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:03:10,637] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:03:10,640] {logging_mixin.py:109} INFO - [2022-08-13 07:03:10,640] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:03:11,191] {logging_mixin.py:109} INFO - [2022-08-13 07:03:11,188] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 07:03:11,208] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:03:11,220] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.594 seconds
[2022-08-13 07:03:41,468] {processor.py:163} INFO - Started process (PID=14567) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:03:41,471] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:03:41,472] {logging_mixin.py:109} INFO - [2022-08-13 07:03:41,472] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:03:42,076] {logging_mixin.py:109} INFO - [2022-08-13 07:03:42,074] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 07:03:42,098] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:03:42,112] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.649 seconds
[2022-08-13 07:04:12,275] {processor.py:163} INFO - Started process (PID=14633) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:04:12,280] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:04:12,283] {logging_mixin.py:109} INFO - [2022-08-13 07:04:12,282] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:04:12,973] {logging_mixin.py:109} INFO - [2022-08-13 07:04:12,970] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 07:04:12,996] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:04:13,016] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.750 seconds
[2022-08-13 07:04:43,698] {processor.py:163} INFO - Started process (PID=14701) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:04:43,701] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:04:43,704] {logging_mixin.py:109} INFO - [2022-08-13 07:04:43,703] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:04:44,428] {logging_mixin.py:109} INFO - [2022-08-13 07:04:44,425] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 07:04:44,445] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:04:44,455] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.784 seconds
[2022-08-13 07:05:14,805] {processor.py:163} INFO - Started process (PID=14780) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:05:14,808] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:05:14,811] {logging_mixin.py:109} INFO - [2022-08-13 07:05:14,811] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:05:15,603] {logging_mixin.py:109} INFO - [2022-08-13 07:05:15,601] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 07:05:15,629] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:05:15,651] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.850 seconds
[2022-08-13 07:05:46,062] {processor.py:163} INFO - Started process (PID=14848) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:05:46,065] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:05:46,067] {logging_mixin.py:109} INFO - [2022-08-13 07:05:46,066] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:05:46,812] {logging_mixin.py:109} INFO - [2022-08-13 07:05:46,809] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 07:05:46,837] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:05:46,850] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.792 seconds
[2022-08-13 07:06:17,149] {processor.py:163} INFO - Started process (PID=14926) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:06:17,152] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:06:17,153] {logging_mixin.py:109} INFO - [2022-08-13 07:06:17,153] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:06:17,922] {logging_mixin.py:109} INFO - [2022-08-13 07:06:17,919] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 07:06:17,940] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:06:17,952] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.808 seconds
[2022-08-13 07:06:48,252] {processor.py:163} INFO - Started process (PID=14993) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:06:48,255] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:06:48,256] {logging_mixin.py:109} INFO - [2022-08-13 07:06:48,256] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:06:48,886] {logging_mixin.py:109} INFO - [2022-08-13 07:06:48,884] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 07:06:48,914] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:06:48,925] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.679 seconds
[2022-08-13 07:07:19,689] {processor.py:163} INFO - Started process (PID=15068) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:07:19,693] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:07:19,696] {logging_mixin.py:109} INFO - [2022-08-13 07:07:19,696] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:07:20,307] {logging_mixin.py:109} INFO - [2022-08-13 07:07:20,305] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 07:07:20,321] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:07:20,330] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.646 seconds
[2022-08-13 07:07:50,416] {processor.py:163} INFO - Started process (PID=15137) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:07:50,419] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:07:50,422] {logging_mixin.py:109} INFO - [2022-08-13 07:07:50,422] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:07:51,690] {logging_mixin.py:109} INFO - [2022-08-13 07:07:51,676] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 07:07:51,870] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:07:51,895] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.486 seconds
[2022-08-13 07:08:22,138] {processor.py:163} INFO - Started process (PID=15206) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:08:22,141] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:08:22,144] {logging_mixin.py:109} INFO - [2022-08-13 07:08:22,143] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:08:22,777] {logging_mixin.py:109} INFO - [2022-08-13 07:08:22,774] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 07:08:22,794] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:08:22,805] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.673 seconds
[2022-08-13 07:08:53,261] {processor.py:163} INFO - Started process (PID=15279) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:08:53,263] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:08:53,266] {logging_mixin.py:109} INFO - [2022-08-13 07:08:53,266] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:08:53,946] {logging_mixin.py:109} INFO - [2022-08-13 07:08:53,943] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 07:08:53,966] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:08:53,980] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.725 seconds
[2022-08-13 07:09:24,090] {processor.py:163} INFO - Started process (PID=15343) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:09:24,094] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:09:24,097] {logging_mixin.py:109} INFO - [2022-08-13 07:09:24,096] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:09:24,801] {logging_mixin.py:109} INFO - [2022-08-13 07:09:24,798] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgres_ingestion.py", line 8, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
[2022-08-13 07:09:24,832] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:09:24,850] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.768 seconds
[2022-08-13 07:09:58,509] {processor.py:163} INFO - Started process (PID=38) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:09:58,513] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:09:58,517] {logging_mixin.py:109} INFO - [2022-08-13 07:09:58,517] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:10:00,872] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:10:01,614] {logging_mixin.py:109} INFO - [2022-08-13 07:10:01,613] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:10:01,643] {logging_mixin.py:109} INFO - [2022-08-13 07:10:01,643] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:10:01,668] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 3.166 seconds
[2022-08-13 07:10:19,765] {processor.py:163} INFO - Started process (PID=103) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:10:19,768] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:10:19,771] {logging_mixin.py:109} INFO - [2022-08-13 07:10:19,770] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:10:20,445] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:10:20,476] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 10, 20, 462376, tzinfo=Timezone('UTC')), 'duration': 10}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:10:20,488] {logging_mixin.py:109} INFO - [2022-08-13 07:10:20,488] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:10:20,508] {logging_mixin.py:109} INFO - [2022-08-13 07:10:20,508] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:10:20,522] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.762 seconds
[2022-08-13 07:10:29,812] {processor.py:163} INFO - Started process (PID=108) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:10:29,814] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:10:29,816] {logging_mixin.py:109} INFO - [2022-08-13 07:10:29,816] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:10:30,331] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:10:30,358] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 10, 30, 345775, tzinfo=Timezone('UTC')), 'duration': 20}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:10:30,372] {logging_mixin.py:109} INFO - [2022-08-13 07:10:30,372] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:10:30,391] {logging_mixin.py:109} INFO - [2022-08-13 07:10:30,391] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:10:30,406] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.599 seconds
[2022-08-13 07:10:39,847] {processor.py:163} INFO - Started process (PID=161) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:10:39,849] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:10:39,852] {logging_mixin.py:109} INFO - [2022-08-13 07:10:39,852] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:10:40,511] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:10:40,536] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 10, 40, 525770, tzinfo=Timezone('UTC')), 'duration': 30}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:10:40,552] {logging_mixin.py:109} INFO - [2022-08-13 07:10:40,552] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:10:40,570] {logging_mixin.py:109} INFO - [2022-08-13 07:10:40,570] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:10:40,580] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.738 seconds
[2022-08-13 07:10:50,418] {processor.py:163} INFO - Started process (PID=179) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:10:50,420] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:10:50,422] {logging_mixin.py:109} INFO - [2022-08-13 07:10:50,422] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:10:51,080] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:10:51,117] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 10, 51, 103873, tzinfo=Timezone('UTC')), 'duration': 41}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:10:51,136] {logging_mixin.py:109} INFO - [2022-08-13 07:10:51,136] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:10:51,153] {logging_mixin.py:109} INFO - [2022-08-13 07:10:51,153] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:10:51,167] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.753 seconds
[2022-08-13 07:11:00,706] {processor.py:163} INFO - Started process (PID=193) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:11:00,708] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:11:00,710] {logging_mixin.py:109} INFO - [2022-08-13 07:11:00,709] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:11:01,360] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:11:01,391] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 11, 1, 381005, tzinfo=Timezone('UTC')), 'duration': 51}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:11:01,408] {logging_mixin.py:109} INFO - [2022-08-13 07:11:01,408] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:11:01,423] {logging_mixin.py:109} INFO - [2022-08-13 07:11:01,423] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:11:01,437] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.734 seconds
[2022-08-13 07:11:10,742] {processor.py:163} INFO - Started process (PID=240) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:11:10,744] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:11:10,746] {logging_mixin.py:109} INFO - [2022-08-13 07:11:10,746] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:11:11,369] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:11:11,399] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 11, 11, 387061, tzinfo=Timezone('UTC')), 'duration': 61}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:11:11,422] {logging_mixin.py:109} INFO - [2022-08-13 07:11:11,421] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:11:11,438] {logging_mixin.py:109} INFO - [2022-08-13 07:11:11,437] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:11:11,450] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.712 seconds
[2022-08-13 07:11:20,784] {processor.py:163} INFO - Started process (PID=254) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:11:20,786] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:11:20,788] {logging_mixin.py:109} INFO - [2022-08-13 07:11:20,787] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:11:21,384] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:11:21,419] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 11, 21, 406580, tzinfo=Timezone('UTC')), 'duration': 71}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:11:21,436] {logging_mixin.py:109} INFO - [2022-08-13 07:11:21,436] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:11:21,460] {logging_mixin.py:109} INFO - [2022-08-13 07:11:21,460] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:11:21,471] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.690 seconds
[2022-08-13 07:11:31,570] {processor.py:163} INFO - Started process (PID=268) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:11:31,572] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:11:31,573] {logging_mixin.py:109} INFO - [2022-08-13 07:11:31,573] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:11:32,165] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:11:32,199] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 11, 32, 183003, tzinfo=Timezone('UTC')), 'duration': 82}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:11:32,221] {logging_mixin.py:109} INFO - [2022-08-13 07:11:32,220] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:11:32,239] {logging_mixin.py:109} INFO - [2022-08-13 07:11:32,239] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:11:32,256] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.689 seconds
[2022-08-13 07:11:41,781] {processor.py:163} INFO - Started process (PID=321) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:11:41,783] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:11:41,785] {logging_mixin.py:109} INFO - [2022-08-13 07:11:41,785] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:11:42,338] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:11:42,364] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 11, 42, 351595, tzinfo=Timezone('UTC')), 'duration': 92}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:11:42,383] {logging_mixin.py:109} INFO - [2022-08-13 07:11:42,382] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:11:42,398] {logging_mixin.py:109} INFO - [2022-08-13 07:11:42,398] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:11:42,407] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.634 seconds
[2022-08-13 07:11:52,047] {processor.py:163} INFO - Started process (PID=338) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:11:52,050] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:11:52,051] {logging_mixin.py:109} INFO - [2022-08-13 07:11:52,051] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:11:53,200] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:11:53,247] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 11, 53, 227587, tzinfo=Timezone('UTC')), 'duration': 103}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:11:53,357] {logging_mixin.py:109} INFO - [2022-08-13 07:11:53,357] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:11:53,402] {logging_mixin.py:109} INFO - [2022-08-13 07:11:53,402] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:11:53,422] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.380 seconds
[2022-08-13 07:12:02,444] {processor.py:163} INFO - Started process (PID=343) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:12:02,446] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:12:02,448] {logging_mixin.py:109} INFO - [2022-08-13 07:12:02,447] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:12:03,100] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:12:03,145] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 12, 3, 126467, tzinfo=Timezone('UTC')), 'duration': 113}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:12:03,176] {logging_mixin.py:109} INFO - [2022-08-13 07:12:03,174] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:12:03,245] {logging_mixin.py:109} INFO - [2022-08-13 07:12:03,244] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:12:03,284] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.843 seconds
[2022-08-13 07:12:12,628] {processor.py:163} INFO - Started process (PID=393) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:12:12,630] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:12:12,632] {logging_mixin.py:109} INFO - [2022-08-13 07:12:12,631] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:12:13,131] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:12:13,181] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 12, 13, 163077, tzinfo=Timezone('UTC')), 'duration': 123}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:12:13,199] {logging_mixin.py:109} INFO - [2022-08-13 07:12:13,198] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:12:13,215] {logging_mixin.py:109} INFO - [2022-08-13 07:12:13,215] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:12:13,230] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.608 seconds
[2022-08-13 07:12:23,566] {processor.py:163} INFO - Started process (PID=413) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:12:23,568] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:12:23,572] {logging_mixin.py:109} INFO - [2022-08-13 07:12:23,571] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:12:24,116] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:12:24,143] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 12, 24, 131231, tzinfo=Timezone('UTC')), 'duration': 134}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:12:24,160] {logging_mixin.py:109} INFO - [2022-08-13 07:12:24,160] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:12:24,176] {logging_mixin.py:109} INFO - [2022-08-13 07:12:24,175] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:12:24,186] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.624 seconds
[2022-08-13 07:12:33,681] {processor.py:163} INFO - Started process (PID=427) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:12:33,683] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:12:33,685] {logging_mixin.py:109} INFO - [2022-08-13 07:12:33,685] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:12:34,208] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:12:34,241] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 12, 34, 227103, tzinfo=Timezone('UTC')), 'duration': 144}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:12:34,259] {logging_mixin.py:109} INFO - [2022-08-13 07:12:34,258] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:12:34,275] {logging_mixin.py:109} INFO - [2022-08-13 07:12:34,275] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:12:34,286] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.610 seconds
[2022-08-13 07:12:44,265] {processor.py:163} INFO - Started process (PID=477) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:12:44,267] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:12:44,269] {logging_mixin.py:109} INFO - [2022-08-13 07:12:44,269] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:12:44,860] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:12:44,893] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 12, 44, 880314, tzinfo=Timezone('UTC')), 'duration': 155}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:12:44,910] {logging_mixin.py:109} INFO - [2022-08-13 07:12:44,909] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:12:44,926] {logging_mixin.py:109} INFO - [2022-08-13 07:12:44,926] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:12:44,941] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.681 seconds
[2022-08-13 07:12:55,015] {processor.py:163} INFO - Started process (PID=498) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:12:55,017] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:12:55,018] {logging_mixin.py:109} INFO - [2022-08-13 07:12:55,018] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:12:55,546] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:12:55,577] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 12, 55, 564472, tzinfo=Timezone('UTC')), 'duration': 165}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:12:55,597] {logging_mixin.py:109} INFO - [2022-08-13 07:12:55,597] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:12:55,613] {logging_mixin.py:109} INFO - [2022-08-13 07:12:55,613] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:12:55,628] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.616 seconds
[2022-08-13 07:13:05,065] {processor.py:163} INFO - Started process (PID=503) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:13:05,068] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:13:05,069] {logging_mixin.py:109} INFO - [2022-08-13 07:13:05,069] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:13:05,623] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:13:05,653] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 13, 5, 639329, tzinfo=Timezone('UTC')), 'duration': 176}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:13:05,684] {logging_mixin.py:109} INFO - [2022-08-13 07:13:05,684] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:13:05,753] {logging_mixin.py:109} INFO - [2022-08-13 07:13:05,752] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:13:05,769] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.707 seconds
[2022-08-13 07:13:16,006] {processor.py:163} INFO - Started process (PID=559) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:13:16,008] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:13:16,009] {logging_mixin.py:109} INFO - [2022-08-13 07:13:16,009] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:13:16,632] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:13:16,662] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 13, 16, 648786, tzinfo=Timezone('UTC')), 'duration': 187}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:13:16,682] {logging_mixin.py:109} INFO - [2022-08-13 07:13:16,681] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:13:16,702] {logging_mixin.py:109} INFO - [2022-08-13 07:13:16,701] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:13:16,716] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.713 seconds
[2022-08-13 07:13:26,122] {processor.py:163} INFO - Started process (PID=574) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:13:26,124] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:13:26,125] {logging_mixin.py:109} INFO - [2022-08-13 07:13:26,125] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:13:26,654] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:13:26,681] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 13, 26, 669469, tzinfo=Timezone('UTC')), 'duration': 197}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:13:26,696] {logging_mixin.py:109} INFO - [2022-08-13 07:13:26,695] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:13:26,709] {logging_mixin.py:109} INFO - [2022-08-13 07:13:26,709] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:13:26,720] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.602 seconds
[2022-08-13 07:13:36,202] {processor.py:163} INFO - Started process (PID=589) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:13:36,204] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:13:36,205] {logging_mixin.py:109} INFO - [2022-08-13 07:13:36,205] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:13:36,750] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:13:36,778] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 13, 36, 767287, tzinfo=Timezone('UTC')), 'duration': 207}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:13:36,810] {logging_mixin.py:109} INFO - [2022-08-13 07:13:36,810] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:13:36,826] {logging_mixin.py:109} INFO - [2022-08-13 07:13:36,825] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:13:36,841] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.644 seconds
[2022-08-13 07:13:46,534] {processor.py:163} INFO - Started process (PID=645) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:13:46,535] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:13:46,537] {logging_mixin.py:109} INFO - [2022-08-13 07:13:46,537] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:13:47,080] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:13:47,105] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 13, 47, 95008, tzinfo=Timezone('UTC')), 'duration': 217}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:13:47,123] {logging_mixin.py:109} INFO - [2022-08-13 07:13:47,123] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:13:47,136] {logging_mixin.py:109} INFO - [2022-08-13 07:13:47,136] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:13:47,147] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.617 seconds
[2022-08-13 07:13:56,623] {processor.py:163} INFO - Started process (PID=650) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:13:56,625] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:13:56,626] {logging_mixin.py:109} INFO - [2022-08-13 07:13:56,626] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:13:57,234] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:13:57,270] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 13, 57, 259277, tzinfo=Timezone('UTC')), 'duration': 227}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:13:57,301] {logging_mixin.py:109} INFO - [2022-08-13 07:13:57,301] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:13:57,317] {logging_mixin.py:109} INFO - [2022-08-13 07:13:57,317] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:13:57,330] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.711 seconds
[2022-08-13 07:14:07,329] {processor.py:163} INFO - Started process (PID=664) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:14:07,331] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:14:07,334] {logging_mixin.py:109} INFO - [2022-08-13 07:14:07,333] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:14:07,912] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:14:07,952] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 14, 7, 938293, tzinfo=Timezone('UTC')), 'duration': 238}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:14:07,976] {logging_mixin.py:109} INFO - [2022-08-13 07:14:07,976] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:14:07,995] {logging_mixin.py:109} INFO - [2022-08-13 07:14:07,995] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:14:08,010] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.685 seconds
[2022-08-13 07:14:18,080] {processor.py:163} INFO - Started process (PID=720) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:14:18,082] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:14:18,083] {logging_mixin.py:109} INFO - [2022-08-13 07:14:18,083] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:14:18,598] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:14:18,634] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 14, 18, 614705, tzinfo=Timezone('UTC')), 'duration': 249}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:14:18,653] {logging_mixin.py:109} INFO - [2022-08-13 07:14:18,651] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:14:18,667] {logging_mixin.py:109} INFO - [2022-08-13 07:14:18,667] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:14:18,678] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.602 seconds
[2022-08-13 07:14:28,148] {processor.py:163} INFO - Started process (PID=734) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:14:28,151] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:14:28,154] {logging_mixin.py:109} INFO - [2022-08-13 07:14:28,153] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:14:28,736] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:14:28,761] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 14, 28, 751488, tzinfo=Timezone('UTC')), 'duration': 259}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:14:28,774] {logging_mixin.py:109} INFO - [2022-08-13 07:14:28,774] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:14:28,788] {logging_mixin.py:109} INFO - [2022-08-13 07:14:28,788] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:14:28,797] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.652 seconds
[2022-08-13 07:14:38,989] {processor.py:163} INFO - Started process (PID=750) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:14:38,993] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:14:38,997] {logging_mixin.py:109} INFO - [2022-08-13 07:14:38,997] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:14:39,942] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:14:39,970] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 14, 39, 957342, tzinfo=Timezone('UTC')), 'duration': 270}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:14:39,995] {logging_mixin.py:109} INFO - [2022-08-13 07:14:39,995] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:14:40,015] {logging_mixin.py:109} INFO - [2022-08-13 07:14:40,015] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:14:40,029] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.046 seconds
[2022-08-13 07:14:49,770] {processor.py:163} INFO - Started process (PID=804) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:14:49,772] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:14:49,773] {logging_mixin.py:109} INFO - [2022-08-13 07:14:49,773] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:14:50,309] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:14:50,341] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 14, 50, 328442, tzinfo=Timezone('UTC')), 'duration': 280}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:14:50,364] {logging_mixin.py:109} INFO - [2022-08-13 07:14:50,363] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:14:50,384] {logging_mixin.py:109} INFO - [2022-08-13 07:14:50,384] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:14:50,398] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.634 seconds
[2022-08-13 07:14:59,853] {processor.py:163} INFO - Started process (PID=809) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:14:59,856] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:14:59,858] {logging_mixin.py:109} INFO - [2022-08-13 07:14:59,857] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:15:00,417] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:15:00,445] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 15, 0, 435222, tzinfo=Timezone('UTC')), 'duration': 290}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:15:00,462] {logging_mixin.py:109} INFO - [2022-08-13 07:15:00,461] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:15:00,477] {logging_mixin.py:109} INFO - [2022-08-13 07:15:00,477] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:15:00,494] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.647 seconds
[2022-08-13 07:15:10,743] {processor.py:163} INFO - Started process (PID=826) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:15:10,745] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:15:10,747] {logging_mixin.py:109} INFO - [2022-08-13 07:15:10,747] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:15:11,349] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:15:11,394] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 15, 11, 375977, tzinfo=Timezone('UTC')), 'duration': 301}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:15:11,415] {logging_mixin.py:109} INFO - [2022-08-13 07:15:11,413] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:15:11,432] {logging_mixin.py:109} INFO - [2022-08-13 07:15:11,432] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:15:11,443] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.704 seconds
[2022-08-13 07:15:21,356] {processor.py:163} INFO - Started process (PID=879) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:15:21,362] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:15:21,365] {logging_mixin.py:109} INFO - [2022-08-13 07:15:21,365] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:15:22,055] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:15:22,081] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 15, 22, 70871, tzinfo=Timezone('UTC')), 'duration': 312}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:15:22,095] {logging_mixin.py:109} INFO - [2022-08-13 07:15:22,095] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:15:22,112] {logging_mixin.py:109} INFO - [2022-08-13 07:15:22,112] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:15:22,121] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.770 seconds
[2022-08-13 07:15:31,378] {processor.py:163} INFO - Started process (PID=893) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:15:31,379] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:15:31,381] {logging_mixin.py:109} INFO - [2022-08-13 07:15:31,381] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:15:31,909] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:15:31,935] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 15, 31, 923091, tzinfo=Timezone('UTC')), 'duration': 322}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:15:31,952] {logging_mixin.py:109} INFO - [2022-08-13 07:15:31,951] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:15:31,965] {logging_mixin.py:109} INFO - [2022-08-13 07:15:31,964] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:15:31,973] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.602 seconds
[2022-08-13 07:15:41,687] {processor.py:163} INFO - Started process (PID=915) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:15:41,690] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:15:41,691] {logging_mixin.py:109} INFO - [2022-08-13 07:15:41,691] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:15:42,288] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:15:42,342] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 15, 42, 320499, tzinfo=Timezone('UTC')), 'duration': 332}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:15:42,377] {logging_mixin.py:109} INFO - [2022-08-13 07:15:42,377] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:15:42,395] {logging_mixin.py:109} INFO - [2022-08-13 07:15:42,395] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:15:42,412] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.729 seconds
[2022-08-13 07:15:52,602] {processor.py:163} INFO - Started process (PID=964) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:15:52,604] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:15:52,606] {logging_mixin.py:109} INFO - [2022-08-13 07:15:52,606] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:15:53,203] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:15:53,230] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 15, 53, 218072, tzinfo=Timezone('UTC')), 'duration': 343}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:15:53,246] {logging_mixin.py:109} INFO - [2022-08-13 07:15:53,246] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:15:53,260] {logging_mixin.py:109} INFO - [2022-08-13 07:15:53,260] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:15:53,271] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.672 seconds
[2022-08-13 07:16:02,680] {processor.py:163} INFO - Started process (PID=969) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:16:02,682] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:16:02,683] {logging_mixin.py:109} INFO - [2022-08-13 07:16:02,683] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:16:03,334] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:16:03,367] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 16, 3, 353291, tzinfo=Timezone('UTC')), 'duration': 353}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:16:03,391] {logging_mixin.py:109} INFO - [2022-08-13 07:16:03,391] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:16:03,413] {logging_mixin.py:109} INFO - [2022-08-13 07:16:03,413] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:16:03,429] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.752 seconds
[2022-08-13 07:16:12,734] {processor.py:163} INFO - Started process (PID=992) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:16:12,736] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:16:12,737] {logging_mixin.py:109} INFO - [2022-08-13 07:16:12,737] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:16:13,340] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:16:13,376] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 16, 13, 359507, tzinfo=Timezone('UTC')), 'duration': 363}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:16:13,402] {logging_mixin.py:109} INFO - [2022-08-13 07:16:13,402] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:16:13,423] {logging_mixin.py:109} INFO - [2022-08-13 07:16:13,423] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:16:13,440] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.712 seconds
[2022-08-13 07:16:23,405] {processor.py:163} INFO - Started process (PID=1039) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:16:23,407] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:16:23,409] {logging_mixin.py:109} INFO - [2022-08-13 07:16:23,409] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:16:24,012] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:16:24,042] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 16, 24, 28504, tzinfo=Timezone('UTC')), 'duration': 374}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:16:24,074] {logging_mixin.py:109} INFO - [2022-08-13 07:16:24,073] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:16:24,109] {logging_mixin.py:109} INFO - [2022-08-13 07:16:24,108] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:16:24,195] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.793 seconds
[2022-08-13 07:16:33,486] {processor.py:163} INFO - Started process (PID=1053) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:16:33,487] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:16:33,489] {logging_mixin.py:109} INFO - [2022-08-13 07:16:33,489] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:16:34,048] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:16:34,073] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 16, 34, 62744, tzinfo=Timezone('UTC')), 'duration': 384}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:16:34,084] {logging_mixin.py:109} INFO - [2022-08-13 07:16:34,084] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:16:34,096] {logging_mixin.py:109} INFO - [2022-08-13 07:16:34,096] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:16:34,105] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.623 seconds
[2022-08-13 07:16:43,792] {processor.py:163} INFO - Started process (PID=1071) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:16:43,795] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:16:43,796] {logging_mixin.py:109} INFO - [2022-08-13 07:16:43,796] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:16:44,457] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:16:44,489] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 37, 680357, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 10, 9, 585322, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 16, 44, 473274, tzinfo=Timezone('UTC')), 'duration': 394}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:16:44,506] {logging_mixin.py:109} INFO - [2022-08-13 07:16:44,504] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:16:44,521] {logging_mixin.py:109} INFO - [2022-08-13 07:16:44,521] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:16:44,537] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.770 seconds
[2022-08-13 07:17:14,733] {processor.py:163} INFO - Started process (PID=1136) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:17:14,735] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:17:14,736] {logging_mixin.py:109} INFO - [2022-08-13 07:17:14,736] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:17:15,270] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:17:15,279] {logging_mixin.py:109} INFO - [2022-08-13 07:17:15,279] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:17:15,293] {logging_mixin.py:109} INFO - [2022-08-13 07:17:15,293] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:17:15,308] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.578 seconds
[2022-08-13 07:17:45,553] {processor.py:163} INFO - Started process (PID=1215) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:17:45,556] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:17:45,558] {logging_mixin.py:109} INFO - [2022-08-13 07:17:45,558] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:17:46,135] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:17:46,144] {logging_mixin.py:109} INFO - [2022-08-13 07:17:46,144] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:17:46,165] {logging_mixin.py:109} INFO - [2022-08-13 07:17:46,165] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:17:46,174] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.628 seconds
[2022-08-13 07:18:16,251] {processor.py:163} INFO - Started process (PID=1275) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:18:16,254] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:18:16,256] {logging_mixin.py:109} INFO - [2022-08-13 07:18:16,256] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:18:16,829] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:18:16,837] {logging_mixin.py:109} INFO - [2022-08-13 07:18:16,836] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:18:16,850] {logging_mixin.py:109} INFO - [2022-08-13 07:18:16,850] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:18:16,860] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.612 seconds
[2022-08-13 07:18:47,428] {processor.py:163} INFO - Started process (PID=1350) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:18:47,431] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:18:47,432] {logging_mixin.py:109} INFO - [2022-08-13 07:18:47,432] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:18:47,990] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:18:48,001] {logging_mixin.py:109} INFO - [2022-08-13 07:18:48,000] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:18:48,017] {logging_mixin.py:109} INFO - [2022-08-13 07:18:48,017] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:18:48,033] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.609 seconds
[2022-08-13 07:19:18,441] {processor.py:163} INFO - Started process (PID=1415) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:19:18,443] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:19:18,444] {logging_mixin.py:109} INFO - [2022-08-13 07:19:18,444] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:19:18,989] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:19:18,998] {logging_mixin.py:109} INFO - [2022-08-13 07:19:18,998] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:19:19,011] {logging_mixin.py:109} INFO - [2022-08-13 07:19:19,011] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:19:19,020] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.583 seconds
[2022-08-13 07:19:49,253] {processor.py:163} INFO - Started process (PID=1488) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:19:49,256] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:19:49,258] {logging_mixin.py:109} INFO - [2022-08-13 07:19:49,258] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:19:49,894] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:19:49,904] {logging_mixin.py:109} INFO - [2022-08-13 07:19:49,903] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:19:49,921] {logging_mixin.py:109} INFO - [2022-08-13 07:19:49,921] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:19:49,931] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.685 seconds
[2022-08-13 07:20:20,577] {processor.py:163} INFO - Started process (PID=1554) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:20:20,579] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:20:20,581] {logging_mixin.py:109} INFO - [2022-08-13 07:20:20,581] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:20:21,168] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:20:21,177] {logging_mixin.py:109} INFO - [2022-08-13 07:20:21,177] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:20:21,193] {logging_mixin.py:109} INFO - [2022-08-13 07:20:21,193] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:20:21,203] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.630 seconds
[2022-08-13 07:20:31,399] {processor.py:163} INFO - Started process (PID=1606) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:20:31,402] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:20:31,403] {logging_mixin.py:109} INFO - [2022-08-13 07:20:31,403] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:20:31,985] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:20:32,011] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 20, 31, 999550, tzinfo=Timezone('UTC')), 'duration': 3}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:20:32,025] {logging_mixin.py:109} INFO - [2022-08-13 07:20:32,025] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:20:32,036] {logging_mixin.py:109} INFO - [2022-08-13 07:20:32,036] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:20:32,045] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.650 seconds
[2022-08-13 07:20:41,534] {processor.py:163} INFO - Started process (PID=1620) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:20:41,536] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:20:41,538] {logging_mixin.py:109} INFO - [2022-08-13 07:20:41,537] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:20:42,136] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:20:42,170] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 20, 42, 153415, tzinfo=Timezone('UTC')), 'duration': 13}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:20:42,183] {logging_mixin.py:109} INFO - [2022-08-13 07:20:42,183] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:20:42,194] {logging_mixin.py:109} INFO - [2022-08-13 07:20:42,194] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:20:42,202] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.672 seconds
[2022-08-13 07:20:51,633] {processor.py:163} INFO - Started process (PID=1635) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:20:51,647] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:20:51,651] {logging_mixin.py:109} INFO - [2022-08-13 07:20:51,651] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:20:52,233] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:20:52,273] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 20, 52, 261258, tzinfo=Timezone('UTC')), 'duration': 24}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:20:52,289] {logging_mixin.py:109} INFO - [2022-08-13 07:20:52,289] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:20:52,305] {logging_mixin.py:109} INFO - [2022-08-13 07:20:52,305] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:20:52,315] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.689 seconds
[2022-08-13 07:21:01,733] {processor.py:163} INFO - Started process (PID=1682) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:21:01,735] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:21:01,737] {logging_mixin.py:109} INFO - [2022-08-13 07:21:01,737] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:21:02,399] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:21:02,431] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 21, 2, 415042, tzinfo=Timezone('UTC')), 'duration': 34}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:21:02,447] {logging_mixin.py:109} INFO - [2022-08-13 07:21:02,446] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:21:02,462] {logging_mixin.py:109} INFO - [2022-08-13 07:21:02,462] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:21:02,476] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.746 seconds
[2022-08-13 07:21:11,834] {processor.py:163} INFO - Started process (PID=1696) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:21:11,836] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:21:11,838] {logging_mixin.py:109} INFO - [2022-08-13 07:21:11,838] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:21:12,585] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:21:12,622] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 21, 12, 607806, tzinfo=Timezone('UTC')), 'duration': 44}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:21:12,641] {logging_mixin.py:109} INFO - [2022-08-13 07:21:12,641] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:21:12,655] {logging_mixin.py:109} INFO - [2022-08-13 07:21:12,655] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:21:12,665] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.837 seconds
[2022-08-13 07:21:21,848] {processor.py:163} INFO - Started process (PID=1714) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:21:21,851] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:21:21,852] {logging_mixin.py:109} INFO - [2022-08-13 07:21:21,852] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:21:22,475] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:21:22,503] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 21, 22, 493228, tzinfo=Timezone('UTC')), 'duration': 54}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:21:22,516] {logging_mixin.py:109} INFO - [2022-08-13 07:21:22,515] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:21:22,528] {logging_mixin.py:109} INFO - [2022-08-13 07:21:22,527] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:21:22,539] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.695 seconds
[2022-08-13 07:21:32,228] {processor.py:163} INFO - Started process (PID=1766) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:21:32,230] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:21:32,232] {logging_mixin.py:109} INFO - [2022-08-13 07:21:32,232] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:21:32,779] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:21:32,808] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 21, 32, 796534, tzinfo=Timezone('UTC')), 'duration': 64}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:21:32,821] {logging_mixin.py:109} INFO - [2022-08-13 07:21:32,821] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:21:32,835] {logging_mixin.py:109} INFO - [2022-08-13 07:21:32,835] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:21:32,845] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.622 seconds
[2022-08-13 07:21:42,505] {processor.py:163} INFO - Started process (PID=1771) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:21:42,507] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:21:42,508] {logging_mixin.py:109} INFO - [2022-08-13 07:21:42,508] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:21:43,087] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:21:43,117] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 21, 43, 105195, tzinfo=Timezone('UTC')), 'duration': 74}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:21:43,133] {logging_mixin.py:109} INFO - [2022-08-13 07:21:43,133] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:21:43,151] {logging_mixin.py:109} INFO - [2022-08-13 07:21:43,151] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:21:43,163] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.661 seconds
[2022-08-13 07:21:53,234] {processor.py:163} INFO - Started process (PID=1789) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:21:53,235] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:21:53,237] {logging_mixin.py:109} INFO - [2022-08-13 07:21:53,237] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:21:53,841] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:21:53,879] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 21, 53, 867057, tzinfo=Timezone('UTC')), 'duration': 85}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:21:53,893] {logging_mixin.py:109} INFO - [2022-08-13 07:21:53,893] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:21:53,908] {logging_mixin.py:109} INFO - [2022-08-13 07:21:53,908] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:21:53,922] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.691 seconds
[2022-08-13 07:22:03,269] {processor.py:163} INFO - Started process (PID=1841) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:22:03,271] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:22:03,272] {logging_mixin.py:109} INFO - [2022-08-13 07:22:03,272] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:22:03,849] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:22:03,883] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 22, 3, 867723, tzinfo=Timezone('UTC')), 'duration': 95}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:22:03,896] {logging_mixin.py:109} INFO - [2022-08-13 07:22:03,895] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:22:03,911] {logging_mixin.py:109} INFO - [2022-08-13 07:22:03,911] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:22:03,927] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.662 seconds
[2022-08-13 07:22:13,313] {processor.py:163} INFO - Started process (PID=1855) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:22:13,316] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:22:13,318] {logging_mixin.py:109} INFO - [2022-08-13 07:22:13,317] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:22:13,860] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:22:13,890] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 22, 13, 879777, tzinfo=Timezone('UTC')), 'duration': 105}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:22:13,906] {logging_mixin.py:109} INFO - [2022-08-13 07:22:13,906] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:22:13,922] {logging_mixin.py:109} INFO - [2022-08-13 07:22:13,922] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:22:13,934] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.646 seconds
[2022-08-13 07:22:23,811] {processor.py:163} INFO - Started process (PID=1873) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:22:23,813] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:22:23,815] {logging_mixin.py:109} INFO - [2022-08-13 07:22:23,815] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:22:24,484] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:22:24,513] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 22, 24, 501362, tzinfo=Timezone('UTC')), 'duration': 116}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:22:24,527] {logging_mixin.py:109} INFO - [2022-08-13 07:22:24,527] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:22:24,545] {logging_mixin.py:109} INFO - [2022-08-13 07:22:24,545] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:22:24,559] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.751 seconds
[2022-08-13 07:22:34,071] {processor.py:163} INFO - Started process (PID=1924) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:22:34,074] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:22:34,076] {logging_mixin.py:109} INFO - [2022-08-13 07:22:34,076] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:22:34,648] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:22:34,678] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 22, 34, 664218, tzinfo=Timezone('UTC')), 'duration': 126}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:22:34,691] {logging_mixin.py:109} INFO - [2022-08-13 07:22:34,690] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:22:34,704] {logging_mixin.py:109} INFO - [2022-08-13 07:22:34,703] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:22:34,713] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.648 seconds
[2022-08-13 07:22:44,156] {processor.py:163} INFO - Started process (PID=1931) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:22:44,158] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:22:44,160] {logging_mixin.py:109} INFO - [2022-08-13 07:22:44,160] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:22:44,710] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:22:44,733] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 22, 44, 724274, tzinfo=Timezone('UTC')), 'duration': 136}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:22:44,747] {logging_mixin.py:109} INFO - [2022-08-13 07:22:44,747] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:22:44,760] {logging_mixin.py:109} INFO - [2022-08-13 07:22:44,760] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:22:44,768] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.616 seconds
[2022-08-13 07:22:54,246] {processor.py:163} INFO - Started process (PID=1948) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:22:54,248] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:22:54,250] {logging_mixin.py:109} INFO - [2022-08-13 07:22:54,250] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:22:54,820] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:22:54,852] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 22, 54, 838040, tzinfo=Timezone('UTC')), 'duration': 146}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:22:54,866] {logging_mixin.py:109} INFO - [2022-08-13 07:22:54,866] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:22:54,882] {logging_mixin.py:109} INFO - [2022-08-13 07:22:54,882] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:22:54,896] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.654 seconds
[2022-08-13 07:23:05,103] {processor.py:163} INFO - Started process (PID=2000) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:23:05,105] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:23:05,106] {logging_mixin.py:109} INFO - [2022-08-13 07:23:05,106] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:23:05,705] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:23:05,738] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 23, 5, 723950, tzinfo=Timezone('UTC')), 'duration': 157}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:23:05,754] {logging_mixin.py:109} INFO - [2022-08-13 07:23:05,754] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:23:05,768] {logging_mixin.py:109} INFO - [2022-08-13 07:23:05,768] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:23:05,786] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.686 seconds
[2022-08-13 07:23:15,185] {processor.py:163} INFO - Started process (PID=2014) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:23:15,187] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:23:15,188] {logging_mixin.py:109} INFO - [2022-08-13 07:23:15,188] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:23:15,761] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:23:15,788] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 23, 15, 776824, tzinfo=Timezone('UTC')), 'duration': 167}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:23:15,806] {logging_mixin.py:109} INFO - [2022-08-13 07:23:15,806] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:23:15,819] {logging_mixin.py:109} INFO - [2022-08-13 07:23:15,819] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:23:15,829] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.649 seconds
[2022-08-13 07:23:25,333] {processor.py:163} INFO - Started process (PID=2032) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:23:25,335] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:23:25,336] {logging_mixin.py:109} INFO - [2022-08-13 07:23:25,336] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:23:25,912] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:23:25,952] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 23, 25, 936969, tzinfo=Timezone('UTC')), 'duration': 177}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:23:25,986] {logging_mixin.py:109} INFO - [2022-08-13 07:23:25,986] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:23:26,017] {logging_mixin.py:109} INFO - [2022-08-13 07:23:26,017] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:23:26,027] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.697 seconds
[2022-08-13 07:23:35,421] {processor.py:163} INFO - Started process (PID=2075) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:23:35,424] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:23:35,425] {logging_mixin.py:109} INFO - [2022-08-13 07:23:35,425] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:23:35,999] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:23:36,034] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 23, 36, 22583, tzinfo=Timezone('UTC')), 'duration': 187}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:23:36,051] {logging_mixin.py:109} INFO - [2022-08-13 07:23:36,051] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:23:36,068] {logging_mixin.py:109} INFO - [2022-08-13 07:23:36,068] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:23:36,083] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.666 seconds
[2022-08-13 07:23:45,476] {processor.py:163} INFO - Started process (PID=2089) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:23:45,479] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:23:45,480] {logging_mixin.py:109} INFO - [2022-08-13 07:23:45,480] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:23:46,022] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:23:46,047] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 23, 46, 36195, tzinfo=Timezone('UTC')), 'duration': 197}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:23:46,060] {logging_mixin.py:109} INFO - [2022-08-13 07:23:46,059] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:23:46,071] {logging_mixin.py:109} INFO - [2022-08-13 07:23:46,071] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:23:46,085] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.612 seconds
[2022-08-13 07:23:55,706] {processor.py:163} INFO - Started process (PID=2108) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:23:55,709] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:23:55,710] {logging_mixin.py:109} INFO - [2022-08-13 07:23:55,710] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:23:56,275] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:23:56,301] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 23, 56, 290288, tzinfo=Timezone('UTC')), 'duration': 208}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:23:56,314] {logging_mixin.py:109} INFO - [2022-08-13 07:23:56,314] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:23:56,326] {logging_mixin.py:109} INFO - [2022-08-13 07:23:56,326] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:23:56,336] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.633 seconds
[2022-08-13 07:24:06,288] {processor.py:163} INFO - Started process (PID=2160) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:24:06,289] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:24:06,291] {logging_mixin.py:109} INFO - [2022-08-13 07:24:06,291] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:24:06,877] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:24:06,903] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 24, 6, 891872, tzinfo=Timezone('UTC')), 'duration': 218}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:24:06,919] {logging_mixin.py:109} INFO - [2022-08-13 07:24:06,918] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:24:06,930] {logging_mixin.py:109} INFO - [2022-08-13 07:24:06,930] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:24:06,939] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.655 seconds
[2022-08-13 07:24:16,321] {processor.py:163} INFO - Started process (PID=2175) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:24:16,323] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:24:16,325] {logging_mixin.py:109} INFO - [2022-08-13 07:24:16,324] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:24:16,968] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:24:16,996] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 24, 16, 985354, tzinfo=Timezone('UTC')), 'duration': 228}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:24:17,013] {logging_mixin.py:109} INFO - [2022-08-13 07:24:17,012] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:24:17,030] {logging_mixin.py:109} INFO - [2022-08-13 07:24:17,030] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:24:17,044] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.726 seconds
[2022-08-13 07:24:26,507] {processor.py:163} INFO - Started process (PID=2184) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:24:26,509] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:24:26,510] {logging_mixin.py:109} INFO - [2022-08-13 07:24:26,510] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:24:27,096] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:24:27,123] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 24, 27, 111811, tzinfo=Timezone('UTC')), 'duration': 238}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:24:27,139] {logging_mixin.py:109} INFO - [2022-08-13 07:24:27,139] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:24:27,155] {logging_mixin.py:109} INFO - [2022-08-13 07:24:27,155] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:24:27,168] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.664 seconds
[2022-08-13 07:24:36,894] {processor.py:163} INFO - Started process (PID=2237) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:24:36,895] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:24:36,897] {logging_mixin.py:109} INFO - [2022-08-13 07:24:36,897] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:24:37,492] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:24:37,521] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 24, 37, 508546, tzinfo=Timezone('UTC')), 'duration': 249}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:24:37,535] {logging_mixin.py:109} INFO - [2022-08-13 07:24:37,534] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:24:37,549] {logging_mixin.py:109} INFO - [2022-08-13 07:24:37,549] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:24:37,559] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.671 seconds
[2022-08-13 07:24:46,976] {processor.py:163} INFO - Started process (PID=2251) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:24:46,978] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:24:46,979] {logging_mixin.py:109} INFO - [2022-08-13 07:24:46,979] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:24:47,537] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:24:47,561] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 24, 47, 550632, tzinfo=Timezone('UTC')), 'duration': 259}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:24:47,576] {logging_mixin.py:109} INFO - [2022-08-13 07:24:47,576] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:24:47,587] {logging_mixin.py:109} INFO - [2022-08-13 07:24:47,587] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:24:47,596] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.624 seconds
[2022-08-13 07:24:57,110] {processor.py:163} INFO - Started process (PID=2269) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:24:57,113] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:24:57,115] {logging_mixin.py:109} INFO - [2022-08-13 07:24:57,114] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:24:57,658] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:24:57,683] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 24, 57, 671483, tzinfo=Timezone('UTC')), 'duration': 269}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:24:57,698] {logging_mixin.py:109} INFO - [2022-08-13 07:24:57,697] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:24:57,710] {logging_mixin.py:109} INFO - [2022-08-13 07:24:57,710] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:24:57,721] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.614 seconds
[2022-08-13 07:25:07,135] {processor.py:163} INFO - Started process (PID=2319) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:25:07,137] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:25:07,139] {logging_mixin.py:109} INFO - [2022-08-13 07:25:07,139] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:25:07,744] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:25:07,780] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 25, 7, 765958, tzinfo=Timezone('UTC')), 'duration': 279}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:25:07,797] {logging_mixin.py:109} INFO - [2022-08-13 07:25:07,797] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:25:07,818] {logging_mixin.py:109} INFO - [2022-08-13 07:25:07,818] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:25:07,845] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.714 seconds
[2022-08-13 07:25:17,171] {processor.py:163} INFO - Started process (PID=2326) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:25:17,173] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:25:17,174] {logging_mixin.py:109} INFO - [2022-08-13 07:25:17,174] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:25:17,722] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:25:17,751] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 25, 17, 737764, tzinfo=Timezone('UTC')), 'duration': 289}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:25:17,766] {logging_mixin.py:109} INFO - [2022-08-13 07:25:17,765] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:25:17,779] {logging_mixin.py:109} INFO - [2022-08-13 07:25:17,778] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:25:17,788] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.621 seconds
[2022-08-13 07:25:27,476] {processor.py:163} INFO - Started process (PID=2344) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:25:27,479] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:25:27,481] {logging_mixin.py:109} INFO - [2022-08-13 07:25:27,481] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:25:28,026] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:25:28,049] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 25, 28, 40391, tzinfo=Timezone('UTC')), 'duration': 299}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:25:28,061] {logging_mixin.py:109} INFO - [2022-08-13 07:25:28,061] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:25:28,073] {logging_mixin.py:109} INFO - [2022-08-13 07:25:28,072] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:25:28,083] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.613 seconds
[2022-08-13 07:25:37,763] {processor.py:163} INFO - Started process (PID=2396) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:25:37,765] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:25:37,767] {logging_mixin.py:109} INFO - [2022-08-13 07:25:37,766] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:25:38,197] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:25:38,228] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 25, 38, 214229, tzinfo=Timezone('UTC')), 'duration': 310}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:25:38,242] {logging_mixin.py:109} INFO - [2022-08-13 07:25:38,242] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:25:38,253] {logging_mixin.py:109} INFO - [2022-08-13 07:25:38,253] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:25:38,262] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.502 seconds
[2022-08-13 07:25:47,792] {processor.py:163} INFO - Started process (PID=2410) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:25:47,795] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:25:47,796] {logging_mixin.py:109} INFO - [2022-08-13 07:25:47,796] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:25:48,280] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:25:48,305] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 25, 48, 294857, tzinfo=Timezone('UTC')), 'duration': 320}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:25:48,317] {logging_mixin.py:109} INFO - [2022-08-13 07:25:48,317] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:25:48,329] {logging_mixin.py:109} INFO - [2022-08-13 07:25:48,329] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:25:48,338] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.549 seconds
[2022-08-13 07:25:58,042] {processor.py:163} INFO - Started process (PID=2419) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:25:58,044] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:25:58,045] {logging_mixin.py:109} INFO - [2022-08-13 07:25:58,045] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:25:58,491] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:25:58,517] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 25, 58, 506013, tzinfo=Timezone('UTC')), 'duration': 330}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:25:58,532] {logging_mixin.py:109} INFO - [2022-08-13 07:25:58,532] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:25:58,545] {logging_mixin.py:109} INFO - [2022-08-13 07:25:58,545] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:25:58,555] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.517 seconds
[2022-08-13 07:26:08,520] {processor.py:163} INFO - Started process (PID=2472) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:26:08,522] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:26:08,523] {logging_mixin.py:109} INFO - [2022-08-13 07:26:08,523] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:26:08,952] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:26:08,979] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 26, 8, 967276, tzinfo=Timezone('UTC')), 'duration': 340}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:26:08,992] {logging_mixin.py:109} INFO - [2022-08-13 07:26:08,991] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:26:09,004] {logging_mixin.py:109} INFO - [2022-08-13 07:26:09,004] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:26:09,014] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.499 seconds
[2022-08-13 07:26:18,558] {processor.py:163} INFO - Started process (PID=2487) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:26:18,561] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:26:18,563] {logging_mixin.py:109} INFO - [2022-08-13 07:26:18,562] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:26:19,041] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:26:19,070] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 26, 19, 59066, tzinfo=Timezone('UTC')), 'duration': 350}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:26:19,087] {logging_mixin.py:109} INFO - [2022-08-13 07:26:19,087] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:26:19,103] {logging_mixin.py:109} INFO - [2022-08-13 07:26:19,102] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:26:19,116] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.563 seconds
[2022-08-13 07:26:28,617] {processor.py:163} INFO - Started process (PID=2505) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:26:28,619] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:26:28,620] {logging_mixin.py:109} INFO - [2022-08-13 07:26:28,620] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:26:29,076] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:26:29,102] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 26, 29, 92555, tzinfo=Timezone('UTC')), 'duration': 360}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:26:29,115] {logging_mixin.py:109} INFO - [2022-08-13 07:26:29,114] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:26:29,127] {logging_mixin.py:109} INFO - [2022-08-13 07:26:29,127] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:26:29,138] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.525 seconds
[2022-08-13 07:26:38,816] {processor.py:163} INFO - Started process (PID=2555) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:26:38,819] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:26:38,822] {logging_mixin.py:109} INFO - [2022-08-13 07:26:38,821] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:26:39,352] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:26:39,385] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 26, 39, 369301, tzinfo=Timezone('UTC')), 'duration': 371}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:26:39,399] {logging_mixin.py:109} INFO - [2022-08-13 07:26:39,398] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:26:39,412] {logging_mixin.py:109} INFO - [2022-08-13 07:26:39,412] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:26:39,425] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.613 seconds
[2022-08-13 07:26:49,703] {processor.py:163} INFO - Started process (PID=2562) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:26:49,705] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:26:49,707] {logging_mixin.py:109} INFO - [2022-08-13 07:26:49,706] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:26:50,224] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:26:50,260] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 26, 50, 243002, tzinfo=Timezone('UTC')), 'duration': 382}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:26:50,278] {logging_mixin.py:109} INFO - [2022-08-13 07:26:50,277] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:26:50,297] {logging_mixin.py:109} INFO - [2022-08-13 07:26:50,297] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:26:50,315] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.616 seconds
[2022-08-13 07:27:00,200] {processor.py:163} INFO - Started process (PID=2580) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:27:00,201] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:27:00,203] {logging_mixin.py:109} INFO - [2022-08-13 07:27:00,203] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:27:00,653] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:27:00,690] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 27, 0, 674341, tzinfo=Timezone('UTC')), 'duration': 392}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:27:00,709] {logging_mixin.py:109} INFO - [2022-08-13 07:27:00,709] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:27:00,724] {logging_mixin.py:109} INFO - [2022-08-13 07:27:00,724] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:27:00,733] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.537 seconds
[2022-08-13 07:27:10,462] {processor.py:163} INFO - Started process (PID=2630) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:27:10,463] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:27:10,465] {logging_mixin.py:109} INFO - [2022-08-13 07:27:10,464] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:27:10,928] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:27:10,961] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 27, 10, 947150, tzinfo=Timezone('UTC')), 'duration': 402}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:27:10,983] {logging_mixin.py:109} INFO - [2022-08-13 07:27:10,983] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:27:10,999] {logging_mixin.py:109} INFO - [2022-08-13 07:27:10,998] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:27:11,010] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.553 seconds
[2022-08-13 07:27:20,677] {processor.py:163} INFO - Started process (PID=2646) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:27:20,678] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:27:20,680] {logging_mixin.py:109} INFO - [2022-08-13 07:27:20,680] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:27:21,104] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:27:21,132] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 27, 21, 121316, tzinfo=Timezone('UTC')), 'duration': 412}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:27:21,146] {logging_mixin.py:109} INFO - [2022-08-13 07:27:21,146] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:27:21,161] {logging_mixin.py:109} INFO - [2022-08-13 07:27:21,161] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:27:21,172] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.499 seconds
[2022-08-13 07:27:31,402] {processor.py:163} INFO - Started process (PID=2664) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:27:31,404] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:27:31,405] {logging_mixin.py:109} INFO - [2022-08-13 07:27:31,405] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:27:32,044] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:27:32,095] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 27, 32, 74507, tzinfo=Timezone('UTC')), 'duration': 423}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:27:32,122] {logging_mixin.py:109} INFO - [2022-08-13 07:27:32,122] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:27:32,141] {logging_mixin.py:109} INFO - [2022-08-13 07:27:32,141] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:27:32,159] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.760 seconds
[2022-08-13 07:27:42,056] {processor.py:163} INFO - Started process (PID=2707) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:27:42,057] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:27:42,059] {logging_mixin.py:109} INFO - [2022-08-13 07:27:42,058] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:27:42,441] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:27:42,472] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 27, 42, 461373, tzinfo=Timezone('UTC')), 'duration': 434}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:27:42,488] {logging_mixin.py:109} INFO - [2022-08-13 07:27:42,488] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:27:42,500] {logging_mixin.py:109} INFO - [2022-08-13 07:27:42,500] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:27:42,510] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.457 seconds
[2022-08-13 07:27:52,102] {processor.py:163} INFO - Started process (PID=2722) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:27:52,104] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:27:52,107] {logging_mixin.py:109} INFO - [2022-08-13 07:27:52,106] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:27:52,605] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:27:52,640] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 27, 52, 625874, tzinfo=Timezone('UTC')), 'duration': 444}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:27:52,659] {logging_mixin.py:109} INFO - [2022-08-13 07:27:52,659] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:27:52,676] {logging_mixin.py:109} INFO - [2022-08-13 07:27:52,676] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:27:52,687] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.589 seconds
[2022-08-13 07:28:02,865] {processor.py:163} INFO - Started process (PID=2740) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:28:02,867] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:28:02,868] {logging_mixin.py:109} INFO - [2022-08-13 07:28:02,868] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:28:03,358] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:28:03,387] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 28, 3, 376033, tzinfo=Timezone('UTC')), 'duration': 455}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:28:03,409] {logging_mixin.py:109} INFO - [2022-08-13 07:28:03,409] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:28:03,429] {logging_mixin.py:109} INFO - [2022-08-13 07:28:03,429] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:28:03,442] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.580 seconds
[2022-08-13 07:28:13,121] {processor.py:163} INFO - Started process (PID=2792) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:28:13,123] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:28:13,124] {logging_mixin.py:109} INFO - [2022-08-13 07:28:13,124] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:28:13,661] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:28:13,700] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 28, 13, 681788, tzinfo=Timezone('UTC')), 'duration': 465}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:28:13,722] {logging_mixin.py:109} INFO - [2022-08-13 07:28:13,721] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:28:13,735] {logging_mixin.py:109} INFO - [2022-08-13 07:28:13,735] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:28:13,749] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.653 seconds
[2022-08-13 07:28:23,373] {processor.py:163} INFO - Started process (PID=2806) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:28:23,376] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:28:23,378] {logging_mixin.py:109} INFO - [2022-08-13 07:28:23,378] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:28:23,903] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:28:23,966] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 28, 23, 939421, tzinfo=Timezone('UTC')), 'duration': 475}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:28:24,010] {logging_mixin.py:109} INFO - [2022-08-13 07:28:24,009] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:28:24,056] {logging_mixin.py:109} INFO - [2022-08-13 07:28:24,055] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:28:24,085] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.715 seconds
[2022-08-13 07:28:33,415] {processor.py:163} INFO - Started process (PID=2815) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:28:33,418] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:28:33,420] {logging_mixin.py:109} INFO - [2022-08-13 07:28:33,420] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:28:33,979] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:28:34,020] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 28, 34, 6450, tzinfo=Timezone('UTC')), 'duration': 485}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:28:34,041] {logging_mixin.py:109} INFO - [2022-08-13 07:28:34,041] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:28:34,060] {logging_mixin.py:109} INFO - [2022-08-13 07:28:34,060] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:28:34,074] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.662 seconds
[2022-08-13 07:28:43,521] {processor.py:163} INFO - Started process (PID=2868) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:28:43,524] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:28:43,525] {logging_mixin.py:109} INFO - [2022-08-13 07:28:43,525] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:28:43,938] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:28:43,968] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 28, 43, 956378, tzinfo=Timezone('UTC')), 'duration': 495}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:28:43,985] {logging_mixin.py:109} INFO - [2022-08-13 07:28:43,984] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:28:44,001] {logging_mixin.py:109} INFO - [2022-08-13 07:28:44,001] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:28:44,012] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.494 seconds
[2022-08-13 07:28:53,851] {processor.py:163} INFO - Started process (PID=2882) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:28:53,853] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:28:53,855] {logging_mixin.py:109} INFO - [2022-08-13 07:28:53,854] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:28:54,442] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:28:54,479] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 28, 54, 465058, tzinfo=Timezone('UTC')), 'duration': 506}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:28:54,506] {logging_mixin.py:109} INFO - [2022-08-13 07:28:54,506] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:28:54,531] {logging_mixin.py:109} INFO - [2022-08-13 07:28:54,531] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:28:54,545] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.699 seconds
[2022-08-13 07:29:04,206] {processor.py:163} INFO - Started process (PID=2905) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:29:04,209] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:29:04,211] {logging_mixin.py:109} INFO - [2022-08-13 07:29:04,211] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:29:04,708] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:29:04,736] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 29, 4, 724615, tzinfo=Timezone('UTC')), 'duration': 516}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:29:04,750] {logging_mixin.py:109} INFO - [2022-08-13 07:29:04,750] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:29:04,763] {logging_mixin.py:109} INFO - [2022-08-13 07:29:04,763] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:29:04,775] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.575 seconds
[2022-08-13 07:29:14,356] {processor.py:163} INFO - Started process (PID=2938) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:29:14,360] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:29:14,362] {logging_mixin.py:109} INFO - [2022-08-13 07:29:14,362] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:29:14,907] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:29:14,957] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 29, 14, 938689, tzinfo=Timezone('UTC')), 'duration': 526}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:29:14,990] {logging_mixin.py:109} INFO - [2022-08-13 07:29:14,990] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:29:15,007] {logging_mixin.py:109} INFO - [2022-08-13 07:29:15,007] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:29:15,019] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.667 seconds
[2022-08-13 07:29:24,441] {processor.py:163} INFO - Started process (PID=2958) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:29:24,443] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:29:24,445] {logging_mixin.py:109} INFO - [2022-08-13 07:29:24,444] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:29:24,854] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:29:24,884] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 29, 24, 870402, tzinfo=Timezone('UTC')), 'duration': 536}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:29:24,901] {logging_mixin.py:109} INFO - [2022-08-13 07:29:24,899] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:29:24,913] {logging_mixin.py:109} INFO - [2022-08-13 07:29:24,913] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:29:24,921] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.485 seconds
[2022-08-13 07:29:35,154] {processor.py:163} INFO - Started process (PID=2975) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:29:35,156] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:29:35,158] {logging_mixin.py:109} INFO - [2022-08-13 07:29:35,158] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:29:35,764] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:29:35,799] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 29, 35, 784994, tzinfo=Timezone('UTC')), 'duration': 547}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:29:35,819] {logging_mixin.py:109} INFO - [2022-08-13 07:29:35,818] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:29:35,834] {logging_mixin.py:109} INFO - [2022-08-13 07:29:35,834] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:29:35,845] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.695 seconds
[2022-08-13 07:29:45,775] {processor.py:163} INFO - Started process (PID=3022) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:29:45,779] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:29:45,782] {logging_mixin.py:109} INFO - [2022-08-13 07:29:45,781] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:29:46,565] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:29:46,704] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 29, 46, 602187, tzinfo=Timezone('UTC')), 'duration': 558}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:29:46,750] {logging_mixin.py:109} INFO - [2022-08-13 07:29:46,747] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:29:46,769] {logging_mixin.py:109} INFO - [2022-08-13 07:29:46,768] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:29:46,782] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.014 seconds
[2022-08-13 07:29:55,933] {processor.py:163} INFO - Started process (PID=3042) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:29:55,939] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:29:55,941] {logging_mixin.py:109} INFO - [2022-08-13 07:29:55,941] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:29:56,557] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:29:56,598] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 29, 56, 580473, tzinfo=Timezone('UTC')), 'duration': 568}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:29:56,622] {logging_mixin.py:109} INFO - [2022-08-13 07:29:56,621] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:29:56,642] {logging_mixin.py:109} INFO - [2022-08-13 07:29:56,642] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:29:56,690] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.772 seconds
[2022-08-13 07:30:06,007] {processor.py:163} INFO - Started process (PID=3057) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:30:06,009] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:30:06,011] {logging_mixin.py:109} INFO - [2022-08-13 07:30:06,010] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:30:06,390] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:30:06,418] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 30, 6, 406660, tzinfo=Timezone('UTC')), 'duration': 578}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:30:06,433] {logging_mixin.py:109} INFO - [2022-08-13 07:30:06,433] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:30:06,446] {logging_mixin.py:109} INFO - [2022-08-13 07:30:06,446] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:30:06,457] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.453 seconds
[2022-08-13 07:30:16,618] {processor.py:163} INFO - Started process (PID=3097) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:30:16,621] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:30:16,623] {logging_mixin.py:109} INFO - [2022-08-13 07:30:16,623] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:30:16,986] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:30:17,015] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 30, 17, 2721, tzinfo=Timezone('UTC')), 'duration': 588}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:30:17,032] {logging_mixin.py:109} INFO - [2022-08-13 07:30:17,032] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:30:17,048] {logging_mixin.py:109} INFO - [2022-08-13 07:30:17,048] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:30:17,058] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.444 seconds
[2022-08-13 07:30:27,408] {processor.py:163} INFO - Started process (PID=3119) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:30:27,409] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:30:27,411] {logging_mixin.py:109} INFO - [2022-08-13 07:30:27,411] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:30:27,912] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:30:27,947] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 30, 27, 935004, tzinfo=Timezone('UTC')), 'duration': 599}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:30:27,960] {logging_mixin.py:109} INFO - [2022-08-13 07:30:27,960] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:30:27,975] {logging_mixin.py:109} INFO - [2022-08-13 07:30:27,975] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:30:27,986] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.582 seconds
[2022-08-13 07:30:37,467] {processor.py:163} INFO - Started process (PID=3143) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:30:37,469] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:30:37,470] {logging_mixin.py:109} INFO - [2022-08-13 07:30:37,470] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:30:37,938] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:30:37,973] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 30, 37, 959248, tzinfo=Timezone('UTC')), 'duration': 609}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:30:37,996] {logging_mixin.py:109} INFO - [2022-08-13 07:30:37,996] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:30:38,015] {logging_mixin.py:109} INFO - [2022-08-13 07:30:38,015] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:30:38,026] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.563 seconds
[2022-08-13 07:30:47,850] {processor.py:163} INFO - Started process (PID=3182) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:30:47,852] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:30:47,854] {logging_mixin.py:109} INFO - [2022-08-13 07:30:47,854] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:30:48,373] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:30:48,404] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 30, 48, 393052, tzinfo=Timezone('UTC')), 'duration': 620}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:30:48,420] {logging_mixin.py:109} INFO - [2022-08-13 07:30:48,419] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:30:48,436] {logging_mixin.py:109} INFO - [2022-08-13 07:30:48,436] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:30:48,448] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.601 seconds
[2022-08-13 07:30:58,655] {processor.py:163} INFO - Started process (PID=3205) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:30:58,658] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:30:58,659] {logging_mixin.py:109} INFO - [2022-08-13 07:30:58,659] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:30:59,141] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:30:59,169] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 30, 59, 158636, tzinfo=Timezone('UTC')), 'duration': 630}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:30:59,184] {logging_mixin.py:109} INFO - [2022-08-13 07:30:59,184] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:30:59,197] {logging_mixin.py:109} INFO - [2022-08-13 07:30:59,197] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:30:59,206] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.556 seconds
[2022-08-13 07:31:08,687] {processor.py:163} INFO - Started process (PID=3221) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:31:08,691] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:31:08,693] {logging_mixin.py:109} INFO - [2022-08-13 07:31:08,693] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:31:09,194] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:31:09,224] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 31, 9, 211509, tzinfo=Timezone('UTC')), 'duration': 641}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:31:09,241] {logging_mixin.py:109} INFO - [2022-08-13 07:31:09,241] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:31:09,254] {logging_mixin.py:109} INFO - [2022-08-13 07:31:09,254] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:31:09,264] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.583 seconds
[2022-08-13 07:31:19,208] {processor.py:163} INFO - Started process (PID=3258) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:31:19,211] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:31:19,213] {logging_mixin.py:109} INFO - [2022-08-13 07:31:19,213] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:31:19,648] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:31:19,679] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 31, 19, 665102, tzinfo=Timezone('UTC')), 'duration': 651}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:31:19,695] {logging_mixin.py:109} INFO - [2022-08-13 07:31:19,694] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:31:19,710] {logging_mixin.py:109} INFO - [2022-08-13 07:31:19,709] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:31:19,721] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.519 seconds
[2022-08-13 07:31:29,505] {processor.py:163} INFO - Started process (PID=3280) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:31:29,507] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:31:29,508] {logging_mixin.py:109} INFO - [2022-08-13 07:31:29,508] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:31:30,043] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:31:30,094] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 31, 30, 68546, tzinfo=Timezone('UTC')), 'duration': 661}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:31:30,121] {logging_mixin.py:109} INFO - [2022-08-13 07:31:30,119] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:31:30,138] {logging_mixin.py:109} INFO - [2022-08-13 07:31:30,138] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:31:30,152] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.652 seconds
[2022-08-13 07:31:39,587] {processor.py:163} INFO - Started process (PID=3310) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:31:39,589] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:31:39,591] {logging_mixin.py:109} INFO - [2022-08-13 07:31:39,591] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:31:40,050] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:31:40,088] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 31, 40, 69822, tzinfo=Timezone('UTC')), 'duration': 671}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:31:40,110] {logging_mixin.py:109} INFO - [2022-08-13 07:31:40,109] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:31:40,129] {logging_mixin.py:109} INFO - [2022-08-13 07:31:40,129] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:31:40,146] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.563 seconds
[2022-08-13 07:31:50,058] {processor.py:163} INFO - Started process (PID=3340) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:31:50,060] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:31:50,062] {logging_mixin.py:109} INFO - [2022-08-13 07:31:50,062] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:31:50,562] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:31:50,601] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 31, 50, 584043, tzinfo=Timezone('UTC')), 'duration': 682}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:31:50,619] {logging_mixin.py:109} INFO - [2022-08-13 07:31:50,618] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:31:50,634] {logging_mixin.py:109} INFO - [2022-08-13 07:31:50,634] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:31:50,645] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.591 seconds
[2022-08-13 07:32:00,618] {processor.py:163} INFO - Started process (PID=3355) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:32:00,620] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:32:00,622] {logging_mixin.py:109} INFO - [2022-08-13 07:32:00,622] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:32:01,083] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:32:01,118] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 32, 1, 102160, tzinfo=Timezone('UTC')), 'duration': 692}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:32:01,139] {logging_mixin.py:109} INFO - [2022-08-13 07:32:01,139] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:32:01,153] {logging_mixin.py:109} INFO - [2022-08-13 07:32:01,153] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:32:01,165] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.553 seconds
[2022-08-13 07:32:10,973] {processor.py:163} INFO - Started process (PID=3385) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:32:10,976] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:32:10,977] {logging_mixin.py:109} INFO - [2022-08-13 07:32:10,977] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:32:11,426] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:32:11,456] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 32, 11, 444574, tzinfo=Timezone('UTC')), 'duration': 703}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:32:11,471] {logging_mixin.py:109} INFO - [2022-08-13 07:32:11,470] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:32:11,483] {logging_mixin.py:109} INFO - [2022-08-13 07:32:11,483] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:32:11,495] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.525 seconds
[2022-08-13 07:32:21,890] {processor.py:163} INFO - Started process (PID=3417) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:32:21,892] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:32:21,895] {logging_mixin.py:109} INFO - [2022-08-13 07:32:21,894] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:32:22,359] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:32:22,394] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 32, 22, 378426, tzinfo=Timezone('UTC')), 'duration': 714}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:32:22,415] {logging_mixin.py:109} INFO - [2022-08-13 07:32:22,413] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:32:22,433] {logging_mixin.py:109} INFO - [2022-08-13 07:32:22,433] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:32:22,446] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.559 seconds
[2022-08-13 07:32:31,960] {processor.py:163} INFO - Started process (PID=3440) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:32:31,962] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:32:31,964] {logging_mixin.py:109} INFO - [2022-08-13 07:32:31,964] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:32:32,388] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:32:32,422] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 32, 32, 409129, tzinfo=Timezone('UTC')), 'duration': 724}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:32:32,440] {logging_mixin.py:109} INFO - [2022-08-13 07:32:32,439] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:32:32,452] {logging_mixin.py:109} INFO - [2022-08-13 07:32:32,452] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:32:32,461] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.505 seconds
[2022-08-13 07:32:42,598] {processor.py:163} INFO - Started process (PID=3473) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:32:42,602] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:32:42,603] {logging_mixin.py:109} INFO - [2022-08-13 07:32:42,603] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:32:43,089] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:32:43,123] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 32, 43, 108397, tzinfo=Timezone('UTC')), 'duration': 734}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:32:43,139] {logging_mixin.py:109} INFO - [2022-08-13 07:32:43,138] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:32:43,161] {logging_mixin.py:109} INFO - [2022-08-13 07:32:43,160] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:32:43,174] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.581 seconds
[2022-08-13 07:32:53,157] {processor.py:163} INFO - Started process (PID=3493) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:32:53,159] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:32:53,161] {logging_mixin.py:109} INFO - [2022-08-13 07:32:53,161] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:32:53,570] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:32:53,600] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 32, 53, 588081, tzinfo=Timezone('UTC')), 'duration': 745}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:32:53,613] {logging_mixin.py:109} INFO - [2022-08-13 07:32:53,613] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:32:53,626] {logging_mixin.py:109} INFO - [2022-08-13 07:32:53,626] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:32:53,635] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.482 seconds
[2022-08-13 07:33:03,264] {processor.py:163} INFO - Started process (PID=3516) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:33:03,266] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:33:03,267] {logging_mixin.py:109} INFO - [2022-08-13 07:33:03,267] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:33:03,678] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:33:03,706] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 33, 3, 693926, tzinfo=Timezone('UTC')), 'duration': 755}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:33:03,721] {logging_mixin.py:109} INFO - [2022-08-13 07:33:03,721] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:33:03,733] {logging_mixin.py:109} INFO - [2022-08-13 07:33:03,733] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:33:03,743] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.483 seconds
[2022-08-13 07:33:13,837] {processor.py:163} INFO - Started process (PID=3548) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:33:13,839] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:33:13,842] {logging_mixin.py:109} INFO - [2022-08-13 07:33:13,842] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:33:14,262] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:33:14,294] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 33, 14, 281334, tzinfo=Timezone('UTC')), 'duration': 766}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:33:14,307] {logging_mixin.py:109} INFO - [2022-08-13 07:33:14,306] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:33:14,321] {logging_mixin.py:109} INFO - [2022-08-13 07:33:14,321] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:33:14,333] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.500 seconds
[2022-08-13 07:33:24,731] {processor.py:163} INFO - Started process (PID=3577) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:33:24,734] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:33:24,737] {logging_mixin.py:109} INFO - [2022-08-13 07:33:24,736] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:33:25,365] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:33:25,402] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 33, 25, 385756, tzinfo=Timezone('UTC')), 'duration': 777}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:33:25,420] {logging_mixin.py:109} INFO - [2022-08-13 07:33:25,420] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:33:25,435] {logging_mixin.py:109} INFO - [2022-08-13 07:33:25,435] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:33:25,450] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.724 seconds
[2022-08-13 07:33:34,845] {processor.py:163} INFO - Started process (PID=3600) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:33:34,850] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:33:34,853] {logging_mixin.py:109} INFO - [2022-08-13 07:33:34,852] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:33:35,527] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:33:35,574] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 33, 35, 554325, tzinfo=Timezone('UTC')), 'duration': 3}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:33:35,616] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 33, 35, 601074, tzinfo=Timezone('UTC')), 'duration': 787}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:33:35,632] {logging_mixin.py:109} INFO - [2022-08-13 07:33:35,632] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:33:35,653] {logging_mixin.py:109} INFO - [2022-08-13 07:33:35,653] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:33:35,670] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.835 seconds
[2022-08-13 07:33:45,615] {processor.py:163} INFO - Started process (PID=3623) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:33:45,618] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:33:45,619] {logging_mixin.py:109} INFO - [2022-08-13 07:33:45,619] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:33:46,063] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:33:46,091] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 33, 46, 79265, tzinfo=Timezone('UTC')), 'duration': 14}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:33:46,113] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 33, 46, 107097, tzinfo=Timezone('UTC')), 'duration': 797}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:33:46,123] {logging_mixin.py:109} INFO - [2022-08-13 07:33:46,123] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:33:46,136] {logging_mixin.py:109} INFO - [2022-08-13 07:33:46,136] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:33:46,146] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.534 seconds
[2022-08-13 07:33:56,229] {processor.py:163} INFO - Started process (PID=3652) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:33:56,231] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:33:56,232] {logging_mixin.py:109} INFO - [2022-08-13 07:33:56,232] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:33:56,690] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:33:56,728] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 33, 56, 711874, tzinfo=Timezone('UTC')), 'duration': 25}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:33:56,761] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 33, 56, 750908, tzinfo=Timezone('UTC')), 'duration': 808}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:33:56,775] {logging_mixin.py:109} INFO - [2022-08-13 07:33:56,775] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:33:56,792] {logging_mixin.py:109} INFO - [2022-08-13 07:33:56,791] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:33:56,804] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.580 seconds
[2022-08-13 07:34:07,079] {processor.py:163} INFO - Started process (PID=3675) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:34:07,081] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:34:07,083] {logging_mixin.py:109} INFO - [2022-08-13 07:34:07,082] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:34:07,503] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:34:07,534] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 34, 7, 521382, tzinfo=Timezone('UTC')), 'duration': 35}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:34:07,564] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 34, 7, 554993, tzinfo=Timezone('UTC')), 'duration': 819}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:34:07,576] {logging_mixin.py:109} INFO - [2022-08-13 07:34:07,575] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:34:07,589] {logging_mixin.py:109} INFO - [2022-08-13 07:34:07,589] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:34:07,599] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.523 seconds
[2022-08-13 07:34:17,350] {processor.py:163} INFO - Started process (PID=3711) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:34:17,352] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:34:17,354] {logging_mixin.py:109} INFO - [2022-08-13 07:34:17,354] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:34:17,883] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:34:17,956] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 34, 17, 933135, tzinfo=Timezone('UTC')), 'duration': 46}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:34:18,001] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 34, 17, 980961, tzinfo=Timezone('UTC')), 'duration': 829}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:34:18,020] {logging_mixin.py:109} INFO - [2022-08-13 07:34:18,018] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:34:18,040] {logging_mixin.py:109} INFO - [2022-08-13 07:34:18,040] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:34:18,051] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.705 seconds
[2022-08-13 07:34:27,974] {processor.py:163} INFO - Started process (PID=3736) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:34:27,976] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:34:27,977] {logging_mixin.py:109} INFO - [2022-08-13 07:34:27,977] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:34:28,412] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:34:28,444] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 34, 28, 431163, tzinfo=Timezone('UTC')), 'duration': 56}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:34:28,474] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 34, 28, 463282, tzinfo=Timezone('UTC')), 'duration': 840}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:34:28,496] {logging_mixin.py:109} INFO - [2022-08-13 07:34:28,495] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:34:28,513] {logging_mixin.py:109} INFO - [2022-08-13 07:34:28,513] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:34:28,525] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.558 seconds
[2022-08-13 07:34:38,031] {processor.py:163} INFO - Started process (PID=3750) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:34:38,033] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:34:38,035] {logging_mixin.py:109} INFO - [2022-08-13 07:34:38,035] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:34:38,425] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:34:38,450] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 34, 38, 440323, tzinfo=Timezone('UTC')), 'duration': 66}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:34:38,472] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 34, 38, 465544, tzinfo=Timezone('UTC')), 'duration': 850}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:34:38,482] {logging_mixin.py:109} INFO - [2022-08-13 07:34:38,482] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:34:38,495] {logging_mixin.py:109} INFO - [2022-08-13 07:34:38,494] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:34:38,505] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.477 seconds
[2022-08-13 07:34:48,334] {processor.py:163} INFO - Started process (PID=3787) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:34:48,337] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:34:48,339] {logging_mixin.py:109} INFO - [2022-08-13 07:34:48,339] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:34:48,783] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:34:48,811] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 34, 48, 800376, tzinfo=Timezone('UTC')), 'duration': 77}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:34:48,840] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 34, 48, 829417, tzinfo=Timezone('UTC')), 'duration': 860}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:34:48,851] {logging_mixin.py:109} INFO - [2022-08-13 07:34:48,851] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:34:48,867] {logging_mixin.py:109} INFO - [2022-08-13 07:34:48,867] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:34:48,881] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.551 seconds
[2022-08-13 07:34:58,556] {processor.py:163} INFO - Started process (PID=3812) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:34:58,558] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:34:58,559] {logging_mixin.py:109} INFO - [2022-08-13 07:34:58,559] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:34:58,920] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:34:58,946] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 34, 58, 935946, tzinfo=Timezone('UTC')), 'duration': 87}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:34:58,969] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 34, 58, 960509, tzinfo=Timezone('UTC')), 'duration': 870}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:34:58,979] {logging_mixin.py:109} INFO - [2022-08-13 07:34:58,979] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:34:58,993] {logging_mixin.py:109} INFO - [2022-08-13 07:34:58,993] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:34:59,003] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.450 seconds
[2022-08-13 07:35:09,354] {processor.py:163} INFO - Started process (PID=3835) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:35:09,356] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:35:09,358] {logging_mixin.py:109} INFO - [2022-08-13 07:35:09,358] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:35:09,798] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:35:09,827] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 35, 9, 815302, tzinfo=Timezone('UTC')), 'duration': 98}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:35:09,851] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 35, 9, 842783, tzinfo=Timezone('UTC')), 'duration': 881}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:35:09,861] {logging_mixin.py:109} INFO - [2022-08-13 07:35:09,861] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:35:09,879] {logging_mixin.py:109} INFO - [2022-08-13 07:35:09,879] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:35:09,889] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.541 seconds
[2022-08-13 07:35:19,406] {processor.py:163} INFO - Started process (PID=3880) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:35:19,408] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:35:19,410] {logging_mixin.py:109} INFO - [2022-08-13 07:35:19,410] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:35:19,823] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:35:19,856] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 35, 19, 844609, tzinfo=Timezone('UTC')), 'duration': 108}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:35:19,886] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 35, 19, 876838, tzinfo=Timezone('UTC')), 'duration': 891}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:35:19,898] {logging_mixin.py:109} INFO - [2022-08-13 07:35:19,898] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:35:19,914] {logging_mixin.py:109} INFO - [2022-08-13 07:35:19,914] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:35:19,928] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.527 seconds
[2022-08-13 07:35:29,469] {processor.py:163} INFO - Started process (PID=3888) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:35:29,471] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:35:29,472] {logging_mixin.py:109} INFO - [2022-08-13 07:35:29,472] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:35:29,861] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:35:29,893] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 35, 29, 878156, tzinfo=Timezone('UTC')), 'duration': 118}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:35:29,919] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 35, 29, 911319, tzinfo=Timezone('UTC')), 'duration': 901}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:35:29,931] {logging_mixin.py:109} INFO - [2022-08-13 07:35:29,930] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:35:29,943] {logging_mixin.py:109} INFO - [2022-08-13 07:35:29,943] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:35:29,954] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.488 seconds
[2022-08-13 07:35:39,814] {processor.py:163} INFO - Started process (PID=3910) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:35:39,815] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:35:39,817] {logging_mixin.py:109} INFO - [2022-08-13 07:35:39,817] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:35:40,184] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:35:40,214] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 35, 40, 201468, tzinfo=Timezone('UTC')), 'duration': 128}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:35:40,237] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 35, 40, 231324, tzinfo=Timezone('UTC')), 'duration': 912}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:35:40,246] {logging_mixin.py:109} INFO - [2022-08-13 07:35:40,245] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:35:40,257] {logging_mixin.py:109} INFO - [2022-08-13 07:35:40,257] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:35:40,264] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.454 seconds
[2022-08-13 07:35:50,701] {processor.py:163} INFO - Started process (PID=3956) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:35:50,703] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:35:50,705] {logging_mixin.py:109} INFO - [2022-08-13 07:35:50,705] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:35:51,792] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:35:51,835] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 35, 51, 813899, tzinfo=Timezone('UTC')), 'duration': 140}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:35:51,868] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 35, 51, 859512, tzinfo=Timezone('UTC')), 'duration': 923}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:35:51,880] {logging_mixin.py:109} INFO - [2022-08-13 07:35:51,880] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:35:51,894] {logging_mixin.py:109} INFO - [2022-08-13 07:35:51,894] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:35:51,903] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.206 seconds
[2022-08-13 07:36:00,772] {processor.py:163} INFO - Started process (PID=3972) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:36:00,774] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:36:00,775] {logging_mixin.py:109} INFO - [2022-08-13 07:36:00,775] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:36:01,247] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:36:01,275] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 36, 1, 264115, tzinfo=Timezone('UTC')), 'duration': 149}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:36:01,306] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 36, 1, 297332, tzinfo=Timezone('UTC')), 'duration': 933}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:36:01,316] {logging_mixin.py:109} INFO - [2022-08-13 07:36:01,316] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:36:01,329] {logging_mixin.py:109} INFO - [2022-08-13 07:36:01,329] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:36:01,337] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.569 seconds
[2022-08-13 07:36:10,912] {processor.py:163} INFO - Started process (PID=3997) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:36:10,914] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:36:10,916] {logging_mixin.py:109} INFO - [2022-08-13 07:36:10,915] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:36:11,341] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:36:11,368] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 36, 11, 356791, tzinfo=Timezone('UTC')), 'duration': 159}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:36:11,391] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 36, 11, 384331, tzinfo=Timezone('UTC')), 'duration': 943}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:36:11,401] {logging_mixin.py:109} INFO - [2022-08-13 07:36:11,400] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:36:11,413] {logging_mixin.py:109} INFO - [2022-08-13 07:36:11,413] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:36:11,423] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.515 seconds
[2022-08-13 07:36:20,923] {processor.py:163} INFO - Started process (PID=4041) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:36:20,924] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:36:20,926] {logging_mixin.py:109} INFO - [2022-08-13 07:36:20,925] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:36:21,397] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:36:21,428] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 36, 21, 415235, tzinfo=Timezone('UTC')), 'duration': 169}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:36:21,454] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 36, 21, 445472, tzinfo=Timezone('UTC')), 'duration': 953}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:36:21,471] {logging_mixin.py:109} INFO - [2022-08-13 07:36:21,471] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:36:21,487] {logging_mixin.py:109} INFO - [2022-08-13 07:36:21,487] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:36:21,499] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.580 seconds
[2022-08-13 07:36:31,646] {processor.py:163} INFO - Started process (PID=4048) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:36:31,649] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:36:31,653] {logging_mixin.py:109} INFO - [2022-08-13 07:36:31,652] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:36:32,117] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:36:32,145] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 36, 32, 135058, tzinfo=Timezone('UTC')), 'duration': 180}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:36:32,183] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 36, 32, 165876, tzinfo=Timezone('UTC')), 'duration': 963}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:36:32,192] {logging_mixin.py:109} INFO - [2022-08-13 07:36:32,192] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:36:32,204] {logging_mixin.py:109} INFO - [2022-08-13 07:36:32,204] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:36:32,214] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.576 seconds
[2022-08-13 07:36:42,434] {processor.py:163} INFO - Started process (PID=4072) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:36:42,437] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:36:42,438] {logging_mixin.py:109} INFO - [2022-08-13 07:36:42,438] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:36:42,892] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:36:42,941] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 36, 42, 928631, tzinfo=Timezone('UTC')), 'duration': 191}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:36:42,966] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 36, 42, 956953, tzinfo=Timezone('UTC')), 'duration': 974}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:36:42,976] {logging_mixin.py:109} INFO - [2022-08-13 07:36:42,976] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:36:42,990] {logging_mixin.py:109} INFO - [2022-08-13 07:36:42,990] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:36:42,998] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.568 seconds
[2022-08-13 07:36:52,753] {processor.py:163} INFO - Started process (PID=4116) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:36:52,756] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:36:52,758] {logging_mixin.py:109} INFO - [2022-08-13 07:36:52,758] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:36:53,214] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:36:53,243] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 36, 53, 230153, tzinfo=Timezone('UTC')), 'duration': 201}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:36:53,267] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 36, 53, 259720, tzinfo=Timezone('UTC')), 'duration': 985}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:36:53,281] {logging_mixin.py:109} INFO - [2022-08-13 07:36:53,281] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:36:53,293] {logging_mixin.py:109} INFO - [2022-08-13 07:36:53,293] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:36:53,303] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.554 seconds
[2022-08-13 07:37:03,232] {processor.py:163} INFO - Started process (PID=4135) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:37:03,235] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:37:03,236] {logging_mixin.py:109} INFO - [2022-08-13 07:37:03,236] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:37:03,703] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:37:03,734] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 37, 3, 722896, tzinfo=Timezone('UTC')), 'duration': 212}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:37:03,771] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 37, 3, 758659, tzinfo=Timezone('UTC')), 'duration': 995}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:37:03,785] {logging_mixin.py:109} INFO - [2022-08-13 07:37:03,784] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:37:03,801] {logging_mixin.py:109} INFO - [2022-08-13 07:37:03,801] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:37:03,817] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.589 seconds
[2022-08-13 07:37:13,369] {processor.py:163} INFO - Started process (PID=4163) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:37:13,371] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:37:13,373] {logging_mixin.py:109} INFO - [2022-08-13 07:37:13,373] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:37:13,827] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:37:13,856] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 37, 13, 845654, tzinfo=Timezone('UTC')), 'duration': 222}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:37:13,878] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 37, 13, 871712, tzinfo=Timezone('UTC')), 'duration': 1005}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:37:13,888] {logging_mixin.py:109} INFO - [2022-08-13 07:37:13,888] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:37:13,900] {logging_mixin.py:109} INFO - [2022-08-13 07:37:13,900] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:37:13,909] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.544 seconds
[2022-08-13 07:37:23,537] {processor.py:163} INFO - Started process (PID=4202) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:37:23,540] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:37:23,541] {logging_mixin.py:109} INFO - [2022-08-13 07:37:23,541] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:37:23,986] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:37:24,016] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 37, 24, 3446, tzinfo=Timezone('UTC')), 'duration': 232}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:37:24,043] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 37, 24, 33027, tzinfo=Timezone('UTC')), 'duration': 1015}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:37:24,053] {logging_mixin.py:109} INFO - [2022-08-13 07:37:24,052] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:37:24,064] {logging_mixin.py:109} INFO - [2022-08-13 07:37:24,064] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:37:24,072] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.538 seconds
[2022-08-13 07:37:33,704] {processor.py:163} INFO - Started process (PID=4210) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:37:33,707] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:37:33,708] {logging_mixin.py:109} INFO - [2022-08-13 07:37:33,708] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:37:34,169] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:37:34,195] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 37, 34, 184514, tzinfo=Timezone('UTC')), 'duration': 242}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:37:34,222] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 37, 34, 213404, tzinfo=Timezone('UTC')), 'duration': 1026}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:37:34,232] {logging_mixin.py:109} INFO - [2022-08-13 07:37:34,232] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:37:34,249] {logging_mixin.py:109} INFO - [2022-08-13 07:37:34,249] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:37:34,259] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.558 seconds
[2022-08-13 07:37:43,883] {processor.py:163} INFO - Started process (PID=4232) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:37:43,885] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:37:43,886] {logging_mixin.py:109} INFO - [2022-08-13 07:37:43,886] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:37:44,366] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:37:44,394] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 37, 44, 382430, tzinfo=Timezone('UTC')), 'duration': 252}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:37:44,419] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 37, 44, 409807, tzinfo=Timezone('UTC')), 'duration': 1036}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:37:44,431] {logging_mixin.py:109} INFO - [2022-08-13 07:37:44,430] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:37:44,443] {logging_mixin.py:109} INFO - [2022-08-13 07:37:44,443] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:37:44,453] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.573 seconds
[2022-08-13 07:37:54,352] {processor.py:163} INFO - Started process (PID=4277) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:37:54,354] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:37:54,356] {logging_mixin.py:109} INFO - [2022-08-13 07:37:54,356] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:37:54,829] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:37:54,856] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 37, 54, 844613, tzinfo=Timezone('UTC')), 'duration': 263}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:37:54,885] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 37, 54, 876062, tzinfo=Timezone('UTC')), 'duration': 1046}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:37:54,897] {logging_mixin.py:109} INFO - [2022-08-13 07:37:54,897] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:37:54,910] {logging_mixin.py:109} INFO - [2022-08-13 07:37:54,910] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:37:54,919] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.571 seconds
[2022-08-13 07:38:04,901] {processor.py:163} INFO - Started process (PID=4295) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:38:04,903] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:38:04,905] {logging_mixin.py:109} INFO - [2022-08-13 07:38:04,905] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:38:05,384] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:38:05,419] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 38, 5, 404437, tzinfo=Timezone('UTC')), 'duration': 273}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:38:05,448] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 38, 5, 438157, tzinfo=Timezone('UTC')), 'duration': 1057}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:38:05,469] {logging_mixin.py:109} INFO - [2022-08-13 07:38:05,468] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:38:05,482] {logging_mixin.py:109} INFO - [2022-08-13 07:38:05,482] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:38:05,495] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.597 seconds
[2022-08-13 07:38:15,114] {processor.py:163} INFO - Started process (PID=4317) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:38:15,116] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:38:15,117] {logging_mixin.py:109} INFO - [2022-08-13 07:38:15,117] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:38:15,606] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:38:15,641] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 38, 15, 626449, tzinfo=Timezone('UTC')), 'duration': 284}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:38:15,686] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 38, 15, 674133, tzinfo=Timezone('UTC')), 'duration': 1067}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:38:15,703] {logging_mixin.py:109} INFO - [2022-08-13 07:38:15,702] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:38:15,719] {logging_mixin.py:109} INFO - [2022-08-13 07:38:15,719] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:38:15,734] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.623 seconds
[2022-08-13 07:38:25,608] {processor.py:163} INFO - Started process (PID=4359) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:38:25,610] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:38:25,612] {logging_mixin.py:109} INFO - [2022-08-13 07:38:25,612] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:38:26,081] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:38:26,114] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 38, 26, 100459, tzinfo=Timezone('UTC')), 'duration': 294}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:38:26,145] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 38, 26, 137788, tzinfo=Timezone('UTC')), 'duration': 1077}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:38:26,156] {logging_mixin.py:109} INFO - [2022-08-13 07:38:26,156] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:38:26,168] {logging_mixin.py:109} INFO - [2022-08-13 07:38:26,168] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:38:26,178] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.574 seconds
[2022-08-13 07:38:36,209] {processor.py:163} INFO - Started process (PID=4370) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:38:36,211] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:38:36,213] {logging_mixin.py:109} INFO - [2022-08-13 07:38:36,212] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:38:36,714] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:38:36,746] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 38, 36, 734852, tzinfo=Timezone('UTC')), 'duration': 305}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:38:36,773] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 38, 36, 764332, tzinfo=Timezone('UTC')), 'duration': 1088}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:38:36,783] {logging_mixin.py:109} INFO - [2022-08-13 07:38:36,783] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:38:36,795] {logging_mixin.py:109} INFO - [2022-08-13 07:38:36,795] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:38:36,805] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.598 seconds
[2022-08-13 07:38:46,261] {processor.py:163} INFO - Started process (PID=4399) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:38:46,267] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:38:46,269] {logging_mixin.py:109} INFO - [2022-08-13 07:38:46,269] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:38:46,735] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:38:46,790] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 38, 46, 772370, tzinfo=Timezone('UTC')), 'duration': 315}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:38:46,833] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 38, 46, 820511, tzinfo=Timezone('UTC')), 'duration': 1098}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:38:46,844] {logging_mixin.py:109} INFO - [2022-08-13 07:38:46,844] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:38:46,858] {logging_mixin.py:109} INFO - [2022-08-13 07:38:46,858] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:38:46,868] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.611 seconds
[2022-08-13 07:38:56,440] {processor.py:163} INFO - Started process (PID=4437) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:38:56,442] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:38:56,443] {logging_mixin.py:109} INFO - [2022-08-13 07:38:56,443] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:38:56,870] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:38:56,901] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 38, 56, 887067, tzinfo=Timezone('UTC')), 'duration': 325}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:38:56,924] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 38, 56, 917506, tzinfo=Timezone('UTC')), 'duration': 1108}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:38:56,935] {logging_mixin.py:109} INFO - [2022-08-13 07:38:56,934] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:38:56,947] {logging_mixin.py:109} INFO - [2022-08-13 07:38:56,947] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:38:56,956] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.520 seconds
[2022-08-13 07:39:06,983] {processor.py:163} INFO - Started process (PID=4455) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:39:06,985] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:39:06,987] {logging_mixin.py:109} INFO - [2022-08-13 07:39:06,986] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:39:07,408] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:39:07,436] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 39, 7, 424954, tzinfo=Timezone('UTC')), 'duration': 335}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:39:07,460] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 39, 7, 452342, tzinfo=Timezone('UTC')), 'duration': 1119}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:39:07,470] {logging_mixin.py:109} INFO - [2022-08-13 07:39:07,470] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:39:07,483] {logging_mixin.py:109} INFO - [2022-08-13 07:39:07,483] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:39:07,494] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.513 seconds
[2022-08-13 07:39:17,044] {processor.py:163} INFO - Started process (PID=4487) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:39:17,046] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:39:17,048] {logging_mixin.py:109} INFO - [2022-08-13 07:39:17,048] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:39:17,497] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:39:17,527] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 39, 17, 516104, tzinfo=Timezone('UTC')), 'duration': 345}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:39:17,555] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 39, 17, 544488, tzinfo=Timezone('UTC')), 'duration': 1129}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:39:17,566] {logging_mixin.py:109} INFO - [2022-08-13 07:39:17,566] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:39:17,578] {logging_mixin.py:109} INFO - [2022-08-13 07:39:17,578] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:39:17,589] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.549 seconds
[2022-08-13 07:39:27,151] {processor.py:163} INFO - Started process (PID=4513) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:39:27,154] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:39:27,155] {logging_mixin.py:109} INFO - [2022-08-13 07:39:27,155] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:39:27,577] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:39:27,606] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 39, 27, 593678, tzinfo=Timezone('UTC')), 'duration': 355}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:39:27,631] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 39, 27, 622462, tzinfo=Timezone('UTC')), 'duration': 1139}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:39:27,641] {logging_mixin.py:109} INFO - [2022-08-13 07:39:27,640] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:39:27,652] {logging_mixin.py:109} INFO - [2022-08-13 07:39:27,652] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:39:27,662] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.515 seconds
[2022-08-13 07:39:37,692] {processor.py:163} INFO - Started process (PID=4531) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:39:37,694] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:39:37,696] {logging_mixin.py:109} INFO - [2022-08-13 07:39:37,696] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:39:38,094] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:39:38,124] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 39, 38, 111032, tzinfo=Timezone('UTC')), 'duration': 366}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:39:38,151] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 39, 38, 144549, tzinfo=Timezone('UTC')), 'duration': 1149}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:39:38,162] {logging_mixin.py:109} INFO - [2022-08-13 07:39:38,162] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:39:38,173] {logging_mixin.py:109} INFO - [2022-08-13 07:39:38,173] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:39:38,182] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.493 seconds
[2022-08-13 07:39:47,905] {processor.py:163} INFO - Started process (PID=4562) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:39:47,907] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:39:47,909] {logging_mixin.py:109} INFO - [2022-08-13 07:39:47,909] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:39:48,370] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:39:48,400] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 39, 48, 388584, tzinfo=Timezone('UTC')), 'duration': 376}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:39:48,430] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 39, 48, 419273, tzinfo=Timezone('UTC')), 'duration': 1160}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:39:48,440] {logging_mixin.py:109} INFO - [2022-08-13 07:39:48,440] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:39:48,454] {logging_mixin.py:109} INFO - [2022-08-13 07:39:48,454] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:39:48,464] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.564 seconds
[2022-08-13 07:39:58,058] {processor.py:163} INFO - Started process (PID=4599) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:39:58,060] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:39:58,062] {logging_mixin.py:109} INFO - [2022-08-13 07:39:58,062] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:39:58,536] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:39:58,586] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 39, 58, 572949, tzinfo=Timezone('UTC')), 'duration': 386}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:39:58,628] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 39, 58, 612082, tzinfo=Timezone('UTC')), 'duration': 1170}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:39:58,644] {logging_mixin.py:109} INFO - [2022-08-13 07:39:58,644] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:39:58,661] {logging_mixin.py:109} INFO - [2022-08-13 07:39:58,661] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:39:58,676] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.622 seconds
[2022-08-13 07:40:09,063] {processor.py:163} INFO - Started process (PID=4618) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:40:09,085] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:40:09,086] {logging_mixin.py:109} INFO - [2022-08-13 07:40:09,086] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:40:09,834] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:40:09,874] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 40, 9, 861065, tzinfo=Timezone('UTC')), 'duration': 398}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:40:09,904] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 40, 9, 894291, tzinfo=Timezone('UTC')), 'duration': 1181}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:40:09,917] {logging_mixin.py:109} INFO - [2022-08-13 07:40:09,917] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:40:09,930] {logging_mixin.py:109} INFO - [2022-08-13 07:40:09,930] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:40:09,943] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.889 seconds
[2022-08-13 07:40:20,034] {processor.py:163} INFO - Started process (PID=4644) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:40:20,038] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:40:20,040] {logging_mixin.py:109} INFO - [2022-08-13 07:40:20,040] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:40:20,506] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:40:20,538] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 40, 20, 524283, tzinfo=Timezone('UTC')), 'duration': 408}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:40:20,564] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 40, 20, 555195, tzinfo=Timezone('UTC')), 'duration': 1192}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:40:20,575] {logging_mixin.py:109} INFO - [2022-08-13 07:40:20,575] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:40:20,588] {logging_mixin.py:109} INFO - [2022-08-13 07:40:20,588] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:40:20,598] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.567 seconds
[2022-08-13 07:40:30,760] {processor.py:163} INFO - Started process (PID=4676) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:40:30,763] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:40:30,765] {logging_mixin.py:109} INFO - [2022-08-13 07:40:30,764] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:40:31,173] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:40:31,205] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 40, 31, 192410, tzinfo=Timezone('UTC')), 'duration': 419}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:40:31,231] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 40, 31, 222381, tzinfo=Timezone('UTC')), 'duration': 1203}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:40:31,241] {logging_mixin.py:109} INFO - [2022-08-13 07:40:31,241] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:40:31,253] {logging_mixin.py:109} INFO - [2022-08-13 07:40:31,252] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:40:31,261] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.505 seconds
[2022-08-13 07:40:40,883] {processor.py:163} INFO - Started process (PID=4699) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:40:40,885] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:40:40,887] {logging_mixin.py:109} INFO - [2022-08-13 07:40:40,887] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:40:41,256] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:40:41,285] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 40, 41, 272520, tzinfo=Timezone('UTC')), 'duration': 429}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:40:41,308] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 40, 41, 302015, tzinfo=Timezone('UTC')), 'duration': 1213}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:40:41,318] {logging_mixin.py:109} INFO - [2022-08-13 07:40:41,318] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:40:41,332] {logging_mixin.py:109} INFO - [2022-08-13 07:40:41,331] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:40:41,342] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.463 seconds
[2022-08-13 07:40:51,729] {processor.py:163} INFO - Started process (PID=4731) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:40:51,731] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:40:51,732] {logging_mixin.py:109} INFO - [2022-08-13 07:40:51,732] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:40:52,104] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:40:52,131] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 40, 52, 120456, tzinfo=Timezone('UTC')), 'duration': 440}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:40:52,154] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 40, 52, 146752, tzinfo=Timezone('UTC')), 'duration': 1223}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:40:52,164] {logging_mixin.py:109} INFO - [2022-08-13 07:40:52,164] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:40:52,177] {logging_mixin.py:109} INFO - [2022-08-13 07:40:52,177] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:40:52,186] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.461 seconds
[2022-08-13 07:41:02,119] {processor.py:163} INFO - Started process (PID=4761) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:41:02,121] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:41:02,123] {logging_mixin.py:109} INFO - [2022-08-13 07:41:02,123] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:41:02,569] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:41:02,601] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 41, 2, 586881, tzinfo=Timezone('UTC')), 'duration': 450}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:41:02,628] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 41, 2, 620194, tzinfo=Timezone('UTC')), 'duration': 1234}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:41:02,639] {logging_mixin.py:109} INFO - [2022-08-13 07:41:02,639] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:41:02,652] {logging_mixin.py:109} INFO - [2022-08-13 07:41:02,652] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:41:02,662] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.547 seconds
[2022-08-13 07:41:12,213] {processor.py:163} INFO - Started process (PID=4784) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:41:12,215] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:41:12,216] {logging_mixin.py:109} INFO - [2022-08-13 07:41:12,216] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:41:12,673] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:41:12,703] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 41, 12, 690056, tzinfo=Timezone('UTC')), 'duration': 461}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:41:12,730] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 41, 12, 720795, tzinfo=Timezone('UTC')), 'duration': 1244}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:41:12,741] {logging_mixin.py:109} INFO - [2022-08-13 07:41:12,741] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:41:12,756] {logging_mixin.py:109} INFO - [2022-08-13 07:41:12,756] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:41:12,767] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.559 seconds
[2022-08-13 07:41:22,547] {processor.py:163} INFO - Started process (PID=4807) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:41:22,550] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:41:22,551] {logging_mixin.py:109} INFO - [2022-08-13 07:41:22,551] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:41:22,921] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:41:22,952] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 41, 22, 939015, tzinfo=Timezone('UTC')), 'duration': 471}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:41:22,976] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 41, 22, 967983, tzinfo=Timezone('UTC')), 'duration': 1254}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:41:22,987] {logging_mixin.py:109} INFO - [2022-08-13 07:41:22,986] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:41:23,003] {logging_mixin.py:109} INFO - [2022-08-13 07:41:23,002] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:41:23,012] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.469 seconds
[2022-08-13 07:41:33,190] {processor.py:163} INFO - Started process (PID=4836) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:41:33,192] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:41:33,193] {logging_mixin.py:109} INFO - [2022-08-13 07:41:33,193] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:41:33,588] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:41:33,628] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 41, 33, 612685, tzinfo=Timezone('UTC')), 'duration': 482}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:41:33,652] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 41, 33, 644037, tzinfo=Timezone('UTC')), 'duration': 1265}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:41:33,664] {logging_mixin.py:109} INFO - [2022-08-13 07:41:33,664] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:41:33,677] {logging_mixin.py:109} INFO - [2022-08-13 07:41:33,677] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:41:33,686] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.499 seconds
[2022-08-13 07:41:43,919] {processor.py:163} INFO - Started process (PID=4859) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:41:43,924] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:41:43,927] {logging_mixin.py:109} INFO - [2022-08-13 07:41:43,926] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:41:44,414] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:41:44,451] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 41, 44, 435321, tzinfo=Timezone('UTC')), 'duration': 492}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:41:44,490] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 41, 44, 477003, tzinfo=Timezone('UTC')), 'duration': 1276}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:41:44,509] {logging_mixin.py:109} INFO - [2022-08-13 07:41:44,509] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:41:44,529] {logging_mixin.py:109} INFO - [2022-08-13 07:41:44,529] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:41:44,546] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.632 seconds
[2022-08-13 07:41:54,428] {processor.py:163} INFO - Started process (PID=4892) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:41:54,430] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:41:54,431] {logging_mixin.py:109} INFO - [2022-08-13 07:41:54,431] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:41:54,935] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:41:54,969] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 41, 54, 955524, tzinfo=Timezone('UTC')), 'duration': 503}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:41:55,001] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 41, 54, 991586, tzinfo=Timezone('UTC')), 'duration': 1286}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:41:55,015] {logging_mixin.py:109} INFO - [2022-08-13 07:41:55,015] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:41:55,125] {logging_mixin.py:109} INFO - [2022-08-13 07:41:55,125] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:41:55,140] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.716 seconds
[2022-08-13 07:42:04,814] {processor.py:163} INFO - Started process (PID=4921) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:42:04,816] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:42:04,818] {logging_mixin.py:109} INFO - [2022-08-13 07:42:04,818] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:42:05,254] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:42:05,286] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 42, 5, 272620, tzinfo=Timezone('UTC')), 'duration': 513}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:42:05,315] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 42, 5, 307062, tzinfo=Timezone('UTC')), 'duration': 1297}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:42:05,329] {logging_mixin.py:109} INFO - [2022-08-13 07:42:05,328] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:42:05,431] {logging_mixin.py:109} INFO - [2022-08-13 07:42:05,431] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:42:05,442] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.631 seconds
[2022-08-13 07:42:15,171] {processor.py:163} INFO - Started process (PID=4943) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:42:15,173] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:42:15,174] {logging_mixin.py:109} INFO - [2022-08-13 07:42:15,174] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:42:15,640] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:42:15,678] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 42, 15, 662912, tzinfo=Timezone('UTC')), 'duration': 524}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:42:15,727] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 42, 15, 714105, tzinfo=Timezone('UTC')), 'duration': 1307}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:42:15,740] {logging_mixin.py:109} INFO - [2022-08-13 07:42:15,740] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:42:15,852] {logging_mixin.py:109} INFO - [2022-08-13 07:42:15,852] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:42:15,863] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.695 seconds
[2022-08-13 07:42:25,803] {processor.py:163} INFO - Started process (PID=4966) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:42:25,805] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:42:25,807] {logging_mixin.py:109} INFO - [2022-08-13 07:42:25,807] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:42:26,235] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:42:26,264] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 42, 26, 250899, tzinfo=Timezone('UTC')), 'duration': 534}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:42:26,289] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 42, 26, 282555, tzinfo=Timezone('UTC')), 'duration': 1318}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:42:26,299] {logging_mixin.py:109} INFO - [2022-08-13 07:42:26,299] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:42:26,403] {logging_mixin.py:109} INFO - [2022-08-13 07:42:26,403] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:42:26,413] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.613 seconds
[2022-08-13 07:42:36,446] {processor.py:163} INFO - Started process (PID=4996) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:42:36,448] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:42:36,450] {logging_mixin.py:109} INFO - [2022-08-13 07:42:36,450] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:42:36,907] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:42:36,935] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 42, 36, 923144, tzinfo=Timezone('UTC')), 'duration': 545}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:42:36,964] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 42, 36, 956882, tzinfo=Timezone('UTC')), 'duration': 1328}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:42:36,974] {logging_mixin.py:109} INFO - [2022-08-13 07:42:36,974] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:42:37,076] {logging_mixin.py:109} INFO - [2022-08-13 07:42:37,076] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:42:37,086] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.643 seconds
[2022-08-13 07:42:46,582] {processor.py:163} INFO - Started process (PID=5018) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:42:46,584] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:42:46,585] {logging_mixin.py:109} INFO - [2022-08-13 07:42:46,585] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:42:47,049] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:42:47,089] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 42, 47, 71887, tzinfo=Timezone('UTC')), 'duration': 555}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:42:47,116] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 42, 47, 108536, tzinfo=Timezone('UTC')), 'duration': 1338}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:42:47,128] {logging_mixin.py:109} INFO - [2022-08-13 07:42:47,128] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:42:47,247] {logging_mixin.py:109} INFO - [2022-08-13 07:42:47,247] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:42:47,260] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.683 seconds
[2022-08-13 07:42:56,689] {processor.py:163} INFO - Started process (PID=5051) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:42:56,693] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:42:56,696] {logging_mixin.py:109} INFO - [2022-08-13 07:42:56,695] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:42:57,262] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:42:57,296] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 42, 57, 282825, tzinfo=Timezone('UTC')), 'duration': 565}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:42:57,324] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 42, 51, 362402, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 42, 52, 737433, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 42, 57, 315150, tzinfo=Timezone('UTC')), 'duration': 4}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:42:57,444] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 42, 57, 337096, tzinfo=Timezone('UTC')), 'duration': 1349}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:42:57,455] {logging_mixin.py:109} INFO - [2022-08-13 07:42:57,455] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:42:57,471] {logging_mixin.py:109} INFO - [2022-08-13 07:42:57,471] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:42:57,480] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.798 seconds
[2022-08-13 07:43:07,249] {processor.py:163} INFO - Started process (PID=5080) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:43:07,312] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:43:07,315] {logging_mixin.py:109} INFO - [2022-08-13 07:43:07,314] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:43:07,821] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:43:07,850] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 43, 7, 836999, tzinfo=Timezone('UTC')), 'duration': 576}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:43:07,975] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 42, 51, 362402, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 42, 52, 737433, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 43, 7, 965997, tzinfo=Timezone('UTC')), 'duration': 15}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:43:08,000] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 43, 7, 992066, tzinfo=Timezone('UTC')), 'duration': 1359}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:43:08,016] {logging_mixin.py:109} INFO - [2022-08-13 07:43:08,016] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:43:08,039] {logging_mixin.py:109} INFO - [2022-08-13 07:43:08,039] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:43:08,051] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.807 seconds
[2022-08-13 07:43:17,305] {processor.py:163} INFO - Started process (PID=5093) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:43:17,307] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:43:17,309] {logging_mixin.py:109} INFO - [2022-08-13 07:43:17,309] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:43:17,748] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:43:17,786] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 43, 17, 770120, tzinfo=Timezone('UTC')), 'duration': 586}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:43:17,909] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 42, 51, 362402, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 42, 52, 737433, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 43, 17, 899998, tzinfo=Timezone('UTC')), 'duration': 25}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:43:17,935] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 43, 17, 925499, tzinfo=Timezone('UTC')), 'duration': 1369}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:43:17,946] {logging_mixin.py:109} INFO - [2022-08-13 07:43:17,946] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:43:17,959] {logging_mixin.py:109} INFO - [2022-08-13 07:43:17,959] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:43:17,968] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.667 seconds
[2022-08-13 07:43:27,903] {processor.py:163} INFO - Started process (PID=5125) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:43:27,906] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:43:27,908] {logging_mixin.py:109} INFO - [2022-08-13 07:43:27,908] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:43:28,377] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:43:28,409] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 33, 30, 508351, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 33, 31, 607816, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 43, 28, 395187, tzinfo=Timezone('UTC')), 'duration': 596}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:43:28,536] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 13, 7, 42, 51, 362402, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 42, 52, 737433, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 43, 28, 523690, tzinfo=Timezone('UTC')), 'duration': 35}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:43:28,562] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 43, 28, 552391, tzinfo=Timezone('UTC')), 'duration': 1380}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:43:28,574] {logging_mixin.py:109} INFO - [2022-08-13 07:43:28,573] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:43:28,587] {logging_mixin.py:109} INFO - [2022-08-13 07:43:28,587] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:43:28,597] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.698 seconds
[2022-08-13 07:43:38,020] {processor.py:163} INFO - Started process (PID=5157) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:43:38,023] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:43:38,024] {logging_mixin.py:109} INFO - [2022-08-13 07:43:38,024] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:43:38,466] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:43:38,499] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgres_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_netflix', 'dag_id': 'load_data', 'execution_date': datetime.datetime(2022, 8, 12, 22, 24, 13, 381465, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 8, 13, 7, 20, 28, 179821, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 8, 13, 7, 43, 38, 484475, tzinfo=Timezone('UTC')), 'duration': 1390}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-08-13 07:43:38,617] {logging_mixin.py:109} INFO - [2022-08-13 07:43:38,515] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:43:38,631] {logging_mixin.py:109} INFO - [2022-08-13 07:43:38,631] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:43:38,640] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.625 seconds
[2022-08-13 07:44:09,222] {processor.py:163} INFO - Started process (PID=5222) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:44:09,225] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:44:09,226] {logging_mixin.py:109} INFO - [2022-08-13 07:44:09,226] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:44:09,683] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:44:09,695] {logging_mixin.py:109} INFO - [2022-08-13 07:44:09,694] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:44:09,711] {logging_mixin.py:109} INFO - [2022-08-13 07:44:09,711] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:44:09,724] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.505 seconds
[2022-08-13 07:44:40,553] {processor.py:163} INFO - Started process (PID=5296) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:44:40,558] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:44:40,560] {logging_mixin.py:109} INFO - [2022-08-13 07:44:40,560] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:44:41,572] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:44:41,589] {logging_mixin.py:109} INFO - [2022-08-13 07:44:41,587] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:44:41,713] {logging_mixin.py:109} INFO - [2022-08-13 07:44:41,713] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:44:41,723] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.177 seconds
[2022-08-13 07:45:12,596] {processor.py:163} INFO - Started process (PID=5362) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:45:12,599] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:45:12,600] {logging_mixin.py:109} INFO - [2022-08-13 07:45:12,600] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:45:12,972] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:45:12,991] {logging_mixin.py:109} INFO - [2022-08-13 07:45:12,990] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:45:13,006] {logging_mixin.py:109} INFO - [2022-08-13 07:45:13,006] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:45:13,014] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.446 seconds
[2022-08-13 07:45:43,806] {processor.py:163} INFO - Started process (PID=5436) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:45:43,808] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:45:43,810] {logging_mixin.py:109} INFO - [2022-08-13 07:45:43,810] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:45:44,293] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:45:44,305] {logging_mixin.py:109} INFO - [2022-08-13 07:45:44,304] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:45:44,321] {logging_mixin.py:109} INFO - [2022-08-13 07:45:44,321] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:45:44,333] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.531 seconds
[2022-08-13 07:46:15,214] {processor.py:163} INFO - Started process (PID=5510) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:46:15,216] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:46:15,217] {logging_mixin.py:109} INFO - [2022-08-13 07:46:15,217] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:46:15,634] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:46:15,645] {logging_mixin.py:109} INFO - [2022-08-13 07:46:15,644] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:46:15,659] {logging_mixin.py:109} INFO - [2022-08-13 07:46:15,659] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:46:15,668] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.458 seconds
[2022-08-13 07:46:46,572] {processor.py:163} INFO - Started process (PID=5585) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:46:46,584] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:46:46,591] {logging_mixin.py:109} INFO - [2022-08-13 07:46:46,591] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:46:47,055] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:46:47,066] {logging_mixin.py:109} INFO - [2022-08-13 07:46:47,065] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:46:47,081] {logging_mixin.py:109} INFO - [2022-08-13 07:46:47,081] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:46:47,092] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.526 seconds
[2022-08-13 07:47:17,155] {processor.py:163} INFO - Started process (PID=5661) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:47:17,158] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:47:17,159] {logging_mixin.py:109} INFO - [2022-08-13 07:47:17,159] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:47:17,600] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:47:17,614] {logging_mixin.py:109} INFO - [2022-08-13 07:47:17,613] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:47:17,635] {logging_mixin.py:109} INFO - [2022-08-13 07:47:17,635] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:47:17,649] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.497 seconds
[2022-08-13 07:47:48,291] {processor.py:163} INFO - Started process (PID=5726) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:47:48,295] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:47:48,297] {logging_mixin.py:109} INFO - [2022-08-13 07:47:48,296] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:47:48,726] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:47:48,737] {logging_mixin.py:109} INFO - [2022-08-13 07:47:48,736] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:47:48,751] {logging_mixin.py:109} INFO - [2022-08-13 07:47:48,751] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:47:48,761] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.476 seconds
[2022-08-13 07:48:19,440] {processor.py:163} INFO - Started process (PID=5800) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:48:19,443] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:48:19,445] {logging_mixin.py:109} INFO - [2022-08-13 07:48:19,445] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:48:19,920] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:48:19,943] {logging_mixin.py:109} INFO - [2022-08-13 07:48:19,942] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:48:19,963] {logging_mixin.py:109} INFO - [2022-08-13 07:48:19,963] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:48:19,980] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.544 seconds
[2022-08-13 07:48:50,558] {processor.py:163} INFO - Started process (PID=5865) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:48:50,560] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:48:50,562] {logging_mixin.py:109} INFO - [2022-08-13 07:48:50,562] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:48:51,002] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:48:51,013] {logging_mixin.py:109} INFO - [2022-08-13 07:48:51,012] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:48:51,028] {logging_mixin.py:109} INFO - [2022-08-13 07:48:51,028] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:48:51,038] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.484 seconds
[2022-08-13 07:49:21,778] {processor.py:163} INFO - Started process (PID=5940) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:49:21,781] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:49:21,783] {logging_mixin.py:109} INFO - [2022-08-13 07:49:21,783] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:49:22,274] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:49:22,292] {logging_mixin.py:109} INFO - [2022-08-13 07:49:22,291] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:49:22,318] {logging_mixin.py:109} INFO - [2022-08-13 07:49:22,318] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:49:22,331] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.557 seconds
[2022-08-13 07:49:52,425] {processor.py:163} INFO - Started process (PID=6006) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:49:52,428] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:49:52,430] {logging_mixin.py:109} INFO - [2022-08-13 07:49:52,430] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:49:52,846] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:49:52,862] {logging_mixin.py:109} INFO - [2022-08-13 07:49:52,861] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:49:52,882] {logging_mixin.py:109} INFO - [2022-08-13 07:49:52,881] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:49:52,897] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.478 seconds
[2022-08-13 07:50:23,688] {processor.py:163} INFO - Started process (PID=6073) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:50:23,691] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:50:23,694] {logging_mixin.py:109} INFO - [2022-08-13 07:50:23,693] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:50:24,188] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:50:24,200] {logging_mixin.py:109} INFO - [2022-08-13 07:50:24,199] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:50:24,218] {logging_mixin.py:109} INFO - [2022-08-13 07:50:24,218] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:50:24,235] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.552 seconds
[2022-08-13 07:50:55,259] {processor.py:163} INFO - Started process (PID=6147) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:50:55,262] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:50:55,264] {logging_mixin.py:109} INFO - [2022-08-13 07:50:55,263] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:50:55,758] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:50:55,772] {logging_mixin.py:109} INFO - [2022-08-13 07:50:55,771] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:50:55,789] {logging_mixin.py:109} INFO - [2022-08-13 07:50:55,788] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:50:55,803] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.549 seconds
[2022-08-13 07:51:26,613] {processor.py:163} INFO - Started process (PID=6214) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:51:26,615] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:51:26,616] {logging_mixin.py:109} INFO - [2022-08-13 07:51:26,616] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:51:27,019] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:51:27,033] {logging_mixin.py:109} INFO - [2022-08-13 07:51:27,032] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:51:27,051] {logging_mixin.py:109} INFO - [2022-08-13 07:51:27,051] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:51:27,061] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.452 seconds
[2022-08-13 07:51:58,074] {processor.py:163} INFO - Started process (PID=6289) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:51:58,078] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:51:58,080] {logging_mixin.py:109} INFO - [2022-08-13 07:51:58,080] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:51:58,594] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:51:58,607] {logging_mixin.py:109} INFO - [2022-08-13 07:51:58,606] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:51:58,631] {logging_mixin.py:109} INFO - [2022-08-13 07:51:58,631] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:51:58,644] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.576 seconds
[2022-08-13 07:52:29,362] {processor.py:163} INFO - Started process (PID=6355) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:52:29,364] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:52:29,365] {logging_mixin.py:109} INFO - [2022-08-13 07:52:29,365] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:52:29,784] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:52:29,798] {logging_mixin.py:109} INFO - [2022-08-13 07:52:29,797] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:52:29,817] {logging_mixin.py:109} INFO - [2022-08-13 07:52:29,817] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:52:29,829] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.471 seconds
[2022-08-13 07:52:59,866] {processor.py:163} INFO - Started process (PID=6421) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:52:59,869] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:52:59,870] {logging_mixin.py:109} INFO - [2022-08-13 07:52:59,870] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:53:00,308] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:53:00,321] {logging_mixin.py:109} INFO - [2022-08-13 07:53:00,319] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:53:00,337] {logging_mixin.py:109} INFO - [2022-08-13 07:53:00,336] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:53:00,347] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.485 seconds
[2022-08-13 07:53:31,063] {processor.py:163} INFO - Started process (PID=6496) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:53:31,065] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:53:31,067] {logging_mixin.py:109} INFO - [2022-08-13 07:53:31,067] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:53:31,617] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:53:31,636] {logging_mixin.py:109} INFO - [2022-08-13 07:53:31,635] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:53:31,658] {logging_mixin.py:109} INFO - [2022-08-13 07:53:31,657] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:53:31,673] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.617 seconds
[2022-08-13 07:54:02,486] {processor.py:163} INFO - Started process (PID=6562) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:54:02,489] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:54:02,492] {logging_mixin.py:109} INFO - [2022-08-13 07:54:02,492] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:54:02,950] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:54:02,961] {logging_mixin.py:109} INFO - [2022-08-13 07:54:02,960] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:54:02,976] {logging_mixin.py:109} INFO - [2022-08-13 07:54:02,976] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:54:02,993] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.512 seconds
[2022-08-13 07:54:33,039] {processor.py:163} INFO - Started process (PID=6636) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:54:33,042] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:54:33,044] {logging_mixin.py:109} INFO - [2022-08-13 07:54:33,043] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:54:33,464] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:54:33,475] {logging_mixin.py:109} INFO - [2022-08-13 07:54:33,474] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:54:33,491] {logging_mixin.py:109} INFO - [2022-08-13 07:54:33,491] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:54:33,500] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.466 seconds
[2022-08-13 07:55:04,322] {processor.py:163} INFO - Started process (PID=6701) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:55:04,324] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:55:04,326] {logging_mixin.py:109} INFO - [2022-08-13 07:55:04,326] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:55:04,747] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:55:04,759] {logging_mixin.py:109} INFO - [2022-08-13 07:55:04,758] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:55:04,774] {logging_mixin.py:109} INFO - [2022-08-13 07:55:04,774] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:55:04,785] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.465 seconds
[2022-08-13 07:55:35,548] {processor.py:163} INFO - Started process (PID=6777) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:55:35,550] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:55:35,553] {logging_mixin.py:109} INFO - [2022-08-13 07:55:35,553] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:55:36,073] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:55:36,087] {logging_mixin.py:109} INFO - [2022-08-13 07:55:36,085] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:55:36,105] {logging_mixin.py:109} INFO - [2022-08-13 07:55:36,105] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:55:36,117] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.575 seconds
[2022-08-13 07:56:06,207] {processor.py:163} INFO - Started process (PID=6843) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:56:06,210] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:56:06,212] {logging_mixin.py:109} INFO - [2022-08-13 07:56:06,212] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:56:06,611] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:56:06,621] {logging_mixin.py:109} INFO - [2022-08-13 07:56:06,620] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:56:06,636] {logging_mixin.py:109} INFO - [2022-08-13 07:56:06,636] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:56:06,647] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.448 seconds
[2022-08-13 07:56:36,720] {processor.py:163} INFO - Started process (PID=6909) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:56:36,723] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:56:36,725] {logging_mixin.py:109} INFO - [2022-08-13 07:56:36,725] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:56:37,171] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:56:37,186] {logging_mixin.py:109} INFO - [2022-08-13 07:56:37,185] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:56:37,205] {logging_mixin.py:109} INFO - [2022-08-13 07:56:37,204] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:56:37,217] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.501 seconds
[2022-08-13 07:57:07,907] {processor.py:163} INFO - Started process (PID=6984) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:57:07,910] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:57:07,912] {logging_mixin.py:109} INFO - [2022-08-13 07:57:07,911] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:57:08,477] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:57:08,506] {logging_mixin.py:109} INFO - [2022-08-13 07:57:08,505] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:57:08,540] {logging_mixin.py:109} INFO - [2022-08-13 07:57:08,540] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:57:08,557] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.655 seconds
[2022-08-13 07:57:38,706] {processor.py:163} INFO - Started process (PID=7049) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:57:38,715] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:57:38,718] {logging_mixin.py:109} INFO - [2022-08-13 07:57:38,718] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:57:39,200] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:57:39,213] {logging_mixin.py:109} INFO - [2022-08-13 07:57:39,212] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:57:39,232] {logging_mixin.py:109} INFO - [2022-08-13 07:57:39,232] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:57:39,244] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.542 seconds
[2022-08-13 07:58:09,422] {processor.py:163} INFO - Started process (PID=7115) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:58:09,425] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:58:09,427] {logging_mixin.py:109} INFO - [2022-08-13 07:58:09,427] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:58:09,802] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:58:09,813] {logging_mixin.py:109} INFO - [2022-08-13 07:58:09,812] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:58:09,828] {logging_mixin.py:109} INFO - [2022-08-13 07:58:09,828] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:58:09,839] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.423 seconds
[2022-08-13 07:58:39,949] {processor.py:163} INFO - Started process (PID=7191) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:58:39,951] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:58:39,953] {logging_mixin.py:109} INFO - [2022-08-13 07:58:39,952] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:58:40,388] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:58:40,405] {logging_mixin.py:109} INFO - [2022-08-13 07:58:40,404] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:58:40,519] {logging_mixin.py:109} INFO - [2022-08-13 07:58:40,519] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:58:40,528] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.583 seconds
[2022-08-13 07:59:10,673] {processor.py:163} INFO - Started process (PID=7253) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:59:10,675] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:59:10,677] {logging_mixin.py:109} INFO - [2022-08-13 07:59:10,676] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:59:11,136] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:59:11,147] {logging_mixin.py:109} INFO - [2022-08-13 07:59:11,146] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:59:11,255] {logging_mixin.py:109} INFO - [2022-08-13 07:59:11,255] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:59:11,266] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.597 seconds
[2022-08-13 07:59:41,559] {processor.py:163} INFO - Started process (PID=7318) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:59:41,561] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 07:59:41,562] {logging_mixin.py:109} INFO - [2022-08-13 07:59:41,562] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:59:42,043] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 07:59:42,056] {logging_mixin.py:109} INFO - [2022-08-13 07:59:42,055] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 07:59:42,161] {logging_mixin.py:109} INFO - [2022-08-13 07:59:42,161] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 07:59:42,173] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.617 seconds
[2022-08-13 08:00:12,902] {processor.py:163} INFO - Started process (PID=7392) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:00:12,905] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:00:12,907] {logging_mixin.py:109} INFO - [2022-08-13 08:00:12,906] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:00:13,339] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:00:13,350] {logging_mixin.py:109} INFO - [2022-08-13 08:00:13,349] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:00:13,460] {logging_mixin.py:109} INFO - [2022-08-13 08:00:13,460] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:00:13,484] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.588 seconds
[2022-08-13 08:00:44,328] {processor.py:163} INFO - Started process (PID=7457) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:00:44,331] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:00:44,335] {logging_mixin.py:109} INFO - [2022-08-13 08:00:44,334] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:00:44,835] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:00:44,847] {logging_mixin.py:109} INFO - [2022-08-13 08:00:44,846] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:00:44,952] {logging_mixin.py:109} INFO - [2022-08-13 08:00:44,952] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:00:44,965] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.643 seconds
[2022-08-13 08:01:15,566] {processor.py:163} INFO - Started process (PID=7531) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:01:15,570] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:01:15,576] {logging_mixin.py:109} INFO - [2022-08-13 08:01:15,576] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:01:16,191] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:01:16,203] {logging_mixin.py:109} INFO - [2022-08-13 08:01:16,202] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:01:16,224] {logging_mixin.py:109} INFO - [2022-08-13 08:01:16,224] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:01:16,239] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.685 seconds
[2022-08-13 08:01:46,850] {processor.py:163} INFO - Started process (PID=7596) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:01:46,852] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:01:46,854] {logging_mixin.py:109} INFO - [2022-08-13 08:01:46,854] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:01:47,352] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:01:47,365] {logging_mixin.py:109} INFO - [2022-08-13 08:01:47,364] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:01:47,382] {logging_mixin.py:109} INFO - [2022-08-13 08:01:47,382] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:01:47,392] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.547 seconds
[2022-08-13 08:02:17,531] {processor.py:163} INFO - Started process (PID=7670) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:02:17,534] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:02:17,536] {logging_mixin.py:109} INFO - [2022-08-13 08:02:17,536] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:02:18,038] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:02:18,050] {logging_mixin.py:109} INFO - [2022-08-13 08:02:18,049] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:02:18,072] {logging_mixin.py:109} INFO - [2022-08-13 08:02:18,071] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:02:18,085] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.557 seconds
[2022-08-13 08:02:48,529] {processor.py:163} INFO - Started process (PID=7737) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:02:48,533] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:02:48,535] {logging_mixin.py:109} INFO - [2022-08-13 08:02:48,535] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:02:49,068] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:02:49,088] {logging_mixin.py:109} INFO - [2022-08-13 08:02:49,087] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:02:49,108] {logging_mixin.py:109} INFO - [2022-08-13 08:02:49,108] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:02:49,123] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.598 seconds
[2022-08-13 08:03:19,427] {processor.py:163} INFO - Started process (PID=7802) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:03:19,430] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:03:19,432] {logging_mixin.py:109} INFO - [2022-08-13 08:03:19,432] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:03:19,872] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:03:19,883] {logging_mixin.py:109} INFO - [2022-08-13 08:03:19,882] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:03:19,899] {logging_mixin.py:109} INFO - [2022-08-13 08:03:19,899] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:03:19,910] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.488 seconds
[2022-08-13 08:03:50,043] {processor.py:163} INFO - Started process (PID=7877) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:03:50,046] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:03:50,049] {logging_mixin.py:109} INFO - [2022-08-13 08:03:50,049] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:03:50,731] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:03:50,756] {logging_mixin.py:109} INFO - [2022-08-13 08:03:50,755] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:03:50,771] {logging_mixin.py:109} INFO - [2022-08-13 08:03:50,771] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:03:50,782] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.744 seconds
[2022-08-13 08:04:21,231] {processor.py:163} INFO - Started process (PID=7943) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:04:21,234] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:04:21,236] {logging_mixin.py:109} INFO - [2022-08-13 08:04:21,236] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:04:21,778] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:04:21,792] {logging_mixin.py:109} INFO - [2022-08-13 08:04:21,791] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:04:21,810] {logging_mixin.py:109} INFO - [2022-08-13 08:04:21,810] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:04:21,825] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.599 seconds
[2022-08-13 08:04:52,061] {processor.py:163} INFO - Started process (PID=8013) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:04:52,063] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:04:52,064] {logging_mixin.py:109} INFO - [2022-08-13 08:04:52,064] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:04:52,563] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:04:52,578] {logging_mixin.py:109} INFO - [2022-08-13 08:04:52,577] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:04:52,597] {logging_mixin.py:109} INFO - [2022-08-13 08:04:52,597] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:04:52,610] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.554 seconds
[2022-08-13 08:05:22,969] {processor.py:163} INFO - Started process (PID=8083) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:05:22,973] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:05:22,980] {logging_mixin.py:109} INFO - [2022-08-13 08:05:22,980] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:05:23,595] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:05:23,611] {logging_mixin.py:109} INFO - [2022-08-13 08:05:23,610] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:05:23,641] {logging_mixin.py:109} INFO - [2022-08-13 08:05:23,641] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:05:23,655] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.692 seconds
[2022-08-13 08:05:53,779] {processor.py:163} INFO - Started process (PID=8154) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:05:53,784] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:05:53,787] {logging_mixin.py:109} INFO - [2022-08-13 08:05:53,787] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:05:54,320] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:05:54,333] {logging_mixin.py:109} INFO - [2022-08-13 08:05:54,332] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:05:54,351] {logging_mixin.py:109} INFO - [2022-08-13 08:05:54,350] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:05:54,367] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.593 seconds
[2022-08-13 08:06:24,582] {processor.py:163} INFO - Started process (PID=8221) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:06:24,585] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:06:24,586] {logging_mixin.py:109} INFO - [2022-08-13 08:06:24,586] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:06:25,031] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:06:25,042] {logging_mixin.py:109} INFO - [2022-08-13 08:06:25,041] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:06:25,058] {logging_mixin.py:109} INFO - [2022-08-13 08:06:25,058] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:06:25,069] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.491 seconds
[2022-08-13 08:06:55,295] {processor.py:163} INFO - Started process (PID=8299) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:06:55,297] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:06:55,300] {logging_mixin.py:109} INFO - [2022-08-13 08:06:55,300] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:06:55,821] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:06:55,834] {logging_mixin.py:109} INFO - [2022-08-13 08:06:55,833] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:06:55,851] {logging_mixin.py:109} INFO - [2022-08-13 08:06:55,851] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:06:55,863] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.573 seconds
[2022-08-13 08:07:26,077] {processor.py:163} INFO - Started process (PID=8368) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:07:26,083] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:07:26,086] {logging_mixin.py:109} INFO - [2022-08-13 08:07:26,085] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:07:26,627] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:07:26,641] {logging_mixin.py:109} INFO - [2022-08-13 08:07:26,640] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:07:26,657] {logging_mixin.py:109} INFO - [2022-08-13 08:07:26,657] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:07:26,671] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.598 seconds
[2022-08-13 08:07:57,342] {processor.py:163} INFO - Started process (PID=8434) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:07:57,345] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:07:57,346] {logging_mixin.py:109} INFO - [2022-08-13 08:07:57,346] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:07:57,736] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:07:57,748] {logging_mixin.py:109} INFO - [2022-08-13 08:07:57,747] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:07:57,763] {logging_mixin.py:109} INFO - [2022-08-13 08:07:57,763] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:07:57,773] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.437 seconds
[2022-08-13 08:08:28,388] {processor.py:163} INFO - Started process (PID=8508) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:08:28,390] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:08:28,392] {logging_mixin.py:109} INFO - [2022-08-13 08:08:28,392] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:08:28,861] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:08:28,872] {logging_mixin.py:109} INFO - [2022-08-13 08:08:28,871] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:08:28,891] {logging_mixin.py:109} INFO - [2022-08-13 08:08:28,891] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:08:28,901] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.517 seconds
[2022-08-13 08:08:59,636] {processor.py:163} INFO - Started process (PID=8575) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:08:59,639] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:08:59,640] {logging_mixin.py:109} INFO - [2022-08-13 08:08:59,640] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:09:00,131] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:09:00,143] {logging_mixin.py:109} INFO - [2022-08-13 08:09:00,142] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:09:00,157] {logging_mixin.py:109} INFO - [2022-08-13 08:09:00,157] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:09:00,168] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.535 seconds
[2022-08-13 08:09:31,112] {processor.py:163} INFO - Started process (PID=8649) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:09:31,114] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:09:31,117] {logging_mixin.py:109} INFO - [2022-08-13 08:09:31,116] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:09:31,650] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:09:31,665] {logging_mixin.py:109} INFO - [2022-08-13 08:09:31,664] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:09:31,685] {logging_mixin.py:109} INFO - [2022-08-13 08:09:31,685] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:09:31,700] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.591 seconds
[2022-08-13 08:10:02,779] {processor.py:163} INFO - Started process (PID=8716) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:10:02,783] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:10:02,786] {logging_mixin.py:109} INFO - [2022-08-13 08:10:02,785] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:10:03,285] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:10:03,298] {logging_mixin.py:109} INFO - [2022-08-13 08:10:03,297] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:10:03,315] {logging_mixin.py:109} INFO - [2022-08-13 08:10:03,315] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:10:03,329] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.557 seconds
[2022-08-13 08:10:34,244] {processor.py:163} INFO - Started process (PID=8783) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:10:34,248] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:10:34,250] {logging_mixin.py:109} INFO - [2022-08-13 08:10:34,250] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:10:34,707] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:10:34,720] {logging_mixin.py:109} INFO - [2022-08-13 08:10:34,719] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:10:34,740] {logging_mixin.py:109} INFO - [2022-08-13 08:10:34,740] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:10:34,754] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.513 seconds
[2022-08-13 08:11:04,819] {processor.py:163} INFO - Started process (PID=8859) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:11:04,821] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:11:04,823] {logging_mixin.py:109} INFO - [2022-08-13 08:11:04,822] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:11:05,313] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:11:05,326] {logging_mixin.py:109} INFO - [2022-08-13 08:11:05,325] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:11:05,345] {logging_mixin.py:109} INFO - [2022-08-13 08:11:05,345] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:11:05,355] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.541 seconds
[2022-08-13 08:11:35,646] {processor.py:163} INFO - Started process (PID=8924) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:11:35,648] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:11:35,650] {logging_mixin.py:109} INFO - [2022-08-13 08:11:35,650] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:11:36,071] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:11:36,089] {logging_mixin.py:109} INFO - [2022-08-13 08:11:36,088] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:11:36,108] {logging_mixin.py:109} INFO - [2022-08-13 08:11:36,108] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:11:36,122] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.480 seconds
[2022-08-13 08:12:06,231] {processor.py:163} INFO - Started process (PID=8999) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:12:06,235] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:12:06,239] {logging_mixin.py:109} INFO - [2022-08-13 08:12:06,239] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:12:07,000] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:12:07,013] {logging_mixin.py:109} INFO - [2022-08-13 08:12:07,012] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:12:07,033] {logging_mixin.py:109} INFO - [2022-08-13 08:12:07,033] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:12:07,044] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.818 seconds
[2022-08-13 08:12:37,681] {processor.py:163} INFO - Started process (PID=9063) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:12:37,684] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:12:37,686] {logging_mixin.py:109} INFO - [2022-08-13 08:12:37,686] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:12:38,159] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:12:38,171] {logging_mixin.py:109} INFO - [2022-08-13 08:12:38,170] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:12:38,187] {logging_mixin.py:109} INFO - [2022-08-13 08:12:38,187] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:12:38,199] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.523 seconds
[2022-08-13 08:13:08,699] {processor.py:163} INFO - Started process (PID=9128) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:13:08,703] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:13:08,705] {logging_mixin.py:109} INFO - [2022-08-13 08:13:08,704] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:13:09,345] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:13:09,358] {logging_mixin.py:109} INFO - [2022-08-13 08:13:09,357] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:13:09,376] {logging_mixin.py:109} INFO - [2022-08-13 08:13:09,376] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:13:09,390] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.702 seconds
[2022-08-13 08:13:39,480] {processor.py:163} INFO - Started process (PID=9202) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:13:39,484] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:13:39,487] {logging_mixin.py:109} INFO - [2022-08-13 08:13:39,487] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:13:40,096] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:13:40,111] {logging_mixin.py:109} INFO - [2022-08-13 08:13:40,110] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:13:40,233] {logging_mixin.py:109} INFO - [2022-08-13 08:13:40,232] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:13:40,253] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.778 seconds
[2022-08-13 08:14:10,372] {processor.py:163} INFO - Started process (PID=9268) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:14:10,374] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:14:10,376] {logging_mixin.py:109} INFO - [2022-08-13 08:14:10,375] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:14:10,870] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:14:10,882] {logging_mixin.py:109} INFO - [2022-08-13 08:14:10,881] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:14:11,003] {logging_mixin.py:109} INFO - [2022-08-13 08:14:11,003] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:14:11,014] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.646 seconds
[2022-08-13 08:14:41,299] {processor.py:163} INFO - Started process (PID=9333) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:14:41,301] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:14:41,303] {logging_mixin.py:109} INFO - [2022-08-13 08:14:41,303] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:14:41,805] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:14:41,818] {logging_mixin.py:109} INFO - [2022-08-13 08:14:41,817] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:14:41,931] {logging_mixin.py:109} INFO - [2022-08-13 08:14:41,931] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:14:41,944] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.675 seconds
[2022-08-13 08:15:12,081] {processor.py:163} INFO - Started process (PID=9405) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:15:12,086] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:15:12,089] {logging_mixin.py:109} INFO - [2022-08-13 08:15:12,088] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:15:12,642] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:15:12,662] {logging_mixin.py:109} INFO - [2022-08-13 08:15:12,660] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:15:12,782] {logging_mixin.py:109} INFO - [2022-08-13 08:15:12,782] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:15:12,795] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.721 seconds
[2022-08-13 08:15:43,426] {processor.py:163} INFO - Started process (PID=9471) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:15:43,429] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:15:43,431] {logging_mixin.py:109} INFO - [2022-08-13 08:15:43,431] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:15:43,974] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:15:43,990] {logging_mixin.py:109} INFO - [2022-08-13 08:15:43,990] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:15:44,014] {logging_mixin.py:109} INFO - [2022-08-13 08:15:44,014] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:15:44,030] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.610 seconds
[2022-08-13 08:16:14,273] {processor.py:163} INFO - Started process (PID=9545) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:16:14,276] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:16:14,278] {logging_mixin.py:109} INFO - [2022-08-13 08:16:14,278] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:16:14,949] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:16:14,965] {logging_mixin.py:109} INFO - [2022-08-13 08:16:14,964] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:16:14,987] {logging_mixin.py:109} INFO - [2022-08-13 08:16:14,987] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:16:14,999] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.730 seconds
[2022-08-13 08:16:45,694] {processor.py:163} INFO - Started process (PID=9611) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:16:45,697] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:16:45,699] {logging_mixin.py:109} INFO - [2022-08-13 08:16:45,699] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:16:46,301] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:16:46,313] {logging_mixin.py:109} INFO - [2022-08-13 08:16:46,312] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:16:46,333] {logging_mixin.py:109} INFO - [2022-08-13 08:16:46,333] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:16:46,342] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.653 seconds
[2022-08-13 08:17:16,583] {processor.py:163} INFO - Started process (PID=9677) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:17:16,591] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:17:16,593] {logging_mixin.py:109} INFO - [2022-08-13 08:17:16,593] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:17:17,269] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:17:17,292] {logging_mixin.py:109} INFO - [2022-08-13 08:17:17,291] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:17:17,314] {logging_mixin.py:109} INFO - [2022-08-13 08:17:17,314] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:17:17,328] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.749 seconds
[2022-08-13 08:17:47,400] {processor.py:163} INFO - Started process (PID=9752) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:17:47,403] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:17:47,407] {logging_mixin.py:109} INFO - [2022-08-13 08:17:47,406] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:17:48,101] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:17:48,119] {logging_mixin.py:109} INFO - [2022-08-13 08:17:48,118] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:17:48,143] {logging_mixin.py:109} INFO - [2022-08-13 08:17:48,143] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:17:48,156] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.765 seconds
[2022-08-13 08:18:18,774] {processor.py:163} INFO - Started process (PID=9819) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:18:18,777] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:18:18,779] {logging_mixin.py:109} INFO - [2022-08-13 08:18:18,778] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:18:19,238] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:18:19,250] {logging_mixin.py:109} INFO - [2022-08-13 08:18:19,249] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:18:19,269] {logging_mixin.py:109} INFO - [2022-08-13 08:18:19,269] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:18:19,282] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.514 seconds
[2022-08-13 08:18:49,353] {processor.py:163} INFO - Started process (PID=9886) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:18:49,356] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:18:49,358] {logging_mixin.py:109} INFO - [2022-08-13 08:18:49,357] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:18:50,262] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:18:50,277] {logging_mixin.py:109} INFO - [2022-08-13 08:18:50,275] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:18:50,293] {logging_mixin.py:109} INFO - [2022-08-13 08:18:50,293] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:18:50,308] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.960 seconds
[2022-08-13 08:19:20,536] {processor.py:163} INFO - Started process (PID=9959) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:19:20,539] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:19:20,541] {logging_mixin.py:109} INFO - [2022-08-13 08:19:20,541] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:19:20,972] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:19:20,983] {logging_mixin.py:109} INFO - [2022-08-13 08:19:20,982] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:19:20,998] {logging_mixin.py:109} INFO - [2022-08-13 08:19:20,997] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:19:21,008] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.478 seconds
[2022-08-13 08:19:51,333] {processor.py:163} INFO - Started process (PID=10026) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:19:51,335] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:19:51,336] {logging_mixin.py:109} INFO - [2022-08-13 08:19:51,336] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:19:51,817] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:19:51,830] {logging_mixin.py:109} INFO - [2022-08-13 08:19:51,829] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:19:51,844] {logging_mixin.py:109} INFO - [2022-08-13 08:19:51,844] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:19:51,853] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.525 seconds
[2022-08-13 08:20:22,094] {processor.py:163} INFO - Started process (PID=10102) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:20:22,097] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:20:22,098] {logging_mixin.py:109} INFO - [2022-08-13 08:20:22,098] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:20:22,593] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:20:22,608] {logging_mixin.py:109} INFO - [2022-08-13 08:20:22,607] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:20:22,631] {logging_mixin.py:109} INFO - [2022-08-13 08:20:22,630] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:20:22,685] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.595 seconds
[2022-08-13 08:20:53,675] {processor.py:163} INFO - Started process (PID=10171) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:20:53,682] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:20:53,685] {logging_mixin.py:109} INFO - [2022-08-13 08:20:53,684] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:20:54,185] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:20:54,198] {logging_mixin.py:109} INFO - [2022-08-13 08:20:54,197] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:20:54,218] {logging_mixin.py:109} INFO - [2022-08-13 08:20:54,218] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:20:54,233] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.565 seconds
[2022-08-13 08:21:24,694] {processor.py:163} INFO - Started process (PID=10241) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:21:24,697] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:21:24,699] {logging_mixin.py:109} INFO - [2022-08-13 08:21:24,698] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:21:25,184] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:21:25,195] {logging_mixin.py:109} INFO - [2022-08-13 08:21:25,194] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:21:25,211] {logging_mixin.py:109} INFO - [2022-08-13 08:21:25,210] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:21:25,223] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.533 seconds
[2022-08-13 08:21:55,266] {processor.py:163} INFO - Started process (PID=10318) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:21:55,270] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:21:55,272] {logging_mixin.py:109} INFO - [2022-08-13 08:21:55,272] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:21:55,660] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:21:55,674] {logging_mixin.py:109} INFO - [2022-08-13 08:21:55,673] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:21:55,694] {logging_mixin.py:109} INFO - [2022-08-13 08:21:55,694] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:21:55,703] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.441 seconds
[2022-08-13 08:22:25,794] {processor.py:163} INFO - Started process (PID=10384) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:22:25,797] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:22:25,799] {logging_mixin.py:109} INFO - [2022-08-13 08:22:25,798] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:22:26,273] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:22:26,287] {logging_mixin.py:109} INFO - [2022-08-13 08:22:26,286] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:22:26,303] {logging_mixin.py:109} INFO - [2022-08-13 08:22:26,303] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:22:26,316] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.525 seconds
[2022-08-13 08:22:56,402] {processor.py:163} INFO - Started process (PID=10459) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:22:56,405] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:22:56,408] {logging_mixin.py:109} INFO - [2022-08-13 08:22:56,408] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:22:56,997] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:22:57,007] {logging_mixin.py:109} INFO - [2022-08-13 08:22:57,007] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:22:57,023] {logging_mixin.py:109} INFO - [2022-08-13 08:22:57,023] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:22:57,036] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.637 seconds
[2022-08-13 08:23:27,119] {processor.py:163} INFO - Started process (PID=10527) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:23:27,122] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:23:27,124] {logging_mixin.py:109} INFO - [2022-08-13 08:23:27,124] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:23:27,686] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:23:27,699] {logging_mixin.py:109} INFO - [2022-08-13 08:23:27,698] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:23:27,717] {logging_mixin.py:109} INFO - [2022-08-13 08:23:27,717] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:23:27,731] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.617 seconds
[2022-08-13 08:23:58,372] {processor.py:163} INFO - Started process (PID=10592) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:23:58,378] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:23:58,380] {logging_mixin.py:109} INFO - [2022-08-13 08:23:58,380] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:23:58,931] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:23:58,941] {logging_mixin.py:109} INFO - [2022-08-13 08:23:58,941] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:23:58,958] {logging_mixin.py:109} INFO - [2022-08-13 08:23:58,957] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:23:58,969] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.607 seconds
[2022-08-13 08:24:29,371] {processor.py:163} INFO - Started process (PID=10666) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:24:29,376] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:24:29,380] {logging_mixin.py:109} INFO - [2022-08-13 08:24:29,379] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:24:29,850] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:24:29,861] {logging_mixin.py:109} INFO - [2022-08-13 08:24:29,860] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:24:29,877] {logging_mixin.py:109} INFO - [2022-08-13 08:24:29,877] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:24:29,887] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.528 seconds
[2022-08-13 08:25:00,559] {processor.py:163} INFO - Started process (PID=10732) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:25:00,561] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:25:00,563] {logging_mixin.py:109} INFO - [2022-08-13 08:25:00,563] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:25:00,996] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:25:01,007] {logging_mixin.py:109} INFO - [2022-08-13 08:25:01,006] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:25:01,030] {logging_mixin.py:109} INFO - [2022-08-13 08:25:01,030] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:25:01,041] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.487 seconds
[2022-08-13 08:25:31,995] {processor.py:163} INFO - Started process (PID=10808) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:25:31,999] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:25:32,001] {logging_mixin.py:109} INFO - [2022-08-13 08:25:32,000] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:25:32,499] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:25:32,512] {logging_mixin.py:109} INFO - [2022-08-13 08:25:32,511] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:25:32,530] {logging_mixin.py:109} INFO - [2022-08-13 08:25:32,530] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:25:32,543] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.555 seconds
[2022-08-13 08:26:02,766] {processor.py:163} INFO - Started process (PID=10874) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:26:02,769] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:26:02,771] {logging_mixin.py:109} INFO - [2022-08-13 08:26:02,771] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:26:03,149] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:26:03,161] {logging_mixin.py:109} INFO - [2022-08-13 08:26:03,160] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:26:03,176] {logging_mixin.py:109} INFO - [2022-08-13 08:26:03,176] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:26:03,186] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.424 seconds
[2022-08-13 08:26:33,556] {processor.py:163} INFO - Started process (PID=10947) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:26:33,559] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:26:33,561] {logging_mixin.py:109} INFO - [2022-08-13 08:26:33,561] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:26:34,005] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:26:34,016] {logging_mixin.py:109} INFO - [2022-08-13 08:26:34,015] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:26:34,033] {logging_mixin.py:109} INFO - [2022-08-13 08:26:34,032] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:26:34,046] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.493 seconds
[2022-08-13 08:27:04,478] {processor.py:163} INFO - Started process (PID=11012) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:27:04,481] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:27:04,482] {logging_mixin.py:109} INFO - [2022-08-13 08:27:04,482] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:27:04,975] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:27:04,986] {logging_mixin.py:109} INFO - [2022-08-13 08:27:04,985] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:27:05,001] {logging_mixin.py:109} INFO - [2022-08-13 08:27:05,001] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:27:05,011] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.537 seconds
[2022-08-13 08:27:35,189] {processor.py:163} INFO - Started process (PID=11077) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:27:35,191] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:27:35,193] {logging_mixin.py:109} INFO - [2022-08-13 08:27:35,193] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:27:35,607] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:27:35,617] {logging_mixin.py:109} INFO - [2022-08-13 08:27:35,616] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:27:35,724] {logging_mixin.py:109} INFO - [2022-08-13 08:27:35,724] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:27:35,738] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.553 seconds
[2022-08-13 08:28:06,227] {processor.py:163} INFO - Started process (PID=11151) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:28:06,229] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:28:06,231] {logging_mixin.py:109} INFO - [2022-08-13 08:28:06,231] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:28:06,668] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:28:06,678] {logging_mixin.py:109} INFO - [2022-08-13 08:28:06,677] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:28:06,783] {logging_mixin.py:109} INFO - [2022-08-13 08:28:06,783] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:28:06,792] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.570 seconds
[2022-08-13 08:28:37,424] {processor.py:163} INFO - Started process (PID=11216) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:28:37,426] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:28:37,428] {logging_mixin.py:109} INFO - [2022-08-13 08:28:37,428] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:28:37,860] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:28:37,871] {logging_mixin.py:109} INFO - [2022-08-13 08:28:37,870] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:28:37,975] {logging_mixin.py:109} INFO - [2022-08-13 08:28:37,975] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:28:37,986] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.566 seconds
[2022-08-13 08:29:08,637] {processor.py:163} INFO - Started process (PID=11292) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:29:08,639] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:29:08,641] {logging_mixin.py:109} INFO - [2022-08-13 08:29:08,641] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:29:09,081] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:29:09,091] {logging_mixin.py:109} INFO - [2022-08-13 08:29:09,090] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:29:09,194] {logging_mixin.py:109} INFO - [2022-08-13 08:29:09,194] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:29:09,204] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.570 seconds
[2022-08-13 08:29:39,250] {processor.py:163} INFO - Started process (PID=11358) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:29:39,252] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:29:39,254] {logging_mixin.py:109} INFO - [2022-08-13 08:29:39,254] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:29:39,680] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:29:39,691] {logging_mixin.py:109} INFO - [2022-08-13 08:29:39,690] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:29:39,803] {logging_mixin.py:109} INFO - [2022-08-13 08:29:39,802] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:29:39,813] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.567 seconds
[2022-08-13 08:30:10,456] {processor.py:163} INFO - Started process (PID=11433) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:30:10,458] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:30:10,460] {logging_mixin.py:109} INFO - [2022-08-13 08:30:10,459] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:30:10,949] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:30:10,959] {logging_mixin.py:109} INFO - [2022-08-13 08:30:10,958] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:30:10,972] {logging_mixin.py:109} INFO - [2022-08-13 08:30:10,972] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:30:10,980] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.528 seconds
[2022-08-13 08:30:41,026] {processor.py:163} INFO - Started process (PID=11500) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:30:41,028] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:30:41,030] {logging_mixin.py:109} INFO - [2022-08-13 08:30:41,030] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:30:41,503] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:30:41,513] {logging_mixin.py:109} INFO - [2022-08-13 08:30:41,513] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:30:41,530] {logging_mixin.py:109} INFO - [2022-08-13 08:30:41,530] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:30:41,542] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.543 seconds
[2022-08-13 08:31:11,806] {processor.py:163} INFO - Started process (PID=11575) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:31:11,809] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:31:11,811] {logging_mixin.py:109} INFO - [2022-08-13 08:31:11,811] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:31:12,321] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:31:12,340] {logging_mixin.py:109} INFO - [2022-08-13 08:31:12,339] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:31:12,355] {logging_mixin.py:109} INFO - [2022-08-13 08:31:12,355] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:31:12,365] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.565 seconds
[2022-08-13 08:31:42,950] {processor.py:163} INFO - Started process (PID=11640) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:31:42,952] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:31:42,954] {logging_mixin.py:109} INFO - [2022-08-13 08:31:42,954] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:31:43,445] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:31:43,457] {logging_mixin.py:109} INFO - [2022-08-13 08:31:43,457] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:31:43,470] {logging_mixin.py:109} INFO - [2022-08-13 08:31:43,470] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:31:43,479] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.532 seconds
[2022-08-13 08:32:14,179] {processor.py:163} INFO - Started process (PID=11715) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:32:14,181] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:32:14,183] {logging_mixin.py:109} INFO - [2022-08-13 08:32:14,183] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:32:14,724] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:32:14,734] {logging_mixin.py:109} INFO - [2022-08-13 08:32:14,734] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:32:14,748] {logging_mixin.py:109} INFO - [2022-08-13 08:32:14,748] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:32:14,758] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.584 seconds
[2022-08-13 08:32:44,964] {processor.py:163} INFO - Started process (PID=11782) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:32:44,966] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:32:44,971] {logging_mixin.py:109} INFO - [2022-08-13 08:32:44,970] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:32:45,434] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:32:45,442] {logging_mixin.py:109} INFO - [2022-08-13 08:32:45,441] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:32:45,456] {logging_mixin.py:109} INFO - [2022-08-13 08:32:45,456] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:32:45,466] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.506 seconds
[2022-08-13 08:33:15,897] {processor.py:163} INFO - Started process (PID=11847) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:33:15,900] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:33:15,903] {logging_mixin.py:109} INFO - [2022-08-13 08:33:15,902] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:33:16,393] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:33:16,406] {logging_mixin.py:109} INFO - [2022-08-13 08:33:16,406] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:33:16,423] {logging_mixin.py:109} INFO - [2022-08-13 08:33:16,422] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:33:16,477] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.586 seconds
[2022-08-13 08:33:46,555] {processor.py:163} INFO - Started process (PID=11922) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:33:46,557] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:33:46,560] {logging_mixin.py:109} INFO - [2022-08-13 08:33:46,559] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:33:47,142] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:33:47,151] {logging_mixin.py:109} INFO - [2022-08-13 08:33:47,151] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:33:47,165] {logging_mixin.py:109} INFO - [2022-08-13 08:33:47,165] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:33:47,175] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.624 seconds
[2022-08-13 08:34:17,253] {processor.py:163} INFO - Started process (PID=11988) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:34:17,257] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:34:17,259] {logging_mixin.py:109} INFO - [2022-08-13 08:34:17,259] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:34:17,802] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:34:17,812] {logging_mixin.py:109} INFO - [2022-08-13 08:34:17,811] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:34:17,825] {logging_mixin.py:109} INFO - [2022-08-13 08:34:17,825] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:34:17,835] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.587 seconds
[2022-08-13 08:34:47,979] {processor.py:163} INFO - Started process (PID=12062) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:34:47,982] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:34:47,984] {logging_mixin.py:109} INFO - [2022-08-13 08:34:47,984] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:34:48,460] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:34:48,469] {logging_mixin.py:109} INFO - [2022-08-13 08:34:48,468] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:34:48,483] {logging_mixin.py:109} INFO - [2022-08-13 08:34:48,483] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:34:48,494] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.520 seconds
[2022-08-13 08:35:19,146] {processor.py:163} INFO - Started process (PID=12127) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:35:19,149] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:35:19,151] {logging_mixin.py:109} INFO - [2022-08-13 08:35:19,151] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:35:19,717] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:35:19,726] {logging_mixin.py:109} INFO - [2022-08-13 08:35:19,726] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:35:19,740] {logging_mixin.py:109} INFO - [2022-08-13 08:35:19,740] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:35:19,750] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.609 seconds
[2022-08-13 08:35:50,557] {processor.py:163} INFO - Started process (PID=12201) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:35:50,560] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:35:50,562] {logging_mixin.py:109} INFO - [2022-08-13 08:35:50,562] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:35:51,028] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:35:51,037] {logging_mixin.py:109} INFO - [2022-08-13 08:35:51,036] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:35:51,057] {logging_mixin.py:109} INFO - [2022-08-13 08:35:51,057] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:35:51,070] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.519 seconds
[2022-08-13 08:36:21,391] {processor.py:163} INFO - Started process (PID=12266) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:36:21,394] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:36:21,396] {logging_mixin.py:109} INFO - [2022-08-13 08:36:21,395] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:36:21,858] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:36:21,866] {logging_mixin.py:109} INFO - [2022-08-13 08:36:21,866] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:36:21,881] {logging_mixin.py:109} INFO - [2022-08-13 08:36:21,881] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:36:21,892] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.506 seconds
[2022-08-13 08:36:52,022] {processor.py:163} INFO - Started process (PID=12342) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:36:52,025] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:36:52,028] {logging_mixin.py:109} INFO - [2022-08-13 08:36:52,028] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:36:52,632] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:36:52,640] {logging_mixin.py:109} INFO - [2022-08-13 08:36:52,639] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:36:52,654] {logging_mixin.py:109} INFO - [2022-08-13 08:36:52,654] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:36:52,670] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.651 seconds
[2022-08-13 08:37:22,933] {processor.py:163} INFO - Started process (PID=12407) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:37:22,939] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:37:22,941] {logging_mixin.py:109} INFO - [2022-08-13 08:37:22,941] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:37:23,437] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:37:23,445] {logging_mixin.py:109} INFO - [2022-08-13 08:37:23,445] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:37:23,459] {logging_mixin.py:109} INFO - [2022-08-13 08:37:23,459] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:37:23,468] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.540 seconds
[2022-08-13 08:37:54,036] {processor.py:163} INFO - Started process (PID=12483) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:37:54,039] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:37:54,041] {logging_mixin.py:109} INFO - [2022-08-13 08:37:54,040] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:37:54,564] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:37:54,573] {logging_mixin.py:109} INFO - [2022-08-13 08:37:54,572] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:37:54,588] {logging_mixin.py:109} INFO - [2022-08-13 08:37:54,588] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:37:54,597] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.566 seconds
[2022-08-13 08:38:24,794] {processor.py:163} INFO - Started process (PID=12548) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:38:24,796] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:38:24,797] {logging_mixin.py:109} INFO - [2022-08-13 08:38:24,797] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:38:25,270] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:38:25,278] {logging_mixin.py:109} INFO - [2022-08-13 08:38:25,278] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:38:25,292] {logging_mixin.py:109} INFO - [2022-08-13 08:38:25,292] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:38:25,301] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.512 seconds
[2022-08-13 08:38:56,014] {processor.py:163} INFO - Started process (PID=12614) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:38:56,017] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:38:56,019] {logging_mixin.py:109} INFO - [2022-08-13 08:38:56,019] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:38:56,509] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:38:56,518] {logging_mixin.py:109} INFO - [2022-08-13 08:38:56,517] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:38:56,533] {logging_mixin.py:109} INFO - [2022-08-13 08:38:56,533] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:38:56,542] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.534 seconds
[2022-08-13 08:39:26,757] {processor.py:163} INFO - Started process (PID=12689) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:39:26,760] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:39:26,762] {logging_mixin.py:109} INFO - [2022-08-13 08:39:26,761] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:39:27,261] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:39:27,271] {logging_mixin.py:109} INFO - [2022-08-13 08:39:27,270] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:39:27,285] {logging_mixin.py:109} INFO - [2022-08-13 08:39:27,285] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:39:27,295] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.542 seconds
[2022-08-13 08:39:57,867] {processor.py:163} INFO - Started process (PID=12755) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:39:57,870] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:39:57,871] {logging_mixin.py:109} INFO - [2022-08-13 08:39:57,871] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:39:58,455] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:39:58,463] {logging_mixin.py:109} INFO - [2022-08-13 08:39:58,463] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:39:58,477] {logging_mixin.py:109} INFO - [2022-08-13 08:39:58,477] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:39:58,486] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.624 seconds
[2022-08-13 08:40:28,711] {processor.py:163} INFO - Started process (PID=12829) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:40:28,714] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:40:28,715] {logging_mixin.py:109} INFO - [2022-08-13 08:40:28,715] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:40:29,220] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:40:29,228] {logging_mixin.py:109} INFO - [2022-08-13 08:40:29,227] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:40:29,243] {logging_mixin.py:109} INFO - [2022-08-13 08:40:29,242] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:40:29,253] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.548 seconds
[2022-08-13 08:41:00,158] {processor.py:163} INFO - Started process (PID=12896) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:41:00,161] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:41:00,163] {logging_mixin.py:109} INFO - [2022-08-13 08:41:00,162] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:41:00,682] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:41:00,693] {logging_mixin.py:109} INFO - [2022-08-13 08:41:00,693] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:41:00,711] {logging_mixin.py:109} INFO - [2022-08-13 08:41:00,711] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:41:00,726] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.572 seconds
[2022-08-13 08:41:31,470] {processor.py:163} INFO - Started process (PID=12970) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:41:31,473] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:41:31,474] {logging_mixin.py:109} INFO - [2022-08-13 08:41:31,474] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:41:31,972] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:41:31,983] {logging_mixin.py:109} INFO - [2022-08-13 08:41:31,982] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:41:31,999] {logging_mixin.py:109} INFO - [2022-08-13 08:41:31,999] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:41:32,009] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.543 seconds
[2022-08-13 08:42:02,829] {processor.py:163} INFO - Started process (PID=13037) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:42:02,832] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:42:02,833] {logging_mixin.py:109} INFO - [2022-08-13 08:42:02,833] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:42:03,444] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:42:03,454] {logging_mixin.py:109} INFO - [2022-08-13 08:42:03,453] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:42:03,468] {logging_mixin.py:109} INFO - [2022-08-13 08:42:03,468] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:42:03,478] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.652 seconds
[2022-08-13 08:42:33,653] {processor.py:163} INFO - Started process (PID=13112) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:42:33,660] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:42:33,663] {logging_mixin.py:109} INFO - [2022-08-13 08:42:33,662] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:42:34,135] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:42:34,146] {logging_mixin.py:109} INFO - [2022-08-13 08:42:34,146] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:42:34,164] {logging_mixin.py:109} INFO - [2022-08-13 08:42:34,164] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:42:34,176] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.528 seconds
[2022-08-13 08:43:04,278] {processor.py:163} INFO - Started process (PID=13177) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:43:04,281] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:43:04,282] {logging_mixin.py:109} INFO - [2022-08-13 08:43:04,282] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:43:04,759] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:43:04,768] {logging_mixin.py:109} INFO - [2022-08-13 08:43:04,767] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:43:04,781] {logging_mixin.py:109} INFO - [2022-08-13 08:43:04,781] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:43:04,790] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.517 seconds
[2022-08-13 08:43:35,149] {processor.py:163} INFO - Started process (PID=13251) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:43:35,151] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:43:35,154] {logging_mixin.py:109} INFO - [2022-08-13 08:43:35,154] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:43:35,725] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:43:35,736] {logging_mixin.py:109} INFO - [2022-08-13 08:43:35,735] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:43:35,752] {logging_mixin.py:109} INFO - [2022-08-13 08:43:35,752] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:43:35,767] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.622 seconds
[2022-08-13 08:44:06,353] {processor.py:163} INFO - Started process (PID=13316) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:44:06,357] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:44:06,358] {logging_mixin.py:109} INFO - [2022-08-13 08:44:06,358] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:44:06,887] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:44:06,895] {logging_mixin.py:109} INFO - [2022-08-13 08:44:06,894] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:44:06,908] {logging_mixin.py:109} INFO - [2022-08-13 08:44:06,908] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:44:06,917] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.569 seconds
[2022-08-13 08:44:37,860] {processor.py:163} INFO - Started process (PID=13392) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:44:37,862] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:44:37,864] {logging_mixin.py:109} INFO - [2022-08-13 08:44:37,864] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:44:38,481] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:44:38,493] {logging_mixin.py:109} INFO - [2022-08-13 08:44:38,493] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:44:38,513] {logging_mixin.py:109} INFO - [2022-08-13 08:44:38,513] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:44:38,527] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.670 seconds
[2022-08-13 08:45:09,214] {processor.py:163} INFO - Started process (PID=13458) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:45:09,216] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:45:09,217] {logging_mixin.py:109} INFO - [2022-08-13 08:45:09,217] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:45:09,679] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:45:09,689] {logging_mixin.py:109} INFO - [2022-08-13 08:45:09,688] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:45:09,703] {logging_mixin.py:109} INFO - [2022-08-13 08:45:09,703] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:45:09,712] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.503 seconds
[2022-08-13 08:45:40,385] {processor.py:163} INFO - Started process (PID=13534) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:45:40,388] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:45:40,390] {logging_mixin.py:109} INFO - [2022-08-13 08:45:40,390] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:45:40,899] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:45:40,908] {logging_mixin.py:109} INFO - [2022-08-13 08:45:40,907] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:45:40,921] {logging_mixin.py:109} INFO - [2022-08-13 08:45:40,921] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:45:40,930] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.573 seconds
[2022-08-13 08:46:11,850] {processor.py:163} INFO - Started process (PID=13600) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:46:11,853] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:46:11,855] {logging_mixin.py:109} INFO - [2022-08-13 08:46:11,855] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:46:12,391] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:46:12,400] {logging_mixin.py:109} INFO - [2022-08-13 08:46:12,400] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:46:12,414] {logging_mixin.py:109} INFO - [2022-08-13 08:46:12,413] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:46:12,422] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.575 seconds
[2022-08-13 08:46:42,492] {processor.py:163} INFO - Started process (PID=13668) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:46:42,493] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:46:42,495] {logging_mixin.py:109} INFO - [2022-08-13 08:46:42,494] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:46:42,995] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:46:43,005] {logging_mixin.py:109} INFO - [2022-08-13 08:46:43,004] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:46:43,018] {logging_mixin.py:109} INFO - [2022-08-13 08:46:43,018] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:46:43,027] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.539 seconds
[2022-08-13 08:47:13,100] {processor.py:163} INFO - Started process (PID=13741) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:47:13,102] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:47:13,104] {logging_mixin.py:109} INFO - [2022-08-13 08:47:13,103] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:47:13,612] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:47:13,621] {logging_mixin.py:109} INFO - [2022-08-13 08:47:13,621] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:47:13,635] {logging_mixin.py:109} INFO - [2022-08-13 08:47:13,635] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:47:13,643] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.550 seconds
[2022-08-13 08:47:44,283] {processor.py:163} INFO - Started process (PID=13807) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:47:44,285] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:47:44,286] {logging_mixin.py:109} INFO - [2022-08-13 08:47:44,286] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:47:44,781] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:47:44,792] {logging_mixin.py:109} INFO - [2022-08-13 08:47:44,791] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:47:44,807] {logging_mixin.py:109} INFO - [2022-08-13 08:47:44,807] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:47:44,818] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.539 seconds
[2022-08-13 08:48:14,858] {processor.py:163} INFO - Started process (PID=13882) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:48:14,860] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:48:14,861] {logging_mixin.py:109} INFO - [2022-08-13 08:48:14,861] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:48:15,327] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:48:15,335] {logging_mixin.py:109} INFO - [2022-08-13 08:48:15,334] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:48:15,348] {logging_mixin.py:109} INFO - [2022-08-13 08:48:15,347] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:48:15,356] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.501 seconds
[2022-08-13 08:48:46,123] {processor.py:163} INFO - Started process (PID=13947) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:48:46,126] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:48:46,128] {logging_mixin.py:109} INFO - [2022-08-13 08:48:46,128] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:48:46,860] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:48:46,872] {logging_mixin.py:109} INFO - [2022-08-13 08:48:46,871] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:48:46,896] {logging_mixin.py:109} INFO - [2022-08-13 08:48:46,896] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:48:46,916] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.799 seconds
[2022-08-13 08:49:17,613] {processor.py:163} INFO - Started process (PID=14025) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:49:17,615] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:49:17,617] {logging_mixin.py:109} INFO - [2022-08-13 08:49:17,617] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:49:18,217] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:49:18,226] {logging_mixin.py:109} INFO - [2022-08-13 08:49:18,226] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:49:18,240] {logging_mixin.py:109} INFO - [2022-08-13 08:49:18,240] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:49:18,249] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.642 seconds
[2022-08-13 08:49:48,367] {processor.py:163} INFO - Started process (PID=14095) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:49:48,369] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:49:48,370] {logging_mixin.py:109} INFO - [2022-08-13 08:49:48,370] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:49:48,951] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:49:48,961] {logging_mixin.py:109} INFO - [2022-08-13 08:49:48,961] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:49:48,975] {logging_mixin.py:109} INFO - [2022-08-13 08:49:48,975] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:49:48,985] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.622 seconds
[2022-08-13 08:50:19,823] {processor.py:163} INFO - Started process (PID=14172) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:50:19,835] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:50:19,837] {logging_mixin.py:109} INFO - [2022-08-13 08:50:19,837] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:50:20,398] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:50:20,408] {logging_mixin.py:109} INFO - [2022-08-13 08:50:20,408] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:50:20,423] {logging_mixin.py:109} INFO - [2022-08-13 08:50:20,423] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:50:20,433] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.613 seconds
[2022-08-13 08:50:51,217] {processor.py:163} INFO - Started process (PID=14239) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:50:51,219] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:50:51,221] {logging_mixin.py:109} INFO - [2022-08-13 08:50:51,221] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:50:51,810] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:50:51,820] {logging_mixin.py:109} INFO - [2022-08-13 08:50:51,819] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:50:51,834] {logging_mixin.py:109} INFO - [2022-08-13 08:50:51,833] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:50:51,846] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.632 seconds
[2022-08-13 08:51:22,631] {processor.py:163} INFO - Started process (PID=14315) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:51:22,639] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:51:22,642] {logging_mixin.py:109} INFO - [2022-08-13 08:51:22,641] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:51:23,185] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:51:23,195] {logging_mixin.py:109} INFO - [2022-08-13 08:51:23,194] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:51:23,209] {logging_mixin.py:109} INFO - [2022-08-13 08:51:23,209] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:51:23,218] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.590 seconds
[2022-08-13 08:51:53,302] {processor.py:163} INFO - Started process (PID=14385) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:51:53,308] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:51:53,311] {logging_mixin.py:109} INFO - [2022-08-13 08:51:53,310] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:51:53,822] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:51:53,833] {logging_mixin.py:109} INFO - [2022-08-13 08:51:53,833] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:51:53,847] {logging_mixin.py:109} INFO - [2022-08-13 08:51:53,847] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:51:53,857] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.560 seconds
[2022-08-13 08:52:24,318] {processor.py:163} INFO - Started process (PID=14451) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:52:24,320] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:52:24,322] {logging_mixin.py:109} INFO - [2022-08-13 08:52:24,322] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:52:24,835] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:52:24,844] {logging_mixin.py:109} INFO - [2022-08-13 08:52:24,844] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:52:24,859] {logging_mixin.py:109} INFO - [2022-08-13 08:52:24,859] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:52:24,871] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.559 seconds
[2022-08-13 08:52:55,073] {processor.py:163} INFO - Started process (PID=14523) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:52:55,075] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:52:55,077] {logging_mixin.py:109} INFO - [2022-08-13 08:52:55,077] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:52:55,613] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:52:55,622] {logging_mixin.py:109} INFO - [2022-08-13 08:52:55,621] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:52:55,636] {logging_mixin.py:109} INFO - [2022-08-13 08:52:55,636] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:52:55,646] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.577 seconds
[2022-08-13 08:53:25,715] {processor.py:163} INFO - Started process (PID=14589) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:53:25,717] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:53:25,718] {logging_mixin.py:109} INFO - [2022-08-13 08:53:25,718] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:53:26,198] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:53:26,207] {logging_mixin.py:109} INFO - [2022-08-13 08:53:26,207] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:53:26,220] {logging_mixin.py:109} INFO - [2022-08-13 08:53:26,220] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:53:26,228] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.517 seconds
[2022-08-13 08:53:56,776] {processor.py:163} INFO - Started process (PID=14663) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:53:56,779] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:53:56,781] {logging_mixin.py:109} INFO - [2022-08-13 08:53:56,781] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:53:57,221] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:53:57,231] {logging_mixin.py:109} INFO - [2022-08-13 08:53:57,231] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:53:57,244] {logging_mixin.py:109} INFO - [2022-08-13 08:53:57,244] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:53:57,253] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.484 seconds
[2022-08-13 08:54:27,373] {processor.py:163} INFO - Started process (PID=14728) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:54:27,375] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:54:27,376] {logging_mixin.py:109} INFO - [2022-08-13 08:54:27,376] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:54:27,957] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:54:27,966] {logging_mixin.py:109} INFO - [2022-08-13 08:54:27,966] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:54:27,979] {logging_mixin.py:109} INFO - [2022-08-13 08:54:27,979] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:54:27,989] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.619 seconds
[2022-08-13 08:54:58,789] {processor.py:163} INFO - Started process (PID=14804) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:54:58,791] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:54:58,792] {logging_mixin.py:109} INFO - [2022-08-13 08:54:58,792] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:54:59,259] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:54:59,269] {logging_mixin.py:109} INFO - [2022-08-13 08:54:59,268] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:54:59,283] {logging_mixin.py:109} INFO - [2022-08-13 08:54:59,283] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:54:59,292] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.507 seconds
[2022-08-13 08:55:30,189] {processor.py:163} INFO - Started process (PID=14869) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:55:30,191] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:55:30,192] {logging_mixin.py:109} INFO - [2022-08-13 08:55:30,192] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:55:30,714] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:55:30,723] {logging_mixin.py:109} INFO - [2022-08-13 08:55:30,723] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:55:30,738] {logging_mixin.py:109} INFO - [2022-08-13 08:55:30,738] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:55:30,748] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.563 seconds
[2022-08-13 08:56:01,721] {processor.py:163} INFO - Started process (PID=14945) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:56:01,724] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:56:01,725] {logging_mixin.py:109} INFO - [2022-08-13 08:56:01,725] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:56:02,244] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:56:02,252] {logging_mixin.py:109} INFO - [2022-08-13 08:56:02,252] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:56:02,266] {logging_mixin.py:109} INFO - [2022-08-13 08:56:02,266] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:56:02,276] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.559 seconds
[2022-08-13 08:56:32,360] {processor.py:163} INFO - Started process (PID=15012) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:56:32,362] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:56:32,364] {logging_mixin.py:109} INFO - [2022-08-13 08:56:32,363] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:56:32,889] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:56:32,899] {logging_mixin.py:109} INFO - [2022-08-13 08:56:32,898] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:56:32,915] {logging_mixin.py:109} INFO - [2022-08-13 08:56:32,915] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:56:32,928] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.571 seconds
[2022-08-13 08:57:03,456] {processor.py:163} INFO - Started process (PID=15085) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:57:03,459] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:57:03,461] {logging_mixin.py:109} INFO - [2022-08-13 08:57:03,461] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:57:03,973] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:57:03,982] {logging_mixin.py:109} INFO - [2022-08-13 08:57:03,982] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:57:04,000] {logging_mixin.py:109} INFO - [2022-08-13 08:57:04,000] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:57:04,010] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.557 seconds
[2022-08-13 08:57:34,217] {processor.py:163} INFO - Started process (PID=15151) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:57:34,221] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:57:34,224] {logging_mixin.py:109} INFO - [2022-08-13 08:57:34,223] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:57:34,768] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:57:34,777] {logging_mixin.py:109} INFO - [2022-08-13 08:57:34,777] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:57:34,794] {logging_mixin.py:109} INFO - [2022-08-13 08:57:34,794] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:57:34,812] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.600 seconds
[2022-08-13 08:58:04,938] {processor.py:163} INFO - Started process (PID=15227) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:58:04,940] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:58:04,943] {logging_mixin.py:109} INFO - [2022-08-13 08:58:04,943] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:58:05,459] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:58:05,468] {logging_mixin.py:109} INFO - [2022-08-13 08:58:05,467] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:58:05,482] {logging_mixin.py:109} INFO - [2022-08-13 08:58:05,482] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:58:05,495] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.561 seconds
[2022-08-13 08:58:35,634] {processor.py:163} INFO - Started process (PID=15294) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:58:35,636] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:58:35,638] {logging_mixin.py:109} INFO - [2022-08-13 08:58:35,638] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:58:36,179] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:58:36,188] {logging_mixin.py:109} INFO - [2022-08-13 08:58:36,187] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:58:36,209] {logging_mixin.py:109} INFO - [2022-08-13 08:58:36,209] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:58:36,228] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.599 seconds
[2022-08-13 08:59:06,490] {processor.py:163} INFO - Started process (PID=15362) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:59:06,492] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:59:06,494] {logging_mixin.py:109} INFO - [2022-08-13 08:59:06,493] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:59:07,001] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:59:07,013] {logging_mixin.py:109} INFO - [2022-08-13 08:59:07,012] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:59:07,028] {logging_mixin.py:109} INFO - [2022-08-13 08:59:07,028] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:59:07,037] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.551 seconds
[2022-08-13 08:59:37,959] {processor.py:163} INFO - Started process (PID=15440) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:59:37,961] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 08:59:37,962] {logging_mixin.py:109} INFO - [2022-08-13 08:59:37,962] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:59:38,504] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 08:59:38,516] {logging_mixin.py:109} INFO - [2022-08-13 08:59:38,516] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 08:59:38,535] {logging_mixin.py:109} INFO - [2022-08-13 08:59:38,535] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 08:59:38,547] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.592 seconds
[2022-08-13 09:00:09,036] {processor.py:163} INFO - Started process (PID=15506) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:00:09,039] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:00:09,040] {logging_mixin.py:109} INFO - [2022-08-13 09:00:09,040] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:00:09,598] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:00:09,611] {logging_mixin.py:109} INFO - [2022-08-13 09:00:09,611] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:00:09,625] {logging_mixin.py:109} INFO - [2022-08-13 09:00:09,625] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:00:09,634] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.605 seconds
[2022-08-13 09:00:39,761] {processor.py:163} INFO - Started process (PID=15583) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:00:39,764] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:00:39,766] {logging_mixin.py:109} INFO - [2022-08-13 09:00:39,765] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:00:40,300] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:00:40,309] {logging_mixin.py:109} INFO - [2022-08-13 09:00:40,309] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:00:40,323] {logging_mixin.py:109} INFO - [2022-08-13 09:00:40,323] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:00:40,335] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.602 seconds
[2022-08-13 09:01:10,410] {processor.py:163} INFO - Started process (PID=15649) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:01:10,412] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:01:10,413] {logging_mixin.py:109} INFO - [2022-08-13 09:01:10,413] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:01:10,922] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:01:10,933] {logging_mixin.py:109} INFO - [2022-08-13 09:01:10,932] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:01:10,947] {logging_mixin.py:109} INFO - [2022-08-13 09:01:10,947] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:01:10,957] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.551 seconds
[2022-08-13 09:01:41,245] {processor.py:163} INFO - Started process (PID=15725) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:01:41,247] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:01:41,248] {logging_mixin.py:109} INFO - [2022-08-13 09:01:41,248] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:01:41,803] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:01:41,811] {logging_mixin.py:109} INFO - [2022-08-13 09:01:41,811] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:01:41,825] {logging_mixin.py:109} INFO - [2022-08-13 09:01:41,824] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:01:41,836] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.594 seconds
[2022-08-13 09:02:12,677] {processor.py:163} INFO - Started process (PID=15791) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:02:12,679] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:02:12,680] {logging_mixin.py:109} INFO - [2022-08-13 09:02:12,680] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:02:13,233] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:02:13,244] {logging_mixin.py:109} INFO - [2022-08-13 09:02:13,244] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:02:13,257] {logging_mixin.py:109} INFO - [2022-08-13 09:02:13,257] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:02:13,267] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.594 seconds
[2022-08-13 09:02:43,331] {processor.py:163} INFO - Started process (PID=15865) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:02:43,333] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:02:43,335] {logging_mixin.py:109} INFO - [2022-08-13 09:02:43,335] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:02:43,887] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:02:43,896] {logging_mixin.py:109} INFO - [2022-08-13 09:02:43,895] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:02:43,910] {logging_mixin.py:109} INFO - [2022-08-13 09:02:43,910] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:02:43,918] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.590 seconds
[2022-08-13 09:03:14,795] {processor.py:163} INFO - Started process (PID=15932) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:03:14,797] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:03:14,799] {logging_mixin.py:109} INFO - [2022-08-13 09:03:14,799] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:03:15,327] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:03:15,335] {logging_mixin.py:109} INFO - [2022-08-13 09:03:15,335] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:03:15,349] {logging_mixin.py:109} INFO - [2022-08-13 09:03:15,348] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:03:15,359] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.571 seconds
[2022-08-13 09:03:46,030] {processor.py:163} INFO - Started process (PID=16007) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:03:46,033] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:03:46,035] {logging_mixin.py:109} INFO - [2022-08-13 09:03:46,034] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:03:46,545] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:03:46,556] {logging_mixin.py:109} INFO - [2022-08-13 09:03:46,556] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:03:46,574] {logging_mixin.py:109} INFO - [2022-08-13 09:03:46,573] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:03:46,588] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.562 seconds
[2022-08-13 09:04:16,714] {processor.py:163} INFO - Started process (PID=16072) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:04:16,717] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:04:16,719] {logging_mixin.py:109} INFO - [2022-08-13 09:04:16,719] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:04:17,171] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:04:17,179] {logging_mixin.py:109} INFO - [2022-08-13 09:04:17,179] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:04:17,193] {logging_mixin.py:109} INFO - [2022-08-13 09:04:17,193] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:04:17,200] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.492 seconds
[2022-08-13 09:04:47,982] {processor.py:163} INFO - Started process (PID=16144) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:04:47,985] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:04:47,987] {logging_mixin.py:109} INFO - [2022-08-13 09:04:47,987] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:04:48,555] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:04:48,565] {logging_mixin.py:109} INFO - [2022-08-13 09:04:48,565] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:04:48,579] {logging_mixin.py:109} INFO - [2022-08-13 09:04:48,579] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:04:48,588] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.613 seconds
[2022-08-13 09:05:18,994] {processor.py:163} INFO - Started process (PID=16212) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:05:18,997] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:05:18,999] {logging_mixin.py:109} INFO - [2022-08-13 09:05:18,998] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:05:19,536] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:05:19,548] {logging_mixin.py:109} INFO - [2022-08-13 09:05:19,547] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:05:19,566] {logging_mixin.py:109} INFO - [2022-08-13 09:05:19,566] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:05:19,579] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.591 seconds
[2022-08-13 09:05:49,736] {processor.py:163} INFO - Started process (PID=16277) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:05:49,740] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:05:49,743] {logging_mixin.py:109} INFO - [2022-08-13 09:05:49,742] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:05:50,218] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:05:50,227] {logging_mixin.py:109} INFO - [2022-08-13 09:05:50,226] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:05:50,240] {logging_mixin.py:109} INFO - [2022-08-13 09:05:50,240] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:05:50,250] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.523 seconds
[2022-08-13 09:06:20,775] {processor.py:163} INFO - Started process (PID=16352) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:06:20,777] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:06:20,779] {logging_mixin.py:109} INFO - [2022-08-13 09:06:20,779] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:06:21,256] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:06:21,265] {logging_mixin.py:109} INFO - [2022-08-13 09:06:21,264] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:06:21,277] {logging_mixin.py:109} INFO - [2022-08-13 09:06:21,277] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:06:21,286] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.516 seconds
[2022-08-13 09:06:51,360] {processor.py:163} INFO - Started process (PID=16417) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:06:51,363] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:06:51,365] {logging_mixin.py:109} INFO - [2022-08-13 09:06:51,365] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:06:51,885] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:06:51,895] {logging_mixin.py:109} INFO - [2022-08-13 09:06:51,895] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:06:51,911] {logging_mixin.py:109} INFO - [2022-08-13 09:06:51,911] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:06:51,920] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.565 seconds
[2022-08-13 09:07:22,602] {processor.py:163} INFO - Started process (PID=16491) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:07:22,604] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:07:22,606] {logging_mixin.py:109} INFO - [2022-08-13 09:07:22,606] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:07:23,108] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:07:23,117] {logging_mixin.py:109} INFO - [2022-08-13 09:07:23,117] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:07:23,134] {logging_mixin.py:109} INFO - [2022-08-13 09:07:23,134] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:07:23,142] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.545 seconds
[2022-08-13 09:07:53,422] {processor.py:163} INFO - Started process (PID=16557) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:07:53,427] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:07:53,429] {logging_mixin.py:109} INFO - [2022-08-13 09:07:53,429] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:07:53,981] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:07:53,990] {logging_mixin.py:109} INFO - [2022-08-13 09:07:53,990] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:07:54,008] {logging_mixin.py:109} INFO - [2022-08-13 09:07:54,008] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:07:54,026] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.608 seconds
[2022-08-13 09:08:24,681] {processor.py:163} INFO - Started process (PID=16632) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:08:24,684] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:08:24,686] {logging_mixin.py:109} INFO - [2022-08-13 09:08:24,685] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:08:25,189] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:08:25,198] {logging_mixin.py:109} INFO - [2022-08-13 09:08:25,198] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:08:25,221] {logging_mixin.py:109} INFO - [2022-08-13 09:08:25,221] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:08:25,232] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.554 seconds
[2022-08-13 09:08:55,937] {processor.py:163} INFO - Started process (PID=16698) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:08:55,940] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:08:55,943] {logging_mixin.py:109} INFO - [2022-08-13 09:08:55,942] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:08:56,525] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:08:56,534] {logging_mixin.py:109} INFO - [2022-08-13 09:08:56,533] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:08:56,548] {logging_mixin.py:109} INFO - [2022-08-13 09:08:56,548] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:08:56,561] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.627 seconds
[2022-08-13 09:09:26,806] {processor.py:163} INFO - Started process (PID=16774) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:09:26,812] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:09:26,814] {logging_mixin.py:109} INFO - [2022-08-13 09:09:26,814] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:09:27,360] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:09:27,369] {logging_mixin.py:109} INFO - [2022-08-13 09:09:27,368] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:09:27,383] {logging_mixin.py:109} INFO - [2022-08-13 09:09:27,382] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:09:27,398] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.597 seconds
[2022-08-13 09:09:58,123] {processor.py:163} INFO - Started process (PID=16841) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:09:58,125] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:09:58,127] {logging_mixin.py:109} INFO - [2022-08-13 09:09:58,127] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:09:58,677] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:09:58,687] {logging_mixin.py:109} INFO - [2022-08-13 09:09:58,686] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:09:58,700] {logging_mixin.py:109} INFO - [2022-08-13 09:09:58,700] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:09:58,709] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.594 seconds
[2022-08-13 09:10:29,498] {processor.py:163} INFO - Started process (PID=16918) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:10:29,500] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:10:29,501] {logging_mixin.py:109} INFO - [2022-08-13 09:10:29,501] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:10:30,061] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:10:30,070] {logging_mixin.py:109} INFO - [2022-08-13 09:10:30,070] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:10:30,087] {logging_mixin.py:109} INFO - [2022-08-13 09:10:30,087] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:10:30,099] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.605 seconds
[2022-08-13 09:11:00,783] {processor.py:163} INFO - Started process (PID=16983) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:11:00,786] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:11:00,787] {logging_mixin.py:109} INFO - [2022-08-13 09:11:00,787] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:11:01,331] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:11:01,342] {logging_mixin.py:109} INFO - [2022-08-13 09:11:01,342] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:11:01,362] {logging_mixin.py:109} INFO - [2022-08-13 09:11:01,361] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:11:01,374] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.595 seconds
[2022-08-13 09:11:32,138] {processor.py:163} INFO - Started process (PID=17054) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:11:32,141] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:11:32,142] {logging_mixin.py:109} INFO - [2022-08-13 09:11:32,142] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:11:32,664] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:11:32,673] {logging_mixin.py:109} INFO - [2022-08-13 09:11:32,672] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:11:32,686] {logging_mixin.py:109} INFO - [2022-08-13 09:11:32,686] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:11:32,694] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.560 seconds
[2022-08-13 09:12:02,819] {processor.py:163} INFO - Started process (PID=17122) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:12:02,822] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:12:02,824] {logging_mixin.py:109} INFO - [2022-08-13 09:12:02,823] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:12:03,377] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:12:03,389] {logging_mixin.py:109} INFO - [2022-08-13 09:12:03,388] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:12:03,407] {logging_mixin.py:109} INFO - [2022-08-13 09:12:03,407] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:12:03,415] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.601 seconds
[2022-08-13 09:12:34,166] {processor.py:163} INFO - Started process (PID=17187) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:12:34,168] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:12:34,170] {logging_mixin.py:109} INFO - [2022-08-13 09:12:34,170] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:12:34,649] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:12:34,661] {logging_mixin.py:109} INFO - [2022-08-13 09:12:34,661] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:12:34,675] {logging_mixin.py:109} INFO - [2022-08-13 09:12:34,675] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:12:34,685] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.524 seconds
[2022-08-13 09:13:05,459] {processor.py:163} INFO - Started process (PID=17262) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:13:05,462] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:13:05,464] {logging_mixin.py:109} INFO - [2022-08-13 09:13:05,464] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:13:05,961] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:13:05,972] {logging_mixin.py:109} INFO - [2022-08-13 09:13:05,972] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:13:05,997] {logging_mixin.py:109} INFO - [2022-08-13 09:13:05,997] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:13:06,011] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.557 seconds
[2022-08-13 09:13:36,805] {processor.py:163} INFO - Started process (PID=17327) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:13:36,808] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:13:36,810] {logging_mixin.py:109} INFO - [2022-08-13 09:13:36,810] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:13:37,294] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:13:37,302] {logging_mixin.py:109} INFO - [2022-08-13 09:13:37,302] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:13:37,316] {logging_mixin.py:109} INFO - [2022-08-13 09:13:37,316] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:13:37,325] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.528 seconds
[2022-08-13 09:14:08,206] {processor.py:163} INFO - Started process (PID=17401) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:14:08,208] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:14:08,209] {logging_mixin.py:109} INFO - [2022-08-13 09:14:08,209] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:14:08,706] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:14:08,714] {logging_mixin.py:109} INFO - [2022-08-13 09:14:08,714] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:14:08,728] {logging_mixin.py:109} INFO - [2022-08-13 09:14:08,728] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:14:08,737] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.536 seconds
[2022-08-13 09:14:39,162] {processor.py:163} INFO - Started process (PID=17469) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:14:39,166] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:14:39,167] {logging_mixin.py:109} INFO - [2022-08-13 09:14:39,167] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:14:39,786] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:14:39,800] {logging_mixin.py:109} INFO - [2022-08-13 09:14:39,799] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:14:39,819] {logging_mixin.py:109} INFO - [2022-08-13 09:14:39,819] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:14:39,832] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.695 seconds
[2022-08-13 09:15:10,739] {processor.py:163} INFO - Started process (PID=17544) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:15:10,742] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:15:10,744] {logging_mixin.py:109} INFO - [2022-08-13 09:15:10,744] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:15:11,486] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:15:11,499] {logging_mixin.py:109} INFO - [2022-08-13 09:15:11,499] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:15:11,521] {logging_mixin.py:109} INFO - [2022-08-13 09:15:11,521] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:15:11,533] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.799 seconds
[2022-08-13 09:15:46,518] {processor.py:163} INFO - Started process (PID=17610) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:15:46,606] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:15:46,872] {logging_mixin.py:109} INFO - [2022-08-13 09:15:46,871] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:15:58,558] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:15:58,619] {logging_mixin.py:109} INFO - [2022-08-13 09:15:58,617] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:15:58,746] {logging_mixin.py:109} INFO - [2022-08-13 09:15:58,746] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:15:58,799] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 12.379 seconds
[2022-08-13 09:16:30,598] {processor.py:163} INFO - Started process (PID=17679) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:16:30,640] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:16:30,676] {logging_mixin.py:109} INFO - [2022-08-13 09:16:30,675] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:16:44,706] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:16:44,875] {logging_mixin.py:109} INFO - [2022-08-13 09:16:44,870] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:16:44,945] {logging_mixin.py:109} INFO - [2022-08-13 09:16:44,945] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:16:45,003] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 14.501 seconds
[2022-08-13 09:17:15,856] {processor.py:163} INFO - Started process (PID=17755) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:17:15,864] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:17:15,870] {logging_mixin.py:109} INFO - [2022-08-13 09:17:15,869] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:17:17,127] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:17:17,148] {logging_mixin.py:109} INFO - [2022-08-13 09:17:17,147] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:17:17,187] {logging_mixin.py:109} INFO - [2022-08-13 09:17:17,187] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:17:17,210] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.366 seconds
[2022-08-13 09:17:52,041] {processor.py:163} INFO - Started process (PID=17816) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:17:52,080] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:17:52,087] {logging_mixin.py:109} INFO - [2022-08-13 09:17:52,087] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:17:59,687] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:17:59,743] {logging_mixin.py:109} INFO - [2022-08-13 09:17:59,741] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:17:59,882] {logging_mixin.py:109} INFO - [2022-08-13 09:17:59,881] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:17:59,940] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 7.991 seconds
[2022-08-13 09:18:55,726] {processor.py:163} INFO - Started process (PID=17884) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:18:55,762] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:18:55,781] {logging_mixin.py:109} INFO - [2022-08-13 09:18:55,781] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:19:13,256] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:19:13,637] {logging_mixin.py:109} INFO - [2022-08-13 09:19:13,635] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:19:13,877] {logging_mixin.py:109} INFO - [2022-08-13 09:19:13,877] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:19:14,079] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 18.445 seconds
[2022-08-13 09:19:51,745] {processor.py:163} INFO - Started process (PID=17943) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:19:51,754] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:19:51,782] {logging_mixin.py:109} INFO - [2022-08-13 09:19:51,781] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:20:05,346] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:20:05,488] {logging_mixin.py:109} INFO - [2022-08-13 09:20:05,484] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:20:05,871] {logging_mixin.py:109} INFO - [2022-08-13 09:20:05,871] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:20:06,062] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 14.415 seconds
[2022-08-13 09:20:39,267] {processor.py:163} INFO - Started process (PID=18008) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:20:39,276] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:20:39,284] {logging_mixin.py:109} INFO - [2022-08-13 09:20:39,283] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:20:43,233] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:20:43,312] {logging_mixin.py:109} INFO - [2022-08-13 09:20:43,308] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:20:43,475] {logging_mixin.py:109} INFO - [2022-08-13 09:20:43,474] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:20:43,616] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 4.377 seconds
[2022-08-13 09:21:16,527] {processor.py:163} INFO - Started process (PID=18071) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:21:16,538] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:21:16,557] {logging_mixin.py:109} INFO - [2022-08-13 09:21:16,556] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:21:20,802] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:21:20,877] {logging_mixin.py:109} INFO - [2022-08-13 09:21:20,876] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:21:20,949] {logging_mixin.py:109} INFO - [2022-08-13 09:21:20,949] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:21:21,008] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 4.525 seconds
[2022-08-13 09:21:52,690] {processor.py:163} INFO - Started process (PID=18138) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:21:52,703] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:21:52,708] {logging_mixin.py:109} INFO - [2022-08-13 09:21:52,708] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:21:58,731] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:21:58,830] {logging_mixin.py:109} INFO - [2022-08-13 09:21:58,811] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:21:58,976] {logging_mixin.py:109} INFO - [2022-08-13 09:21:58,976] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:21:59,037] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 6.409 seconds
[2022-08-13 09:22:31,178] {processor.py:163} INFO - Started process (PID=18199) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:22:31,188] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:22:31,215] {logging_mixin.py:109} INFO - [2022-08-13 09:22:31,214] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:22:38,734] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:22:38,977] {logging_mixin.py:109} INFO - [2022-08-13 09:22:38,957] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:22:39,141] {logging_mixin.py:109} INFO - [2022-08-13 09:22:39,139] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:22:39,233] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 8.158 seconds
[2022-08-13 09:23:19,973] {processor.py:163} INFO - Started process (PID=18267) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:23:19,982] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:23:19,988] {logging_mixin.py:109} INFO - [2022-08-13 09:23:19,987] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:23:27,903] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:23:28,045] {logging_mixin.py:109} INFO - [2022-08-13 09:23:28,042] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:23:28,276] {logging_mixin.py:109} INFO - [2022-08-13 09:23:28,276] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:23:28,344] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 8.419 seconds
[2022-08-13 09:24:00,586] {processor.py:163} INFO - Started process (PID=18333) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:24:00,595] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:24:00,606] {logging_mixin.py:109} INFO - [2022-08-13 09:24:00,605] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:24:07,122] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:24:07,296] {logging_mixin.py:109} INFO - [2022-08-13 09:24:07,254] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:24:07,729] {logging_mixin.py:109} INFO - [2022-08-13 09:24:07,728] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:24:07,855] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 7.323 seconds
[2022-08-13 09:24:41,693] {processor.py:163} INFO - Started process (PID=18398) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:24:41,708] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:24:41,724] {logging_mixin.py:109} INFO - [2022-08-13 09:24:41,721] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:24:43,427] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:24:43,451] {logging_mixin.py:109} INFO - [2022-08-13 09:24:43,450] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:24:43,494] {logging_mixin.py:109} INFO - [2022-08-13 09:24:43,494] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:24:43,521] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.854 seconds
[2022-08-13 09:25:20,152] {processor.py:163} INFO - Started process (PID=18463) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:25:20,185] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:25:20,214] {logging_mixin.py:109} INFO - [2022-08-13 09:25:20,214] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:25:24,828] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:25:24,980] {logging_mixin.py:109} INFO - [2022-08-13 09:25:24,978] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:25:25,120] {logging_mixin.py:109} INFO - [2022-08-13 09:25:25,119] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:25:25,233] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 5.099 seconds
[2022-08-13 09:25:57,093] {processor.py:163} INFO - Started process (PID=18530) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:25:57,117] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:25:57,127] {logging_mixin.py:109} INFO - [2022-08-13 09:25:57,126] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:26:02,176] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:26:02,305] {logging_mixin.py:109} INFO - [2022-08-13 09:26:02,303] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:26:02,546] {logging_mixin.py:109} INFO - [2022-08-13 09:26:02,545] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:26:02,662] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 5.598 seconds
[2022-08-13 09:26:36,279] {processor.py:163} INFO - Started process (PID=18596) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:26:36,315] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:26:36,332] {logging_mixin.py:109} INFO - [2022-08-13 09:26:36,331] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:26:43,802] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:26:43,892] {logging_mixin.py:109} INFO - [2022-08-13 09:26:43,890] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:26:44,096] {logging_mixin.py:109} INFO - [2022-08-13 09:26:44,096] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:26:44,136] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 8.005 seconds
[2022-08-13 09:27:14,490] {processor.py:163} INFO - Started process (PID=18663) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:27:14,496] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:27:14,500] {logging_mixin.py:109} INFO - [2022-08-13 09:27:14,500] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:27:15,418] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:27:15,446] {logging_mixin.py:109} INFO - [2022-08-13 09:27:15,444] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:27:15,512] {logging_mixin.py:109} INFO - [2022-08-13 09:27:15,511] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:27:15,557] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.075 seconds
[2022-08-13 09:27:45,869] {processor.py:163} INFO - Started process (PID=18730) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:27:45,878] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:27:45,884] {logging_mixin.py:109} INFO - [2022-08-13 09:27:45,883] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:27:47,312] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:27:47,360] {logging_mixin.py:109} INFO - [2022-08-13 09:27:47,358] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:27:47,409] {logging_mixin.py:109} INFO - [2022-08-13 09:27:47,409] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:27:47,440] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.593 seconds
[2022-08-13 09:28:17,865] {processor.py:163} INFO - Started process (PID=18796) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:28:17,872] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:28:17,876] {logging_mixin.py:109} INFO - [2022-08-13 09:28:17,876] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:28:19,412] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:28:19,441] {logging_mixin.py:109} INFO - [2022-08-13 09:28:19,439] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:28:19,506] {logging_mixin.py:109} INFO - [2022-08-13 09:28:19,505] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:28:19,539] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.689 seconds
[2022-08-13 09:28:49,652] {processor.py:163} INFO - Started process (PID=18862) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:28:49,656] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:28:49,659] {logging_mixin.py:109} INFO - [2022-08-13 09:28:49,658] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:28:50,544] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:28:50,563] {logging_mixin.py:109} INFO - [2022-08-13 09:28:50,561] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:28:50,592] {logging_mixin.py:109} INFO - [2022-08-13 09:28:50,592] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:28:50,609] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.965 seconds
[2022-08-13 09:29:20,857] {processor.py:163} INFO - Started process (PID=18928) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:29:20,859] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:29:20,862] {logging_mixin.py:109} INFO - [2022-08-13 09:29:20,862] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:29:21,566] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:29:21,586] {logging_mixin.py:109} INFO - [2022-08-13 09:29:21,585] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:29:21,607] {logging_mixin.py:109} INFO - [2022-08-13 09:29:21,607] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:29:21,622] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.772 seconds
[2022-08-13 09:29:52,293] {processor.py:163} INFO - Started process (PID=18995) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:29:52,297] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:29:52,301] {logging_mixin.py:109} INFO - [2022-08-13 09:29:52,300] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:29:53,254] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:29:53,270] {logging_mixin.py:109} INFO - [2022-08-13 09:29:53,269] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:29:53,301] {logging_mixin.py:109} INFO - [2022-08-13 09:29:53,301] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:29:53,319] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.034 seconds
[2022-08-13 09:30:23,683] {processor.py:163} INFO - Started process (PID=19066) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:30:23,688] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:30:23,691] {logging_mixin.py:109} INFO - [2022-08-13 09:30:23,691] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:30:24,636] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:30:24,680] {logging_mixin.py:109} INFO - [2022-08-13 09:30:24,677] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:30:24,707] {logging_mixin.py:109} INFO - [2022-08-13 09:30:24,707] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:30:24,725] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.050 seconds
[2022-08-13 09:30:55,446] {processor.py:163} INFO - Started process (PID=19134) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:30:55,448] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:30:55,450] {logging_mixin.py:109} INFO - [2022-08-13 09:30:55,450] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:30:56,091] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:30:56,104] {logging_mixin.py:109} INFO - [2022-08-13 09:30:56,102] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:30:56,124] {logging_mixin.py:109} INFO - [2022-08-13 09:30:56,124] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:30:56,138] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.696 seconds
[2022-08-13 09:31:26,600] {processor.py:163} INFO - Started process (PID=19201) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:31:26,607] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:31:26,617] {logging_mixin.py:109} INFO - [2022-08-13 09:31:26,613] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:31:27,837] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:31:27,870] {logging_mixin.py:109} INFO - [2022-08-13 09:31:27,869] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:31:27,908] {logging_mixin.py:109} INFO - [2022-08-13 09:31:27,907] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:31:27,931] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.347 seconds
[2022-08-13 09:31:58,555] {processor.py:163} INFO - Started process (PID=19268) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:31:58,558] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:31:58,560] {logging_mixin.py:109} INFO - [2022-08-13 09:31:58,560] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:31:59,341] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:31:59,355] {logging_mixin.py:109} INFO - [2022-08-13 09:31:59,354] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:31:59,378] {logging_mixin.py:109} INFO - [2022-08-13 09:31:59,377] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:31:59,391] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.847 seconds
[2022-08-13 09:32:30,040] {processor.py:163} INFO - Started process (PID=19345) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:32:30,044] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:32:30,047] {logging_mixin.py:109} INFO - [2022-08-13 09:32:30,047] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:32:30,746] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:32:30,761] {logging_mixin.py:109} INFO - [2022-08-13 09:32:30,760] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:32:30,785] {logging_mixin.py:109} INFO - [2022-08-13 09:32:30,784] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:32:30,803] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.773 seconds
[2022-08-13 09:33:01,033] {processor.py:163} INFO - Started process (PID=19410) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:33:01,038] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:33:01,040] {logging_mixin.py:109} INFO - [2022-08-13 09:33:01,040] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:33:01,821] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:33:01,838] {logging_mixin.py:109} INFO - [2022-08-13 09:33:01,837] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:33:01,860] {logging_mixin.py:109} INFO - [2022-08-13 09:33:01,860] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:33:01,875] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.848 seconds
[2022-08-13 09:33:32,484] {processor.py:163} INFO - Started process (PID=19476) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:33:32,486] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:33:32,488] {logging_mixin.py:109} INFO - [2022-08-13 09:33:32,488] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:33:33,086] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:33:33,098] {logging_mixin.py:109} INFO - [2022-08-13 09:33:33,097] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:33:33,115] {logging_mixin.py:109} INFO - [2022-08-13 09:33:33,115] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:33:33,128] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.651 seconds
[2022-08-13 09:34:03,435] {processor.py:163} INFO - Started process (PID=19550) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:34:03,439] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:34:03,441] {logging_mixin.py:109} INFO - [2022-08-13 09:34:03,441] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:34:04,075] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:34:04,089] {logging_mixin.py:109} INFO - [2022-08-13 09:34:04,088] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:34:04,116] {logging_mixin.py:109} INFO - [2022-08-13 09:34:04,116] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:34:04,132] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.707 seconds
[2022-08-13 09:34:34,288] {processor.py:163} INFO - Started process (PID=19617) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:34:34,290] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:34:34,291] {logging_mixin.py:109} INFO - [2022-08-13 09:34:34,291] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:34:34,985] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:34:35,000] {logging_mixin.py:109} INFO - [2022-08-13 09:34:34,999] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:34:35,022] {logging_mixin.py:109} INFO - [2022-08-13 09:34:35,022] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:34:35,037] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.760 seconds
[2022-08-13 09:35:05,254] {processor.py:163} INFO - Started process (PID=19686) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:35:05,257] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:35:05,258] {logging_mixin.py:109} INFO - [2022-08-13 09:35:05,258] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:35:05,853] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:35:05,870] {logging_mixin.py:109} INFO - [2022-08-13 09:35:05,869] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:35:05,896] {logging_mixin.py:109} INFO - [2022-08-13 09:35:05,896] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:35:05,908] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.658 seconds
[2022-08-13 09:35:36,665] {processor.py:163} INFO - Started process (PID=19759) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:35:36,669] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:35:36,671] {logging_mixin.py:109} INFO - [2022-08-13 09:35:36,670] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:35:37,304] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:35:37,321] {logging_mixin.py:109} INFO - [2022-08-13 09:35:37,320] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:35:37,343] {logging_mixin.py:109} INFO - [2022-08-13 09:35:37,343] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:35:37,362] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.702 seconds
[2022-08-13 09:36:07,889] {processor.py:163} INFO - Started process (PID=19827) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:36:07,891] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:36:07,893] {logging_mixin.py:109} INFO - [2022-08-13 09:36:07,893] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:36:08,502] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:36:08,523] {logging_mixin.py:109} INFO - [2022-08-13 09:36:08,523] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:36:08,548] {logging_mixin.py:109} INFO - [2022-08-13 09:36:08,548] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:36:08,564] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.681 seconds
[2022-08-13 09:36:38,942] {processor.py:163} INFO - Started process (PID=19892) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:36:38,946] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:36:38,949] {logging_mixin.py:109} INFO - [2022-08-13 09:36:38,949] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:36:39,654] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:36:39,668] {logging_mixin.py:109} INFO - [2022-08-13 09:36:39,668] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:36:39,688] {logging_mixin.py:109} INFO - [2022-08-13 09:36:39,687] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:36:39,702] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.774 seconds
[2022-08-13 09:37:09,763] {processor.py:163} INFO - Started process (PID=19969) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:37:09,769] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:37:09,771] {logging_mixin.py:109} INFO - [2022-08-13 09:37:09,771] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:37:10,604] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:37:10,618] {logging_mixin.py:109} INFO - [2022-08-13 09:37:10,618] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:37:10,647] {logging_mixin.py:109} INFO - [2022-08-13 09:37:10,647] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:37:10,657] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.902 seconds
[2022-08-13 09:37:40,912] {processor.py:163} INFO - Started process (PID=20035) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:37:40,914] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:37:40,915] {logging_mixin.py:109} INFO - [2022-08-13 09:37:40,915] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:37:41,584] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:37:41,604] {logging_mixin.py:109} INFO - [2022-08-13 09:37:41,603] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:37:41,624] {logging_mixin.py:109} INFO - [2022-08-13 09:37:41,624] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:37:41,648] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.740 seconds
[2022-08-13 09:38:12,681] {processor.py:163} INFO - Started process (PID=20105) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:38:12,685] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:38:12,687] {logging_mixin.py:109} INFO - [2022-08-13 09:38:12,687] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:38:13,311] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:38:13,322] {logging_mixin.py:109} INFO - [2022-08-13 09:38:13,321] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:38:13,338] {logging_mixin.py:109} INFO - [2022-08-13 09:38:13,338] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:38:13,355] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.686 seconds
[2022-08-13 09:38:43,947] {processor.py:163} INFO - Started process (PID=20181) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:38:43,951] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:38:43,953] {logging_mixin.py:109} INFO - [2022-08-13 09:38:43,953] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:38:44,636] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:38:44,651] {logging_mixin.py:109} INFO - [2022-08-13 09:38:44,651] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:38:44,668] {logging_mixin.py:109} INFO - [2022-08-13 09:38:44,668] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:38:44,683] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.742 seconds
[2022-08-13 09:39:14,740] {processor.py:163} INFO - Started process (PID=20246) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:39:14,744] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:39:14,747] {logging_mixin.py:109} INFO - [2022-08-13 09:39:14,747] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:39:15,392] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:39:15,405] {logging_mixin.py:109} INFO - [2022-08-13 09:39:15,404] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:39:15,421] {logging_mixin.py:109} INFO - [2022-08-13 09:39:15,421] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:39:15,433] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.699 seconds
[2022-08-13 09:39:46,069] {processor.py:163} INFO - Started process (PID=20313) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:39:46,072] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:39:46,074] {logging_mixin.py:109} INFO - [2022-08-13 09:39:46,074] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:39:46,683] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:39:46,699] {logging_mixin.py:109} INFO - [2022-08-13 09:39:46,698] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:39:46,715] {logging_mixin.py:109} INFO - [2022-08-13 09:39:46,714] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:39:46,728] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.664 seconds
[2022-08-13 09:40:16,919] {processor.py:163} INFO - Started process (PID=20388) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:40:16,921] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:40:16,923] {logging_mixin.py:109} INFO - [2022-08-13 09:40:16,923] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:40:17,524] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:40:17,536] {logging_mixin.py:109} INFO - [2022-08-13 09:40:17,536] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:40:17,554] {logging_mixin.py:109} INFO - [2022-08-13 09:40:17,554] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:40:17,567] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.655 seconds
[2022-08-13 09:40:47,910] {processor.py:163} INFO - Started process (PID=20452) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:40:47,913] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:40:47,915] {logging_mixin.py:109} INFO - [2022-08-13 09:40:47,914] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:40:48,575] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:40:48,586] {logging_mixin.py:109} INFO - [2022-08-13 09:40:48,586] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:40:48,607] {logging_mixin.py:109} INFO - [2022-08-13 09:40:48,607] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:40:48,620] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.716 seconds
[2022-08-13 09:41:18,946] {processor.py:163} INFO - Started process (PID=20528) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:41:18,949] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:41:18,951] {logging_mixin.py:109} INFO - [2022-08-13 09:41:18,951] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:41:19,552] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:41:19,564] {logging_mixin.py:109} INFO - [2022-08-13 09:41:19,563] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:41:19,581] {logging_mixin.py:109} INFO - [2022-08-13 09:41:19,581] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:41:19,598] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.656 seconds
[2022-08-13 09:41:50,343] {processor.py:163} INFO - Started process (PID=20594) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:41:50,345] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:41:50,347] {logging_mixin.py:109} INFO - [2022-08-13 09:41:50,347] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:41:50,960] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:41:50,971] {logging_mixin.py:109} INFO - [2022-08-13 09:41:50,970] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:41:50,988] {logging_mixin.py:109} INFO - [2022-08-13 09:41:50,988] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:41:51,000] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.663 seconds
[2022-08-13 09:42:21,309] {processor.py:163} INFO - Started process (PID=20659) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:42:21,312] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:42:21,314] {logging_mixin.py:109} INFO - [2022-08-13 09:42:21,313] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:42:21,893] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:42:21,905] {logging_mixin.py:109} INFO - [2022-08-13 09:42:21,905] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:42:21,924] {logging_mixin.py:109} INFO - [2022-08-13 09:42:21,924] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:42:21,937] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.633 seconds
[2022-08-13 09:42:52,844] {processor.py:163} INFO - Started process (PID=20734) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:42:52,847] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:42:52,850] {logging_mixin.py:109} INFO - [2022-08-13 09:42:52,849] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:42:53,468] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:42:53,479] {logging_mixin.py:109} INFO - [2022-08-13 09:42:53,479] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:42:53,499] {logging_mixin.py:109} INFO - [2022-08-13 09:42:53,499] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:42:53,512] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.676 seconds
[2022-08-13 09:43:23,697] {processor.py:163} INFO - Started process (PID=20799) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:43:23,703] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:43:23,709] {logging_mixin.py:109} INFO - [2022-08-13 09:43:23,707] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:43:24,963] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:43:24,990] {logging_mixin.py:109} INFO - [2022-08-13 09:43:24,989] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:43:25,031] {logging_mixin.py:109} INFO - [2022-08-13 09:43:25,030] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:43:25,054] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.366 seconds
[2022-08-13 09:43:55,752] {processor.py:163} INFO - Started process (PID=20864) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:43:55,756] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:43:55,759] {logging_mixin.py:109} INFO - [2022-08-13 09:43:55,758] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:43:56,445] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:43:56,461] {logging_mixin.py:109} INFO - [2022-08-13 09:43:56,459] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:43:56,481] {logging_mixin.py:109} INFO - [2022-08-13 09:43:56,481] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:43:56,493] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.746 seconds
[2022-08-13 09:44:26,676] {processor.py:163} INFO - Started process (PID=20929) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:44:26,679] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:44:26,680] {logging_mixin.py:109} INFO - [2022-08-13 09:44:26,680] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:44:27,267] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:44:27,278] {logging_mixin.py:109} INFO - [2022-08-13 09:44:27,278] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:44:27,299] {logging_mixin.py:109} INFO - [2022-08-13 09:44:27,299] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:44:27,313] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.643 seconds
[2022-08-13 09:44:57,658] {processor.py:163} INFO - Started process (PID=21004) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:44:57,661] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:44:57,663] {logging_mixin.py:109} INFO - [2022-08-13 09:44:57,663] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:44:58,251] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:44:58,263] {logging_mixin.py:109} INFO - [2022-08-13 09:44:58,263] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:44:58,281] {logging_mixin.py:109} INFO - [2022-08-13 09:44:58,281] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:44:58,295] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.644 seconds
[2022-08-13 09:45:28,956] {processor.py:163} INFO - Started process (PID=21070) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:45:28,962] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:45:28,963] {logging_mixin.py:109} INFO - [2022-08-13 09:45:28,963] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:45:29,631] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:45:29,640] {logging_mixin.py:109} INFO - [2022-08-13 09:45:29,640] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:45:29,661] {logging_mixin.py:109} INFO - [2022-08-13 09:45:29,661] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:45:29,672] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.719 seconds
[2022-08-13 09:45:59,778] {processor.py:163} INFO - Started process (PID=21135) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:45:59,782] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:45:59,784] {logging_mixin.py:109} INFO - [2022-08-13 09:45:59,783] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:46:00,360] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:46:00,372] {logging_mixin.py:109} INFO - [2022-08-13 09:46:00,371] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:46:00,388] {logging_mixin.py:109} INFO - [2022-08-13 09:46:00,388] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:46:00,405] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.633 seconds
[2022-08-13 09:46:30,511] {processor.py:163} INFO - Started process (PID=21210) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:46:30,515] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:46:30,517] {logging_mixin.py:109} INFO - [2022-08-13 09:46:30,517] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:46:31,096] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:46:31,113] {logging_mixin.py:109} INFO - [2022-08-13 09:46:31,113] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:46:31,136] {logging_mixin.py:109} INFO - [2022-08-13 09:46:31,136] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:46:31,154] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.649 seconds
[2022-08-13 09:47:01,709] {processor.py:163} INFO - Started process (PID=21276) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:47:01,712] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:47:01,713] {logging_mixin.py:109} INFO - [2022-08-13 09:47:01,713] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:47:02,321] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:47:02,332] {logging_mixin.py:109} INFO - [2022-08-13 09:47:02,331] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:47:02,350] {logging_mixin.py:109} INFO - [2022-08-13 09:47:02,350] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:47:02,362] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.659 seconds
[2022-08-13 09:47:32,648] {processor.py:163} INFO - Started process (PID=21349) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:47:32,651] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:47:32,652] {logging_mixin.py:109} INFO - [2022-08-13 09:47:32,652] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:47:33,290] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:47:33,304] {logging_mixin.py:109} INFO - [2022-08-13 09:47:33,304] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:47:33,321] {logging_mixin.py:109} INFO - [2022-08-13 09:47:33,320] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:47:33,336] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.691 seconds
[2022-08-13 09:48:03,917] {processor.py:163} INFO - Started process (PID=21414) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:48:03,920] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:48:03,921] {logging_mixin.py:109} INFO - [2022-08-13 09:48:03,921] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:48:04,543] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:48:04,554] {logging_mixin.py:109} INFO - [2022-08-13 09:48:04,553] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:48:04,571] {logging_mixin.py:109} INFO - [2022-08-13 09:48:04,571] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:48:04,581] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.669 seconds
[2022-08-13 09:48:35,298] {processor.py:163} INFO - Started process (PID=21479) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:48:35,302] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:48:35,303] {logging_mixin.py:109} INFO - [2022-08-13 09:48:35,303] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:48:35,889] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:48:35,903] {logging_mixin.py:109} INFO - [2022-08-13 09:48:35,902] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:48:35,921] {logging_mixin.py:109} INFO - [2022-08-13 09:48:35,921] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:48:35,931] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.640 seconds
[2022-08-13 09:49:06,476] {processor.py:163} INFO - Started process (PID=21555) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:49:06,479] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:49:06,482] {logging_mixin.py:109} INFO - [2022-08-13 09:49:06,481] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:49:07,135] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:49:07,150] {logging_mixin.py:109} INFO - [2022-08-13 09:49:07,149] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:49:07,170] {logging_mixin.py:109} INFO - [2022-08-13 09:49:07,170] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:49:07,187] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.716 seconds
[2022-08-13 09:49:37,828] {processor.py:163} INFO - Started process (PID=21620) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:49:37,830] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:49:37,832] {logging_mixin.py:109} INFO - [2022-08-13 09:49:37,832] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:49:38,381] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:49:38,391] {logging_mixin.py:109} INFO - [2022-08-13 09:49:38,391] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:49:38,410] {logging_mixin.py:109} INFO - [2022-08-13 09:49:38,409] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:49:38,421] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.619 seconds
[2022-08-13 09:50:08,703] {processor.py:163} INFO - Started process (PID=21682) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:50:08,707] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:50:08,708] {logging_mixin.py:109} INFO - [2022-08-13 09:50:08,708] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:50:09,317] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:50:09,333] {logging_mixin.py:109} INFO - [2022-08-13 09:50:09,332] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:50:09,354] {logging_mixin.py:109} INFO - [2022-08-13 09:50:09,354] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:50:09,372] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.674 seconds
[2022-08-13 09:50:40,182] {processor.py:163} INFO - Started process (PID=21756) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:50:40,184] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:50:40,187] {logging_mixin.py:109} INFO - [2022-08-13 09:50:40,186] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:50:40,859] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:50:40,869] {logging_mixin.py:109} INFO - [2022-08-13 09:50:40,868] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:50:40,889] {logging_mixin.py:109} INFO - [2022-08-13 09:50:40,888] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:50:40,899] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.725 seconds
[2022-08-13 09:51:11,376] {processor.py:163} INFO - Started process (PID=21822) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:51:11,408] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:51:11,422] {logging_mixin.py:109} INFO - [2022-08-13 09:51:11,421] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:51:12,092] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:51:12,105] {logging_mixin.py:109} INFO - [2022-08-13 09:51:12,104] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:51:12,124] {logging_mixin.py:109} INFO - [2022-08-13 09:51:12,124] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:51:12,139] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.772 seconds
[2022-08-13 09:51:42,564] {processor.py:163} INFO - Started process (PID=21894) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:51:42,566] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:51:42,568] {logging_mixin.py:109} INFO - [2022-08-13 09:51:42,567] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:51:43,152] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:51:43,165] {logging_mixin.py:109} INFO - [2022-08-13 09:51:43,164] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:51:43,182] {logging_mixin.py:109} INFO - [2022-08-13 09:51:43,182] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:51:43,197] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.637 seconds
[2022-08-13 09:52:14,114] {processor.py:163} INFO - Started process (PID=21959) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:52:14,116] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:52:14,118] {logging_mixin.py:109} INFO - [2022-08-13 09:52:14,117] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:52:14,734] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:52:14,748] {logging_mixin.py:109} INFO - [2022-08-13 09:52:14,747] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:52:14,767] {logging_mixin.py:109} INFO - [2022-08-13 09:52:14,767] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:52:14,783] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.674 seconds
[2022-08-13 09:52:45,509] {processor.py:163} INFO - Started process (PID=22025) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:52:45,513] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:52:45,515] {logging_mixin.py:109} INFO - [2022-08-13 09:52:45,515] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:52:46,046] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:52:46,058] {logging_mixin.py:109} INFO - [2022-08-13 09:52:46,057] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:52:46,076] {logging_mixin.py:109} INFO - [2022-08-13 09:52:46,075] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:52:46,092] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.587 seconds
[2022-08-13 09:53:17,114] {processor.py:163} INFO - Started process (PID=22100) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:53:17,116] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:53:17,117] {logging_mixin.py:109} INFO - [2022-08-13 09:53:17,117] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:53:17,710] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:53:17,725] {logging_mixin.py:109} INFO - [2022-08-13 09:53:17,725] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:53:17,744] {logging_mixin.py:109} INFO - [2022-08-13 09:53:17,744] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:53:17,760] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.651 seconds
[2022-08-13 09:53:47,922] {processor.py:163} INFO - Started process (PID=22164) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:53:47,926] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:53:47,928] {logging_mixin.py:109} INFO - [2022-08-13 09:53:47,927] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:53:48,489] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:53:48,500] {logging_mixin.py:109} INFO - [2022-08-13 09:53:48,499] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:53:48,518] {logging_mixin.py:109} INFO - [2022-08-13 09:53:48,518] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:53:48,531] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.615 seconds
[2022-08-13 09:54:19,298] {processor.py:163} INFO - Started process (PID=22238) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:54:19,301] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:54:19,306] {logging_mixin.py:109} INFO - [2022-08-13 09:54:19,305] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:54:20,048] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:54:20,061] {logging_mixin.py:109} INFO - [2022-08-13 09:54:20,060] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:54:20,081] {logging_mixin.py:109} INFO - [2022-08-13 09:54:20,080] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:54:20,108] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.819 seconds
[2022-08-13 09:54:50,301] {processor.py:163} INFO - Started process (PID=22306) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:54:50,305] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:54:50,308] {logging_mixin.py:109} INFO - [2022-08-13 09:54:50,307] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:54:50,905] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:54:50,918] {logging_mixin.py:109} INFO - [2022-08-13 09:54:50,918] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:54:50,942] {logging_mixin.py:109} INFO - [2022-08-13 09:54:50,942] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:54:50,957] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.660 seconds
[2022-08-13 09:55:21,062] {processor.py:163} INFO - Started process (PID=22374) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:55:21,064] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:55:21,066] {logging_mixin.py:109} INFO - [2022-08-13 09:55:21,065] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:55:21,675] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:55:21,689] {logging_mixin.py:109} INFO - [2022-08-13 09:55:21,688] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:55:21,707] {logging_mixin.py:109} INFO - [2022-08-13 09:55:21,707] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:55:21,716] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.659 seconds
[2022-08-13 09:55:51,823] {processor.py:163} INFO - Started process (PID=22442) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:55:51,826] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:55:51,827] {logging_mixin.py:109} INFO - [2022-08-13 09:55:51,827] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:55:52,428] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:55:52,441] {logging_mixin.py:109} INFO - [2022-08-13 09:55:52,440] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:55:52,458] {logging_mixin.py:109} INFO - [2022-08-13 09:55:52,458] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:55:52,470] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.652 seconds
[2022-08-13 09:56:22,765] {processor.py:163} INFO - Started process (PID=22517) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:56:22,767] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:56:22,773] {logging_mixin.py:109} INFO - [2022-08-13 09:56:22,773] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:56:23,426] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:56:23,440] {logging_mixin.py:109} INFO - [2022-08-13 09:56:23,440] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:56:23,459] {logging_mixin.py:109} INFO - [2022-08-13 09:56:23,459] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:56:23,470] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.710 seconds
[2022-08-13 09:56:54,129] {processor.py:163} INFO - Started process (PID=22582) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:56:54,132] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:56:54,134] {logging_mixin.py:109} INFO - [2022-08-13 09:56:54,134] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:56:54,791] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:56:54,803] {logging_mixin.py:109} INFO - [2022-08-13 09:56:54,802] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:56:54,823] {logging_mixin.py:109} INFO - [2022-08-13 09:56:54,823] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:56:54,836] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.711 seconds
[2022-08-13 09:57:25,021] {processor.py:163} INFO - Started process (PID=22661) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:57:25,024] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:57:25,025] {logging_mixin.py:109} INFO - [2022-08-13 09:57:25,025] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:57:25,673] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:57:25,694] {logging_mixin.py:109} INFO - [2022-08-13 09:57:25,693] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:57:25,714] {logging_mixin.py:109} INFO - [2022-08-13 09:57:25,714] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:57:25,725] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.709 seconds
[2022-08-13 09:57:55,911] {processor.py:163} INFO - Started process (PID=22728) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:57:55,913] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:57:55,915] {logging_mixin.py:109} INFO - [2022-08-13 09:57:55,915] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:57:56,527] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:57:56,542] {logging_mixin.py:109} INFO - [2022-08-13 09:57:56,542] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:57:56,564] {logging_mixin.py:109} INFO - [2022-08-13 09:57:56,564] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:57:56,576] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.670 seconds
[2022-08-13 09:58:27,109] {processor.py:163} INFO - Started process (PID=22793) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:58:27,112] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:58:27,114] {logging_mixin.py:109} INFO - [2022-08-13 09:58:27,114] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:58:27,758] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:58:27,768] {logging_mixin.py:109} INFO - [2022-08-13 09:58:27,767] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:58:27,784] {logging_mixin.py:109} INFO - [2022-08-13 09:58:27,784] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:58:27,799] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.693 seconds
[2022-08-13 09:58:58,083] {processor.py:163} INFO - Started process (PID=22868) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:58:58,089] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:58:58,092] {logging_mixin.py:109} INFO - [2022-08-13 09:58:58,092] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:58:58,816] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:58:58,830] {logging_mixin.py:109} INFO - [2022-08-13 09:58:58,830] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:58:58,862] {logging_mixin.py:109} INFO - [2022-08-13 09:58:58,862] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:58:58,877] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.803 seconds
[2022-08-13 09:59:29,564] {processor.py:163} INFO - Started process (PID=22934) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:59:29,567] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 09:59:29,569] {logging_mixin.py:109} INFO - [2022-08-13 09:59:29,569] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:59:30,134] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 09:59:30,146] {logging_mixin.py:109} INFO - [2022-08-13 09:59:30,146] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 09:59:30,164] {logging_mixin.py:109} INFO - [2022-08-13 09:59:30,163] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 09:59:30,174] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.616 seconds
[2022-08-13 10:00:00,761] {processor.py:163} INFO - Started process (PID=22999) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:00:00,764] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:00:00,765] {logging_mixin.py:109} INFO - [2022-08-13 10:00:00,765] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:00:01,470] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:00:01,486] {logging_mixin.py:109} INFO - [2022-08-13 10:00:01,486] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:00:01,509] {logging_mixin.py:109} INFO - [2022-08-13 10:00:01,509] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:00:01,525] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.768 seconds
[2022-08-13 10:00:32,093] {processor.py:163} INFO - Started process (PID=23073) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:00:32,096] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:00:32,098] {logging_mixin.py:109} INFO - [2022-08-13 10:00:32,098] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:00:32,668] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:00:32,679] {logging_mixin.py:109} INFO - [2022-08-13 10:00:32,678] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:00:32,699] {logging_mixin.py:109} INFO - [2022-08-13 10:00:32,699] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:00:32,711] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.624 seconds
[2022-08-13 10:01:02,828] {processor.py:163} INFO - Started process (PID=23137) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:01:02,832] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:01:02,834] {logging_mixin.py:109} INFO - [2022-08-13 10:01:02,834] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:01:03,379] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:01:03,388] {logging_mixin.py:109} INFO - [2022-08-13 10:01:03,388] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:01:03,403] {logging_mixin.py:109} INFO - [2022-08-13 10:01:03,403] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:01:03,413] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.591 seconds
[2022-08-13 10:01:33,918] {processor.py:163} INFO - Started process (PID=23203) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:01:33,922] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:01:33,926] {logging_mixin.py:109} INFO - [2022-08-13 10:01:33,926] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:01:34,642] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:01:34,662] {logging_mixin.py:109} INFO - [2022-08-13 10:01:34,661] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:01:34,701] {logging_mixin.py:109} INFO - [2022-08-13 10:01:34,700] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:01:34,716] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.802 seconds
[2022-08-13 10:02:05,191] {processor.py:163} INFO - Started process (PID=23276) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:02:05,197] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:02:05,199] {logging_mixin.py:109} INFO - [2022-08-13 10:02:05,199] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:02:05,854] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:02:05,866] {logging_mixin.py:109} INFO - [2022-08-13 10:02:05,865] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:02:05,882] {logging_mixin.py:109} INFO - [2022-08-13 10:02:05,882] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:02:05,894] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.714 seconds
[2022-08-13 10:02:35,997] {processor.py:163} INFO - Started process (PID=23342) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:02:35,999] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:02:36,001] {logging_mixin.py:109} INFO - [2022-08-13 10:02:36,001] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:02:36,669] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:02:36,681] {logging_mixin.py:109} INFO - [2022-08-13 10:02:36,680] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:02:36,698] {logging_mixin.py:109} INFO - [2022-08-13 10:02:36,698] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:02:36,708] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.717 seconds
[2022-08-13 10:03:06,927] {processor.py:163} INFO - Started process (PID=23416) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:03:06,931] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:03:06,933] {logging_mixin.py:109} INFO - [2022-08-13 10:03:06,933] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:03:07,625] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:03:07,636] {logging_mixin.py:109} INFO - [2022-08-13 10:03:07,635] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:03:07,656] {logging_mixin.py:109} INFO - [2022-08-13 10:03:07,655] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:03:07,676] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.758 seconds
[2022-08-13 10:03:37,934] {processor.py:163} INFO - Started process (PID=23481) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:03:37,937] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:03:37,939] {logging_mixin.py:109} INFO - [2022-08-13 10:03:37,939] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:03:38,571] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:03:38,583] {logging_mixin.py:109} INFO - [2022-08-13 10:03:38,582] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:03:38,604] {logging_mixin.py:109} INFO - [2022-08-13 10:03:38,604] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:03:38,619] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.690 seconds
[2022-08-13 10:04:08,878] {processor.py:163} INFO - Started process (PID=23546) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:04:08,881] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:04:08,883] {logging_mixin.py:109} INFO - [2022-08-13 10:04:08,883] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:04:09,460] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:04:09,472] {logging_mixin.py:109} INFO - [2022-08-13 10:04:09,471] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:04:09,488] {logging_mixin.py:109} INFO - [2022-08-13 10:04:09,488] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:04:09,499] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.631 seconds
[2022-08-13 10:04:39,679] {processor.py:163} INFO - Started process (PID=23621) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:04:39,682] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:04:39,684] {logging_mixin.py:109} INFO - [2022-08-13 10:04:39,684] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:04:40,303] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:04:40,317] {logging_mixin.py:109} INFO - [2022-08-13 10:04:40,316] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:04:40,335] {logging_mixin.py:109} INFO - [2022-08-13 10:04:40,335] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:04:40,346] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.672 seconds
[2022-08-13 10:05:11,271] {processor.py:163} INFO - Started process (PID=23686) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:05:11,275] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:05:11,276] {logging_mixin.py:109} INFO - [2022-08-13 10:05:11,276] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:05:11,835] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:05:11,845] {logging_mixin.py:109} INFO - [2022-08-13 10:05:11,844] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:05:11,860] {logging_mixin.py:109} INFO - [2022-08-13 10:05:11,860] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:05:11,872] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.607 seconds
[2022-08-13 10:05:42,034] {processor.py:163} INFO - Started process (PID=23752) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:05:42,039] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:05:42,041] {logging_mixin.py:109} INFO - [2022-08-13 10:05:42,040] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:05:42,658] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:05:42,669] {logging_mixin.py:109} INFO - [2022-08-13 10:05:42,668] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:05:42,685] {logging_mixin.py:109} INFO - [2022-08-13 10:05:42,685] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:05:42,697] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.670 seconds
[2022-08-13 10:06:13,030] {processor.py:163} INFO - Started process (PID=23826) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:06:13,034] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:06:13,035] {logging_mixin.py:109} INFO - [2022-08-13 10:06:13,035] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:06:13,590] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:06:13,599] {logging_mixin.py:109} INFO - [2022-08-13 10:06:13,599] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:06:13,615] {logging_mixin.py:109} INFO - [2022-08-13 10:06:13,615] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:06:13,627] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.602 seconds
[2022-08-13 10:06:43,870] {processor.py:163} INFO - Started process (PID=23891) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:06:43,874] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:06:43,875] {logging_mixin.py:109} INFO - [2022-08-13 10:06:43,875] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:06:44,411] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:06:44,422] {logging_mixin.py:109} INFO - [2022-08-13 10:06:44,421] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:06:44,438] {logging_mixin.py:109} INFO - [2022-08-13 10:06:44,438] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:06:44,451] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.588 seconds
[2022-08-13 10:07:14,818] {processor.py:163} INFO - Started process (PID=23955) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:07:14,821] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:07:14,823] {logging_mixin.py:109} INFO - [2022-08-13 10:07:14,823] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:07:15,486] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:07:15,498] {logging_mixin.py:109} INFO - [2022-08-13 10:07:15,496] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:07:15,515] {logging_mixin.py:109} INFO - [2022-08-13 10:07:15,515] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:07:15,530] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.718 seconds
[2022-08-13 10:07:46,072] {processor.py:163} INFO - Started process (PID=24029) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:07:46,075] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:07:46,077] {logging_mixin.py:109} INFO - [2022-08-13 10:07:46,077] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:07:46,652] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:07:46,673] {logging_mixin.py:109} INFO - [2022-08-13 10:07:46,673] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:07:46,699] {logging_mixin.py:109} INFO - [2022-08-13 10:07:46,699] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:07:46,710] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.643 seconds
[2022-08-13 10:08:17,274] {processor.py:163} INFO - Started process (PID=24095) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:08:17,277] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:08:17,279] {logging_mixin.py:109} INFO - [2022-08-13 10:08:17,279] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:08:17,890] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:08:17,902] {logging_mixin.py:109} INFO - [2022-08-13 10:08:17,901] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:08:17,918] {logging_mixin.py:109} INFO - [2022-08-13 10:08:17,917] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:08:17,931] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.665 seconds
[2022-08-13 10:08:48,069] {processor.py:163} INFO - Started process (PID=24166) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:08:48,071] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:08:48,076] {logging_mixin.py:109} INFO - [2022-08-13 10:08:48,075] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:08:48,764] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:08:48,778] {logging_mixin.py:109} INFO - [2022-08-13 10:08:48,778] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:08:48,802] {logging_mixin.py:109} INFO - [2022-08-13 10:08:48,802] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:08:48,816] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.758 seconds
[2022-08-13 10:09:19,118] {processor.py:163} INFO - Started process (PID=24240) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:09:19,120] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:09:19,122] {logging_mixin.py:109} INFO - [2022-08-13 10:09:19,121] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:09:19,711] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:09:19,724] {logging_mixin.py:109} INFO - [2022-08-13 10:09:19,723] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:09:19,739] {logging_mixin.py:109} INFO - [2022-08-13 10:09:19,739] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:09:19,760] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.648 seconds
[2022-08-13 10:09:50,210] {processor.py:163} INFO - Started process (PID=24306) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:09:50,214] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:09:50,216] {logging_mixin.py:109} INFO - [2022-08-13 10:09:50,216] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:09:50,794] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:09:50,807] {logging_mixin.py:109} INFO - [2022-08-13 10:09:50,807] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:09:50,827] {logging_mixin.py:109} INFO - [2022-08-13 10:09:50,826] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:09:50,840] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.636 seconds
[2022-08-13 10:10:20,973] {processor.py:163} INFO - Started process (PID=24379) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:10:20,975] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:10:20,976] {logging_mixin.py:109} INFO - [2022-08-13 10:10:20,976] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:10:21,558] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:10:21,573] {logging_mixin.py:109} INFO - [2022-08-13 10:10:21,572] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:10:21,596] {logging_mixin.py:109} INFO - [2022-08-13 10:10:21,596] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:10:21,613] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.646 seconds
[2022-08-13 10:10:52,371] {processor.py:163} INFO - Started process (PID=24444) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:10:52,376] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:10:52,378] {logging_mixin.py:109} INFO - [2022-08-13 10:10:52,378] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:10:53,007] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:10:53,020] {logging_mixin.py:109} INFO - [2022-08-13 10:10:53,020] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:10:53,046] {logging_mixin.py:109} INFO - [2022-08-13 10:10:53,046] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:10:53,060] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.693 seconds
[2022-08-13 10:11:23,240] {processor.py:163} INFO - Started process (PID=24509) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:11:23,243] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:11:23,244] {logging_mixin.py:109} INFO - [2022-08-13 10:11:23,244] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:11:23,930] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:11:23,943] {logging_mixin.py:109} INFO - [2022-08-13 10:11:23,943] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:11:23,964] {logging_mixin.py:109} INFO - [2022-08-13 10:11:23,964] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:11:23,977] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.742 seconds
[2022-08-13 10:11:54,277] {processor.py:163} INFO - Started process (PID=24584) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:11:54,282] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:11:54,284] {logging_mixin.py:109} INFO - [2022-08-13 10:11:54,284] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:11:54,936] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:11:54,945] {logging_mixin.py:109} INFO - [2022-08-13 10:11:54,945] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:11:54,967] {logging_mixin.py:109} INFO - [2022-08-13 10:11:54,967] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:11:54,979] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.707 seconds
[2022-08-13 10:12:25,584] {processor.py:163} INFO - Started process (PID=24650) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:12:25,587] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:12:25,589] {logging_mixin.py:109} INFO - [2022-08-13 10:12:25,589] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:12:26,234] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:12:26,244] {logging_mixin.py:109} INFO - [2022-08-13 10:12:26,243] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:12:26,262] {logging_mixin.py:109} INFO - [2022-08-13 10:12:26,262] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:12:26,278] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.705 seconds
[2022-08-13 10:12:56,511] {processor.py:163} INFO - Started process (PID=24716) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:12:56,516] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:12:56,518] {logging_mixin.py:109} INFO - [2022-08-13 10:12:56,518] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:12:57,499] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:12:57,530] {logging_mixin.py:109} INFO - [2022-08-13 10:12:57,529] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:12:57,572] {logging_mixin.py:109} INFO - [2022-08-13 10:12:57,572] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:12:57,593] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.091 seconds
[2022-08-13 10:13:28,504] {processor.py:163} INFO - Started process (PID=24792) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:13:28,506] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:13:28,508] {logging_mixin.py:109} INFO - [2022-08-13 10:13:28,508] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:13:29,122] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:13:29,138] {logging_mixin.py:109} INFO - [2022-08-13 10:13:29,137] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:13:29,157] {logging_mixin.py:109} INFO - [2022-08-13 10:13:29,157] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:13:29,171] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.673 seconds
[2022-08-13 10:13:59,383] {processor.py:163} INFO - Started process (PID=24863) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:13:59,386] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:13:59,388] {logging_mixin.py:109} INFO - [2022-08-13 10:13:59,388] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:14:00,010] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:14:00,022] {logging_mixin.py:109} INFO - [2022-08-13 10:14:00,021] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:14:00,041] {logging_mixin.py:109} INFO - [2022-08-13 10:14:00,041] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:14:00,053] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.676 seconds
[2022-08-13 10:14:30,924] {processor.py:163} INFO - Started process (PID=24939) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:14:30,927] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:14:30,928] {logging_mixin.py:109} INFO - [2022-08-13 10:14:30,928] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:14:31,569] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:14:31,585] {logging_mixin.py:109} INFO - [2022-08-13 10:14:31,585] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:14:31,607] {logging_mixin.py:109} INFO - [2022-08-13 10:14:31,607] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:14:31,625] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.709 seconds
[2022-08-13 10:15:02,421] {processor.py:163} INFO - Started process (PID=25004) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:15:02,425] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:15:02,428] {logging_mixin.py:109} INFO - [2022-08-13 10:15:02,427] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:15:03,028] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:15:03,042] {logging_mixin.py:109} INFO - [2022-08-13 10:15:03,042] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:15:03,058] {logging_mixin.py:109} INFO - [2022-08-13 10:15:03,058] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:15:03,073] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.658 seconds
[2022-08-13 10:15:33,291] {processor.py:163} INFO - Started process (PID=25071) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:15:33,293] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:15:33,295] {logging_mixin.py:109} INFO - [2022-08-13 10:15:33,295] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:15:33,891] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:15:33,903] {logging_mixin.py:109} INFO - [2022-08-13 10:15:33,902] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:15:33,919] {logging_mixin.py:109} INFO - [2022-08-13 10:15:33,919] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:15:33,930] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.645 seconds
[2022-08-13 10:16:04,039] {processor.py:163} INFO - Started process (PID=25146) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:16:04,041] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:16:04,043] {logging_mixin.py:109} INFO - [2022-08-13 10:16:04,043] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:16:04,617] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:16:04,628] {logging_mixin.py:109} INFO - [2022-08-13 10:16:04,627] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:16:04,649] {logging_mixin.py:109} INFO - [2022-08-13 10:16:04,648] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:16:04,659] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.625 seconds
[2022-08-13 10:16:35,217] {processor.py:163} INFO - Started process (PID=25212) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:16:35,221] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:16:35,223] {logging_mixin.py:109} INFO - [2022-08-13 10:16:35,223] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:16:35,838] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:16:35,854] {logging_mixin.py:109} INFO - [2022-08-13 10:16:35,853] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:16:35,873] {logging_mixin.py:109} INFO - [2022-08-13 10:16:35,873] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:16:35,888] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.682 seconds
[2022-08-13 10:17:06,078] {processor.py:163} INFO - Started process (PID=25285) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:17:06,082] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:17:06,102] {logging_mixin.py:109} INFO - [2022-08-13 10:17:06,102] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:17:06,775] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:17:06,787] {logging_mixin.py:109} INFO - [2022-08-13 10:17:06,786] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:17:06,805] {logging_mixin.py:109} INFO - [2022-08-13 10:17:06,805] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:17:06,818] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.745 seconds
[2022-08-13 10:17:36,968] {processor.py:163} INFO - Started process (PID=25353) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:17:36,972] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:17:36,974] {logging_mixin.py:109} INFO - [2022-08-13 10:17:36,974] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:17:37,498] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:17:37,511] {logging_mixin.py:109} INFO - [2022-08-13 10:17:37,510] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:17:37,528] {logging_mixin.py:109} INFO - [2022-08-13 10:17:37,528] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:17:37,540] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.597 seconds
[2022-08-13 10:18:07,836] {processor.py:163} INFO - Started process (PID=25419) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:18:07,839] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:18:07,842] {logging_mixin.py:109} INFO - [2022-08-13 10:18:07,842] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:18:08,414] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:18:08,423] {logging_mixin.py:109} INFO - [2022-08-13 10:18:08,423] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:18:08,440] {logging_mixin.py:109} INFO - [2022-08-13 10:18:08,440] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:18:08,453] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.621 seconds
[2022-08-13 10:18:38,545] {processor.py:163} INFO - Started process (PID=25493) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:18:38,548] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:18:38,550] {logging_mixin.py:109} INFO - [2022-08-13 10:18:38,550] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:18:39,116] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:18:39,125] {logging_mixin.py:109} INFO - [2022-08-13 10:18:39,124] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:18:39,142] {logging_mixin.py:109} INFO - [2022-08-13 10:18:39,141] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:18:39,165] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.632 seconds
[2022-08-13 10:19:10,162] {processor.py:163} INFO - Started process (PID=25558) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:19:10,166] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:19:10,167] {logging_mixin.py:109} INFO - [2022-08-13 10:19:10,167] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:19:10,729] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:19:10,739] {logging_mixin.py:109} INFO - [2022-08-13 10:19:10,738] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:19:10,756] {logging_mixin.py:109} INFO - [2022-08-13 10:19:10,756] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:19:10,770] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.614 seconds
[2022-08-13 10:19:40,849] {processor.py:163} INFO - Started process (PID=25624) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:19:40,851] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:19:40,853] {logging_mixin.py:109} INFO - [2022-08-13 10:19:40,853] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:19:41,481] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:19:41,493] {logging_mixin.py:109} INFO - [2022-08-13 10:19:41,492] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:19:41,509] {logging_mixin.py:109} INFO - [2022-08-13 10:19:41,509] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:19:41,520] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.676 seconds
[2022-08-13 10:20:12,318] {processor.py:163} INFO - Started process (PID=25698) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:20:12,319] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:20:12,321] {logging_mixin.py:109} INFO - [2022-08-13 10:20:12,321] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:20:12,957] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:20:12,973] {logging_mixin.py:109} INFO - [2022-08-13 10:20:12,972] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:20:12,995] {logging_mixin.py:109} INFO - [2022-08-13 10:20:12,995] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:20:13,019] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.707 seconds
[2022-08-13 10:20:43,401] {processor.py:163} INFO - Started process (PID=25763) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:20:43,405] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:20:43,406] {logging_mixin.py:109} INFO - [2022-08-13 10:20:43,406] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:20:43,968] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:20:43,980] {logging_mixin.py:109} INFO - [2022-08-13 10:20:43,979] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:20:43,998] {logging_mixin.py:109} INFO - [2022-08-13 10:20:43,998] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:20:44,010] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.615 seconds
[2022-08-13 10:21:14,539] {processor.py:163} INFO - Started process (PID=25828) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:21:14,543] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:21:14,545] {logging_mixin.py:109} INFO - [2022-08-13 10:21:14,544] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:21:15,083] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:21:15,092] {logging_mixin.py:109} INFO - [2022-08-13 10:21:15,092] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:21:15,107] {logging_mixin.py:109} INFO - [2022-08-13 10:21:15,107] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:21:15,118] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.584 seconds
[2022-08-13 10:21:45,251] {processor.py:163} INFO - Started process (PID=25902) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:21:45,255] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:21:45,258] {logging_mixin.py:109} INFO - [2022-08-13 10:21:45,258] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:21:45,831] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:21:45,841] {logging_mixin.py:109} INFO - [2022-08-13 10:21:45,841] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:21:45,856] {logging_mixin.py:109} INFO - [2022-08-13 10:21:45,856] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:21:45,868] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.623 seconds
[2022-08-13 10:22:16,619] {processor.py:163} INFO - Started process (PID=25967) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:22:16,622] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:22:16,626] {logging_mixin.py:109} INFO - [2022-08-13 10:22:16,625] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:22:17,253] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:22:17,266] {logging_mixin.py:109} INFO - [2022-08-13 10:22:17,266] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:22:17,284] {logging_mixin.py:109} INFO - [2022-08-13 10:22:17,284] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:22:17,296] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.683 seconds
[2022-08-13 10:22:47,383] {processor.py:163} INFO - Started process (PID=26041) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:22:47,385] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:22:47,386] {logging_mixin.py:109} INFO - [2022-08-13 10:22:47,386] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:22:47,999] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:22:48,011] {logging_mixin.py:109} INFO - [2022-08-13 10:22:48,010] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:22:48,026] {logging_mixin.py:109} INFO - [2022-08-13 10:22:48,026] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:22:48,036] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.658 seconds
[2022-08-13 10:23:18,529] {processor.py:163} INFO - Started process (PID=26106) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:23:18,533] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:23:18,535] {logging_mixin.py:109} INFO - [2022-08-13 10:23:18,534] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:23:19,067] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:23:19,077] {logging_mixin.py:109} INFO - [2022-08-13 10:23:19,076] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:23:19,092] {logging_mixin.py:109} INFO - [2022-08-13 10:23:19,092] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:23:19,103] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.581 seconds
[2022-08-13 10:23:50,011] {processor.py:163} INFO - Started process (PID=26172) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:23:50,013] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:23:50,015] {logging_mixin.py:109} INFO - [2022-08-13 10:23:50,015] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:23:50,622] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:23:50,638] {logging_mixin.py:109} INFO - [2022-08-13 10:23:50,638] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:23:50,659] {logging_mixin.py:109} INFO - [2022-08-13 10:23:50,658] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:23:50,672] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.666 seconds
[2022-08-13 10:24:20,876] {processor.py:163} INFO - Started process (PID=26247) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:24:20,881] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:24:20,884] {logging_mixin.py:109} INFO - [2022-08-13 10:24:20,883] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:24:21,529] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:24:21,542] {logging_mixin.py:109} INFO - [2022-08-13 10:24:21,540] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:24:21,559] {logging_mixin.py:109} INFO - [2022-08-13 10:24:21,559] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:24:21,571] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.699 seconds
[2022-08-13 10:24:51,740] {processor.py:163} INFO - Started process (PID=26312) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:24:51,743] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:24:51,745] {logging_mixin.py:109} INFO - [2022-08-13 10:24:51,745] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:24:52,349] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:24:52,361] {logging_mixin.py:109} INFO - [2022-08-13 10:24:52,361] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:24:52,378] {logging_mixin.py:109} INFO - [2022-08-13 10:24:52,378] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:24:52,388] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.654 seconds
[2022-08-13 10:25:22,786] {processor.py:163} INFO - Started process (PID=26382) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:25:22,789] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:25:22,791] {logging_mixin.py:109} INFO - [2022-08-13 10:25:22,790] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:25:23,428] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:25:23,439] {logging_mixin.py:109} INFO - [2022-08-13 10:25:23,438] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:25:23,456] {logging_mixin.py:109} INFO - [2022-08-13 10:25:23,456] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:25:23,471] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.688 seconds
[2022-08-13 10:25:53,638] {processor.py:163} INFO - Started process (PID=26458) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:25:53,641] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:25:53,643] {logging_mixin.py:109} INFO - [2022-08-13 10:25:53,643] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:25:54,499] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:25:54,520] {logging_mixin.py:109} INFO - [2022-08-13 10:25:54,514] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:25:54,539] {logging_mixin.py:109} INFO - [2022-08-13 10:25:54,538] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:25:54,554] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.920 seconds
[2022-08-13 10:26:24,649] {processor.py:163} INFO - Started process (PID=26525) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:26:24,651] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:26:24,653] {logging_mixin.py:109} INFO - [2022-08-13 10:26:24,653] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:26:25,337] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:26:25,352] {logging_mixin.py:109} INFO - [2022-08-13 10:26:25,352] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:26:25,377] {logging_mixin.py:109} INFO - [2022-08-13 10:26:25,377] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:26:25,393] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.748 seconds
[2022-08-13 10:26:56,158] {processor.py:163} INFO - Started process (PID=26602) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:26:56,162] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:26:56,166] {logging_mixin.py:109} INFO - [2022-08-13 10:26:56,164] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:26:56,880] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:26:56,893] {logging_mixin.py:109} INFO - [2022-08-13 10:26:56,891] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:26:56,912] {logging_mixin.py:109} INFO - [2022-08-13 10:26:56,912] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:26:56,927] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.780 seconds
[2022-08-13 10:27:27,145] {processor.py:163} INFO - Started process (PID=26673) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:27:27,149] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:27:27,151] {logging_mixin.py:109} INFO - [2022-08-13 10:27:27,151] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:27:27,813] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:27:27,828] {logging_mixin.py:109} INFO - [2022-08-13 10:27:27,827] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:27:27,847] {logging_mixin.py:109} INFO - [2022-08-13 10:27:27,847] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:27:27,861] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.720 seconds
[2022-08-13 10:27:58,467] {processor.py:163} INFO - Started process (PID=26741) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:27:58,472] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:27:58,476] {logging_mixin.py:109} INFO - [2022-08-13 10:27:58,475] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:27:59,155] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:27:59,167] {logging_mixin.py:109} INFO - [2022-08-13 10:27:59,166] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:27:59,189] {logging_mixin.py:109} INFO - [2022-08-13 10:27:59,189] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:27:59,201] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.747 seconds
[2022-08-13 10:28:29,933] {processor.py:163} INFO - Started process (PID=26815) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:28:29,936] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:28:29,937] {logging_mixin.py:109} INFO - [2022-08-13 10:28:29,937] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:28:30,530] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:28:30,541] {logging_mixin.py:109} INFO - [2022-08-13 10:28:30,540] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:28:30,558] {logging_mixin.py:109} INFO - [2022-08-13 10:28:30,558] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:28:30,570] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.642 seconds
[2022-08-13 10:29:01,406] {processor.py:163} INFO - Started process (PID=26880) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:29:01,428] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:29:01,431] {logging_mixin.py:109} INFO - [2022-08-13 10:29:01,431] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:29:02,024] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:29:02,036] {logging_mixin.py:109} INFO - [2022-08-13 10:29:02,035] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:29:02,053] {logging_mixin.py:109} INFO - [2022-08-13 10:29:02,053] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:29:02,066] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.664 seconds
[2022-08-13 10:29:32,378] {processor.py:163} INFO - Started process (PID=26952) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:29:32,380] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:29:32,381] {logging_mixin.py:109} INFO - [2022-08-13 10:29:32,381] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:29:33,023] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:29:33,035] {logging_mixin.py:109} INFO - [2022-08-13 10:29:33,035] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:29:33,053] {logging_mixin.py:109} INFO - [2022-08-13 10:29:33,053] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:29:33,068] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.696 seconds
[2022-08-13 10:30:03,769] {processor.py:163} INFO - Started process (PID=27020) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:30:03,773] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:30:03,777] {logging_mixin.py:109} INFO - [2022-08-13 10:30:03,776] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:30:04,402] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:30:04,413] {logging_mixin.py:109} INFO - [2022-08-13 10:30:04,413] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:30:04,436] {logging_mixin.py:109} INFO - [2022-08-13 10:30:04,436] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:30:04,452] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.689 seconds
[2022-08-13 10:30:34,983] {processor.py:163} INFO - Started process (PID=27086) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:30:34,986] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:30:34,987] {logging_mixin.py:109} INFO - [2022-08-13 10:30:34,987] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:30:35,619] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:30:35,632] {logging_mixin.py:109} INFO - [2022-08-13 10:30:35,631] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:30:35,650] {logging_mixin.py:109} INFO - [2022-08-13 10:30:35,650] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:30:35,664] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.685 seconds
[2022-08-13 10:31:06,362] {processor.py:163} INFO - Started process (PID=27160) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:31:06,371] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:31:06,375] {logging_mixin.py:109} INFO - [2022-08-13 10:31:06,373] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:31:07,053] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:31:07,076] {logging_mixin.py:109} INFO - [2022-08-13 10:31:07,075] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:31:07,101] {logging_mixin.py:109} INFO - [2022-08-13 10:31:07,100] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:31:07,117] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.782 seconds
[2022-08-13 10:31:37,797] {processor.py:163} INFO - Started process (PID=27225) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:31:37,799] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:31:37,801] {logging_mixin.py:109} INFO - [2022-08-13 10:31:37,801] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:31:38,355] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:31:38,368] {logging_mixin.py:109} INFO - [2022-08-13 10:31:38,367] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:31:38,385] {logging_mixin.py:109} INFO - [2022-08-13 10:31:38,385] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:31:38,397] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.606 seconds
[2022-08-13 10:32:09,427] {processor.py:163} INFO - Started process (PID=27290) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:32:09,431] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:32:09,433] {logging_mixin.py:109} INFO - [2022-08-13 10:32:09,432] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:32:10,043] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:32:10,056] {logging_mixin.py:109} INFO - [2022-08-13 10:32:10,055] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:32:10,071] {logging_mixin.py:109} INFO - [2022-08-13 10:32:10,071] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:32:10,082] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.660 seconds
[2022-08-13 10:32:40,603] {processor.py:163} INFO - Started process (PID=27364) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:32:40,607] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:32:40,614] {logging_mixin.py:109} INFO - [2022-08-13 10:32:40,613] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:32:41,204] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:32:41,217] {logging_mixin.py:109} INFO - [2022-08-13 10:32:41,216] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:32:41,233] {logging_mixin.py:109} INFO - [2022-08-13 10:32:41,232] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:32:41,245] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.646 seconds
[2022-08-13 10:33:11,785] {processor.py:163} INFO - Started process (PID=27430) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:33:11,789] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:33:11,791] {logging_mixin.py:109} INFO - [2022-08-13 10:33:11,791] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:33:12,432] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:33:12,446] {logging_mixin.py:109} INFO - [2022-08-13 10:33:12,445] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:33:12,466] {logging_mixin.py:109} INFO - [2022-08-13 10:33:12,465] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:33:12,478] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.699 seconds
[2022-08-13 10:33:43,366] {processor.py:163} INFO - Started process (PID=27504) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:33:43,368] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:33:43,370] {logging_mixin.py:109} INFO - [2022-08-13 10:33:43,370] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:33:43,926] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:33:43,938] {logging_mixin.py:109} INFO - [2022-08-13 10:33:43,936] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:33:43,957] {logging_mixin.py:109} INFO - [2022-08-13 10:33:43,957] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:33:43,969] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.609 seconds
[2022-08-13 10:34:14,282] {processor.py:163} INFO - Started process (PID=27570) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:34:14,286] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:34:14,289] {logging_mixin.py:109} INFO - [2022-08-13 10:34:14,289] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:34:14,836] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:34:14,848] {logging_mixin.py:109} INFO - [2022-08-13 10:34:14,847] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:34:14,864] {logging_mixin.py:109} INFO - [2022-08-13 10:34:14,864] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:34:14,875] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.597 seconds
[2022-08-13 10:34:45,741] {processor.py:163} INFO - Started process (PID=27635) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:34:45,744] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:34:45,747] {logging_mixin.py:109} INFO - [2022-08-13 10:34:45,747] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:34:46,406] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:34:46,427] {logging_mixin.py:109} INFO - [2022-08-13 10:34:46,426] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:34:46,444] {logging_mixin.py:109} INFO - [2022-08-13 10:34:46,444] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:34:46,457] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.722 seconds
[2022-08-13 10:35:16,958] {processor.py:163} INFO - Started process (PID=27708) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:35:16,963] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:35:16,966] {logging_mixin.py:109} INFO - [2022-08-13 10:35:16,965] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:35:17,525] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:35:17,535] {logging_mixin.py:109} INFO - [2022-08-13 10:35:17,534] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:35:17,551] {logging_mixin.py:109} INFO - [2022-08-13 10:35:17,551] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:35:17,563] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.613 seconds
[2022-08-13 10:35:48,324] {processor.py:163} INFO - Started process (PID=27774) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:35:48,326] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:35:48,328] {logging_mixin.py:109} INFO - [2022-08-13 10:35:48,328] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:35:48,949] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:35:48,960] {logging_mixin.py:109} INFO - [2022-08-13 10:35:48,959] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:35:48,976] {logging_mixin.py:109} INFO - [2022-08-13 10:35:48,976] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:35:48,986] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.668 seconds
[2022-08-13 10:36:19,074] {processor.py:163} INFO - Started process (PID=27848) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:36:19,077] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:36:19,080] {logging_mixin.py:109} INFO - [2022-08-13 10:36:19,079] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:36:19,698] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:36:19,709] {logging_mixin.py:109} INFO - [2022-08-13 10:36:19,708] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:36:19,725] {logging_mixin.py:109} INFO - [2022-08-13 10:36:19,725] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:36:19,735] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.669 seconds
[2022-08-13 10:36:50,405] {processor.py:163} INFO - Started process (PID=27915) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:36:50,409] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:36:50,411] {logging_mixin.py:109} INFO - [2022-08-13 10:36:50,410] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:36:50,958] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:36:50,968] {logging_mixin.py:109} INFO - [2022-08-13 10:36:50,968] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:36:50,991] {logging_mixin.py:109} INFO - [2022-08-13 10:36:50,991] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:36:51,001] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.601 seconds
[2022-08-13 10:37:21,897] {processor.py:163} INFO - Started process (PID=27981) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:37:21,900] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:37:21,901] {logging_mixin.py:109} INFO - [2022-08-13 10:37:21,901] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:37:22,458] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:37:22,469] {logging_mixin.py:109} INFO - [2022-08-13 10:37:22,469] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:37:22,487] {logging_mixin.py:109} INFO - [2022-08-13 10:37:22,487] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:37:22,502] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.614 seconds
[2022-08-13 10:37:53,382] {processor.py:163} INFO - Started process (PID=28056) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:37:53,384] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:37:53,385] {logging_mixin.py:109} INFO - [2022-08-13 10:37:53,385] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:37:53,924] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:37:53,934] {logging_mixin.py:109} INFO - [2022-08-13 10:37:53,933] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:37:53,949] {logging_mixin.py:109} INFO - [2022-08-13 10:37:53,949] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:37:53,960] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.581 seconds
[2022-08-13 10:38:24,649] {processor.py:163} INFO - Started process (PID=28122) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:38:24,651] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:38:24,652] {logging_mixin.py:109} INFO - [2022-08-13 10:38:24,652] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:38:25,294] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:38:25,307] {logging_mixin.py:109} INFO - [2022-08-13 10:38:25,306] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:38:25,325] {logging_mixin.py:109} INFO - [2022-08-13 10:38:25,324] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:38:25,335] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.690 seconds
[2022-08-13 10:38:55,774] {processor.py:163} INFO - Started process (PID=28195) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:38:55,776] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:38:55,778] {logging_mixin.py:109} INFO - [2022-08-13 10:38:55,777] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:38:56,412] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:38:56,423] {logging_mixin.py:109} INFO - [2022-08-13 10:38:56,422] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:38:56,438] {logging_mixin.py:109} INFO - [2022-08-13 10:38:56,438] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:38:56,450] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.681 seconds
[2022-08-13 10:39:26,540] {processor.py:163} INFO - Started process (PID=28267) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:39:26,542] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:39:26,543] {logging_mixin.py:109} INFO - [2022-08-13 10:39:26,543] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:39:27,094] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:39:27,107] {logging_mixin.py:109} INFO - [2022-08-13 10:39:27,107] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:39:27,127] {logging_mixin.py:109} INFO - [2022-08-13 10:39:27,127] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:39:27,141] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.606 seconds
[2022-08-13 10:39:57,677] {processor.py:163} INFO - Started process (PID=28333) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:39:57,679] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:39:57,682] {logging_mixin.py:109} INFO - [2022-08-13 10:39:57,681] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:39:58,273] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:39:58,284] {logging_mixin.py:109} INFO - [2022-08-13 10:39:58,283] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:39:58,301] {logging_mixin.py:109} INFO - [2022-08-13 10:39:58,301] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:39:58,313] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.642 seconds
[2022-08-13 10:40:28,625] {processor.py:163} INFO - Started process (PID=28408) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:40:28,627] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:40:28,628] {logging_mixin.py:109} INFO - [2022-08-13 10:40:28,628] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:40:29,245] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:40:29,258] {logging_mixin.py:109} INFO - [2022-08-13 10:40:29,257] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:40:29,276] {logging_mixin.py:109} INFO - [2022-08-13 10:40:29,276] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:40:29,290] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.669 seconds
[2022-08-13 10:40:59,912] {processor.py:163} INFO - Started process (PID=28472) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:40:59,916] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:40:59,918] {logging_mixin.py:109} INFO - [2022-08-13 10:40:59,917] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:41:00,544] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:41:00,557] {logging_mixin.py:109} INFO - [2022-08-13 10:41:00,556] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:41:00,577] {logging_mixin.py:109} INFO - [2022-08-13 10:41:00,577] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:41:00,591] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.685 seconds
[2022-08-13 10:41:30,679] {processor.py:163} INFO - Started process (PID=28542) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:41:30,682] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:41:30,683] {logging_mixin.py:109} INFO - [2022-08-13 10:41:30,683] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:41:31,212] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:41:31,222] {logging_mixin.py:109} INFO - [2022-08-13 10:41:31,221] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:41:31,237] {logging_mixin.py:109} INFO - [2022-08-13 10:41:31,236] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:41:31,247] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.573 seconds
[2022-08-13 10:42:01,468] {processor.py:163} INFO - Started process (PID=28618) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:42:01,473] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:42:01,476] {logging_mixin.py:109} INFO - [2022-08-13 10:42:01,476] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:42:02,206] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:42:02,225] {logging_mixin.py:109} INFO - [2022-08-13 10:42:02,223] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:42:02,244] {logging_mixin.py:109} INFO - [2022-08-13 10:42:02,244] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:42:02,254] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.809 seconds
[2022-08-13 10:42:32,315] {processor.py:163} INFO - Started process (PID=28685) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:42:32,318] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:42:32,319] {logging_mixin.py:109} INFO - [2022-08-13 10:42:32,319] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:42:32,977] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:42:32,991] {logging_mixin.py:109} INFO - [2022-08-13 10:42:32,991] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:42:33,012] {logging_mixin.py:109} INFO - [2022-08-13 10:42:33,012] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:42:33,027] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.717 seconds
[2022-08-13 10:43:03,154] {processor.py:163} INFO - Started process (PID=28752) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:43:03,157] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:43:03,160] {logging_mixin.py:109} INFO - [2022-08-13 10:43:03,160] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:43:03,714] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:43:03,724] {logging_mixin.py:109} INFO - [2022-08-13 10:43:03,723] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:43:03,742] {logging_mixin.py:109} INFO - [2022-08-13 10:43:03,742] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:43:03,756] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.609 seconds
[2022-08-13 10:43:34,314] {processor.py:163} INFO - Started process (PID=28827) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:43:34,316] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:43:34,317] {logging_mixin.py:109} INFO - [2022-08-13 10:43:34,317] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:43:34,914] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:43:34,926] {logging_mixin.py:109} INFO - [2022-08-13 10:43:34,926] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:43:34,945] {logging_mixin.py:109} INFO - [2022-08-13 10:43:34,945] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:43:34,960] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.651 seconds
[2022-08-13 10:44:05,015] {processor.py:163} INFO - Started process (PID=28894) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:44:05,018] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:44:05,021] {logging_mixin.py:109} INFO - [2022-08-13 10:44:05,020] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:44:05,724] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:44:05,739] {logging_mixin.py:109} INFO - [2022-08-13 10:44:05,737] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:44:05,780] {logging_mixin.py:109} INFO - [2022-08-13 10:44:05,776] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:44:05,806] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.797 seconds
[2022-08-13 10:44:36,074] {processor.py:163} INFO - Started process (PID=28965) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:44:36,077] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:44:36,078] {logging_mixin.py:109} INFO - [2022-08-13 10:44:36,078] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:44:36,621] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:44:36,630] {logging_mixin.py:109} INFO - [2022-08-13 10:44:36,630] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:44:36,650] {logging_mixin.py:109} INFO - [2022-08-13 10:44:36,650] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:44:36,661] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.612 seconds
[2022-08-13 10:45:06,802] {processor.py:163} INFO - Started process (PID=29033) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:45:06,804] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:45:06,806] {logging_mixin.py:109} INFO - [2022-08-13 10:45:06,806] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:45:07,335] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:45:07,345] {logging_mixin.py:109} INFO - [2022-08-13 10:45:07,344] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:45:07,358] {logging_mixin.py:109} INFO - [2022-08-13 10:45:07,358] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:45:07,367] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.571 seconds
[2022-08-13 10:45:37,832] {processor.py:163} INFO - Started process (PID=29098) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:45:37,835] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:45:37,837] {logging_mixin.py:109} INFO - [2022-08-13 10:45:37,837] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:45:38,416] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:45:38,427] {logging_mixin.py:109} INFO - [2022-08-13 10:45:38,426] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:45:38,447] {logging_mixin.py:109} INFO - [2022-08-13 10:45:38,447] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:45:38,459] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.632 seconds
[2022-08-13 10:46:09,184] {processor.py:163} INFO - Started process (PID=29174) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:46:09,188] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:46:09,191] {logging_mixin.py:109} INFO - [2022-08-13 10:46:09,191] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:46:09,681] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:46:09,692] {logging_mixin.py:109} INFO - [2022-08-13 10:46:09,692] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:46:09,709] {logging_mixin.py:109} INFO - [2022-08-13 10:46:09,708] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:46:09,720] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.541 seconds
[2022-08-13 10:46:39,952] {processor.py:163} INFO - Started process (PID=29240) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:46:39,955] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:46:39,957] {logging_mixin.py:109} INFO - [2022-08-13 10:46:39,957] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:46:40,511] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:46:40,526] {logging_mixin.py:109} INFO - [2022-08-13 10:46:40,526] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:46:40,546] {logging_mixin.py:109} INFO - [2022-08-13 10:46:40,546] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:46:40,561] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.612 seconds
[2022-08-13 10:47:10,761] {processor.py:163} INFO - Started process (PID=29317) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:47:10,763] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:47:10,765] {logging_mixin.py:109} INFO - [2022-08-13 10:47:10,765] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:47:11,340] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:47:11,354] {logging_mixin.py:109} INFO - [2022-08-13 10:47:11,353] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:47:11,370] {logging_mixin.py:109} INFO - [2022-08-13 10:47:11,370] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:47:11,380] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.623 seconds
[2022-08-13 10:47:42,133] {processor.py:163} INFO - Started process (PID=29384) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:47:42,136] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:47:42,139] {logging_mixin.py:109} INFO - [2022-08-13 10:47:42,139] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:47:42,645] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:47:42,655] {logging_mixin.py:109} INFO - [2022-08-13 10:47:42,655] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:47:42,669] {logging_mixin.py:109} INFO - [2022-08-13 10:47:42,669] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:47:42,678] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.551 seconds
[2022-08-13 10:48:13,538] {processor.py:163} INFO - Started process (PID=29460) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:48:13,541] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:48:13,543] {logging_mixin.py:109} INFO - [2022-08-13 10:48:13,542] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:48:14,091] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:48:14,103] {logging_mixin.py:109} INFO - [2022-08-13 10:48:14,102] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:48:14,119] {logging_mixin.py:109} INFO - [2022-08-13 10:48:14,119] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:48:14,131] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.599 seconds
[2022-08-13 10:48:44,805] {processor.py:163} INFO - Started process (PID=29526) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:48:44,808] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:48:44,810] {logging_mixin.py:109} INFO - [2022-08-13 10:48:44,810] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:48:45,269] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:48:45,278] {logging_mixin.py:109} INFO - [2022-08-13 10:48:45,277] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:48:45,295] {logging_mixin.py:109} INFO - [2022-08-13 10:48:45,294] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:48:45,313] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.514 seconds
[2022-08-13 10:49:16,159] {processor.py:163} INFO - Started process (PID=29601) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:49:16,162] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:49:16,163] {logging_mixin.py:109} INFO - [2022-08-13 10:49:16,163] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:49:16,757] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:49:16,767] {logging_mixin.py:109} INFO - [2022-08-13 10:49:16,766] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:49:16,780] {logging_mixin.py:109} INFO - [2022-08-13 10:49:16,780] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:49:16,792] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.636 seconds
[2022-08-13 10:49:47,558] {processor.py:163} INFO - Started process (PID=29666) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:49:47,560] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:49:47,561] {logging_mixin.py:109} INFO - [2022-08-13 10:49:47,561] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:49:48,079] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:49:48,088] {logging_mixin.py:109} INFO - [2022-08-13 10:49:48,087] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:49:48,103] {logging_mixin.py:109} INFO - [2022-08-13 10:49:48,103] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:49:48,113] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.559 seconds
[2022-08-13 10:50:19,065] {processor.py:163} INFO - Started process (PID=29740) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:50:19,067] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:50:19,069] {logging_mixin.py:109} INFO - [2022-08-13 10:50:19,068] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:50:19,591] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:50:19,601] {logging_mixin.py:109} INFO - [2022-08-13 10:50:19,600] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:50:19,622] {logging_mixin.py:109} INFO - [2022-08-13 10:50:19,622] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:50:19,638] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.577 seconds
[2022-08-13 10:50:50,345] {processor.py:163} INFO - Started process (PID=29805) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:50:50,347] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:50:50,350] {logging_mixin.py:109} INFO - [2022-08-13 10:50:50,349] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:50:50,885] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:50:50,893] {logging_mixin.py:109} INFO - [2022-08-13 10:50:50,893] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:50:50,906] {logging_mixin.py:109} INFO - [2022-08-13 10:50:50,906] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:50:50,915] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.576 seconds
[2022-08-13 10:51:21,796] {processor.py:163} INFO - Started process (PID=29882) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:51:21,800] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:51:21,803] {logging_mixin.py:109} INFO - [2022-08-13 10:51:21,802] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:51:22,374] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:51:22,383] {logging_mixin.py:109} INFO - [2022-08-13 10:51:22,382] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:51:22,401] {logging_mixin.py:109} INFO - [2022-08-13 10:51:22,401] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:51:22,412] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.625 seconds
[2022-08-13 10:51:52,541] {processor.py:163} INFO - Started process (PID=29952) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:51:52,545] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:51:52,547] {logging_mixin.py:109} INFO - [2022-08-13 10:51:52,547] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:51:53,074] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:51:53,084] {logging_mixin.py:109} INFO - [2022-08-13 10:51:53,083] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:51:53,100] {logging_mixin.py:109} INFO - [2022-08-13 10:51:53,100] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:51:53,120] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.583 seconds
[2022-08-13 10:52:23,223] {processor.py:163} INFO - Started process (PID=30023) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:52:23,225] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:52:23,227] {logging_mixin.py:109} INFO - [2022-08-13 10:52:23,227] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:52:23,814] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:52:23,822] {logging_mixin.py:109} INFO - [2022-08-13 10:52:23,822] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:52:23,836] {logging_mixin.py:109} INFO - [2022-08-13 10:52:23,836] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:52:23,848] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.629 seconds
[2022-08-13 10:52:53,990] {processor.py:163} INFO - Started process (PID=30102) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:52:53,993] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:52:53,995] {logging_mixin.py:109} INFO - [2022-08-13 10:52:53,994] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:52:54,492] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:52:54,504] {logging_mixin.py:109} INFO - [2022-08-13 10:52:54,504] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:52:54,517] {logging_mixin.py:109} INFO - [2022-08-13 10:52:54,517] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:52:54,527] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.542 seconds
[2022-08-13 10:53:25,182] {processor.py:163} INFO - Started process (PID=30168) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:53:25,186] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:53:25,188] {logging_mixin.py:109} INFO - [2022-08-13 10:53:25,188] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:53:25,696] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:53:25,706] {logging_mixin.py:109} INFO - [2022-08-13 10:53:25,705] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:53:25,718] {logging_mixin.py:109} INFO - [2022-08-13 10:53:25,718] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:53:25,727] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.548 seconds
[2022-08-13 10:53:56,630] {processor.py:163} INFO - Started process (PID=30243) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:53:56,632] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:53:56,634] {logging_mixin.py:109} INFO - [2022-08-13 10:53:56,634] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:53:57,120] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:53:57,129] {logging_mixin.py:109} INFO - [2022-08-13 10:53:57,129] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:53:57,149] {logging_mixin.py:109} INFO - [2022-08-13 10:53:57,149] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:53:57,167] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.541 seconds
[2022-08-13 10:54:27,989] {processor.py:163} INFO - Started process (PID=30308) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:54:27,992] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:54:27,993] {logging_mixin.py:109} INFO - [2022-08-13 10:54:27,993] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:54:28,483] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:54:28,493] {logging_mixin.py:109} INFO - [2022-08-13 10:54:28,493] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:54:28,507] {logging_mixin.py:109} INFO - [2022-08-13 10:54:28,507] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:54:28,514] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.529 seconds
[2022-08-13 10:54:58,968] {processor.py:163} INFO - Started process (PID=30382) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:54:58,971] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:54:58,972] {logging_mixin.py:109} INFO - [2022-08-13 10:54:58,972] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:54:59,448] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:54:59,458] {logging_mixin.py:109} INFO - [2022-08-13 10:54:59,457] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:54:59,471] {logging_mixin.py:109} INFO - [2022-08-13 10:54:59,471] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:54:59,481] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.518 seconds
[2022-08-13 10:55:29,666] {processor.py:163} INFO - Started process (PID=30449) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:55:29,669] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:55:29,670] {logging_mixin.py:109} INFO - [2022-08-13 10:55:29,670] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:55:30,199] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:55:30,212] {logging_mixin.py:109} INFO - [2022-08-13 10:55:30,212] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:55:30,231] {logging_mixin.py:109} INFO - [2022-08-13 10:55:30,231] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:55:30,244] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.582 seconds
[2022-08-13 10:56:00,460] {processor.py:163} INFO - Started process (PID=30524) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:56:00,462] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:56:00,464] {logging_mixin.py:109} INFO - [2022-08-13 10:56:00,464] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:56:01,066] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:56:01,077] {logging_mixin.py:109} INFO - [2022-08-13 10:56:01,077] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:56:01,093] {logging_mixin.py:109} INFO - [2022-08-13 10:56:01,093] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:56:01,107] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.651 seconds
[2022-08-13 10:56:31,455] {processor.py:163} INFO - Started process (PID=30590) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:56:31,459] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:56:31,461] {logging_mixin.py:109} INFO - [2022-08-13 10:56:31,460] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:56:31,947] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:56:31,958] {logging_mixin.py:109} INFO - [2022-08-13 10:56:31,958] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:56:31,973] {logging_mixin.py:109} INFO - [2022-08-13 10:56:31,973] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:56:31,981] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.531 seconds
[2022-08-13 10:57:02,097] {processor.py:163} INFO - Started process (PID=30655) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:57:02,101] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:57:02,103] {logging_mixin.py:109} INFO - [2022-08-13 10:57:02,103] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:57:02,575] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:57:02,584] {logging_mixin.py:109} INFO - [2022-08-13 10:57:02,583] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:57:02,598] {logging_mixin.py:109} INFO - [2022-08-13 10:57:02,598] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:57:02,610] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.518 seconds
[2022-08-13 10:57:32,665] {processor.py:163} INFO - Started process (PID=30730) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:57:32,669] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:57:32,671] {logging_mixin.py:109} INFO - [2022-08-13 10:57:32,671] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:57:33,128] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:57:33,136] {logging_mixin.py:109} INFO - [2022-08-13 10:57:33,135] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:57:33,156] {logging_mixin.py:109} INFO - [2022-08-13 10:57:33,156] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:57:33,226] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.566 seconds
[2022-08-13 10:58:04,266] {processor.py:163} INFO - Started process (PID=30796) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:58:04,268] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:58:04,270] {logging_mixin.py:109} INFO - [2022-08-13 10:58:04,270] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:58:04,810] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:58:04,819] {logging_mixin.py:109} INFO - [2022-08-13 10:58:04,818] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:58:04,834] {logging_mixin.py:109} INFO - [2022-08-13 10:58:04,834] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:58:04,843] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.581 seconds
[2022-08-13 10:58:35,168] {processor.py:163} INFO - Started process (PID=30873) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:58:35,170] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:58:35,172] {logging_mixin.py:109} INFO - [2022-08-13 10:58:35,172] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:58:35,722] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:58:35,735] {logging_mixin.py:109} INFO - [2022-08-13 10:58:35,735] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:58:35,749] {logging_mixin.py:109} INFO - [2022-08-13 10:58:35,749] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:58:35,759] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.618 seconds
[2022-08-13 10:59:06,044] {processor.py:163} INFO - Started process (PID=30937) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:59:06,046] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:59:06,048] {logging_mixin.py:109} INFO - [2022-08-13 10:59:06,047] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:59:06,603] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:59:06,614] {logging_mixin.py:109} INFO - [2022-08-13 10:59:06,614] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:59:06,628] {logging_mixin.py:109} INFO - [2022-08-13 10:59:06,628] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:59:06,639] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.600 seconds
[2022-08-13 10:59:37,213] {processor.py:163} INFO - Started process (PID=31012) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:59:37,216] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 10:59:37,218] {logging_mixin.py:109} INFO - [2022-08-13 10:59:37,218] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:59:37,781] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 10:59:37,794] {logging_mixin.py:109} INFO - [2022-08-13 10:59:37,794] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 10:59:37,814] {logging_mixin.py:109} INFO - [2022-08-13 10:59:37,813] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 10:59:37,840] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.635 seconds
[2022-08-13 11:00:08,537] {processor.py:163} INFO - Started process (PID=31077) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:00:08,539] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:00:08,541] {logging_mixin.py:109} INFO - [2022-08-13 11:00:08,541] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:00:09,136] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:00:09,145] {logging_mixin.py:109} INFO - [2022-08-13 11:00:09,145] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:00:09,159] {logging_mixin.py:109} INFO - [2022-08-13 11:00:09,158] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:00:09,168] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.636 seconds
[2022-08-13 11:00:39,284] {processor.py:163} INFO - Started process (PID=31152) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:00:39,286] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:00:39,288] {logging_mixin.py:109} INFO - [2022-08-13 11:00:39,288] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:00:39,841] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:00:39,850] {logging_mixin.py:109} INFO - [2022-08-13 11:00:39,850] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:00:39,868] {logging_mixin.py:109} INFO - [2022-08-13 11:00:39,868] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:00:39,876] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.595 seconds
[2022-08-13 11:01:10,353] {processor.py:163} INFO - Started process (PID=31217) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:01:10,356] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:01:10,357] {logging_mixin.py:109} INFO - [2022-08-13 11:01:10,357] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:01:10,941] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:01:10,950] {logging_mixin.py:109} INFO - [2022-08-13 11:01:10,950] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:01:10,963] {logging_mixin.py:109} INFO - [2022-08-13 11:01:10,963] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:01:10,973] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.624 seconds
[2022-08-13 11:01:41,212] {processor.py:163} INFO - Started process (PID=31292) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:01:41,214] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:01:41,215] {logging_mixin.py:109} INFO - [2022-08-13 11:01:41,215] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:01:41,863] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:01:41,872] {logging_mixin.py:109} INFO - [2022-08-13 11:01:41,871] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:01:41,886] {logging_mixin.py:109} INFO - [2022-08-13 11:01:41,886] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:01:41,896] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.688 seconds
[2022-08-13 11:02:12,858] {processor.py:163} INFO - Started process (PID=31357) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:02:12,860] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:02:12,861] {logging_mixin.py:109} INFO - [2022-08-13 11:02:12,861] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:02:13,395] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:02:13,405] {logging_mixin.py:109} INFO - [2022-08-13 11:02:13,404] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:02:13,419] {logging_mixin.py:109} INFO - [2022-08-13 11:02:13,419] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:02:13,431] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.577 seconds
[2022-08-13 11:02:44,103] {processor.py:163} INFO - Started process (PID=31432) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:02:44,105] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:02:44,107] {logging_mixin.py:109} INFO - [2022-08-13 11:02:44,107] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:02:44,618] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:02:44,630] {logging_mixin.py:109} INFO - [2022-08-13 11:02:44,629] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:02:44,646] {logging_mixin.py:109} INFO - [2022-08-13 11:02:44,646] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:02:44,657] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.558 seconds
[2022-08-13 11:03:15,432] {processor.py:163} INFO - Started process (PID=31497) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:03:15,434] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:03:15,436] {logging_mixin.py:109} INFO - [2022-08-13 11:03:15,436] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:03:15,896] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:03:15,904] {logging_mixin.py:109} INFO - [2022-08-13 11:03:15,904] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:03:15,920] {logging_mixin.py:109} INFO - [2022-08-13 11:03:15,920] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:03:15,929] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.502 seconds
[2022-08-13 11:03:46,203] {processor.py:163} INFO - Started process (PID=31562) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:03:46,206] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:03:46,212] {logging_mixin.py:109} INFO - [2022-08-13 11:03:46,212] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:03:46,840] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:03:46,850] {logging_mixin.py:109} INFO - [2022-08-13 11:03:46,850] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:03:46,863] {logging_mixin.py:109} INFO - [2022-08-13 11:03:46,863] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:03:46,875] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.680 seconds
[2022-08-13 11:04:17,749] {processor.py:163} INFO - Started process (PID=31639) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:04:17,752] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:04:17,753] {logging_mixin.py:109} INFO - [2022-08-13 11:04:17,753] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:04:18,219] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:04:18,230] {logging_mixin.py:109} INFO - [2022-08-13 11:04:18,229] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:04:18,247] {logging_mixin.py:109} INFO - [2022-08-13 11:04:18,247] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:04:18,258] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.514 seconds
[2022-08-13 11:04:49,087] {processor.py:163} INFO - Started process (PID=31705) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:04:49,090] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:04:49,091] {logging_mixin.py:109} INFO - [2022-08-13 11:04:49,091] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:04:49,598] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:04:49,608] {logging_mixin.py:109} INFO - [2022-08-13 11:04:49,607] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:04:49,621] {logging_mixin.py:109} INFO - [2022-08-13 11:04:49,621] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:04:49,631] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.547 seconds
[2022-08-13 11:05:20,559] {processor.py:163} INFO - Started process (PID=31780) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:05:20,561] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:05:20,562] {logging_mixin.py:109} INFO - [2022-08-13 11:05:20,562] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:05:21,007] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:05:21,015] {logging_mixin.py:109} INFO - [2022-08-13 11:05:21,014] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:05:21,027] {logging_mixin.py:109} INFO - [2022-08-13 11:05:21,027] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:05:21,036] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.481 seconds
[2022-08-13 11:05:51,954] {processor.py:163} INFO - Started process (PID=31845) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:05:51,956] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:05:51,957] {logging_mixin.py:109} INFO - [2022-08-13 11:05:51,957] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:05:52,405] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:05:52,413] {logging_mixin.py:109} INFO - [2022-08-13 11:05:52,413] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:05:52,426] {logging_mixin.py:109} INFO - [2022-08-13 11:05:52,426] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:05:52,435] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.485 seconds
[2022-08-13 11:06:22,643] {processor.py:163} INFO - Started process (PID=31920) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:06:22,646] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:06:22,647] {logging_mixin.py:109} INFO - [2022-08-13 11:06:22,647] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:06:23,192] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:06:23,201] {logging_mixin.py:109} INFO - [2022-08-13 11:06:23,200] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:06:23,214] {logging_mixin.py:109} INFO - [2022-08-13 11:06:23,214] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:06:23,224] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.585 seconds
[2022-08-13 11:06:53,410] {processor.py:163} INFO - Started process (PID=31985) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:06:53,413] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:06:53,415] {logging_mixin.py:109} INFO - [2022-08-13 11:06:53,415] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:06:53,887] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:06:53,896] {logging_mixin.py:109} INFO - [2022-08-13 11:06:53,896] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:06:53,909] {logging_mixin.py:109} INFO - [2022-08-13 11:06:53,909] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:06:53,920] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.516 seconds
[2022-08-13 11:07:24,124] {processor.py:163} INFO - Started process (PID=32059) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:07:24,128] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:07:24,130] {logging_mixin.py:109} INFO - [2022-08-13 11:07:24,130] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:07:24,598] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:07:24,607] {logging_mixin.py:109} INFO - [2022-08-13 11:07:24,607] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:07:24,620] {logging_mixin.py:109} INFO - [2022-08-13 11:07:24,620] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:07:24,628] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.508 seconds
[2022-08-13 11:07:55,554] {processor.py:163} INFO - Started process (PID=32124) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:07:55,556] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:07:55,558] {logging_mixin.py:109} INFO - [2022-08-13 11:07:55,558] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:07:56,060] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:07:56,069] {logging_mixin.py:109} INFO - [2022-08-13 11:07:56,068] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:07:56,082] {logging_mixin.py:109} INFO - [2022-08-13 11:07:56,082] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:07:56,090] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.541 seconds
[2022-08-13 11:08:26,470] {processor.py:163} INFO - Started process (PID=32198) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:08:26,474] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:08:26,475] {logging_mixin.py:109} INFO - [2022-08-13 11:08:26,475] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:08:27,010] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:08:27,020] {logging_mixin.py:109} INFO - [2022-08-13 11:08:27,019] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:08:27,035] {logging_mixin.py:109} INFO - [2022-08-13 11:08:27,034] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:08:27,044] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.578 seconds
[2022-08-13 11:08:57,140] {processor.py:163} INFO - Started process (PID=32263) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:08:57,143] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:08:57,144] {logging_mixin.py:109} INFO - [2022-08-13 11:08:57,144] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:08:57,672] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:08:57,685] {logging_mixin.py:109} INFO - [2022-08-13 11:08:57,684] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:08:57,703] {logging_mixin.py:109} INFO - [2022-08-13 11:08:57,703] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:08:57,716] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.581 seconds
[2022-08-13 11:09:28,309] {processor.py:163} INFO - Started process (PID=32337) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:09:28,312] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:09:28,314] {logging_mixin.py:109} INFO - [2022-08-13 11:09:28,314] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:09:28,842] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:09:28,851] {logging_mixin.py:109} INFO - [2022-08-13 11:09:28,850] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:09:28,865] {logging_mixin.py:109} INFO - [2022-08-13 11:09:28,865] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:09:28,875] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.569 seconds
[2022-08-13 11:09:59,139] {processor.py:163} INFO - Started process (PID=32402) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:09:59,142] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:09:59,144] {logging_mixin.py:109} INFO - [2022-08-13 11:09:59,144] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:09:59,623] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:09:59,632] {logging_mixin.py:109} INFO - [2022-08-13 11:09:59,632] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:09:59,647] {logging_mixin.py:109} INFO - [2022-08-13 11:09:59,647] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:09:59,656] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.523 seconds
[2022-08-13 11:10:30,326] {processor.py:163} INFO - Started process (PID=32467) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:10:30,328] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:10:30,330] {logging_mixin.py:109} INFO - [2022-08-13 11:10:30,329] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:10:30,855] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:10:30,864] {logging_mixin.py:109} INFO - [2022-08-13 11:10:30,863] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:10:30,882] {logging_mixin.py:109} INFO - [2022-08-13 11:10:30,882] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:10:30,894] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.571 seconds
[2022-08-13 11:11:00,958] {processor.py:163} INFO - Started process (PID=32541) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:11:00,960] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:11:00,962] {logging_mixin.py:109} INFO - [2022-08-13 11:11:00,962] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:11:01,456] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:11:01,464] {logging_mixin.py:109} INFO - [2022-08-13 11:11:01,464] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:11:01,478] {logging_mixin.py:109} INFO - [2022-08-13 11:11:01,478] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:11:01,487] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.535 seconds
[2022-08-13 11:11:31,975] {processor.py:163} INFO - Started process (PID=32607) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:11:31,978] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:11:31,979] {logging_mixin.py:109} INFO - [2022-08-13 11:11:31,979] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:11:32,419] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:11:32,428] {logging_mixin.py:109} INFO - [2022-08-13 11:11:32,427] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:11:32,442] {logging_mixin.py:109} INFO - [2022-08-13 11:11:32,441] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:11:32,450] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.478 seconds
[2022-08-13 11:12:03,040] {processor.py:163} INFO - Started process (PID=32681) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:12:03,043] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:12:03,044] {logging_mixin.py:109} INFO - [2022-08-13 11:12:03,044] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:12:03,512] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:12:03,521] {logging_mixin.py:109} INFO - [2022-08-13 11:12:03,520] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:12:03,535] {logging_mixin.py:109} INFO - [2022-08-13 11:12:03,535] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:12:03,543] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.510 seconds
[2022-08-13 11:12:34,178] {processor.py:163} INFO - Started process (PID=32746) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:12:34,181] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:12:34,183] {logging_mixin.py:109} INFO - [2022-08-13 11:12:34,183] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:12:34,652] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:12:34,660] {logging_mixin.py:109} INFO - [2022-08-13 11:12:34,660] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:12:34,673] {logging_mixin.py:109} INFO - [2022-08-13 11:12:34,673] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:12:34,682] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.510 seconds
[2022-08-13 11:13:04,818] {processor.py:163} INFO - Started process (PID=32822) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:13:04,821] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:13:04,823] {logging_mixin.py:109} INFO - [2022-08-13 11:13:04,823] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:13:05,361] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:13:05,374] {logging_mixin.py:109} INFO - [2022-08-13 11:13:05,374] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:13:05,389] {logging_mixin.py:109} INFO - [2022-08-13 11:13:05,389] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:13:05,398] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.606 seconds
[2022-08-13 11:13:35,677] {processor.py:163} INFO - Started process (PID=32887) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:13:35,679] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:13:35,680] {logging_mixin.py:109} INFO - [2022-08-13 11:13:35,680] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:13:36,217] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:13:36,226] {logging_mixin.py:109} INFO - [2022-08-13 11:13:36,226] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:13:36,239] {logging_mixin.py:109} INFO - [2022-08-13 11:13:36,239] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:13:36,250] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.577 seconds
[2022-08-13 11:14:06,568] {processor.py:163} INFO - Started process (PID=32959) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:14:06,571] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:14:06,572] {logging_mixin.py:109} INFO - [2022-08-13 11:14:06,572] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:14:07,102] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:14:07,119] {logging_mixin.py:109} INFO - [2022-08-13 11:14:07,118] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:14:07,138] {logging_mixin.py:109} INFO - [2022-08-13 11:14:07,137] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:14:07,149] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.585 seconds
[2022-08-13 11:14:37,618] {processor.py:163} INFO - Started process (PID=33025) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:14:37,620] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:14:37,622] {logging_mixin.py:109} INFO - [2022-08-13 11:14:37,622] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:14:38,133] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:14:38,143] {logging_mixin.py:109} INFO - [2022-08-13 11:14:38,143] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:14:38,159] {logging_mixin.py:109} INFO - [2022-08-13 11:14:38,158] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:14:38,170] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.557 seconds
[2022-08-13 11:15:08,227] {processor.py:163} INFO - Started process (PID=33090) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:15:08,229] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:15:08,230] {logging_mixin.py:109} INFO - [2022-08-13 11:15:08,230] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:15:08,682] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:15:08,691] {logging_mixin.py:109} INFO - [2022-08-13 11:15:08,690] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:15:08,704] {logging_mixin.py:109} INFO - [2022-08-13 11:15:08,703] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:15:08,712] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.490 seconds
[2022-08-13 11:15:39,381] {processor.py:163} INFO - Started process (PID=33167) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:15:39,383] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:15:39,384] {logging_mixin.py:109} INFO - [2022-08-13 11:15:39,384] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:15:39,853] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:15:39,861] {logging_mixin.py:109} INFO - [2022-08-13 11:15:39,861] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:15:39,874] {logging_mixin.py:109} INFO - [2022-08-13 11:15:39,874] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:15:39,883] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.506 seconds
[2022-08-13 11:16:10,082] {processor.py:163} INFO - Started process (PID=33232) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:16:10,084] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:16:10,086] {logging_mixin.py:109} INFO - [2022-08-13 11:16:10,086] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:16:10,605] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:16:10,614] {logging_mixin.py:109} INFO - [2022-08-13 11:16:10,614] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:16:10,632] {logging_mixin.py:109} INFO - [2022-08-13 11:16:10,632] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:16:10,643] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.565 seconds
[2022-08-13 11:16:40,752] {processor.py:163} INFO - Started process (PID=33306) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:16:40,756] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:16:40,758] {logging_mixin.py:109} INFO - [2022-08-13 11:16:40,757] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:16:41,217] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:16:41,226] {logging_mixin.py:109} INFO - [2022-08-13 11:16:41,225] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:16:41,239] {logging_mixin.py:109} INFO - [2022-08-13 11:16:41,239] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:16:41,248] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.502 seconds
[2022-08-13 11:17:11,575] {processor.py:163} INFO - Started process (PID=33371) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:17:11,578] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:17:11,580] {logging_mixin.py:109} INFO - [2022-08-13 11:17:11,580] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:17:12,036] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:17:12,044] {logging_mixin.py:109} INFO - [2022-08-13 11:17:12,044] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:17:12,057] {logging_mixin.py:109} INFO - [2022-08-13 11:17:12,057] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:17:12,066] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.497 seconds
[2022-08-13 11:17:42,520] {processor.py:163} INFO - Started process (PID=33445) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:17:42,522] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:17:42,523] {logging_mixin.py:109} INFO - [2022-08-13 11:17:42,523] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:17:43,060] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:17:43,070] {logging_mixin.py:109} INFO - [2022-08-13 11:17:43,070] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:17:43,088] {logging_mixin.py:109} INFO - [2022-08-13 11:17:43,088] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:17:43,105] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.589 seconds
[2022-08-13 11:18:13,241] {processor.py:163} INFO - Started process (PID=33516) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:18:13,243] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:18:13,245] {logging_mixin.py:109} INFO - [2022-08-13 11:18:13,245] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:18:13,827] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:18:13,836] {logging_mixin.py:109} INFO - [2022-08-13 11:18:13,836] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:18:13,851] {logging_mixin.py:109} INFO - [2022-08-13 11:18:13,851] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:18:13,860] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.625 seconds
[2022-08-13 11:18:43,952] {processor.py:163} INFO - Started process (PID=33582) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:18:43,955] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:18:43,956] {logging_mixin.py:109} INFO - [2022-08-13 11:18:43,956] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:18:44,489] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:18:44,499] {logging_mixin.py:109} INFO - [2022-08-13 11:18:44,499] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:18:44,517] {logging_mixin.py:109} INFO - [2022-08-13 11:18:44,516] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:18:44,530] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.582 seconds
[2022-08-13 11:19:14,674] {processor.py:163} INFO - Started process (PID=33657) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:19:14,677] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:19:14,704] {logging_mixin.py:109} INFO - [2022-08-13 11:19:14,704] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:19:15,288] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:19:15,300] {logging_mixin.py:109} INFO - [2022-08-13 11:19:15,300] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:19:15,315] {logging_mixin.py:109} INFO - [2022-08-13 11:19:15,315] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:19:15,326] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.657 seconds
[2022-08-13 11:19:45,400] {processor.py:163} INFO - Started process (PID=33728) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:19:45,402] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:19:45,404] {logging_mixin.py:109} INFO - [2022-08-13 11:19:45,404] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:19:45,888] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:19:45,897] {logging_mixin.py:109} INFO - [2022-08-13 11:19:45,897] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:19:45,912] {logging_mixin.py:109} INFO - [2022-08-13 11:19:45,912] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:19:45,921] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.525 seconds
[2022-08-13 11:20:16,321] {processor.py:163} INFO - Started process (PID=33804) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:20:16,336] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:20:16,338] {logging_mixin.py:109} INFO - [2022-08-13 11:20:16,337] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:20:16,859] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:20:16,869] {logging_mixin.py:109} INFO - [2022-08-13 11:20:16,868] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:20:16,883] {logging_mixin.py:109} INFO - [2022-08-13 11:20:16,883] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:20:16,893] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.577 seconds
[2022-08-13 11:20:47,844] {processor.py:163} INFO - Started process (PID=33869) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:20:47,847] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:20:47,848] {logging_mixin.py:109} INFO - [2022-08-13 11:20:47,848] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:20:48,358] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:20:48,368] {logging_mixin.py:109} INFO - [2022-08-13 11:20:48,367] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:20:48,387] {logging_mixin.py:109} INFO - [2022-08-13 11:20:48,387] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:20:48,397] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.558 seconds
[2022-08-13 11:21:18,976] {processor.py:163} INFO - Started process (PID=33944) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:21:18,979] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:21:18,981] {logging_mixin.py:109} INFO - [2022-08-13 11:21:18,980] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:21:19,457] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:21:19,467] {logging_mixin.py:109} INFO - [2022-08-13 11:21:19,466] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:21:19,480] {logging_mixin.py:109} INFO - [2022-08-13 11:21:19,480] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:21:19,489] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.519 seconds
[2022-08-13 11:21:49,818] {processor.py:163} INFO - Started process (PID=34010) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:21:49,820] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:21:49,821] {logging_mixin.py:109} INFO - [2022-08-13 11:21:49,821] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:21:50,544] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:21:50,553] {logging_mixin.py:109} INFO - [2022-08-13 11:21:50,553] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:21:50,567] {logging_mixin.py:109} INFO - [2022-08-13 11:21:50,567] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:21:50,578] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.764 seconds
[2022-08-13 11:22:20,758] {processor.py:163} INFO - Started process (PID=34085) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:22:20,760] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:22:20,762] {logging_mixin.py:109} INFO - [2022-08-13 11:22:20,762] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:22:21,293] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:22:21,305] {logging_mixin.py:109} INFO - [2022-08-13 11:22:21,305] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:22:21,334] {logging_mixin.py:109} INFO - [2022-08-13 11:22:21,334] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:22:21,343] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.590 seconds
[2022-08-13 11:22:51,535] {processor.py:163} INFO - Started process (PID=34150) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:22:51,537] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:22:51,538] {logging_mixin.py:109} INFO - [2022-08-13 11:22:51,538] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:22:52,034] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:22:52,047] {logging_mixin.py:109} INFO - [2022-08-13 11:22:52,046] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:22:52,064] {logging_mixin.py:109} INFO - [2022-08-13 11:22:52,064] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:22:52,073] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.543 seconds
[2022-08-13 11:23:22,335] {processor.py:163} INFO - Started process (PID=34224) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:23:22,337] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:23:22,339] {logging_mixin.py:109} INFO - [2022-08-13 11:23:22,339] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:23:22,948] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:23:22,957] {logging_mixin.py:109} INFO - [2022-08-13 11:23:22,957] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:23:22,973] {logging_mixin.py:109} INFO - [2022-08-13 11:23:22,973] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:23:22,983] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.652 seconds
[2022-08-13 11:23:53,077] {processor.py:163} INFO - Started process (PID=34285) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:23:53,080] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:23:53,082] {logging_mixin.py:109} INFO - [2022-08-13 11:23:53,082] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:23:53,637] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:23:53,650] {logging_mixin.py:109} INFO - [2022-08-13 11:23:53,650] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:23:53,668] {logging_mixin.py:109} INFO - [2022-08-13 11:23:53,668] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:23:53,684] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.614 seconds
[2022-08-13 11:24:23,985] {processor.py:163} INFO - Started process (PID=34350) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:24:23,989] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:24:23,991] {logging_mixin.py:109} INFO - [2022-08-13 11:24:23,990] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:24:24,626] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:24:24,639] {logging_mixin.py:109} INFO - [2022-08-13 11:24:24,639] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:24:24,657] {logging_mixin.py:109} INFO - [2022-08-13 11:24:24,657] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:24:24,671] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.691 seconds
[2022-08-13 11:24:54,787] {processor.py:163} INFO - Started process (PID=34424) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:24:54,789] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:24:54,790] {logging_mixin.py:109} INFO - [2022-08-13 11:24:54,790] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:24:55,420] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:24:55,437] {logging_mixin.py:109} INFO - [2022-08-13 11:24:55,436] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:24:55,460] {logging_mixin.py:109} INFO - [2022-08-13 11:24:55,460] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:24:55,474] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.692 seconds
[2022-08-13 11:25:26,103] {processor.py:163} INFO - Started process (PID=34489) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:25:26,105] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:25:26,106] {logging_mixin.py:109} INFO - [2022-08-13 11:25:26,106] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:25:26,773] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:25:26,786] {logging_mixin.py:109} INFO - [2022-08-13 11:25:26,786] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:25:26,808] {logging_mixin.py:109} INFO - [2022-08-13 11:25:26,808] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:25:26,820] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.724 seconds
[2022-08-13 11:25:57,108] {processor.py:163} INFO - Started process (PID=34554) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:25:57,111] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:25:57,114] {logging_mixin.py:109} INFO - [2022-08-13 11:25:57,113] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:25:57,683] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:25:57,692] {logging_mixin.py:109} INFO - [2022-08-13 11:25:57,692] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:25:57,709] {logging_mixin.py:109} INFO - [2022-08-13 11:25:57,709] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:25:57,721] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.618 seconds
[2022-08-13 11:26:28,068] {processor.py:163} INFO - Started process (PID=34628) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:26:28,071] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:26:28,073] {logging_mixin.py:109} INFO - [2022-08-13 11:26:28,073] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:26:28,715] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:26:28,730] {logging_mixin.py:109} INFO - [2022-08-13 11:26:28,730] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:26:28,750] {logging_mixin.py:109} INFO - [2022-08-13 11:26:28,749] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:26:28,763] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.701 seconds
[2022-08-13 11:26:59,488] {processor.py:163} INFO - Started process (PID=34694) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:26:59,490] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:26:59,491] {logging_mixin.py:109} INFO - [2022-08-13 11:26:59,491] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:27:00,170] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:27:00,185] {logging_mixin.py:109} INFO - [2022-08-13 11:27:00,184] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:27:00,207] {logging_mixin.py:109} INFO - [2022-08-13 11:27:00,207] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:27:00,224] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.741 seconds
[2022-08-13 11:27:30,982] {processor.py:163} INFO - Started process (PID=34769) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:27:30,984] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:27:30,986] {logging_mixin.py:109} INFO - [2022-08-13 11:27:30,986] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:27:31,653] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:27:31,664] {logging_mixin.py:109} INFO - [2022-08-13 11:27:31,663] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:27:31,683] {logging_mixin.py:109} INFO - [2022-08-13 11:27:31,682] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:27:31,697] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.720 seconds
[2022-08-13 11:28:01,908] {processor.py:163} INFO - Started process (PID=34833) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:28:01,910] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:28:01,912] {logging_mixin.py:109} INFO - [2022-08-13 11:28:01,912] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:28:02,555] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:28:02,574] {logging_mixin.py:109} INFO - [2022-08-13 11:28:02,573] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:28:02,595] {logging_mixin.py:109} INFO - [2022-08-13 11:28:02,595] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:28:02,607] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.702 seconds
[2022-08-13 11:28:32,980] {processor.py:163} INFO - Started process (PID=34897) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:28:32,983] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:28:32,985] {logging_mixin.py:109} INFO - [2022-08-13 11:28:32,985] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:28:33,570] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:28:33,581] {logging_mixin.py:109} INFO - [2022-08-13 11:28:33,580] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:28:33,595] {logging_mixin.py:109} INFO - [2022-08-13 11:28:33,595] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:28:33,604] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.633 seconds
[2022-08-13 11:29:04,503] {processor.py:163} INFO - Started process (PID=34972) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:29:04,507] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:29:04,509] {logging_mixin.py:109} INFO - [2022-08-13 11:29:04,508] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:29:05,107] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:29:05,119] {logging_mixin.py:109} INFO - [2022-08-13 11:29:05,118] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:29:05,138] {logging_mixin.py:109} INFO - [2022-08-13 11:29:05,138] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:29:05,151] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.682 seconds
[2022-08-13 11:29:35,424] {processor.py:163} INFO - Started process (PID=35039) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:29:35,426] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:29:35,429] {logging_mixin.py:109} INFO - [2022-08-13 11:29:35,429] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:29:36,043] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:29:36,057] {logging_mixin.py:109} INFO - [2022-08-13 11:29:36,056] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:29:36,074] {logging_mixin.py:109} INFO - [2022-08-13 11:29:36,074] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:29:36,086] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.668 seconds
[2022-08-13 11:30:06,984] {processor.py:163} INFO - Started process (PID=35105) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:30:06,987] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:30:06,990] {logging_mixin.py:109} INFO - [2022-08-13 11:30:06,989] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:30:07,641] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:30:07,656] {logging_mixin.py:109} INFO - [2022-08-13 11:30:07,654] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:30:07,676] {logging_mixin.py:109} INFO - [2022-08-13 11:30:07,676] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:30:07,687] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.714 seconds
[2022-08-13 11:30:38,437] {processor.py:163} INFO - Started process (PID=35182) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:30:38,441] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:30:38,443] {logging_mixin.py:109} INFO - [2022-08-13 11:30:38,443] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:30:39,208] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:30:39,220] {logging_mixin.py:109} INFO - [2022-08-13 11:30:39,219] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:30:39,239] {logging_mixin.py:109} INFO - [2022-08-13 11:30:39,239] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:30:39,252] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.819 seconds
[2022-08-13 11:31:09,324] {processor.py:163} INFO - Started process (PID=35252) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:31:09,326] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:31:09,328] {logging_mixin.py:109} INFO - [2022-08-13 11:31:09,328] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:31:09,862] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:31:09,873] {logging_mixin.py:109} INFO - [2022-08-13 11:31:09,873] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:31:09,888] {logging_mixin.py:109} INFO - [2022-08-13 11:31:09,888] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:31:09,899] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.580 seconds
[2022-08-13 11:31:40,669] {processor.py:163} INFO - Started process (PID=35324) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:31:40,672] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:31:40,675] {logging_mixin.py:109} INFO - [2022-08-13 11:31:40,674] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:31:41,369] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:31:41,385] {logging_mixin.py:109} INFO - [2022-08-13 11:31:41,385] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:31:41,404] {logging_mixin.py:109} INFO - [2022-08-13 11:31:41,404] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:31:41,420] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.754 seconds
[2022-08-13 11:32:11,682] {processor.py:163} INFO - Started process (PID=35397) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:32:11,695] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:32:11,699] {logging_mixin.py:109} INFO - [2022-08-13 11:32:11,699] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:32:12,519] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:32:12,533] {logging_mixin.py:109} INFO - [2022-08-13 11:32:12,532] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:32:12,551] {logging_mixin.py:109} INFO - [2022-08-13 11:32:12,551] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:32:12,567] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.893 seconds
[2022-08-13 11:32:42,797] {processor.py:163} INFO - Started process (PID=35463) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:32:42,800] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:32:42,802] {logging_mixin.py:109} INFO - [2022-08-13 11:32:42,802] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:32:43,378] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:32:43,389] {logging_mixin.py:109} INFO - [2022-08-13 11:32:43,388] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:32:43,406] {logging_mixin.py:109} INFO - [2022-08-13 11:32:43,406] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:32:43,417] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.626 seconds
[2022-08-13 11:33:13,543] {processor.py:163} INFO - Started process (PID=35536) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:33:13,546] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:33:13,548] {logging_mixin.py:109} INFO - [2022-08-13 11:33:13,548] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:33:14,256] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:33:14,274] {logging_mixin.py:109} INFO - [2022-08-13 11:33:14,272] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:33:14,304] {logging_mixin.py:109} INFO - [2022-08-13 11:33:14,304] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:33:14,319] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.782 seconds
[2022-08-13 11:33:44,395] {processor.py:163} INFO - Started process (PID=35603) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:33:44,398] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:33:44,400] {logging_mixin.py:109} INFO - [2022-08-13 11:33:44,400] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:33:45,069] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:33:45,081] {logging_mixin.py:109} INFO - [2022-08-13 11:33:45,080] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:33:45,096] {logging_mixin.py:109} INFO - [2022-08-13 11:33:45,096] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:33:45,109] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.718 seconds
[2022-08-13 11:34:15,266] {processor.py:163} INFO - Started process (PID=35669) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:34:15,269] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:34:15,271] {logging_mixin.py:109} INFO - [2022-08-13 11:34:15,271] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:34:15,926] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:34:15,937] {logging_mixin.py:109} INFO - [2022-08-13 11:34:15,936] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:34:15,954] {logging_mixin.py:109} INFO - [2022-08-13 11:34:15,954] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:34:15,968] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.707 seconds
[2022-08-13 11:34:46,852] {processor.py:163} INFO - Started process (PID=35744) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:34:46,856] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:34:46,858] {logging_mixin.py:109} INFO - [2022-08-13 11:34:46,858] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:34:47,464] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:34:47,476] {logging_mixin.py:109} INFO - [2022-08-13 11:34:47,475] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:34:47,494] {logging_mixin.py:109} INFO - [2022-08-13 11:34:47,494] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:34:47,506] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.658 seconds
[2022-08-13 11:35:18,044] {processor.py:163} INFO - Started process (PID=35809) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:35:18,047] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:35:18,049] {logging_mixin.py:109} INFO - [2022-08-13 11:35:18,049] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:35:18,637] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:35:18,648] {logging_mixin.py:109} INFO - [2022-08-13 11:35:18,647] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:35:18,666] {logging_mixin.py:109} INFO - [2022-08-13 11:35:18,666] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:35:18,677] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.641 seconds
[2022-08-13 11:35:49,637] {processor.py:163} INFO - Started process (PID=35887) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:35:49,641] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:35:49,643] {logging_mixin.py:109} INFO - [2022-08-13 11:35:49,643] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:35:50,298] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:35:50,311] {logging_mixin.py:109} INFO - [2022-08-13 11:35:50,311] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:35:50,329] {logging_mixin.py:109} INFO - [2022-08-13 11:35:50,329] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:35:50,343] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.712 seconds
[2022-08-13 11:36:20,428] {processor.py:163} INFO - Started process (PID=35953) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:36:20,431] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:36:20,433] {logging_mixin.py:109} INFO - [2022-08-13 11:36:20,433] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:36:21,026] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:36:21,041] {logging_mixin.py:109} INFO - [2022-08-13 11:36:21,040] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:36:21,055] {logging_mixin.py:109} INFO - [2022-08-13 11:36:21,055] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:36:21,065] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.640 seconds
[2022-08-13 11:36:51,726] {processor.py:163} INFO - Started process (PID=36019) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:36:51,729] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:36:51,732] {logging_mixin.py:109} INFO - [2022-08-13 11:36:51,732] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:36:52,322] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:36:52,333] {logging_mixin.py:109} INFO - [2022-08-13 11:36:52,333] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:36:52,351] {logging_mixin.py:109} INFO - [2022-08-13 11:36:52,351] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:36:52,367] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.648 seconds
[2022-08-13 11:37:23,149] {processor.py:163} INFO - Started process (PID=36095) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:37:23,151] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:37:23,153] {logging_mixin.py:109} INFO - [2022-08-13 11:37:23,153] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:37:23,704] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:37:23,719] {logging_mixin.py:109} INFO - [2022-08-13 11:37:23,719] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:37:23,742] {logging_mixin.py:109} INFO - [2022-08-13 11:37:23,742] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:37:23,754] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.610 seconds
[2022-08-13 11:37:53,815] {processor.py:163} INFO - Started process (PID=36160) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:37:53,818] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:37:53,820] {logging_mixin.py:109} INFO - [2022-08-13 11:37:53,819] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:37:54,420] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:37:54,433] {logging_mixin.py:109} INFO - [2022-08-13 11:37:54,432] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:37:54,449] {logging_mixin.py:109} INFO - [2022-08-13 11:37:54,449] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:37:54,464] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.655 seconds
[2022-08-13 11:38:25,088] {processor.py:163} INFO - Started process (PID=36226) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:38:25,092] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:38:25,093] {logging_mixin.py:109} INFO - [2022-08-13 11:38:25,093] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:38:25,645] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:38:25,655] {logging_mixin.py:109} INFO - [2022-08-13 11:38:25,654] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:38:25,671] {logging_mixin.py:109} INFO - [2022-08-13 11:38:25,671] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:38:25,684] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.602 seconds
[2022-08-13 11:38:55,883] {processor.py:163} INFO - Started process (PID=36300) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:38:55,885] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:38:55,887] {logging_mixin.py:109} INFO - [2022-08-13 11:38:55,887] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:38:56,501] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:38:56,513] {logging_mixin.py:109} INFO - [2022-08-13 11:38:56,512] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:38:56,528] {logging_mixin.py:109} INFO - [2022-08-13 11:38:56,528] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:38:56,542] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.666 seconds
[2022-08-13 11:39:27,052] {processor.py:163} INFO - Started process (PID=36365) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:39:27,057] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:39:27,058] {logging_mixin.py:109} INFO - [2022-08-13 11:39:27,058] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:39:27,663] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:39:27,674] {logging_mixin.py:109} INFO - [2022-08-13 11:39:27,674] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:39:27,692] {logging_mixin.py:109} INFO - [2022-08-13 11:39:27,692] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:39:27,702] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.653 seconds
[2022-08-13 11:39:58,259] {processor.py:163} INFO - Started process (PID=36440) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:39:58,263] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:39:58,265] {logging_mixin.py:109} INFO - [2022-08-13 11:39:58,265] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:39:58,869] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:39:58,882] {logging_mixin.py:109} INFO - [2022-08-13 11:39:58,881] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:39:58,899] {logging_mixin.py:109} INFO - [2022-08-13 11:39:58,899] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:39:58,910] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.657 seconds
[2022-08-13 11:40:29,503] {processor.py:163} INFO - Started process (PID=36505) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:40:29,507] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:40:29,509] {logging_mixin.py:109} INFO - [2022-08-13 11:40:29,509] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:40:30,060] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:40:30,070] {logging_mixin.py:109} INFO - [2022-08-13 11:40:30,070] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:40:30,087] {logging_mixin.py:109} INFO - [2022-08-13 11:40:30,087] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:40:30,099] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.600 seconds
[2022-08-13 11:41:00,405] {processor.py:163} INFO - Started process (PID=36570) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:41:00,409] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:41:00,411] {logging_mixin.py:109} INFO - [2022-08-13 11:41:00,411] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:41:00,952] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:41:00,965] {logging_mixin.py:109} INFO - [2022-08-13 11:41:00,965] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:41:00,984] {logging_mixin.py:109} INFO - [2022-08-13 11:41:00,984] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:41:00,994] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.594 seconds
[2022-08-13 11:41:31,180] {processor.py:163} INFO - Started process (PID=36644) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:41:31,183] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:41:31,184] {logging_mixin.py:109} INFO - [2022-08-13 11:41:31,184] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:41:31,837] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:41:31,851] {logging_mixin.py:109} INFO - [2022-08-13 11:41:31,850] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:41:31,870] {logging_mixin.py:109} INFO - [2022-08-13 11:41:31,870] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:41:31,883] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.709 seconds
[2022-08-13 11:42:02,498] {processor.py:163} INFO - Started process (PID=36710) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:42:02,500] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:42:02,502] {logging_mixin.py:109} INFO - [2022-08-13 11:42:02,502] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:42:03,048] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:42:03,059] {logging_mixin.py:109} INFO - [2022-08-13 11:42:03,058] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:42:03,076] {logging_mixin.py:109} INFO - [2022-08-13 11:42:03,076] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:42:03,087] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.593 seconds
[2022-08-13 11:42:33,337] {processor.py:163} INFO - Started process (PID=36775) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:42:33,341] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:42:33,343] {logging_mixin.py:109} INFO - [2022-08-13 11:42:33,343] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:42:33,886] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:42:33,899] {logging_mixin.py:109} INFO - [2022-08-13 11:42:33,899] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:42:33,916] {logging_mixin.py:109} INFO - [2022-08-13 11:42:33,915] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:42:33,926] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.594 seconds
[2022-08-13 11:43:04,130] {processor.py:163} INFO - Started process (PID=36849) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:43:04,133] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:43:04,135] {logging_mixin.py:109} INFO - [2022-08-13 11:43:04,135] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:43:04,764] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:43:04,777] {logging_mixin.py:109} INFO - [2022-08-13 11:43:04,776] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:43:04,797] {logging_mixin.py:109} INFO - [2022-08-13 11:43:04,797] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:43:04,811] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.685 seconds
[2022-08-13 11:43:35,032] {processor.py:163} INFO - Started process (PID=36914) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:43:35,036] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:43:35,038] {logging_mixin.py:109} INFO - [2022-08-13 11:43:35,038] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:43:35,627] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:43:35,637] {logging_mixin.py:109} INFO - [2022-08-13 11:43:35,637] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:43:35,654] {logging_mixin.py:109} INFO - [2022-08-13 11:43:35,654] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:43:35,668] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.640 seconds
[2022-08-13 11:44:06,242] {processor.py:163} INFO - Started process (PID=36986) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:44:06,245] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:44:06,246] {logging_mixin.py:109} INFO - [2022-08-13 11:44:06,246] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:44:06,868] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:44:06,881] {logging_mixin.py:109} INFO - [2022-08-13 11:44:06,880] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:44:06,902] {logging_mixin.py:109} INFO - [2022-08-13 11:44:06,901] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:44:06,914] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.677 seconds
[2022-08-13 11:44:37,153] {processor.py:163} INFO - Started process (PID=37055) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:44:37,158] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:44:37,160] {logging_mixin.py:109} INFO - [2022-08-13 11:44:37,159] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:44:37,789] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:44:37,803] {logging_mixin.py:109} INFO - [2022-08-13 11:44:37,803] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:44:37,826] {logging_mixin.py:109} INFO - [2022-08-13 11:44:37,826] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:44:37,840] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.692 seconds
[2022-08-13 11:45:08,076] {processor.py:163} INFO - Started process (PID=37121) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:45:08,078] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:45:08,080] {logging_mixin.py:109} INFO - [2022-08-13 11:45:08,080] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:45:08,700] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:45:08,709] {logging_mixin.py:109} INFO - [2022-08-13 11:45:08,708] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:45:08,722] {logging_mixin.py:109} INFO - [2022-08-13 11:45:08,722] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:45:08,731] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.661 seconds
[2022-08-13 11:45:38,981] {processor.py:163} INFO - Started process (PID=37196) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:45:38,983] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:45:38,985] {logging_mixin.py:109} INFO - [2022-08-13 11:45:38,984] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:45:39,634] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:45:39,649] {logging_mixin.py:109} INFO - [2022-08-13 11:45:39,648] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:45:39,670] {logging_mixin.py:109} INFO - [2022-08-13 11:45:39,670] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:45:39,686] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.708 seconds
[2022-08-13 11:46:10,375] {processor.py:163} INFO - Started process (PID=37262) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:46:10,378] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:46:10,379] {logging_mixin.py:109} INFO - [2022-08-13 11:46:10,379] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:46:10,983] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:46:10,994] {logging_mixin.py:109} INFO - [2022-08-13 11:46:10,994] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:46:11,011] {logging_mixin.py:109} INFO - [2022-08-13 11:46:11,011] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:46:11,022] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.652 seconds
[2022-08-13 11:46:41,122] {processor.py:163} INFO - Started process (PID=37328) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:46:41,125] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:46:41,127] {logging_mixin.py:109} INFO - [2022-08-13 11:46:41,127] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:46:41,701] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:46:41,719] {logging_mixin.py:109} INFO - [2022-08-13 11:46:41,718] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:46:41,737] {logging_mixin.py:109} INFO - [2022-08-13 11:46:41,737] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:46:41,748] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.636 seconds
[2022-08-13 11:47:12,786] {processor.py:163} INFO - Started process (PID=37401) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:47:12,789] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:47:12,792] {logging_mixin.py:109} INFO - [2022-08-13 11:47:12,791] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:47:13,419] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:47:13,429] {logging_mixin.py:109} INFO - [2022-08-13 11:47:13,429] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:47:13,447] {logging_mixin.py:109} INFO - [2022-08-13 11:47:13,447] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:47:13,461] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.680 seconds
[2022-08-13 11:47:43,763] {processor.py:163} INFO - Started process (PID=37466) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:47:43,766] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:47:43,768] {logging_mixin.py:109} INFO - [2022-08-13 11:47:43,767] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:47:44,305] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:47:44,314] {logging_mixin.py:109} INFO - [2022-08-13 11:47:44,314] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:47:44,329] {logging_mixin.py:109} INFO - [2022-08-13 11:47:44,329] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:47:44,342] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.584 seconds
[2022-08-13 11:48:15,007] {processor.py:163} INFO - Started process (PID=37540) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:48:15,010] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:48:15,011] {logging_mixin.py:109} INFO - [2022-08-13 11:48:15,011] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:48:15,625] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:48:15,636] {logging_mixin.py:109} INFO - [2022-08-13 11:48:15,636] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:48:15,654] {logging_mixin.py:109} INFO - [2022-08-13 11:48:15,654] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:48:15,665] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.662 seconds
[2022-08-13 11:48:45,760] {processor.py:163} INFO - Started process (PID=37605) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:48:45,763] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:48:45,768] {logging_mixin.py:109} INFO - [2022-08-13 11:48:45,767] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:48:46,448] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:48:46,461] {logging_mixin.py:109} INFO - [2022-08-13 11:48:46,461] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:48:46,478] {logging_mixin.py:109} INFO - [2022-08-13 11:48:46,478] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:48:46,494] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.741 seconds
[2022-08-13 11:49:17,142] {processor.py:163} INFO - Started process (PID=37670) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:49:17,146] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:49:17,147] {logging_mixin.py:109} INFO - [2022-08-13 11:49:17,147] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:49:17,712] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:49:17,723] {logging_mixin.py:109} INFO - [2022-08-13 11:49:17,723] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:49:17,739] {logging_mixin.py:109} INFO - [2022-08-13 11:49:17,739] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:49:17,751] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.615 seconds
[2022-08-13 11:49:48,805] {processor.py:163} INFO - Started process (PID=37744) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:49:48,809] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:49:48,812] {logging_mixin.py:109} INFO - [2022-08-13 11:49:48,811] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:49:49,432] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:49:49,444] {logging_mixin.py:109} INFO - [2022-08-13 11:49:49,443] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:49:49,462] {logging_mixin.py:109} INFO - [2022-08-13 11:49:49,462] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:49:49,472] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.675 seconds
[2022-08-13 11:50:20,233] {processor.py:163} INFO - Started process (PID=37810) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:50:20,243] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:50:20,246] {logging_mixin.py:109} INFO - [2022-08-13 11:50:20,246] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:50:20,876] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:50:20,887] {logging_mixin.py:109} INFO - [2022-08-13 11:50:20,886] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:50:20,904] {logging_mixin.py:109} INFO - [2022-08-13 11:50:20,904] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:50:20,914] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.685 seconds
[2022-08-13 11:50:51,161] {processor.py:163} INFO - Started process (PID=37882) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:50:51,164] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:50:51,166] {logging_mixin.py:109} INFO - [2022-08-13 11:50:51,166] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:50:51,830] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:50:51,843] {logging_mixin.py:109} INFO - [2022-08-13 11:50:51,842] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:50:51,864] {logging_mixin.py:109} INFO - [2022-08-13 11:50:51,864] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:50:51,879] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.722 seconds
[2022-08-13 11:51:22,788] {processor.py:163} INFO - Started process (PID=37949) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:51:22,791] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:51:22,794] {logging_mixin.py:109} INFO - [2022-08-13 11:51:22,793] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:51:23,338] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:51:23,349] {logging_mixin.py:109} INFO - [2022-08-13 11:51:23,349] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:51:23,365] {logging_mixin.py:109} INFO - [2022-08-13 11:51:23,365] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:51:23,377] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.595 seconds
[2022-08-13 11:51:54,238] {processor.py:163} INFO - Started process (PID=38013) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:51:54,240] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:51:54,243] {logging_mixin.py:109} INFO - [2022-08-13 11:51:54,243] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:51:54,820] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:51:54,833] {logging_mixin.py:109} INFO - [2022-08-13 11:51:54,832] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:51:54,855] {logging_mixin.py:109} INFO - [2022-08-13 11:51:54,855] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:51:54,869] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.638 seconds
[2022-08-13 11:52:25,680] {processor.py:163} INFO - Started process (PID=38088) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:52:25,684] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:52:25,687] {logging_mixin.py:109} INFO - [2022-08-13 11:52:25,687] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:52:26,256] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:52:26,277] {logging_mixin.py:109} INFO - [2022-08-13 11:52:26,275] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:52:26,299] {logging_mixin.py:109} INFO - [2022-08-13 11:52:26,299] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:52:26,321] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.644 seconds
[2022-08-13 11:52:56,382] {processor.py:163} INFO - Started process (PID=38153) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:52:56,386] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:52:56,388] {logging_mixin.py:109} INFO - [2022-08-13 11:52:56,388] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:52:56,962] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:52:56,977] {logging_mixin.py:109} INFO - [2022-08-13 11:52:56,976] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:52:56,996] {logging_mixin.py:109} INFO - [2022-08-13 11:52:56,996] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:52:57,010] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.632 seconds
[2022-08-13 11:53:27,159] {processor.py:163} INFO - Started process (PID=38219) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:53:27,162] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:53:27,163] {logging_mixin.py:109} INFO - [2022-08-13 11:53:27,163] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:53:27,717] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:53:27,729] {logging_mixin.py:109} INFO - [2022-08-13 11:53:27,728] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:53:27,744] {logging_mixin.py:109} INFO - [2022-08-13 11:53:27,744] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:53:27,756] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.602 seconds
[2022-08-13 11:53:57,898] {processor.py:163} INFO - Started process (PID=38293) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:53:57,901] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:53:57,904] {logging_mixin.py:109} INFO - [2022-08-13 11:53:57,903] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:53:58,491] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:53:58,503] {logging_mixin.py:109} INFO - [2022-08-13 11:53:58,503] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:53:58,521] {logging_mixin.py:109} INFO - [2022-08-13 11:53:58,520] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:53:58,531] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.637 seconds
[2022-08-13 11:54:29,257] {processor.py:163} INFO - Started process (PID=38359) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:54:29,260] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:54:29,262] {logging_mixin.py:109} INFO - [2022-08-13 11:54:29,262] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:54:29,830] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:54:29,841] {logging_mixin.py:109} INFO - [2022-08-13 11:54:29,841] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:54:29,859] {logging_mixin.py:109} INFO - [2022-08-13 11:54:29,859] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:54:29,871] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.620 seconds
[2022-08-13 11:55:00,856] {processor.py:163} INFO - Started process (PID=38434) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:55:00,859] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:55:00,861] {logging_mixin.py:109} INFO - [2022-08-13 11:55:00,860] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:55:01,500] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:55:01,515] {logging_mixin.py:109} INFO - [2022-08-13 11:55:01,515] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:55:01,538] {logging_mixin.py:109} INFO - [2022-08-13 11:55:01,537] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:55:01,550] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.701 seconds
[2022-08-13 11:55:32,445] {processor.py:163} INFO - Started process (PID=38500) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:55:32,448] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:55:32,451] {logging_mixin.py:109} INFO - [2022-08-13 11:55:32,451] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:55:33,057] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:55:33,072] {logging_mixin.py:109} INFO - [2022-08-13 11:55:33,072] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:55:33,093] {logging_mixin.py:109} INFO - [2022-08-13 11:55:33,092] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:55:33,104] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.664 seconds
[2022-08-13 11:56:03,508] {processor.py:163} INFO - Started process (PID=38565) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:56:03,512] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:56:03,513] {logging_mixin.py:109} INFO - [2022-08-13 11:56:03,513] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:56:04,116] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:56:04,126] {logging_mixin.py:109} INFO - [2022-08-13 11:56:04,126] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:56:04,145] {logging_mixin.py:109} INFO - [2022-08-13 11:56:04,145] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:56:04,159] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.678 seconds
[2022-08-13 11:56:34,352] {processor.py:163} INFO - Started process (PID=38640) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:56:34,355] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:56:34,357] {logging_mixin.py:109} INFO - [2022-08-13 11:56:34,357] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:56:35,034] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:56:35,047] {logging_mixin.py:109} INFO - [2022-08-13 11:56:35,047] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:56:35,062] {logging_mixin.py:109} INFO - [2022-08-13 11:56:35,062] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:56:35,074] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.726 seconds
[2022-08-13 11:57:05,810] {processor.py:163} INFO - Started process (PID=38707) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:57:05,813] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:57:05,815] {logging_mixin.py:109} INFO - [2022-08-13 11:57:05,815] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:57:06,391] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:57:06,404] {logging_mixin.py:109} INFO - [2022-08-13 11:57:06,403] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:57:06,419] {logging_mixin.py:109} INFO - [2022-08-13 11:57:06,419] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:57:06,430] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.625 seconds
[2022-08-13 11:57:36,971] {processor.py:163} INFO - Started process (PID=38772) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:57:36,973] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:57:36,974] {logging_mixin.py:109} INFO - [2022-08-13 11:57:36,974] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:57:37,594] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:57:37,606] {logging_mixin.py:109} INFO - [2022-08-13 11:57:37,606] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:57:37,624] {logging_mixin.py:109} INFO - [2022-08-13 11:57:37,624] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:57:37,638] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.671 seconds
[2022-08-13 11:58:08,305] {processor.py:163} INFO - Started process (PID=38849) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:58:08,307] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:58:08,308] {logging_mixin.py:109} INFO - [2022-08-13 11:58:08,308] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:58:08,878] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:58:08,892] {logging_mixin.py:109} INFO - [2022-08-13 11:58:08,892] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:58:08,910] {logging_mixin.py:109} INFO - [2022-08-13 11:58:08,910] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:58:08,924] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.624 seconds
[2022-08-13 11:58:39,820] {processor.py:163} INFO - Started process (PID=38915) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:58:39,823] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:58:39,825] {logging_mixin.py:109} INFO - [2022-08-13 11:58:39,825] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:58:40,375] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:58:40,387] {logging_mixin.py:109} INFO - [2022-08-13 11:58:40,386] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:58:40,403] {logging_mixin.py:109} INFO - [2022-08-13 11:58:40,402] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:58:40,413] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.599 seconds
[2022-08-13 11:59:11,212] {processor.py:163} INFO - Started process (PID=38990) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:59:11,215] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:59:11,217] {logging_mixin.py:109} INFO - [2022-08-13 11:59:11,216] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:59:11,827] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:59:11,842] {logging_mixin.py:109} INFO - [2022-08-13 11:59:11,841] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:59:11,860] {logging_mixin.py:109} INFO - [2022-08-13 11:59:11,860] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:59:11,873] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.665 seconds
[2022-08-13 11:59:42,876] {processor.py:163} INFO - Started process (PID=39056) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:59:42,878] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 11:59:42,880] {logging_mixin.py:109} INFO - [2022-08-13 11:59:42,880] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:59:43,418] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 11:59:43,429] {logging_mixin.py:109} INFO - [2022-08-13 11:59:43,429] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 11:59:43,445] {logging_mixin.py:109} INFO - [2022-08-13 11:59:43,445] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 11:59:43,454] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.582 seconds
[2022-08-13 12:00:13,927] {processor.py:163} INFO - Started process (PID=39121) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:00:13,930] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:00:13,932] {logging_mixin.py:109} INFO - [2022-08-13 12:00:13,932] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:00:14,528] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:00:14,540] {logging_mixin.py:109} INFO - [2022-08-13 12:00:14,539] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:00:14,557] {logging_mixin.py:109} INFO - [2022-08-13 12:00:14,557] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:00:14,568] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.647 seconds
[2022-08-13 12:00:45,177] {processor.py:163} INFO - Started process (PID=39195) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:00:45,179] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:00:45,184] {logging_mixin.py:109} INFO - [2022-08-13 12:00:45,183] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:00:45,876] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:00:45,893] {logging_mixin.py:109} INFO - [2022-08-13 12:00:45,892] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:00:45,918] {logging_mixin.py:109} INFO - [2022-08-13 12:00:45,918] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:00:45,939] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.767 seconds
[2022-08-13 12:01:16,346] {processor.py:163} INFO - Started process (PID=39265) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:01:16,356] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:01:16,358] {logging_mixin.py:109} INFO - [2022-08-13 12:01:16,357] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:01:16,979] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:01:16,994] {logging_mixin.py:109} INFO - [2022-08-13 12:01:16,993] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:01:17,018] {logging_mixin.py:109} INFO - [2022-08-13 12:01:17,018] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:01:17,032] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.691 seconds
[2022-08-13 12:01:47,178] {processor.py:163} INFO - Started process (PID=39340) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:01:47,184] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:01:47,187] {logging_mixin.py:109} INFO - [2022-08-13 12:01:47,186] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:01:47,896] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:01:47,909] {logging_mixin.py:109} INFO - [2022-08-13 12:01:47,908] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:01:47,927] {logging_mixin.py:109} INFO - [2022-08-13 12:01:47,927] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:01:47,945] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.773 seconds
[2022-08-13 12:02:18,043] {processor.py:163} INFO - Started process (PID=39407) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:02:18,048] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:02:18,050] {logging_mixin.py:109} INFO - [2022-08-13 12:02:18,050] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:02:18,681] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:02:18,694] {logging_mixin.py:109} INFO - [2022-08-13 12:02:18,694] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:02:18,712] {logging_mixin.py:109} INFO - [2022-08-13 12:02:18,712] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:02:18,724] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.685 seconds
[2022-08-13 12:02:48,855] {processor.py:163} INFO - Started process (PID=39473) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:02:48,857] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:02:48,858] {logging_mixin.py:109} INFO - [2022-08-13 12:02:48,858] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:02:49,508] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:02:49,521] {logging_mixin.py:109} INFO - [2022-08-13 12:02:49,520] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:02:49,541] {logging_mixin.py:109} INFO - [2022-08-13 12:02:49,541] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:02:49,554] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.704 seconds
[2022-08-13 12:03:19,623] {processor.py:163} INFO - Started process (PID=39552) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:03:19,626] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:03:19,627] {logging_mixin.py:109} INFO - [2022-08-13 12:03:19,627] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:03:20,473] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:03:20,492] {logging_mixin.py:109} INFO - [2022-08-13 12:03:20,492] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:03:20,512] {logging_mixin.py:109} INFO - [2022-08-13 12:03:20,512] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:03:20,526] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.909 seconds
[2022-08-13 12:03:50,691] {processor.py:163} INFO - Started process (PID=39617) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:03:50,697] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:03:50,700] {logging_mixin.py:109} INFO - [2022-08-13 12:03:50,699] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:03:51,426] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:03:51,441] {logging_mixin.py:109} INFO - [2022-08-13 12:03:51,440] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:03:51,460] {logging_mixin.py:109} INFO - [2022-08-13 12:03:51,460] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:03:51,472] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.788 seconds
[2022-08-13 12:04:21,584] {processor.py:163} INFO - Started process (PID=39686) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:04:21,587] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:04:21,590] {logging_mixin.py:109} INFO - [2022-08-13 12:04:21,590] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:04:22,161] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:04:22,173] {logging_mixin.py:109} INFO - [2022-08-13 12:04:22,173] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:04:22,194] {logging_mixin.py:109} INFO - [2022-08-13 12:04:22,194] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:04:22,208] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.632 seconds
[2022-08-13 12:04:52,415] {processor.py:163} INFO - Started process (PID=39757) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:04:52,417] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:04:52,419] {logging_mixin.py:109} INFO - [2022-08-13 12:04:52,419] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:04:53,123] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:04:53,134] {logging_mixin.py:109} INFO - [2022-08-13 12:04:53,134] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:04:53,155] {logging_mixin.py:109} INFO - [2022-08-13 12:04:53,155] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:04:53,167] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.757 seconds
[2022-08-13 12:05:23,246] {processor.py:163} INFO - Started process (PID=39822) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:05:23,250] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:05:23,253] {logging_mixin.py:109} INFO - [2022-08-13 12:05:23,252] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:05:23,881] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:05:23,895] {logging_mixin.py:109} INFO - [2022-08-13 12:05:23,894] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:05:23,917] {logging_mixin.py:109} INFO - [2022-08-13 12:05:23,917] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:05:23,931] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.692 seconds
[2022-08-13 12:05:54,250] {processor.py:163} INFO - Started process (PID=39887) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:05:54,253] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:05:54,255] {logging_mixin.py:109} INFO - [2022-08-13 12:05:54,255] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:05:54,911] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:05:54,924] {logging_mixin.py:109} INFO - [2022-08-13 12:05:54,923] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:05:54,941] {logging_mixin.py:109} INFO - [2022-08-13 12:05:54,941] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:05:54,956] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.710 seconds
[2022-08-13 12:06:25,065] {processor.py:163} INFO - Started process (PID=39963) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:06:25,068] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:06:25,071] {logging_mixin.py:109} INFO - [2022-08-13 12:06:25,071] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:06:25,767] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:06:25,777] {logging_mixin.py:109} INFO - [2022-08-13 12:06:25,777] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:06:25,806] {logging_mixin.py:109} INFO - [2022-08-13 12:06:25,806] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:06:25,821] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.763 seconds
[2022-08-13 12:06:56,066] {processor.py:163} INFO - Started process (PID=40029) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:06:56,068] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:06:56,070] {logging_mixin.py:109} INFO - [2022-08-13 12:06:56,070] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:06:56,822] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:06:56,838] {logging_mixin.py:109} INFO - [2022-08-13 12:06:56,838] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:06:56,869] {logging_mixin.py:109} INFO - [2022-08-13 12:06:56,868] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:06:56,882] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.822 seconds
[2022-08-13 12:07:26,958] {processor.py:163} INFO - Started process (PID=40097) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:07:26,960] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:07:26,963] {logging_mixin.py:109} INFO - [2022-08-13 12:07:26,963] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:07:27,597] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:07:27,610] {logging_mixin.py:109} INFO - [2022-08-13 12:07:27,610] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:07:27,631] {logging_mixin.py:109} INFO - [2022-08-13 12:07:27,630] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:07:27,644] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.690 seconds
[2022-08-13 12:07:57,860] {processor.py:163} INFO - Started process (PID=40172) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:07:57,864] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:07:57,867] {logging_mixin.py:109} INFO - [2022-08-13 12:07:57,867] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:07:58,631] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:07:58,654] {logging_mixin.py:109} INFO - [2022-08-13 12:07:58,654] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:07:58,674] {logging_mixin.py:109} INFO - [2022-08-13 12:07:58,674] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:07:58,690] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.838 seconds
[2022-08-13 12:08:28,903] {processor.py:163} INFO - Started process (PID=40240) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:08:28,906] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:08:28,907] {logging_mixin.py:109} INFO - [2022-08-13 12:08:28,907] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:08:29,582] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:08:29,593] {logging_mixin.py:109} INFO - [2022-08-13 12:08:29,593] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:08:29,610] {logging_mixin.py:109} INFO - [2022-08-13 12:08:29,610] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:08:29,623] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.727 seconds
[2022-08-13 12:09:00,566] {processor.py:163} INFO - Started process (PID=40310) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:09:00,569] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:09:00,571] {logging_mixin.py:109} INFO - [2022-08-13 12:09:00,570] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:09:01,295] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:09:01,310] {logging_mixin.py:109} INFO - [2022-08-13 12:09:01,309] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:09:01,323] {logging_mixin.py:109} INFO - [2022-08-13 12:09:01,323] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:09:01,333] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.771 seconds
[2022-08-13 12:09:32,161] {processor.py:163} INFO - Started process (PID=40385) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:09:32,166] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:09:32,167] {logging_mixin.py:109} INFO - [2022-08-13 12:09:32,167] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:09:32,789] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:09:32,806] {logging_mixin.py:109} INFO - [2022-08-13 12:09:32,805] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:09:32,827] {logging_mixin.py:109} INFO - [2022-08-13 12:09:32,827] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:09:32,850] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.693 seconds
[2022-08-13 12:10:03,438] {processor.py:163} INFO - Started process (PID=40449) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:10:03,441] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:10:03,442] {logging_mixin.py:109} INFO - [2022-08-13 12:10:03,442] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:10:04,252] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:10:04,266] {logging_mixin.py:109} INFO - [2022-08-13 12:10:04,265] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:10:04,285] {logging_mixin.py:109} INFO - [2022-08-13 12:10:04,284] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:10:04,300] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.865 seconds
[2022-08-13 12:10:35,228] {processor.py:163} INFO - Started process (PID=40523) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:10:35,231] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:10:35,234] {logging_mixin.py:109} INFO - [2022-08-13 12:10:35,234] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:10:35,905] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:10:35,920] {logging_mixin.py:109} INFO - [2022-08-13 12:10:35,919] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:10:35,951] {logging_mixin.py:109} INFO - [2022-08-13 12:10:35,951] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:10:35,965] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.743 seconds
[2022-08-13 12:11:10,857] {processor.py:163} INFO - Started process (PID=40553) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:11:10,861] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 12:11:10,867] {logging_mixin.py:109} INFO - [2022-08-13 12:11:10,867] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:11:11,932] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 12:11:11,949] {logging_mixin.py:109} INFO - [2022-08-13 12:11:11,948] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 12:11:11,977] {logging_mixin.py:109} INFO - [2022-08-13 12:11:11,977] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 12:11:11,989] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.145 seconds
[2022-08-13 14:11:21,409] {processor.py:163} INFO - Started process (PID=40598) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 14:11:21,417] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 14:11:21,428] {logging_mixin.py:109} INFO - [2022-08-13 14:11:21,426] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 14:11:24,296] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 14:11:24,330] {logging_mixin.py:109} INFO - [2022-08-13 14:11:24,329] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 14:11:24,393] {logging_mixin.py:109} INFO - [2022-08-13 14:11:24,393] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 14:11:24,428] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 3.043 seconds
[2022-08-13 16:11:30,079] {processor.py:163} INFO - Started process (PID=40642) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 16:11:30,092] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 16:11:30,101] {logging_mixin.py:109} INFO - [2022-08-13 16:11:30,099] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 16:11:31,825] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 16:11:31,853] {logging_mixin.py:109} INFO - [2022-08-13 16:11:31,853] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 16:11:31,902] {logging_mixin.py:109} INFO - [2022-08-13 16:11:31,902] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 16:11:31,942] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.880 seconds
[2022-08-13 17:12:24,368] {processor.py:163} INFO - Started process (PID=40695) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:12:24,385] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:12:24,496] {logging_mixin.py:109} INFO - [2022-08-13 17:12:24,442] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:12:27,223] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:12:27,241] {logging_mixin.py:109} INFO - [2022-08-13 17:12:27,240] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:12:27,264] {logging_mixin.py:109} INFO - [2022-08-13 17:12:27,264] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:12:27,298] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 3.033 seconds
[2022-08-13 17:12:58,194] {processor.py:163} INFO - Started process (PID=40760) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:12:58,196] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:12:58,198] {logging_mixin.py:109} INFO - [2022-08-13 17:12:58,198] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:12:58,746] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:12:58,759] {logging_mixin.py:109} INFO - [2022-08-13 17:12:58,758] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:12:58,784] {logging_mixin.py:109} INFO - [2022-08-13 17:12:58,784] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:12:58,794] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.604 seconds
[2022-08-13 17:13:28,895] {processor.py:163} INFO - Started process (PID=40831) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:13:28,899] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:13:28,901] {logging_mixin.py:109} INFO - [2022-08-13 17:13:28,901] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:13:29,387] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:13:29,395] {logging_mixin.py:109} INFO - [2022-08-13 17:13:29,394] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:13:29,407] {logging_mixin.py:109} INFO - [2022-08-13 17:13:29,407] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:13:29,417] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.527 seconds
[2022-08-13 17:13:59,680] {processor.py:163} INFO - Started process (PID=40898) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:13:59,685] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:13:59,687] {logging_mixin.py:109} INFO - [2022-08-13 17:13:59,686] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:14:00,322] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:14:00,331] {logging_mixin.py:109} INFO - [2022-08-13 17:14:00,330] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:14:00,345] {logging_mixin.py:109} INFO - [2022-08-13 17:14:00,345] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:14:00,356] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.685 seconds
[2022-08-13 17:14:30,449] {processor.py:163} INFO - Started process (PID=40971) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:14:30,453] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:14:30,455] {logging_mixin.py:109} INFO - [2022-08-13 17:14:30,455] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:14:30,971] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:14:30,980] {logging_mixin.py:109} INFO - [2022-08-13 17:14:30,980] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:14:30,994] {logging_mixin.py:109} INFO - [2022-08-13 17:14:30,994] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:14:31,012] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.566 seconds
[2022-08-13 17:15:01,403] {processor.py:163} INFO - Started process (PID=41031) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:15:01,406] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:15:01,408] {logging_mixin.py:109} INFO - [2022-08-13 17:15:01,408] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:15:02,017] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:15:02,040] {logging_mixin.py:109} INFO - [2022-08-13 17:15:02,039] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:15:02,054] {logging_mixin.py:109} INFO - [2022-08-13 17:15:02,054] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:15:02,071] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.675 seconds
[2022-08-13 17:15:32,746] {processor.py:163} INFO - Started process (PID=41106) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:15:32,749] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:15:32,751] {logging_mixin.py:109} INFO - [2022-08-13 17:15:32,751] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:15:33,462] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:15:33,473] {logging_mixin.py:109} INFO - [2022-08-13 17:15:33,472] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:15:33,489] {logging_mixin.py:109} INFO - [2022-08-13 17:15:33,489] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:15:33,500] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.758 seconds
[2022-08-13 17:16:03,620] {processor.py:163} INFO - Started process (PID=41177) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:16:03,623] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:16:03,624] {logging_mixin.py:109} INFO - [2022-08-13 17:16:03,624] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:16:04,142] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:16:04,155] {logging_mixin.py:109} INFO - [2022-08-13 17:16:04,154] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:16:04,179] {logging_mixin.py:109} INFO - [2022-08-13 17:16:04,179] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:16:04,196] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.579 seconds
[2022-08-13 17:16:34,675] {processor.py:163} INFO - Started process (PID=41255) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:16:34,678] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:16:34,680] {logging_mixin.py:109} INFO - [2022-08-13 17:16:34,680] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:16:35,361] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:16:35,374] {logging_mixin.py:109} INFO - [2022-08-13 17:16:35,373] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:16:35,405] {logging_mixin.py:109} INFO - [2022-08-13 17:16:35,405] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:16:35,418] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.750 seconds
[2022-08-13 17:17:06,206] {processor.py:163} INFO - Started process (PID=41323) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:17:06,239] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:17:06,241] {logging_mixin.py:109} INFO - [2022-08-13 17:17:06,241] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:17:06,823] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:17:06,833] {logging_mixin.py:109} INFO - [2022-08-13 17:17:06,833] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:17:06,848] {logging_mixin.py:109} INFO - [2022-08-13 17:17:06,848] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:17:06,860] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.665 seconds
[2022-08-13 17:17:37,236] {processor.py:163} INFO - Started process (PID=41396) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:17:37,242] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:17:37,246] {logging_mixin.py:109} INFO - [2022-08-13 17:17:37,245] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:17:37,988] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:17:38,010] {logging_mixin.py:109} INFO - [2022-08-13 17:17:38,009] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:17:38,036] {logging_mixin.py:109} INFO - [2022-08-13 17:17:38,036] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:17:38,048] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.827 seconds
[2022-08-13 17:18:08,920] {processor.py:163} INFO - Started process (PID=41465) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:18:08,923] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:18:08,924] {logging_mixin.py:109} INFO - [2022-08-13 17:18:08,924] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:18:09,560] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:18:09,571] {logging_mixin.py:109} INFO - [2022-08-13 17:18:09,570] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:18:09,588] {logging_mixin.py:109} INFO - [2022-08-13 17:18:09,588] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:18:09,600] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.685 seconds
[2022-08-13 17:18:39,825] {processor.py:163} INFO - Started process (PID=41534) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:18:39,858] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:18:39,866] {logging_mixin.py:109} INFO - [2022-08-13 17:18:39,866] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:18:40,495] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:18:40,513] {logging_mixin.py:109} INFO - [2022-08-13 17:18:40,512] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:18:40,529] {logging_mixin.py:109} INFO - [2022-08-13 17:18:40,529] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:18:40,543] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.723 seconds
[2022-08-13 17:19:11,323] {processor.py:163} INFO - Started process (PID=41611) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:19:11,336] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:19:11,338] {logging_mixin.py:109} INFO - [2022-08-13 17:19:11,338] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:19:12,011] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:19:12,024] {logging_mixin.py:109} INFO - [2022-08-13 17:19:12,023] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:19:12,057] {logging_mixin.py:109} INFO - [2022-08-13 17:19:12,056] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:19:12,075] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.757 seconds
[2022-08-13 17:19:42,449] {processor.py:163} INFO - Started process (PID=41676) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:19:42,451] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:19:42,452] {logging_mixin.py:109} INFO - [2022-08-13 17:19:42,452] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:19:43,002] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:19:43,015] {logging_mixin.py:109} INFO - [2022-08-13 17:19:43,014] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:19:43,038] {logging_mixin.py:109} INFO - [2022-08-13 17:19:43,038] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:19:43,054] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.609 seconds
[2022-08-13 17:20:13,233] {processor.py:163} INFO - Started process (PID=41744) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:20:13,236] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:20:13,238] {logging_mixin.py:109} INFO - [2022-08-13 17:20:13,238] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:20:14,075] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:20:14,092] {logging_mixin.py:109} INFO - [2022-08-13 17:20:14,091] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:20:14,109] {logging_mixin.py:109} INFO - [2022-08-13 17:20:14,109] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:20:14,120] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.892 seconds
[2022-08-13 17:20:44,430] {processor.py:163} INFO - Started process (PID=41821) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:20:44,433] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:20:44,435] {logging_mixin.py:109} INFO - [2022-08-13 17:20:44,435] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:20:45,093] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:20:45,105] {logging_mixin.py:109} INFO - [2022-08-13 17:20:45,104] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:20:45,127] {logging_mixin.py:109} INFO - [2022-08-13 17:20:45,127] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:20:45,149] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.723 seconds
[2022-08-13 17:21:15,757] {processor.py:163} INFO - Started process (PID=41886) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:21:15,760] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:21:15,761] {logging_mixin.py:109} INFO - [2022-08-13 17:21:15,761] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:21:16,356] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:21:16,366] {logging_mixin.py:109} INFO - [2022-08-13 17:21:16,366] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:21:16,379] {logging_mixin.py:109} INFO - [2022-08-13 17:21:16,379] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:21:16,388] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.636 seconds
[2022-08-13 17:21:46,540] {processor.py:163} INFO - Started process (PID=41960) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:21:46,544] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:21:46,546] {logging_mixin.py:109} INFO - [2022-08-13 17:21:46,545] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:21:47,026] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:21:47,036] {logging_mixin.py:109} INFO - [2022-08-13 17:21:47,036] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:21:47,053] {logging_mixin.py:109} INFO - [2022-08-13 17:21:47,053] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:21:47,063] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.528 seconds
[2022-08-13 17:22:17,322] {processor.py:163} INFO - Started process (PID=42025) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:22:17,324] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:22:17,326] {logging_mixin.py:109} INFO - [2022-08-13 17:22:17,325] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:22:17,883] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:22:17,896] {logging_mixin.py:109} INFO - [2022-08-13 17:22:17,896] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:22:17,913] {logging_mixin.py:109} INFO - [2022-08-13 17:22:17,913] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:22:17,926] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.607 seconds
[2022-08-13 17:22:48,680] {processor.py:163} INFO - Started process (PID=42099) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:22:48,683] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:22:48,685] {logging_mixin.py:109} INFO - [2022-08-13 17:22:48,685] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:22:49,276] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:22:49,288] {logging_mixin.py:109} INFO - [2022-08-13 17:22:49,287] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:22:49,302] {logging_mixin.py:109} INFO - [2022-08-13 17:22:49,302] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:22:49,314] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.641 seconds
[2022-08-13 17:23:19,651] {processor.py:163} INFO - Started process (PID=42164) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:23:19,654] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:23:19,656] {logging_mixin.py:109} INFO - [2022-08-13 17:23:19,656] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:23:20,195] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:23:20,205] {logging_mixin.py:109} INFO - [2022-08-13 17:23:20,205] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:23:20,219] {logging_mixin.py:109} INFO - [2022-08-13 17:23:20,219] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:23:20,230] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.582 seconds
[2022-08-13 17:23:50,361] {processor.py:163} INFO - Started process (PID=42237) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:23:50,364] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:23:50,368] {logging_mixin.py:109} INFO - [2022-08-13 17:23:50,367] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:23:50,908] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:23:50,918] {logging_mixin.py:109} INFO - [2022-08-13 17:23:50,918] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:23:50,932] {logging_mixin.py:109} INFO - [2022-08-13 17:23:50,932] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:23:50,941] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.607 seconds
[2022-08-13 17:24:21,247] {processor.py:163} INFO - Started process (PID=42305) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:24:21,250] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:24:21,252] {logging_mixin.py:109} INFO - [2022-08-13 17:24:21,251] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:24:21,813] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:24:21,822] {logging_mixin.py:109} INFO - [2022-08-13 17:24:21,822] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:24:21,836] {logging_mixin.py:109} INFO - [2022-08-13 17:24:21,835] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:24:21,845] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.604 seconds
[2022-08-13 17:24:52,132] {processor.py:163} INFO - Started process (PID=42373) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:24:52,135] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:24:52,138] {logging_mixin.py:109} INFO - [2022-08-13 17:24:52,137] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:24:52,733] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:24:52,741] {logging_mixin.py:109} INFO - [2022-08-13 17:24:52,741] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:24:52,756] {logging_mixin.py:109} INFO - [2022-08-13 17:24:52,756] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:24:52,766] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.639 seconds
[2022-08-13 17:25:23,211] {processor.py:163} INFO - Started process (PID=42448) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:25:23,214] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:25:23,215] {logging_mixin.py:109} INFO - [2022-08-13 17:25:23,215] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:25:23,731] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:25:23,741] {logging_mixin.py:109} INFO - [2022-08-13 17:25:23,741] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:25:23,756] {logging_mixin.py:109} INFO - [2022-08-13 17:25:23,756] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:25:23,767] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.560 seconds
[2022-08-13 17:25:53,885] {processor.py:163} INFO - Started process (PID=42514) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:25:53,888] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:25:53,889] {logging_mixin.py:109} INFO - [2022-08-13 17:25:53,889] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:25:54,460] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:25:54,478] {logging_mixin.py:109} INFO - [2022-08-13 17:25:54,477] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:25:54,496] {logging_mixin.py:109} INFO - [2022-08-13 17:25:54,495] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:25:54,508] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.627 seconds
[2022-08-13 17:26:24,674] {processor.py:163} INFO - Started process (PID=42592) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:26:24,678] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:26:24,680] {logging_mixin.py:109} INFO - [2022-08-13 17:26:24,680] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:26:25,284] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:26:25,293] {logging_mixin.py:109} INFO - [2022-08-13 17:26:25,293] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:26:25,308] {logging_mixin.py:109} INFO - [2022-08-13 17:26:25,308] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:26:25,320] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.650 seconds
[2022-08-13 17:26:56,108] {processor.py:163} INFO - Started process (PID=42660) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:26:56,111] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:26:56,114] {logging_mixin.py:109} INFO - [2022-08-13 17:26:56,114] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:26:56,698] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:26:56,709] {logging_mixin.py:109} INFO - [2022-08-13 17:26:56,708] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:26:56,731] {logging_mixin.py:109} INFO - [2022-08-13 17:26:56,731] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:26:56,745] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.646 seconds
[2022-08-13 17:27:27,012] {processor.py:163} INFO - Started process (PID=42736) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:27:27,015] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:27:27,017] {logging_mixin.py:109} INFO - [2022-08-13 17:27:27,017] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:27:27,626] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:27:27,636] {logging_mixin.py:109} INFO - [2022-08-13 17:27:27,635] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:27:27,656] {logging_mixin.py:109} INFO - [2022-08-13 17:27:27,656] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:27:27,668] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.662 seconds
[2022-08-13 17:27:57,811] {processor.py:163} INFO - Started process (PID=42806) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:27:57,815] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:27:57,817] {logging_mixin.py:109} INFO - [2022-08-13 17:27:57,817] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:27:58,382] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:27:58,394] {logging_mixin.py:109} INFO - [2022-08-13 17:27:58,393] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:27:58,408] {logging_mixin.py:109} INFO - [2022-08-13 17:27:58,408] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:27:58,419] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.612 seconds
[2022-08-13 17:28:29,402] {processor.py:163} INFO - Started process (PID=42881) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:28:29,404] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:28:29,406] {logging_mixin.py:109} INFO - [2022-08-13 17:28:29,406] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:28:30,020] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:28:30,030] {logging_mixin.py:109} INFO - [2022-08-13 17:28:30,030] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:28:30,044] {logging_mixin.py:109} INFO - [2022-08-13 17:28:30,044] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:28:30,056] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.658 seconds
[2022-08-13 17:29:00,873] {processor.py:163} INFO - Started process (PID=42946) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:29:00,876] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:29:00,878] {logging_mixin.py:109} INFO - [2022-08-13 17:29:00,878] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:29:01,402] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:29:01,411] {logging_mixin.py:109} INFO - [2022-08-13 17:29:01,411] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:29:01,425] {logging_mixin.py:109} INFO - [2022-08-13 17:29:01,425] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:29:01,435] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.566 seconds
[2022-08-13 17:29:31,688] {processor.py:163} INFO - Started process (PID=43011) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:29:31,692] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:29:31,693] {logging_mixin.py:109} INFO - [2022-08-13 17:29:31,693] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:29:32,355] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:29:32,366] {logging_mixin.py:109} INFO - [2022-08-13 17:29:32,365] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:29:32,384] {logging_mixin.py:109} INFO - [2022-08-13 17:29:32,384] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:29:32,395] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.712 seconds
[2022-08-13 17:30:02,466] {processor.py:163} INFO - Started process (PID=43087) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:30:02,469] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:30:02,471] {logging_mixin.py:109} INFO - [2022-08-13 17:30:02,471] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:30:03,039] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:30:03,051] {logging_mixin.py:109} INFO - [2022-08-13 17:30:03,051] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:30:03,065] {logging_mixin.py:109} INFO - [2022-08-13 17:30:03,065] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:30:03,074] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.614 seconds
[2022-08-13 17:30:33,785] {processor.py:163} INFO - Started process (PID=43154) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:30:33,788] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:30:33,789] {logging_mixin.py:109} INFO - [2022-08-13 17:30:33,789] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:30:34,330] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:30:34,341] {logging_mixin.py:109} INFO - [2022-08-13 17:30:34,341] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:30:34,357] {logging_mixin.py:109} INFO - [2022-08-13 17:30:34,357] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:30:34,371] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.590 seconds
[2022-08-13 17:31:05,091] {processor.py:163} INFO - Started process (PID=43229) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:31:05,094] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:31:05,096] {logging_mixin.py:109} INFO - [2022-08-13 17:31:05,096] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:31:05,644] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:31:05,653] {logging_mixin.py:109} INFO - [2022-08-13 17:31:05,653] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:31:05,667] {logging_mixin.py:109} INFO - [2022-08-13 17:31:05,667] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:31:05,677] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.592 seconds
[2022-08-13 17:31:35,928] {processor.py:163} INFO - Started process (PID=43294) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:31:35,930] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:31:35,931] {logging_mixin.py:109} INFO - [2022-08-13 17:31:35,931] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:31:36,451] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:31:36,463] {logging_mixin.py:109} INFO - [2022-08-13 17:31:36,462] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:31:36,480] {logging_mixin.py:109} INFO - [2022-08-13 17:31:36,480] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:31:36,491] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.568 seconds
[2022-08-13 17:32:06,764] {processor.py:163} INFO - Started process (PID=43359) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:32:06,768] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:32:06,770] {logging_mixin.py:109} INFO - [2022-08-13 17:32:06,769] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:32:07,284] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:32:07,294] {logging_mixin.py:109} INFO - [2022-08-13 17:32:07,294] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:32:07,308] {logging_mixin.py:109} INFO - [2022-08-13 17:32:07,308] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:32:07,319] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.561 seconds
[2022-08-13 17:32:37,765] {processor.py:163} INFO - Started process (PID=43434) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:32:37,768] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:32:37,770] {logging_mixin.py:109} INFO - [2022-08-13 17:32:37,770] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:32:38,327] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:32:38,336] {logging_mixin.py:109} INFO - [2022-08-13 17:32:38,336] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:32:38,354] {logging_mixin.py:109} INFO - [2022-08-13 17:32:38,354] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:32:38,364] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.602 seconds
[2022-08-13 17:33:08,779] {processor.py:163} INFO - Started process (PID=43499) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:33:08,785] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:33:08,788] {logging_mixin.py:109} INFO - [2022-08-13 17:33:08,787] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:33:09,349] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:33:09,359] {logging_mixin.py:109} INFO - [2022-08-13 17:33:09,359] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:33:09,373] {logging_mixin.py:109} INFO - [2022-08-13 17:33:09,373] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:33:09,382] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.612 seconds
[2022-08-13 17:33:39,869] {processor.py:163} INFO - Started process (PID=43573) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:33:39,872] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:33:39,873] {logging_mixin.py:109} INFO - [2022-08-13 17:33:39,873] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:33:40,394] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:33:40,404] {logging_mixin.py:109} INFO - [2022-08-13 17:33:40,403] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:33:40,419] {logging_mixin.py:109} INFO - [2022-08-13 17:33:40,419] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:33:40,428] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.563 seconds
[2022-08-13 17:34:10,510] {processor.py:163} INFO - Started process (PID=43638) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:34:10,514] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:34:10,516] {logging_mixin.py:109} INFO - [2022-08-13 17:34:10,516] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:34:11,056] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:34:11,067] {logging_mixin.py:109} INFO - [2022-08-13 17:34:11,066] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:34:11,082] {logging_mixin.py:109} INFO - [2022-08-13 17:34:11,082] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:34:11,093] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.591 seconds
[2022-08-13 17:34:41,569] {processor.py:163} INFO - Started process (PID=43713) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:34:41,572] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:34:41,573] {logging_mixin.py:109} INFO - [2022-08-13 17:34:41,573] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:34:42,058] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:34:42,069] {logging_mixin.py:109} INFO - [2022-08-13 17:34:42,068] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:34:42,085] {logging_mixin.py:109} INFO - [2022-08-13 17:34:42,085] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:34:42,095] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.531 seconds
[2022-08-13 17:35:12,262] {processor.py:163} INFO - Started process (PID=43779) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:35:12,266] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:35:12,267] {logging_mixin.py:109} INFO - [2022-08-13 17:35:12,267] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:35:12,752] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:35:12,761] {logging_mixin.py:109} INFO - [2022-08-13 17:35:12,761] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:35:12,776] {logging_mixin.py:109} INFO - [2022-08-13 17:35:12,776] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:35:12,787] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.531 seconds
[2022-08-13 17:35:42,908] {processor.py:163} INFO - Started process (PID=43853) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:35:42,911] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:35:42,913] {logging_mixin.py:109} INFO - [2022-08-13 17:35:42,913] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:35:43,465] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:35:43,475] {logging_mixin.py:109} INFO - [2022-08-13 17:35:43,475] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:35:43,491] {logging_mixin.py:109} INFO - [2022-08-13 17:35:43,491] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:35:43,505] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.601 seconds
[2022-08-13 17:36:14,365] {processor.py:163} INFO - Started process (PID=43918) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:36:14,369] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:36:14,371] {logging_mixin.py:109} INFO - [2022-08-13 17:36:14,371] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:36:14,854] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:36:14,868] {logging_mixin.py:109} INFO - [2022-08-13 17:36:14,867] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:36:14,881] {logging_mixin.py:109} INFO - [2022-08-13 17:36:14,881] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:36:14,890] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.531 seconds
[2022-08-13 17:36:45,180] {processor.py:163} INFO - Started process (PID=43984) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:36:45,182] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:36:45,185] {logging_mixin.py:109} INFO - [2022-08-13 17:36:45,185] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:36:45,740] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:36:45,752] {logging_mixin.py:109} INFO - [2022-08-13 17:36:45,752] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:36:45,767] {logging_mixin.py:109} INFO - [2022-08-13 17:36:45,767] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:36:45,784] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.608 seconds
[2022-08-13 17:37:15,903] {processor.py:163} INFO - Started process (PID=44058) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:37:15,907] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:37:15,909] {logging_mixin.py:109} INFO - [2022-08-13 17:37:15,909] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:37:16,406] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:37:16,417] {logging_mixin.py:109} INFO - [2022-08-13 17:37:16,416] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:37:16,432] {logging_mixin.py:109} INFO - [2022-08-13 17:37:16,432] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:37:16,441] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.543 seconds
[2022-08-13 17:37:47,372] {processor.py:163} INFO - Started process (PID=44123) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:37:47,375] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:37:47,377] {logging_mixin.py:109} INFO - [2022-08-13 17:37:47,377] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:37:47,834] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:37:47,841] {logging_mixin.py:109} INFO - [2022-08-13 17:37:47,841] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:37:47,854] {logging_mixin.py:109} INFO - [2022-08-13 17:37:47,853] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:37:47,863] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.497 seconds
[2022-08-13 17:38:18,110] {processor.py:163} INFO - Started process (PID=44198) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:38:18,112] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:38:18,114] {logging_mixin.py:109} INFO - [2022-08-13 17:38:18,114] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:38:18,649] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:38:18,657] {logging_mixin.py:109} INFO - [2022-08-13 17:38:18,657] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:38:18,669] {logging_mixin.py:109} INFO - [2022-08-13 17:38:18,669] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:38:18,678] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.572 seconds
[2022-08-13 17:38:49,218] {processor.py:163} INFO - Started process (PID=44264) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:38:49,220] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:38:49,221] {logging_mixin.py:109} INFO - [2022-08-13 17:38:49,221] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:38:49,756] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:38:49,770] {logging_mixin.py:109} INFO - [2022-08-13 17:38:49,769] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:38:49,795] {logging_mixin.py:109} INFO - [2022-08-13 17:38:49,795] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:38:49,808] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.594 seconds
[2022-08-13 17:39:20,230] {processor.py:163} INFO - Started process (PID=44338) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:39:20,232] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:39:20,233] {logging_mixin.py:109} INFO - [2022-08-13 17:39:20,233] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:39:20,763] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:39:20,772] {logging_mixin.py:109} INFO - [2022-08-13 17:39:20,772] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:39:20,786] {logging_mixin.py:109} INFO - [2022-08-13 17:39:20,785] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:39:20,795] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.570 seconds
[2022-08-13 17:39:51,241] {processor.py:163} INFO - Started process (PID=44403) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:39:51,244] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:39:51,246] {logging_mixin.py:109} INFO - [2022-08-13 17:39:51,246] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:39:51,772] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:39:51,782] {logging_mixin.py:109} INFO - [2022-08-13 17:39:51,782] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:39:51,796] {logging_mixin.py:109} INFO - [2022-08-13 17:39:51,796] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:39:51,806] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.569 seconds
[2022-08-13 17:40:22,298] {processor.py:163} INFO - Started process (PID=44478) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:40:22,301] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:40:22,303] {logging_mixin.py:109} INFO - [2022-08-13 17:40:22,303] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:40:22,779] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:40:22,787] {logging_mixin.py:109} INFO - [2022-08-13 17:40:22,787] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:40:22,799] {logging_mixin.py:109} INFO - [2022-08-13 17:40:22,799] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:40:22,807] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.515 seconds
[2022-08-13 17:40:53,148] {processor.py:163} INFO - Started process (PID=44542) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:40:53,150] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:40:53,151] {logging_mixin.py:109} INFO - [2022-08-13 17:40:53,151] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:40:53,685] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:40:53,693] {logging_mixin.py:109} INFO - [2022-08-13 17:40:53,693] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:40:53,708] {logging_mixin.py:109} INFO - [2022-08-13 17:40:53,708] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:40:53,720] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.576 seconds
[2022-08-13 17:41:23,994] {processor.py:163} INFO - Started process (PID=44618) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:41:23,996] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:41:23,998] {logging_mixin.py:109} INFO - [2022-08-13 17:41:23,997] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:41:24,540] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:41:24,548] {logging_mixin.py:109} INFO - [2022-08-13 17:41:24,548] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:41:24,560] {logging_mixin.py:109} INFO - [2022-08-13 17:41:24,560] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:41:24,571] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.580 seconds
[2022-08-13 17:41:54,796] {processor.py:163} INFO - Started process (PID=44682) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:41:54,798] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:41:54,800] {logging_mixin.py:109} INFO - [2022-08-13 17:41:54,800] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:41:55,261] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:41:55,271] {logging_mixin.py:109} INFO - [2022-08-13 17:41:55,270] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:41:55,283] {logging_mixin.py:109} INFO - [2022-08-13 17:41:55,283] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:41:55,292] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.500 seconds
[2022-08-13 17:42:25,798] {processor.py:163} INFO - Started process (PID=44756) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:42:25,802] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:42:25,803] {logging_mixin.py:109} INFO - [2022-08-13 17:42:25,803] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:42:26,332] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:42:26,341] {logging_mixin.py:109} INFO - [2022-08-13 17:42:26,341] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:42:26,353] {logging_mixin.py:109} INFO - [2022-08-13 17:42:26,353] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:42:26,364] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.571 seconds
[2022-08-13 17:42:56,861] {processor.py:163} INFO - Started process (PID=44821) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:42:56,865] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:42:56,867] {logging_mixin.py:109} INFO - [2022-08-13 17:42:56,867] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:42:57,374] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:42:57,383] {logging_mixin.py:109} INFO - [2022-08-13 17:42:57,383] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:42:57,396] {logging_mixin.py:109} INFO - [2022-08-13 17:42:57,396] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:42:57,405] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.550 seconds
[2022-08-13 17:43:27,997] {processor.py:163} INFO - Started process (PID=44887) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:43:27,999] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:43:28,000] {logging_mixin.py:109} INFO - [2022-08-13 17:43:28,000] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:43:28,529] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:43:28,539] {logging_mixin.py:109} INFO - [2022-08-13 17:43:28,538] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:43:28,552] {logging_mixin.py:109} INFO - [2022-08-13 17:43:28,552] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:43:28,561] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.568 seconds
[2022-08-13 17:43:58,896] {processor.py:163} INFO - Started process (PID=44962) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:43:58,898] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:43:58,899] {logging_mixin.py:109} INFO - [2022-08-13 17:43:58,899] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:43:59,369] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:43:59,428] {logging_mixin.py:109} INFO - [2022-08-13 17:43:59,427] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:43:59,446] {logging_mixin.py:109} INFO - [2022-08-13 17:43:59,445] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:43:59,455] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.562 seconds
[2022-08-13 17:44:30,175] {processor.py:163} INFO - Started process (PID=45028) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:44:30,178] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:44:30,179] {logging_mixin.py:109} INFO - [2022-08-13 17:44:30,179] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:44:30,657] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:44:30,668] {logging_mixin.py:109} INFO - [2022-08-13 17:44:30,668] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:44:30,684] {logging_mixin.py:109} INFO - [2022-08-13 17:44:30,684] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:44:30,694] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.524 seconds
[2022-08-13 17:45:01,190] {processor.py:163} INFO - Started process (PID=45103) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:45:01,192] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:45:01,194] {logging_mixin.py:109} INFO - [2022-08-13 17:45:01,194] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:45:01,671] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:45:01,680] {logging_mixin.py:109} INFO - [2022-08-13 17:45:01,679] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:45:01,693] {logging_mixin.py:109} INFO - [2022-08-13 17:45:01,692] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:45:01,702] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.516 seconds
[2022-08-13 17:45:31,779] {processor.py:163} INFO - Started process (PID=45168) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:45:31,781] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:45:31,783] {logging_mixin.py:109} INFO - [2022-08-13 17:45:31,783] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:45:32,253] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:45:32,262] {logging_mixin.py:109} INFO - [2022-08-13 17:45:32,261] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:45:32,274] {logging_mixin.py:109} INFO - [2022-08-13 17:45:32,274] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:45:32,283] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.510 seconds
[2022-08-13 17:46:02,671] {processor.py:163} INFO - Started process (PID=45242) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:46:02,674] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:46:02,676] {logging_mixin.py:109} INFO - [2022-08-13 17:46:02,675] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:46:03,152] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:46:03,163] {logging_mixin.py:109} INFO - [2022-08-13 17:46:03,162] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:46:03,176] {logging_mixin.py:109} INFO - [2022-08-13 17:46:03,176] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:46:03,187] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.520 seconds
[2022-08-13 17:46:33,649] {processor.py:163} INFO - Started process (PID=45307) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:46:33,652] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:46:33,654] {logging_mixin.py:109} INFO - [2022-08-13 17:46:33,654] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:46:34,200] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:46:34,210] {logging_mixin.py:109} INFO - [2022-08-13 17:46:34,209] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:46:34,225] {logging_mixin.py:109} INFO - [2022-08-13 17:46:34,225] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:46:34,240] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.594 seconds
[2022-08-13 17:47:04,592] {processor.py:163} INFO - Started process (PID=45373) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:47:04,594] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:47:04,595] {logging_mixin.py:109} INFO - [2022-08-13 17:47:04,595] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:47:05,111] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:47:05,119] {logging_mixin.py:109} INFO - [2022-08-13 17:47:05,119] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:47:05,132] {logging_mixin.py:109} INFO - [2022-08-13 17:47:05,132] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:47:05,143] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.559 seconds
[2022-08-13 17:47:35,486] {processor.py:163} INFO - Started process (PID=45447) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:47:35,488] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:47:35,490] {logging_mixin.py:109} INFO - [2022-08-13 17:47:35,490] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:47:36,014] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:47:36,023] {logging_mixin.py:109} INFO - [2022-08-13 17:47:36,022] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:47:36,036] {logging_mixin.py:109} INFO - [2022-08-13 17:47:36,036] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:47:36,045] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.564 seconds
[2022-08-13 17:48:06,246] {processor.py:163} INFO - Started process (PID=45515) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:48:06,248] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:48:06,250] {logging_mixin.py:109} INFO - [2022-08-13 17:48:06,250] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:48:06,707] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:48:06,715] {logging_mixin.py:109} INFO - [2022-08-13 17:48:06,715] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:48:06,727] {logging_mixin.py:109} INFO - [2022-08-13 17:48:06,727] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:48:06,736] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.494 seconds
[2022-08-13 17:48:37,337] {processor.py:163} INFO - Started process (PID=45590) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:48:37,341] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:48:37,343] {logging_mixin.py:109} INFO - [2022-08-13 17:48:37,343] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:48:37,842] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:48:37,852] {logging_mixin.py:109} INFO - [2022-08-13 17:48:37,851] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:48:37,863] {logging_mixin.py:109} INFO - [2022-08-13 17:48:37,863] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:48:37,872] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.540 seconds
[2022-08-13 17:49:07,921] {processor.py:163} INFO - Started process (PID=45657) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:49:07,924] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:49:07,925] {logging_mixin.py:109} INFO - [2022-08-13 17:49:07,925] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:49:08,471] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:49:08,482] {logging_mixin.py:109} INFO - [2022-08-13 17:49:08,481] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:49:08,499] {logging_mixin.py:109} INFO - [2022-08-13 17:49:08,499] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:49:08,510] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.592 seconds
[2022-08-13 17:49:38,812] {processor.py:163} INFO - Started process (PID=45731) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:49:38,815] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:49:38,816] {logging_mixin.py:109} INFO - [2022-08-13 17:49:38,816] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:49:39,316] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:49:39,328] {logging_mixin.py:109} INFO - [2022-08-13 17:49:39,328] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:49:39,345] {logging_mixin.py:109} INFO - [2022-08-13 17:49:39,345] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:49:39,356] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.548 seconds
[2022-08-13 17:50:09,447] {processor.py:163} INFO - Started process (PID=45798) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:50:09,450] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:50:09,452] {logging_mixin.py:109} INFO - [2022-08-13 17:50:09,451] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:50:10,007] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:50:10,017] {logging_mixin.py:109} INFO - [2022-08-13 17:50:10,016] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:50:10,030] {logging_mixin.py:109} INFO - [2022-08-13 17:50:10,030] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:50:10,042] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.599 seconds
[2022-08-13 17:50:40,717] {processor.py:163} INFO - Started process (PID=45872) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:50:40,719] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:50:40,721] {logging_mixin.py:109} INFO - [2022-08-13 17:50:40,720] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:50:41,244] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:50:41,254] {logging_mixin.py:109} INFO - [2022-08-13 17:50:41,254] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:50:41,267] {logging_mixin.py:109} INFO - [2022-08-13 17:50:41,266] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:50:41,276] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.563 seconds
[2022-08-13 17:51:12,109] {processor.py:163} INFO - Started process (PID=45937) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:51:12,112] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:51:12,114] {logging_mixin.py:109} INFO - [2022-08-13 17:51:12,114] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:51:12,635] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:51:12,645] {logging_mixin.py:109} INFO - [2022-08-13 17:51:12,645] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:51:12,658] {logging_mixin.py:109} INFO - [2022-08-13 17:51:12,658] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:51:12,668] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.564 seconds
[2022-08-13 17:51:43,539] {processor.py:163} INFO - Started process (PID=46013) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:51:43,542] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:51:43,544] {logging_mixin.py:109} INFO - [2022-08-13 17:51:43,544] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:51:44,108] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:51:44,118] {logging_mixin.py:109} INFO - [2022-08-13 17:51:44,117] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:51:44,130] {logging_mixin.py:109} INFO - [2022-08-13 17:51:44,130] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:51:44,141] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.607 seconds
[2022-08-13 17:52:14,749] {processor.py:163} INFO - Started process (PID=46079) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:52:14,752] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:52:14,755] {logging_mixin.py:109} INFO - [2022-08-13 17:52:14,755] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:52:15,313] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:52:15,322] {logging_mixin.py:109} INFO - [2022-08-13 17:52:15,322] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:52:15,335] {logging_mixin.py:109} INFO - [2022-08-13 17:52:15,335] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:52:15,347] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.606 seconds
[2022-08-13 17:52:46,016] {processor.py:163} INFO - Started process (PID=46154) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:52:46,019] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:52:46,021] {logging_mixin.py:109} INFO - [2022-08-13 17:52:46,021] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:52:46,725] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:52:46,736] {logging_mixin.py:109} INFO - [2022-08-13 17:52:46,735] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:52:46,754] {logging_mixin.py:109} INFO - [2022-08-13 17:52:46,754] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:52:46,768] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.772 seconds
[2022-08-13 17:53:17,334] {processor.py:163} INFO - Started process (PID=46221) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:53:17,338] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:53:17,340] {logging_mixin.py:109} INFO - [2022-08-13 17:53:17,339] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:53:17,914] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:53:17,926] {logging_mixin.py:109} INFO - [2022-08-13 17:53:17,925] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:53:17,941] {logging_mixin.py:109} INFO - [2022-08-13 17:53:17,941] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:53:17,952] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.622 seconds
[2022-08-13 17:53:48,599] {processor.py:163} INFO - Started process (PID=46287) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:53:48,602] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:53:48,604] {logging_mixin.py:109} INFO - [2022-08-13 17:53:48,604] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:53:49,069] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:53:49,078] {logging_mixin.py:109} INFO - [2022-08-13 17:53:49,077] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:53:49,090] {logging_mixin.py:109} INFO - [2022-08-13 17:53:49,090] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:53:49,099] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.505 seconds
[2022-08-13 17:54:19,399] {processor.py:163} INFO - Started process (PID=46361) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:54:19,403] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:54:19,404] {logging_mixin.py:109} INFO - [2022-08-13 17:54:19,404] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:54:19,869] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:54:19,878] {logging_mixin.py:109} INFO - [2022-08-13 17:54:19,877] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:54:19,890] {logging_mixin.py:109} INFO - [2022-08-13 17:54:19,890] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:54:19,900] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.505 seconds
[2022-08-13 17:54:49,949] {processor.py:163} INFO - Started process (PID=46426) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:54:49,952] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:54:49,954] {logging_mixin.py:109} INFO - [2022-08-13 17:54:49,954] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:54:50,481] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:54:50,490] {logging_mixin.py:109} INFO - [2022-08-13 17:54:50,490] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:54:50,503] {logging_mixin.py:109} INFO - [2022-08-13 17:54:50,503] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:54:50,512] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.588 seconds
[2022-08-13 17:55:21,271] {processor.py:163} INFO - Started process (PID=46501) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:55:21,274] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:55:21,276] {logging_mixin.py:109} INFO - [2022-08-13 17:55:21,276] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:55:21,735] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:55:21,743] {logging_mixin.py:109} INFO - [2022-08-13 17:55:21,743] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:55:21,755] {logging_mixin.py:109} INFO - [2022-08-13 17:55:21,754] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:55:21,763] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.498 seconds
[2022-08-13 17:55:52,549] {processor.py:163} INFO - Started process (PID=46566) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:55:52,552] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:55:52,553] {logging_mixin.py:109} INFO - [2022-08-13 17:55:52,553] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:55:53,012] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:55:53,020] {logging_mixin.py:109} INFO - [2022-08-13 17:55:53,020] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:55:53,033] {logging_mixin.py:109} INFO - [2022-08-13 17:55:53,033] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:55:53,042] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.497 seconds
[2022-08-13 17:56:23,377] {processor.py:163} INFO - Started process (PID=46640) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:56:23,380] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:56:23,382] {logging_mixin.py:109} INFO - [2022-08-13 17:56:23,382] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:56:23,858] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:56:23,866] {logging_mixin.py:109} INFO - [2022-08-13 17:56:23,866] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:56:23,878] {logging_mixin.py:109} INFO - [2022-08-13 17:56:23,878] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:56:23,886] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.514 seconds
[2022-08-13 17:56:54,108] {processor.py:163} INFO - Started process (PID=46705) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:56:54,110] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:56:54,112] {logging_mixin.py:109} INFO - [2022-08-13 17:56:54,112] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:56:54,661] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:56:54,673] {logging_mixin.py:109} INFO - [2022-08-13 17:56:54,672] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:56:54,689] {logging_mixin.py:109} INFO - [2022-08-13 17:56:54,689] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:56:54,701] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.598 seconds
[2022-08-13 17:57:25,479] {processor.py:163} INFO - Started process (PID=46780) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:57:25,482] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:57:25,484] {logging_mixin.py:109} INFO - [2022-08-13 17:57:25,484] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:57:26,014] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:57:26,023] {logging_mixin.py:109} INFO - [2022-08-13 17:57:26,022] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:57:26,040] {logging_mixin.py:109} INFO - [2022-08-13 17:57:26,040] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:57:26,051] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.577 seconds
[2022-08-13 17:57:56,936] {processor.py:163} INFO - Started process (PID=46845) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:57:56,938] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:57:56,940] {logging_mixin.py:109} INFO - [2022-08-13 17:57:56,940] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:57:57,549] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:57:57,558] {logging_mixin.py:109} INFO - [2022-08-13 17:57:57,558] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:57:57,573] {logging_mixin.py:109} INFO - [2022-08-13 17:57:57,573] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:57:57,584] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.652 seconds
[2022-08-13 17:58:28,453] {processor.py:163} INFO - Started process (PID=46919) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:58:28,456] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:58:28,458] {logging_mixin.py:109} INFO - [2022-08-13 17:58:28,458] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:58:29,012] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:58:29,022] {logging_mixin.py:109} INFO - [2022-08-13 17:58:29,022] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:58:29,037] {logging_mixin.py:109} INFO - [2022-08-13 17:58:29,037] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:58:29,048] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.600 seconds
[2022-08-13 17:59:00,052] {processor.py:163} INFO - Started process (PID=46986) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:59:00,054] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:59:00,055] {logging_mixin.py:109} INFO - [2022-08-13 17:59:00,055] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:59:00,645] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:59:00,654] {logging_mixin.py:109} INFO - [2022-08-13 17:59:00,653] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:59:00,666] {logging_mixin.py:109} INFO - [2022-08-13 17:59:00,666] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:59:00,677] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.630 seconds
[2022-08-13 17:59:31,212] {processor.py:163} INFO - Started process (PID=47058) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:59:31,215] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 17:59:31,217] {logging_mixin.py:109} INFO - [2022-08-13 17:59:31,217] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:59:31,790] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 17:59:31,801] {logging_mixin.py:109} INFO - [2022-08-13 17:59:31,800] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 17:59:31,817] {logging_mixin.py:109} INFO - [2022-08-13 17:59:31,817] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 17:59:31,829] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.624 seconds
[2022-08-13 18:00:02,651] {processor.py:163} INFO - Started process (PID=47127) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:00:02,656] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:00:02,657] {logging_mixin.py:109} INFO - [2022-08-13 18:00:02,657] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:00:03,148] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:00:03,157] {logging_mixin.py:109} INFO - [2022-08-13 18:00:03,156] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:00:03,171] {logging_mixin.py:109} INFO - [2022-08-13 18:00:03,171] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:00:03,182] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.536 seconds
[2022-08-13 18:00:33,798] {processor.py:163} INFO - Started process (PID=47192) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:00:33,802] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:00:33,803] {logging_mixin.py:109} INFO - [2022-08-13 18:00:33,803] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:00:34,347] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:00:34,356] {logging_mixin.py:109} INFO - [2022-08-13 18:00:34,355] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:00:34,372] {logging_mixin.py:109} INFO - [2022-08-13 18:00:34,372] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:00:34,382] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.588 seconds
[2022-08-13 18:01:04,940] {processor.py:163} INFO - Started process (PID=47267) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:01:04,944] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:01:04,945] {logging_mixin.py:109} INFO - [2022-08-13 18:01:04,945] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:01:05,495] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:01:05,508] {logging_mixin.py:109} INFO - [2022-08-13 18:01:05,508] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:01:05,524] {logging_mixin.py:109} INFO - [2022-08-13 18:01:05,524] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:01:05,535] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.600 seconds
[2022-08-13 18:01:35,612] {processor.py:163} INFO - Started process (PID=47332) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:01:35,615] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:01:35,617] {logging_mixin.py:109} INFO - [2022-08-13 18:01:35,617] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:01:36,220] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:01:36,235] {logging_mixin.py:109} INFO - [2022-08-13 18:01:36,234] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:01:36,251] {logging_mixin.py:109} INFO - [2022-08-13 18:01:36,251] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:01:36,264] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.658 seconds
[2022-08-13 18:02:06,645] {processor.py:163} INFO - Started process (PID=47406) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:02:06,649] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:02:06,651] {logging_mixin.py:109} INFO - [2022-08-13 18:02:06,651] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:02:07,281] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:02:07,292] {logging_mixin.py:109} INFO - [2022-08-13 18:02:07,291] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:02:07,307] {logging_mixin.py:109} INFO - [2022-08-13 18:02:07,307] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:02:07,320] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.682 seconds
[2022-08-13 18:02:37,686] {processor.py:163} INFO - Started process (PID=47473) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:02:37,689] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:02:37,691] {logging_mixin.py:109} INFO - [2022-08-13 18:02:37,691] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:02:38,192] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:02:38,201] {logging_mixin.py:109} INFO - [2022-08-13 18:02:38,200] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:02:38,216] {logging_mixin.py:109} INFO - [2022-08-13 18:02:38,215] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:02:38,228] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.547 seconds
[2022-08-13 18:03:09,119] {processor.py:163} INFO - Started process (PID=47539) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:03:09,122] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:03:09,124] {logging_mixin.py:109} INFO - [2022-08-13 18:03:09,124] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:03:09,740] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:03:09,752] {logging_mixin.py:109} INFO - [2022-08-13 18:03:09,752] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:03:09,767] {logging_mixin.py:109} INFO - [2022-08-13 18:03:09,767] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:03:09,778] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.663 seconds
[2022-08-13 18:03:39,941] {processor.py:163} INFO - Started process (PID=47614) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:03:39,944] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:03:39,946] {logging_mixin.py:109} INFO - [2022-08-13 18:03:39,946] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:03:40,461] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:03:40,471] {logging_mixin.py:109} INFO - [2022-08-13 18:03:40,470] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:03:40,488] {logging_mixin.py:109} INFO - [2022-08-13 18:03:40,487] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:03:40,499] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.561 seconds
[2022-08-13 18:04:10,897] {processor.py:163} INFO - Started process (PID=47679) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:04:10,900] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:04:10,902] {logging_mixin.py:109} INFO - [2022-08-13 18:04:10,901] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:04:11,413] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:04:11,422] {logging_mixin.py:109} INFO - [2022-08-13 18:04:11,422] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:04:11,437] {logging_mixin.py:109} INFO - [2022-08-13 18:04:11,437] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:04:11,446] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.554 seconds
[2022-08-13 18:04:42,105] {processor.py:163} INFO - Started process (PID=47752) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:04:42,107] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:04:42,109] {logging_mixin.py:109} INFO - [2022-08-13 18:04:42,109] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:04:42,739] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:04:42,749] {logging_mixin.py:109} INFO - [2022-08-13 18:04:42,748] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:04:42,763] {logging_mixin.py:109} INFO - [2022-08-13 18:04:42,763] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:04:42,773] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.674 seconds
[2022-08-13 18:05:12,967] {processor.py:163} INFO - Started process (PID=47819) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:05:12,973] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:05:12,975] {logging_mixin.py:109} INFO - [2022-08-13 18:05:12,975] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:05:13,720] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:05:13,735] {logging_mixin.py:109} INFO - [2022-08-13 18:05:13,734] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:05:13,749] {logging_mixin.py:109} INFO - [2022-08-13 18:05:13,749] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:05:13,760] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.799 seconds
[2022-08-13 18:05:44,531] {processor.py:163} INFO - Started process (PID=47886) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:05:44,535] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:05:44,538] {logging_mixin.py:109} INFO - [2022-08-13 18:05:44,538] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:05:45,058] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:05:45,070] {logging_mixin.py:109} INFO - [2022-08-13 18:05:45,070] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:05:45,086] {logging_mixin.py:109} INFO - [2022-08-13 18:05:45,086] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:05:45,095] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.571 seconds
[2022-08-13 18:06:15,450] {processor.py:163} INFO - Started process (PID=47961) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:06:15,453] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:06:15,455] {logging_mixin.py:109} INFO - [2022-08-13 18:06:15,455] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:06:16,016] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:06:16,025] {logging_mixin.py:109} INFO - [2022-08-13 18:06:16,024] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:06:16,040] {logging_mixin.py:109} INFO - [2022-08-13 18:06:16,040] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:06:16,050] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.606 seconds
[2022-08-13 18:06:46,809] {processor.py:163} INFO - Started process (PID=48028) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:06:46,812] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:06:46,814] {logging_mixin.py:109} INFO - [2022-08-13 18:06:46,814] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:06:47,383] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:06:47,392] {logging_mixin.py:109} INFO - [2022-08-13 18:06:47,392] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:06:47,406] {logging_mixin.py:109} INFO - [2022-08-13 18:06:47,406] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:06:47,417] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.612 seconds
[2022-08-13 18:07:17,531] {processor.py:163} INFO - Started process (PID=48103) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:07:17,534] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:07:17,536] {logging_mixin.py:109} INFO - [2022-08-13 18:07:17,536] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:07:18,124] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:07:18,135] {logging_mixin.py:109} INFO - [2022-08-13 18:07:18,135] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:07:18,150] {logging_mixin.py:109} INFO - [2022-08-13 18:07:18,149] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:07:18,159] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.632 seconds
[2022-08-13 18:07:48,358] {processor.py:163} INFO - Started process (PID=48169) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:07:48,362] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:07:48,364] {logging_mixin.py:109} INFO - [2022-08-13 18:07:48,364] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:07:48,924] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:07:48,934] {logging_mixin.py:109} INFO - [2022-08-13 18:07:48,933] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:07:48,949] {logging_mixin.py:109} INFO - [2022-08-13 18:07:48,949] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:07:48,959] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.604 seconds
[2022-08-13 18:08:19,200] {processor.py:163} INFO - Started process (PID=48242) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:08:19,202] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:08:19,204] {logging_mixin.py:109} INFO - [2022-08-13 18:08:19,204] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:08:19,781] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:08:19,773] {logging_mixin.py:109} INFO - [2022-08-13 18:08:19,772] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:08:19,789] {logging_mixin.py:109} INFO - [2022-08-13 18:08:19,789] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:08:19,799] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.625 seconds
[2022-08-13 18:08:49,957] {processor.py:163} INFO - Started process (PID=48309) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:08:49,961] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:08:49,963] {logging_mixin.py:109} INFO - [2022-08-13 18:08:49,963] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:08:50,468] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:08:50,476] {logging_mixin.py:109} INFO - [2022-08-13 18:08:50,475] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:08:50,488] {logging_mixin.py:109} INFO - [2022-08-13 18:08:50,488] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:08:50,498] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.547 seconds
[2022-08-13 18:09:20,958] {processor.py:163} INFO - Started process (PID=48375) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:09:20,963] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:09:20,966] {logging_mixin.py:109} INFO - [2022-08-13 18:09:20,966] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:09:21,500] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:09:21,510] {logging_mixin.py:109} INFO - [2022-08-13 18:09:21,510] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:09:21,524] {logging_mixin.py:109} INFO - [2022-08-13 18:09:21,523] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:09:21,533] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.584 seconds
[2022-08-13 18:09:51,586] {processor.py:163} INFO - Started process (PID=48449) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:09:51,590] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:09:51,592] {logging_mixin.py:109} INFO - [2022-08-13 18:09:51,591] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:09:52,129] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:09:52,137] {logging_mixin.py:109} INFO - [2022-08-13 18:09:52,137] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:09:52,149] {logging_mixin.py:109} INFO - [2022-08-13 18:09:52,149] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:09:52,159] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.577 seconds
[2022-08-13 18:10:23,053] {processor.py:163} INFO - Started process (PID=48514) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:10:23,056] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:10:23,059] {logging_mixin.py:109} INFO - [2022-08-13 18:10:23,059] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:10:23,665] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:10:23,674] {logging_mixin.py:109} INFO - [2022-08-13 18:10:23,673] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:10:23,686] {logging_mixin.py:109} INFO - [2022-08-13 18:10:23,686] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:10:23,695] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.647 seconds
[2022-08-13 18:10:54,465] {processor.py:163} INFO - Started process (PID=48588) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:10:54,468] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:10:54,470] {logging_mixin.py:109} INFO - [2022-08-13 18:10:54,470] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:10:55,025] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:10:55,035] {logging_mixin.py:109} INFO - [2022-08-13 18:10:55,034] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:10:55,047] {logging_mixin.py:109} INFO - [2022-08-13 18:10:55,047] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:10:55,057] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.595 seconds
[2022-08-13 18:11:25,691] {processor.py:163} INFO - Started process (PID=48653) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:11:25,694] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:11:25,696] {logging_mixin.py:109} INFO - [2022-08-13 18:11:25,696] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:11:26,254] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:11:26,264] {logging_mixin.py:109} INFO - [2022-08-13 18:11:26,263] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:11:26,277] {logging_mixin.py:109} INFO - [2022-08-13 18:11:26,277] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:11:26,286] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.601 seconds
[2022-08-13 18:11:56,518] {processor.py:163} INFO - Started process (PID=48718) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:11:56,520] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:11:56,521] {logging_mixin.py:109} INFO - [2022-08-13 18:11:56,521] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:11:57,069] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:11:57,078] {logging_mixin.py:109} INFO - [2022-08-13 18:11:57,078] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:11:57,091] {logging_mixin.py:109} INFO - [2022-08-13 18:11:57,091] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:11:57,100] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.587 seconds
[2022-08-13 18:12:27,263] {processor.py:163} INFO - Started process (PID=48793) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:12:27,266] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:12:27,268] {logging_mixin.py:109} INFO - [2022-08-13 18:12:27,268] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:12:27,763] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:12:27,774] {logging_mixin.py:109} INFO - [2022-08-13 18:12:27,773] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:12:27,789] {logging_mixin.py:109} INFO - [2022-08-13 18:12:27,789] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:12:27,802] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.542 seconds
[2022-08-13 18:12:58,573] {processor.py:163} INFO - Started process (PID=48859) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:12:58,577] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:12:58,578] {logging_mixin.py:109} INFO - [2022-08-13 18:12:58,578] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:12:59,195] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:12:59,205] {logging_mixin.py:109} INFO - [2022-08-13 18:12:59,204] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:12:59,221] {logging_mixin.py:109} INFO - [2022-08-13 18:12:59,221] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:12:59,232] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.663 seconds
[2022-08-13 18:13:29,822] {processor.py:163} INFO - Started process (PID=48934) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:13:29,825] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:13:29,829] {logging_mixin.py:109} INFO - [2022-08-13 18:13:29,827] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:13:30,413] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:13:30,425] {logging_mixin.py:109} INFO - [2022-08-13 18:13:30,425] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:13:30,446] {logging_mixin.py:109} INFO - [2022-08-13 18:13:30,446] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:13:30,463] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.648 seconds
[2022-08-13 18:14:00,760] {processor.py:163} INFO - Started process (PID=49001) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:14:00,763] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:14:00,766] {logging_mixin.py:109} INFO - [2022-08-13 18:14:00,765] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:14:01,303] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:14:01,313] {logging_mixin.py:109} INFO - [2022-08-13 18:14:01,312] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:14:01,326] {logging_mixin.py:109} INFO - [2022-08-13 18:14:01,326] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:14:01,336] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.580 seconds
[2022-08-13 18:14:31,530] {processor.py:163} INFO - Started process (PID=49076) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:14:31,533] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:14:31,535] {logging_mixin.py:109} INFO - [2022-08-13 18:14:31,535] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:14:32,143] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:14:32,152] {logging_mixin.py:109} INFO - [2022-08-13 18:14:32,151] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:14:32,168] {logging_mixin.py:109} INFO - [2022-08-13 18:14:32,168] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:14:32,178] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.652 seconds
[2022-08-13 18:15:02,237] {processor.py:163} INFO - Started process (PID=49144) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:15:02,240] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:15:02,242] {logging_mixin.py:109} INFO - [2022-08-13 18:15:02,241] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:15:02,830] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:15:02,842] {logging_mixin.py:109} INFO - [2022-08-13 18:15:02,842] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:15:02,861] {logging_mixin.py:109} INFO - [2022-08-13 18:15:02,861] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:15:02,875] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.641 seconds
[2022-08-13 18:15:33,593] {processor.py:163} INFO - Started process (PID=49209) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:15:33,595] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:15:33,598] {logging_mixin.py:109} INFO - [2022-08-13 18:15:33,597] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:15:34,229] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:15:34,240] {logging_mixin.py:109} INFO - [2022-08-13 18:15:34,240] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:15:34,259] {logging_mixin.py:109} INFO - [2022-08-13 18:15:34,259] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:15:34,273] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.687 seconds
[2022-08-13 18:16:04,996] {processor.py:163} INFO - Started process (PID=49285) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:16:04,998] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:16:05,000] {logging_mixin.py:109} INFO - [2022-08-13 18:16:04,999] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:16:05,612] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:16:05,623] {logging_mixin.py:109} INFO - [2022-08-13 18:16:05,622] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:16:05,637] {logging_mixin.py:109} INFO - [2022-08-13 18:16:05,637] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:16:05,648] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.656 seconds
[2022-08-13 18:16:36,403] {processor.py:163} INFO - Started process (PID=49350) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:16:36,406] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:16:36,407] {logging_mixin.py:109} INFO - [2022-08-13 18:16:36,407] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:16:37,002] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:16:37,012] {logging_mixin.py:109} INFO - [2022-08-13 18:16:37,011] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:16:37,072] {logging_mixin.py:109} INFO - [2022-08-13 18:16:37,072] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:16:37,091] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.696 seconds
[2022-08-13 18:17:07,268] {processor.py:163} INFO - Started process (PID=49426) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:17:07,271] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:17:07,273] {logging_mixin.py:109} INFO - [2022-08-13 18:17:07,272] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:17:07,879] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:17:07,889] {logging_mixin.py:109} INFO - [2022-08-13 18:17:07,889] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:17:07,902] {logging_mixin.py:109} INFO - [2022-08-13 18:17:07,902] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:17:07,913] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.649 seconds
[2022-08-13 18:17:38,837] {processor.py:163} INFO - Started process (PID=49495) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:17:38,840] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:17:38,842] {logging_mixin.py:109} INFO - [2022-08-13 18:17:38,842] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:17:39,331] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:17:39,345] {logging_mixin.py:109} INFO - [2022-08-13 18:17:39,344] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:17:39,363] {logging_mixin.py:109} INFO - [2022-08-13 18:17:39,363] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:17:39,378] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.544 seconds
[2022-08-13 18:18:10,312] {processor.py:163} INFO - Started process (PID=49570) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:18:10,315] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:18:10,316] {logging_mixin.py:109} INFO - [2022-08-13 18:18:10,316] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:18:10,905] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:18:10,914] {logging_mixin.py:109} INFO - [2022-08-13 18:18:10,913] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:18:10,929] {logging_mixin.py:109} INFO - [2022-08-13 18:18:10,929] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:18:10,941] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.633 seconds
[2022-08-13 18:18:41,887] {processor.py:163} INFO - Started process (PID=49634) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:18:41,892] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:18:41,895] {logging_mixin.py:109} INFO - [2022-08-13 18:18:41,894] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:18:42,442] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:18:42,454] {logging_mixin.py:109} INFO - [2022-08-13 18:18:42,453] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:18:42,471] {logging_mixin.py:109} INFO - [2022-08-13 18:18:42,471] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:18:42,483] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.600 seconds
[2022-08-13 18:19:13,333] {processor.py:163} INFO - Started process (PID=49708) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:19:13,336] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:19:13,337] {logging_mixin.py:109} INFO - [2022-08-13 18:19:13,337] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:19:13,866] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:19:13,878] {logging_mixin.py:109} INFO - [2022-08-13 18:19:13,877] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:19:13,893] {logging_mixin.py:109} INFO - [2022-08-13 18:19:13,893] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:19:13,904] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.576 seconds
[2022-08-13 18:19:44,077] {processor.py:163} INFO - Started process (PID=49773) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:19:44,080] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:19:44,082] {logging_mixin.py:109} INFO - [2022-08-13 18:19:44,081] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:19:44,598] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:19:44,608] {logging_mixin.py:109} INFO - [2022-08-13 18:19:44,607] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:19:44,620] {logging_mixin.py:109} INFO - [2022-08-13 18:19:44,620] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:19:44,630] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.559 seconds
[2022-08-13 18:20:15,416] {processor.py:163} INFO - Started process (PID=49848) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:20:15,419] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:20:15,421] {logging_mixin.py:109} INFO - [2022-08-13 18:20:15,421] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:20:16,014] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:20:16,030] {logging_mixin.py:109} INFO - [2022-08-13 18:20:16,029] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:20:16,045] {logging_mixin.py:109} INFO - [2022-08-13 18:20:16,045] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:20:16,065] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.654 seconds
[2022-08-13 18:20:46,323] {processor.py:163} INFO - Started process (PID=49913) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:20:46,329] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:20:46,331] {logging_mixin.py:109} INFO - [2022-08-13 18:20:46,331] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:20:47,043] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:20:47,062] {logging_mixin.py:109} INFO - [2022-08-13 18:20:47,061] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:20:47,089] {logging_mixin.py:109} INFO - [2022-08-13 18:20:47,088] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:20:47,106] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.788 seconds
[2022-08-13 18:21:17,332] {processor.py:163} INFO - Started process (PID=49983) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:21:17,334] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:21:17,336] {logging_mixin.py:109} INFO - [2022-08-13 18:21:17,336] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:21:17,909] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:21:17,920] {logging_mixin.py:109} INFO - [2022-08-13 18:21:17,919] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:21:17,937] {logging_mixin.py:109} INFO - [2022-08-13 18:21:17,937] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:21:17,946] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.618 seconds
[2022-08-13 18:21:48,101] {processor.py:163} INFO - Started process (PID=50062) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:21:48,104] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:21:48,106] {logging_mixin.py:109} INFO - [2022-08-13 18:21:48,105] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:21:48,645] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:21:48,659] {logging_mixin.py:109} INFO - [2022-08-13 18:21:48,659] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:21:48,679] {logging_mixin.py:109} INFO - [2022-08-13 18:21:48,679] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:21:48,695] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.598 seconds
[2022-08-13 18:22:19,735] {processor.py:163} INFO - Started process (PID=50128) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:22:19,739] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:22:19,741] {logging_mixin.py:109} INFO - [2022-08-13 18:22:19,741] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:22:20,347] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:22:20,362] {logging_mixin.py:109} INFO - [2022-08-13 18:22:20,361] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:22:20,381] {logging_mixin.py:109} INFO - [2022-08-13 18:22:20,381] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:22:20,398] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.667 seconds
[2022-08-13 18:22:50,643] {processor.py:163} INFO - Started process (PID=50202) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:22:50,647] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:22:50,652] {logging_mixin.py:109} INFO - [2022-08-13 18:22:50,652] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:22:51,310] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:22:51,320] {logging_mixin.py:109} INFO - [2022-08-13 18:22:51,320] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:22:51,338] {logging_mixin.py:109} INFO - [2022-08-13 18:22:51,338] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:22:51,353] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.721 seconds
[2022-08-13 18:23:21,496] {processor.py:163} INFO - Started process (PID=50270) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:23:21,500] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:23:21,503] {logging_mixin.py:109} INFO - [2022-08-13 18:23:21,502] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:23:22,292] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:23:22,307] {logging_mixin.py:109} INFO - [2022-08-13 18:23:22,307] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:23:22,327] {logging_mixin.py:109} INFO - [2022-08-13 18:23:22,327] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:23:22,349] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.858 seconds
[2022-08-13 18:23:52,475] {processor.py:163} INFO - Started process (PID=50337) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:23:52,477] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:23:52,479] {logging_mixin.py:109} INFO - [2022-08-13 18:23:52,479] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:23:53,079] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:23:53,088] {logging_mixin.py:109} INFO - [2022-08-13 18:23:53,087] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:23:53,101] {logging_mixin.py:109} INFO - [2022-08-13 18:23:53,101] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:23:53,114] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.646 seconds
[2022-08-13 18:24:23,263] {processor.py:163} INFO - Started process (PID=50413) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:24:23,267] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:24:23,268] {logging_mixin.py:109} INFO - [2022-08-13 18:24:23,268] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:24:23,998] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:24:24,031] {logging_mixin.py:109} INFO - [2022-08-13 18:24:24,030] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:24:24,057] {logging_mixin.py:109} INFO - [2022-08-13 18:24:24,057] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:24:24,072] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.815 seconds
[2022-08-13 18:24:54,746] {processor.py:163} INFO - Started process (PID=50478) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:24:54,750] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:24:54,752] {logging_mixin.py:109} INFO - [2022-08-13 18:24:54,752] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:24:55,397] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:24:55,413] {logging_mixin.py:109} INFO - [2022-08-13 18:24:55,412] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:24:55,434] {logging_mixin.py:109} INFO - [2022-08-13 18:24:55,434] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:24:55,463] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.724 seconds
[2022-08-13 18:25:25,667] {processor.py:163} INFO - Started process (PID=50552) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:25:25,670] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:25:25,673] {logging_mixin.py:109} INFO - [2022-08-13 18:25:25,673] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:25:26,295] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:25:26,307] {logging_mixin.py:109} INFO - [2022-08-13 18:25:26,306] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:25:26,322] {logging_mixin.py:109} INFO - [2022-08-13 18:25:26,322] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:25:26,331] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.671 seconds
[2022-08-13 18:25:56,670] {processor.py:163} INFO - Started process (PID=50617) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:25:56,672] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:25:56,673] {logging_mixin.py:109} INFO - [2022-08-13 18:25:56,673] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:25:57,190] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:25:57,200] {logging_mixin.py:109} INFO - [2022-08-13 18:25:57,199] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:25:57,213] {logging_mixin.py:109} INFO - [2022-08-13 18:25:57,213] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:25:57,224] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.558 seconds
[2022-08-13 18:26:27,460] {processor.py:163} INFO - Started process (PID=50691) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:26:27,463] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:26:27,465] {logging_mixin.py:109} INFO - [2022-08-13 18:26:27,465] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:26:28,009] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:26:28,022] {logging_mixin.py:109} INFO - [2022-08-13 18:26:28,021] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:26:28,041] {logging_mixin.py:109} INFO - [2022-08-13 18:26:28,041] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:26:28,051] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.597 seconds
[2022-08-13 18:26:58,210] {processor.py:163} INFO - Started process (PID=50756) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:26:58,214] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:26:58,216] {logging_mixin.py:109} INFO - [2022-08-13 18:26:58,216] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:26:58,806] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:26:58,818] {logging_mixin.py:109} INFO - [2022-08-13 18:26:58,817] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:26:58,834] {logging_mixin.py:109} INFO - [2022-08-13 18:26:58,834] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:26:58,846] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.642 seconds
[2022-08-13 18:27:29,677] {processor.py:163} INFO - Started process (PID=50821) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:27:29,680] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:27:29,682] {logging_mixin.py:109} INFO - [2022-08-13 18:27:29,681] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:27:30,330] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:27:30,347] {logging_mixin.py:109} INFO - [2022-08-13 18:27:30,347] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:27:30,370] {logging_mixin.py:109} INFO - [2022-08-13 18:27:30,369] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:27:30,383] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.712 seconds
[2022-08-13 18:28:00,787] {processor.py:163} INFO - Started process (PID=50895) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:28:00,789] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:28:00,791] {logging_mixin.py:109} INFO - [2022-08-13 18:28:00,791] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:28:01,345] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:28:01,357] {logging_mixin.py:109} INFO - [2022-08-13 18:28:01,356] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:28:01,373] {logging_mixin.py:109} INFO - [2022-08-13 18:28:01,373] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:28:01,382] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.603 seconds
[2022-08-13 18:28:31,459] {processor.py:163} INFO - Started process (PID=50961) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:28:31,461] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:28:31,463] {logging_mixin.py:109} INFO - [2022-08-13 18:28:31,462] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:28:32,003] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:28:32,013] {logging_mixin.py:109} INFO - [2022-08-13 18:28:32,013] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:28:32,027] {logging_mixin.py:109} INFO - [2022-08-13 18:28:32,027] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:28:32,038] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.582 seconds
[2022-08-13 18:29:02,580] {processor.py:163} INFO - Started process (PID=51034) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:29:02,583] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:29:02,585] {logging_mixin.py:109} INFO - [2022-08-13 18:29:02,585] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:29:03,143] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:29:03,154] {logging_mixin.py:109} INFO - [2022-08-13 18:29:03,153] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:29:03,170] {logging_mixin.py:109} INFO - [2022-08-13 18:29:03,170] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:29:03,182] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.613 seconds
[2022-08-13 18:29:33,518] {processor.py:163} INFO - Started process (PID=51100) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:29:33,521] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:29:33,523] {logging_mixin.py:109} INFO - [2022-08-13 18:29:33,523] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:29:34,097] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:29:34,107] {logging_mixin.py:109} INFO - [2022-08-13 18:29:34,106] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:29:34,122] {logging_mixin.py:109} INFO - [2022-08-13 18:29:34,122] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:29:34,132] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.619 seconds
[2022-08-13 18:30:04,289] {processor.py:163} INFO - Started process (PID=51176) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:30:04,292] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:30:04,294] {logging_mixin.py:109} INFO - [2022-08-13 18:30:04,294] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:30:04,901] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:30:04,915] {logging_mixin.py:109} INFO - [2022-08-13 18:30:04,914] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:30:04,931] {logging_mixin.py:109} INFO - [2022-08-13 18:30:04,931] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:30:04,945] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.660 seconds
[2022-08-13 18:30:35,001] {processor.py:163} INFO - Started process (PID=51241) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:30:35,006] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:30:35,009] {logging_mixin.py:109} INFO - [2022-08-13 18:30:35,009] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:30:35,695] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:30:35,712] {logging_mixin.py:109} INFO - [2022-08-13 18:30:35,711] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:30:35,728] {logging_mixin.py:109} INFO - [2022-08-13 18:30:35,728] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:30:35,742] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.747 seconds
[2022-08-13 18:31:05,921] {processor.py:163} INFO - Started process (PID=51307) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:31:05,924] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:31:05,925] {logging_mixin.py:109} INFO - [2022-08-13 18:31:05,925] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:31:06,523] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:31:06,535] {logging_mixin.py:109} INFO - [2022-08-13 18:31:06,534] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:31:06,552] {logging_mixin.py:109} INFO - [2022-08-13 18:31:06,552] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:31:06,566] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.649 seconds
[2022-08-13 18:31:37,501] {processor.py:163} INFO - Started process (PID=51382) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:31:37,504] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:31:37,506] {logging_mixin.py:109} INFO - [2022-08-13 18:31:37,506] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:31:38,092] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:31:38,102] {logging_mixin.py:109} INFO - [2022-08-13 18:31:38,101] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:31:38,117] {logging_mixin.py:109} INFO - [2022-08-13 18:31:38,117] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:31:38,132] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.639 seconds
[2022-08-13 18:32:08,265] {processor.py:163} INFO - Started process (PID=51448) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:32:08,267] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:32:08,269] {logging_mixin.py:109} INFO - [2022-08-13 18:32:08,269] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:32:08,836] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:32:08,846] {logging_mixin.py:109} INFO - [2022-08-13 18:32:08,846] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:32:08,863] {logging_mixin.py:109} INFO - [2022-08-13 18:32:08,863] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:32:08,873] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.618 seconds
[2022-08-13 18:32:39,232] {processor.py:163} INFO - Started process (PID=51523) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:32:39,236] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:32:39,237] {logging_mixin.py:109} INFO - [2022-08-13 18:32:39,237] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:32:39,808] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:32:39,819] {logging_mixin.py:109} INFO - [2022-08-13 18:32:39,819] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:32:39,835] {logging_mixin.py:109} INFO - [2022-08-13 18:32:39,835] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:32:39,847] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.618 seconds
[2022-08-13 18:33:10,244] {processor.py:163} INFO - Started process (PID=51589) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:33:10,248] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:33:10,252] {logging_mixin.py:109} INFO - [2022-08-13 18:33:10,252] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:33:10,804] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:33:10,812] {logging_mixin.py:109} INFO - [2022-08-13 18:33:10,812] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:33:10,829] {logging_mixin.py:109} INFO - [2022-08-13 18:33:10,829] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:33:10,838] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.598 seconds
[2022-08-13 18:33:41,194] {processor.py:163} INFO - Started process (PID=51664) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:33:41,197] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:33:41,198] {logging_mixin.py:109} INFO - [2022-08-13 18:33:41,198] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:33:41,726] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:33:41,738] {logging_mixin.py:109} INFO - [2022-08-13 18:33:41,737] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:33:41,754] {logging_mixin.py:109} INFO - [2022-08-13 18:33:41,754] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:33:41,766] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.578 seconds
[2022-08-13 18:34:12,126] {processor.py:163} INFO - Started process (PID=51729) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:34:12,130] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:34:12,132] {logging_mixin.py:109} INFO - [2022-08-13 18:34:12,131] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:34:12,698] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:34:12,709] {logging_mixin.py:109} INFO - [2022-08-13 18:34:12,708] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:34:12,728] {logging_mixin.py:109} INFO - [2022-08-13 18:34:12,728] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:34:12,738] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.619 seconds
[2022-08-13 18:34:42,795] {processor.py:163} INFO - Started process (PID=51794) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:34:42,798] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:34:42,799] {logging_mixin.py:109} INFO - [2022-08-13 18:34:42,799] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:34:43,352] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:34:43,361] {logging_mixin.py:109} INFO - [2022-08-13 18:34:43,360] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:34:43,378] {logging_mixin.py:109} INFO - [2022-08-13 18:34:43,378] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:34:43,390] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.599 seconds
[2022-08-13 18:35:13,645] {processor.py:163} INFO - Started process (PID=51868) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:35:13,648] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:35:13,649] {logging_mixin.py:109} INFO - [2022-08-13 18:35:13,649] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:35:14,145] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:35:14,156] {logging_mixin.py:109} INFO - [2022-08-13 18:35:14,155] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:35:14,170] {logging_mixin.py:109} INFO - [2022-08-13 18:35:14,170] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:35:14,182] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.541 seconds
[2022-08-13 18:35:44,591] {processor.py:163} INFO - Started process (PID=51933) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:35:44,593] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:35:44,594] {logging_mixin.py:109} INFO - [2022-08-13 18:35:44,594] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:35:45,179] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:35:45,193] {logging_mixin.py:109} INFO - [2022-08-13 18:35:45,192] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:35:45,208] {logging_mixin.py:109} INFO - [2022-08-13 18:35:45,208] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:35:45,217] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.631 seconds
[2022-08-13 18:36:15,485] {processor.py:163} INFO - Started process (PID=52008) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:36:15,488] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:36:15,489] {logging_mixin.py:109} INFO - [2022-08-13 18:36:15,489] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:36:16,116] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:36:16,129] {logging_mixin.py:109} INFO - [2022-08-13 18:36:16,129] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:36:16,146] {logging_mixin.py:109} INFO - [2022-08-13 18:36:16,146] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:36:16,160] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.678 seconds
[2022-08-13 18:36:46,338] {processor.py:163} INFO - Started process (PID=52073) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:36:46,342] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:36:46,343] {logging_mixin.py:109} INFO - [2022-08-13 18:36:46,343] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:36:46,913] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:36:46,925] {logging_mixin.py:109} INFO - [2022-08-13 18:36:46,925] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:36:46,942] {logging_mixin.py:109} INFO - [2022-08-13 18:36:46,941] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:36:46,952] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.618 seconds
[2022-08-13 18:37:17,021] {processor.py:163} INFO - Started process (PID=52138) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:37:17,023] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:37:17,024] {logging_mixin.py:109} INFO - [2022-08-13 18:37:17,024] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:37:17,486] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:37:17,495] {logging_mixin.py:109} INFO - [2022-08-13 18:37:17,494] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:37:17,507] {logging_mixin.py:109} INFO - [2022-08-13 18:37:17,507] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:37:17,520] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.503 seconds
[2022-08-13 18:37:47,696] {processor.py:163} INFO - Started process (PID=52213) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:37:47,699] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:37:47,701] {logging_mixin.py:109} INFO - [2022-08-13 18:37:47,701] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:37:48,305] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:37:48,316] {logging_mixin.py:109} INFO - [2022-08-13 18:37:48,315] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:37:48,330] {logging_mixin.py:109} INFO - [2022-08-13 18:37:48,330] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:37:48,342] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.650 seconds
[2022-08-13 18:38:18,849] {processor.py:163} INFO - Started process (PID=52282) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:38:18,851] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:38:18,853] {logging_mixin.py:109} INFO - [2022-08-13 18:38:18,853] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:38:19,340] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:38:19,349] {logging_mixin.py:109} INFO - [2022-08-13 18:38:19,349] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:38:19,362] {logging_mixin.py:109} INFO - [2022-08-13 18:38:19,362] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:38:19,374] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.528 seconds
[2022-08-13 18:38:50,387] {processor.py:163} INFO - Started process (PID=52356) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:38:50,392] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:38:50,394] {logging_mixin.py:109} INFO - [2022-08-13 18:38:50,394] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:38:51,080] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:38:51,093] {logging_mixin.py:109} INFO - [2022-08-13 18:38:51,093] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:38:51,113] {logging_mixin.py:109} INFO - [2022-08-13 18:38:51,113] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:38:51,127] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.748 seconds
[2022-08-13 18:39:21,304] {processor.py:163} INFO - Started process (PID=52423) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:39:21,308] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:39:21,310] {logging_mixin.py:109} INFO - [2022-08-13 18:39:21,310] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:39:21,913] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:39:21,922] {logging_mixin.py:109} INFO - [2022-08-13 18:39:21,922] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:39:21,934] {logging_mixin.py:109} INFO - [2022-08-13 18:39:21,934] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:39:21,943] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.642 seconds
[2022-08-13 18:39:52,069] {processor.py:163} INFO - Started process (PID=52500) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:39:52,071] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:39:52,072] {logging_mixin.py:109} INFO - [2022-08-13 18:39:52,072] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:39:52,648] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:39:52,659] {logging_mixin.py:109} INFO - [2022-08-13 18:39:52,658] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:39:52,674] {logging_mixin.py:109} INFO - [2022-08-13 18:39:52,674] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:39:52,685] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.620 seconds
[2022-08-13 18:40:22,821] {processor.py:163} INFO - Started process (PID=52567) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:40:22,824] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:40:22,827] {logging_mixin.py:109} INFO - [2022-08-13 18:40:22,826] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:40:23,558] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:40:23,572] {logging_mixin.py:109} INFO - [2022-08-13 18:40:23,571] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:40:23,589] {logging_mixin.py:109} INFO - [2022-08-13 18:40:23,589] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:40:23,600] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.786 seconds
[2022-08-13 18:40:54,407] {processor.py:163} INFO - Started process (PID=52632) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:40:54,409] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:40:54,411] {logging_mixin.py:109} INFO - [2022-08-13 18:40:54,411] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:40:54,920] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:40:54,932] {logging_mixin.py:109} INFO - [2022-08-13 18:40:54,931] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:40:54,948] {logging_mixin.py:109} INFO - [2022-08-13 18:40:54,948] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:40:54,957] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.556 seconds
[2022-08-13 18:41:25,622] {processor.py:163} INFO - Started process (PID=52706) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:41:25,624] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:41:25,626] {logging_mixin.py:109} INFO - [2022-08-13 18:41:25,626] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:41:26,120] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:41:26,130] {logging_mixin.py:109} INFO - [2022-08-13 18:41:26,129] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:41:26,143] {logging_mixin.py:109} INFO - [2022-08-13 18:41:26,143] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:41:26,151] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.534 seconds
[2022-08-13 18:41:56,409] {processor.py:163} INFO - Started process (PID=52771) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:41:56,411] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:41:56,413] {logging_mixin.py:109} INFO - [2022-08-13 18:41:56,413] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:41:56,909] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:41:56,917] {logging_mixin.py:109} INFO - [2022-08-13 18:41:56,917] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:41:56,930] {logging_mixin.py:109} INFO - [2022-08-13 18:41:56,930] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:41:56,941] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.538 seconds
[2022-08-13 18:42:27,060] {processor.py:163} INFO - Started process (PID=52847) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:42:27,063] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:42:27,066] {logging_mixin.py:109} INFO - [2022-08-13 18:42:27,066] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:42:27,727] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:42:27,741] {logging_mixin.py:109} INFO - [2022-08-13 18:42:27,741] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:42:27,763] {logging_mixin.py:109} INFO - [2022-08-13 18:42:27,763] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:42:27,782] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.729 seconds
[2022-08-13 18:42:57,846] {processor.py:163} INFO - Started process (PID=52913) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:42:57,848] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:42:57,849] {logging_mixin.py:109} INFO - [2022-08-13 18:42:57,849] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:42:58,419] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:42:58,429] {logging_mixin.py:109} INFO - [2022-08-13 18:42:58,429] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:42:58,443] {logging_mixin.py:109} INFO - [2022-08-13 18:42:58,443] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:42:58,453] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.612 seconds
[2022-08-13 18:43:28,738] {processor.py:163} INFO - Started process (PID=52978) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:43:28,741] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:43:28,742] {logging_mixin.py:109} INFO - [2022-08-13 18:43:28,742] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:43:29,337] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:43:29,347] {logging_mixin.py:109} INFO - [2022-08-13 18:43:29,347] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:43:29,367] {logging_mixin.py:109} INFO - [2022-08-13 18:43:29,367] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:43:29,377] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.643 seconds
[2022-08-13 18:43:59,762] {processor.py:163} INFO - Started process (PID=53052) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:43:59,765] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:43:59,767] {logging_mixin.py:109} INFO - [2022-08-13 18:43:59,767] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:44:00,247] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:44:00,256] {logging_mixin.py:109} INFO - [2022-08-13 18:44:00,255] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:44:00,268] {logging_mixin.py:109} INFO - [2022-08-13 18:44:00,268] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:44:00,277] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.521 seconds
[2022-08-13 18:44:30,325] {processor.py:163} INFO - Started process (PID=53118) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:44:30,327] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:44:30,330] {logging_mixin.py:109} INFO - [2022-08-13 18:44:30,330] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:44:30,930] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:44:30,940] {logging_mixin.py:109} INFO - [2022-08-13 18:44:30,940] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:44:30,955] {logging_mixin.py:109} INFO - [2022-08-13 18:44:30,955] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:44:30,966] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.651 seconds
[2022-08-13 18:45:01,230] {processor.py:163} INFO - Started process (PID=53193) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:45:01,233] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:45:01,235] {logging_mixin.py:109} INFO - [2022-08-13 18:45:01,235] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:45:01,848] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:45:01,858] {logging_mixin.py:109} INFO - [2022-08-13 18:45:01,857] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:45:01,873] {logging_mixin.py:109} INFO - [2022-08-13 18:45:01,873] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:45:01,885] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.659 seconds
[2022-08-13 18:45:32,636] {processor.py:163} INFO - Started process (PID=53261) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:45:32,639] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:45:32,641] {logging_mixin.py:109} INFO - [2022-08-13 18:45:32,641] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:45:33,179] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:45:33,189] {logging_mixin.py:109} INFO - [2022-08-13 18:45:33,188] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:45:33,203] {logging_mixin.py:109} INFO - [2022-08-13 18:45:33,203] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:45:33,216] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.585 seconds
[2022-08-13 18:46:03,338] {processor.py:163} INFO - Started process (PID=53330) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:46:03,342] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:46:03,344] {logging_mixin.py:109} INFO - [2022-08-13 18:46:03,343] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:46:03,906] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:46:03,915] {logging_mixin.py:109} INFO - [2022-08-13 18:46:03,915] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:46:03,928] {logging_mixin.py:109} INFO - [2022-08-13 18:46:03,928] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:46:03,937] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.604 seconds
[2022-08-13 18:46:34,041] {processor.py:163} INFO - Started process (PID=53406) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:46:34,044] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:46:34,046] {logging_mixin.py:109} INFO - [2022-08-13 18:46:34,046] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:46:34,583] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:46:34,593] {logging_mixin.py:109} INFO - [2022-08-13 18:46:34,593] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:46:34,607] {logging_mixin.py:109} INFO - [2022-08-13 18:46:34,607] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:46:34,618] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.580 seconds
[2022-08-13 18:47:05,210] {processor.py:163} INFO - Started process (PID=53471) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:47:05,212] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:47:05,214] {logging_mixin.py:109} INFO - [2022-08-13 18:47:05,214] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:47:05,789] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:47:05,803] {logging_mixin.py:109} INFO - [2022-08-13 18:47:05,802] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:47:05,821] {logging_mixin.py:109} INFO - [2022-08-13 18:47:05,821] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:47:05,838] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.632 seconds
[2022-08-13 18:47:36,085] {processor.py:163} INFO - Started process (PID=53537) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:47:36,088] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:47:36,090] {logging_mixin.py:109} INFO - [2022-08-13 18:47:36,090] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:47:36,742] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:47:36,753] {logging_mixin.py:109} INFO - [2022-08-13 18:47:36,753] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:47:36,778] {logging_mixin.py:109} INFO - [2022-08-13 18:47:36,778] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:47:36,795] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.715 seconds
[2022-08-13 18:48:06,939] {processor.py:163} INFO - Started process (PID=53615) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:48:06,941] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:48:06,943] {logging_mixin.py:109} INFO - [2022-08-13 18:48:06,943] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:48:07,445] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:48:07,455] {logging_mixin.py:109} INFO - [2022-08-13 18:48:07,454] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:48:07,469] {logging_mixin.py:109} INFO - [2022-08-13 18:48:07,469] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:48:07,479] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.544 seconds
[2022-08-13 18:48:38,067] {processor.py:163} INFO - Started process (PID=53681) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:48:38,070] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:48:38,073] {logging_mixin.py:109} INFO - [2022-08-13 18:48:38,072] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:48:38,655] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:48:38,665] {logging_mixin.py:109} INFO - [2022-08-13 18:48:38,664] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:48:38,682] {logging_mixin.py:109} INFO - [2022-08-13 18:48:38,682] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:48:38,694] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.631 seconds
[2022-08-13 18:49:09,225] {processor.py:163} INFO - Started process (PID=53751) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:49:09,228] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:49:09,230] {logging_mixin.py:109} INFO - [2022-08-13 18:49:09,230] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:49:09,827] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:49:09,842] {logging_mixin.py:109} INFO - [2022-08-13 18:49:09,841] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:49:09,862] {logging_mixin.py:109} INFO - [2022-08-13 18:49:09,862] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:49:09,879] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.663 seconds
[2022-08-13 18:49:40,689] {processor.py:163} INFO - Started process (PID=53816) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:49:40,692] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:49:40,693] {logging_mixin.py:109} INFO - [2022-08-13 18:49:40,693] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:49:41,234] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:49:41,245] {logging_mixin.py:109} INFO - [2022-08-13 18:49:41,245] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:49:41,260] {logging_mixin.py:109} INFO - [2022-08-13 18:49:41,260] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:49:41,274] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.590 seconds
[2022-08-13 18:50:11,359] {processor.py:163} INFO - Started process (PID=53881) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:50:11,361] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:50:11,363] {logging_mixin.py:109} INFO - [2022-08-13 18:50:11,363] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:50:11,976] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:50:11,989] {logging_mixin.py:109} INFO - [2022-08-13 18:50:11,988] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:50:12,008] {logging_mixin.py:109} INFO - [2022-08-13 18:50:12,008] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:50:12,025] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.669 seconds
[2022-08-13 18:50:42,681] {processor.py:163} INFO - Started process (PID=53955) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:50:42,684] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:50:42,686] {logging_mixin.py:109} INFO - [2022-08-13 18:50:42,685] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:50:43,242] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:50:43,257] {logging_mixin.py:109} INFO - [2022-08-13 18:50:43,256] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:50:43,272] {logging_mixin.py:109} INFO - [2022-08-13 18:50:43,271] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:50:43,281] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.608 seconds
[2022-08-13 18:51:14,071] {processor.py:163} INFO - Started process (PID=54023) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:51:14,075] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:51:14,077] {logging_mixin.py:109} INFO - [2022-08-13 18:51:14,077] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:51:14,632] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:51:14,643] {logging_mixin.py:109} INFO - [2022-08-13 18:51:14,642] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:51:14,664] {logging_mixin.py:109} INFO - [2022-08-13 18:51:14,663] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:51:14,678] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.615 seconds
[2022-08-13 18:51:45,543] {processor.py:163} INFO - Started process (PID=54101) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:51:45,546] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:51:45,548] {logging_mixin.py:109} INFO - [2022-08-13 18:51:45,547] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:51:46,108] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:51:46,117] {logging_mixin.py:109} INFO - [2022-08-13 18:51:46,116] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:51:46,130] {logging_mixin.py:109} INFO - [2022-08-13 18:51:46,130] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:51:46,144] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.607 seconds
[2022-08-13 18:52:16,943] {processor.py:163} INFO - Started process (PID=54166) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:52:16,947] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:52:16,949] {logging_mixin.py:109} INFO - [2022-08-13 18:52:16,949] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:52:17,464] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:52:17,476] {logging_mixin.py:109} INFO - [2022-08-13 18:52:17,475] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:52:17,491] {logging_mixin.py:109} INFO - [2022-08-13 18:52:17,491] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:52:17,500] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.562 seconds
[2022-08-13 18:52:47,561] {processor.py:163} INFO - Started process (PID=54240) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:52:47,563] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:52:47,565] {logging_mixin.py:109} INFO - [2022-08-13 18:52:47,565] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:52:48,115] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:52:48,125] {logging_mixin.py:109} INFO - [2022-08-13 18:52:48,124] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:52:48,138] {logging_mixin.py:109} INFO - [2022-08-13 18:52:48,138] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:52:48,126] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.590 seconds
[2022-08-13 18:53:18,821] {processor.py:163} INFO - Started process (PID=54305) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:53:18,825] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:53:18,826] {logging_mixin.py:109} INFO - [2022-08-13 18:53:18,826] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:53:19,341] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:53:19,353] {logging_mixin.py:109} INFO - [2022-08-13 18:53:19,352] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:53:19,370] {logging_mixin.py:109} INFO - [2022-08-13 18:53:19,370] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:53:19,383] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.568 seconds
[2022-08-13 18:53:50,330] {processor.py:163} INFO - Started process (PID=54383) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:53:50,333] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:53:50,335] {logging_mixin.py:109} INFO - [2022-08-13 18:53:50,335] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:53:50,877] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:53:50,889] {logging_mixin.py:109} INFO - [2022-08-13 18:53:50,889] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:53:50,903] {logging_mixin.py:109} INFO - [2022-08-13 18:53:50,903] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:53:50,914] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.590 seconds
[2022-08-13 18:54:21,649] {processor.py:163} INFO - Started process (PID=54448) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:54:21,652] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:54:21,653] {logging_mixin.py:109} INFO - [2022-08-13 18:54:21,653] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:54:22,202] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:54:22,212] {logging_mixin.py:109} INFO - [2022-08-13 18:54:22,212] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:54:22,227] {logging_mixin.py:109} INFO - [2022-08-13 18:54:22,227] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:54:22,236] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.592 seconds
[2022-08-13 18:54:53,176] {processor.py:163} INFO - Started process (PID=54524) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:54:53,180] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:54:53,182] {logging_mixin.py:109} INFO - [2022-08-13 18:54:53,181] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:54:53,859] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:54:53,872] {logging_mixin.py:109} INFO - [2022-08-13 18:54:53,871] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:54:53,890] {logging_mixin.py:109} INFO - [2022-08-13 18:54:53,890] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:54:53,901] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.737 seconds
[2022-08-13 18:55:24,928] {processor.py:163} INFO - Started process (PID=54589) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:55:24,931] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:55:24,937] {logging_mixin.py:109} INFO - [2022-08-13 18:55:24,937] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:55:25,557] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:55:25,572] {logging_mixin.py:109} INFO - [2022-08-13 18:55:25,572] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:55:25,608] {logging_mixin.py:109} INFO - [2022-08-13 18:55:25,608] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:55:25,619] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.706 seconds
[2022-08-13 18:55:56,576] {processor.py:163} INFO - Started process (PID=54654) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:55:56,579] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:55:56,581] {logging_mixin.py:109} INFO - [2022-08-13 18:55:56,581] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:55:57,237] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:55:57,249] {logging_mixin.py:109} INFO - [2022-08-13 18:55:57,249] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:55:57,268] {logging_mixin.py:109} INFO - [2022-08-13 18:55:57,268] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:55:57,281] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.709 seconds
[2022-08-13 18:56:27,913] {processor.py:163} INFO - Started process (PID=54728) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:56:27,916] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:56:27,918] {logging_mixin.py:109} INFO - [2022-08-13 18:56:27,918] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:56:28,492] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:56:28,503] {logging_mixin.py:109} INFO - [2022-08-13 18:56:28,502] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:56:28,519] {logging_mixin.py:109} INFO - [2022-08-13 18:56:28,519] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:56:28,531] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.623 seconds
[2022-08-13 18:56:59,233] {processor.py:163} INFO - Started process (PID=54794) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:56:59,235] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:56:59,237] {logging_mixin.py:109} INFO - [2022-08-13 18:56:59,236] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:56:59,853] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:56:59,870] {logging_mixin.py:109} INFO - [2022-08-13 18:56:59,869] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:56:59,887] {logging_mixin.py:109} INFO - [2022-08-13 18:56:59,887] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:56:59,902] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.675 seconds
[2022-08-13 18:57:30,349] {processor.py:163} INFO - Started process (PID=54867) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:57:30,352] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:57:30,354] {logging_mixin.py:109} INFO - [2022-08-13 18:57:30,354] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:57:31,149] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:57:31,159] {logging_mixin.py:109} INFO - [2022-08-13 18:57:31,158] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:57:31,176] {logging_mixin.py:109} INFO - [2022-08-13 18:57:31,176] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:57:31,187] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.843 seconds
[2022-08-13 18:58:01,932] {processor.py:163} INFO - Started process (PID=54933) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:58:01,936] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:58:01,938] {logging_mixin.py:109} INFO - [2022-08-13 18:58:01,937] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:58:02,626] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:58:02,639] {logging_mixin.py:109} INFO - [2022-08-13 18:58:02,639] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:58:02,656] {logging_mixin.py:109} INFO - [2022-08-13 18:58:02,656] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:58:02,672] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.745 seconds
[2022-08-13 18:58:33,329] {processor.py:163} INFO - Started process (PID=54997) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:58:33,332] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:58:33,334] {logging_mixin.py:109} INFO - [2022-08-13 18:58:33,334] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:58:33,912] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:58:33,922] {logging_mixin.py:109} INFO - [2022-08-13 18:58:33,922] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:58:33,939] {logging_mixin.py:109} INFO - [2022-08-13 18:58:33,939] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:58:33,951] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.626 seconds
[2022-08-13 18:59:04,941] {processor.py:163} INFO - Started process (PID=55071) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:59:04,944] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:59:04,948] {logging_mixin.py:109} INFO - [2022-08-13 18:59:04,948] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:59:05,615] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:59:05,674] {logging_mixin.py:109} INFO - [2022-08-13 18:59:05,673] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:59:05,707] {logging_mixin.py:109} INFO - [2022-08-13 18:59:05,707] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:59:05,725] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.791 seconds
[2022-08-13 18:59:36,418] {processor.py:163} INFO - Started process (PID=55137) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:59:36,423] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 18:59:36,424] {logging_mixin.py:109} INFO - [2022-08-13 18:59:36,424] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:59:37,038] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 18:59:37,050] {logging_mixin.py:109} INFO - [2022-08-13 18:59:37,049] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 18:59:37,068] {logging_mixin.py:109} INFO - [2022-08-13 18:59:37,068] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 18:59:37,081] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.670 seconds
[2022-08-13 19:00:07,640] {processor.py:163} INFO - Started process (PID=55211) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:00:07,644] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:00:07,646] {logging_mixin.py:109} INFO - [2022-08-13 19:00:07,646] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:00:08,226] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:00:08,238] {logging_mixin.py:109} INFO - [2022-08-13 19:00:08,238] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:00:08,264] {logging_mixin.py:109} INFO - [2022-08-13 19:00:08,264] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:00:08,274] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.646 seconds
[2022-08-13 19:00:39,056] {processor.py:163} INFO - Started process (PID=55277) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:00:39,060] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:00:39,062] {logging_mixin.py:109} INFO - [2022-08-13 19:00:39,062] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:00:39,750] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:00:39,761] {logging_mixin.py:109} INFO - [2022-08-13 19:00:39,760] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:00:39,776] {logging_mixin.py:109} INFO - [2022-08-13 19:00:39,776] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:00:39,786] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.745 seconds
[2022-08-13 19:01:10,069] {processor.py:163} INFO - Started process (PID=55341) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:01:10,071] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:01:10,073] {logging_mixin.py:109} INFO - [2022-08-13 19:01:10,073] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:01:10,680] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:01:10,693] {logging_mixin.py:109} INFO - [2022-08-13 19:01:10,693] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:01:10,709] {logging_mixin.py:109} INFO - [2022-08-13 19:01:10,709] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:01:10,728] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.669 seconds
[2022-08-13 19:01:41,665] {processor.py:163} INFO - Started process (PID=55418) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:01:41,668] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:01:41,670] {logging_mixin.py:109} INFO - [2022-08-13 19:01:41,670] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:01:42,303] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:01:42,313] {logging_mixin.py:109} INFO - [2022-08-13 19:01:42,312] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:01:42,328] {logging_mixin.py:109} INFO - [2022-08-13 19:01:42,328] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:01:42,340] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.685 seconds
[2022-08-13 19:02:12,421] {processor.py:163} INFO - Started process (PID=55483) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:02:12,423] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:02:12,425] {logging_mixin.py:109} INFO - [2022-08-13 19:02:12,425] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:02:12,981] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:02:12,990] {logging_mixin.py:109} INFO - [2022-08-13 19:02:12,990] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:02:13,005] {logging_mixin.py:109} INFO - [2022-08-13 19:02:13,005] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:02:13,015] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.598 seconds
[2022-08-13 19:02:43,846] {processor.py:163} INFO - Started process (PID=55558) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:02:43,848] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:02:43,850] {logging_mixin.py:109} INFO - [2022-08-13 19:02:43,849] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:02:44,418] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:02:44,426] {logging_mixin.py:109} INFO - [2022-08-13 19:02:44,426] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:02:44,445] {logging_mixin.py:109} INFO - [2022-08-13 19:02:44,445] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:02:44,457] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.616 seconds
[2022-08-13 19:03:14,554] {processor.py:163} INFO - Started process (PID=55629) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:03:14,556] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:03:14,558] {logging_mixin.py:109} INFO - [2022-08-13 19:03:14,557] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:03:15,026] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:03:15,036] {logging_mixin.py:109} INFO - [2022-08-13 19:03:15,036] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:03:15,050] {logging_mixin.py:109} INFO - [2022-08-13 19:03:15,050] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:03:15,059] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.510 seconds
[2022-08-13 19:03:45,861] {processor.py:163} INFO - Started process (PID=55704) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:03:45,864] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:03:45,865] {logging_mixin.py:109} INFO - [2022-08-13 19:03:45,865] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:03:46,354] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:03:46,363] {logging_mixin.py:109} INFO - [2022-08-13 19:03:46,362] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:03:46,377] {logging_mixin.py:109} INFO - [2022-08-13 19:03:46,377] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:03:46,387] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.532 seconds
[2022-08-13 19:04:17,217] {processor.py:163} INFO - Started process (PID=55771) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:04:17,220] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:04:17,222] {logging_mixin.py:109} INFO - [2022-08-13 19:04:17,221] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:04:17,681] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:04:17,670] {logging_mixin.py:109} INFO - [2022-08-13 19:04:17,669] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:04:17,682] {logging_mixin.py:109} INFO - [2022-08-13 19:04:17,682] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:04:17,691] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.499 seconds
[2022-08-13 19:04:48,613] {processor.py:163} INFO - Started process (PID=55846) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:04:48,616] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:04:48,618] {logging_mixin.py:109} INFO - [2022-08-13 19:04:48,618] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:04:49,159] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:04:49,170] {logging_mixin.py:109} INFO - [2022-08-13 19:04:49,169] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:04:49,183] {logging_mixin.py:109} INFO - [2022-08-13 19:04:49,182] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:04:49,192] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.587 seconds
[2022-08-13 19:05:19,471] {processor.py:163} INFO - Started process (PID=55913) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:05:19,475] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:05:19,477] {logging_mixin.py:109} INFO - [2022-08-13 19:05:19,477] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:05:20,018] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:05:20,026] {logging_mixin.py:109} INFO - [2022-08-13 19:05:20,026] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:05:20,041] {logging_mixin.py:109} INFO - [2022-08-13 19:05:20,041] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:05:20,052] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.586 seconds
[2022-08-13 19:05:50,945] {processor.py:163} INFO - Started process (PID=55990) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:05:50,947] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:05:50,948] {logging_mixin.py:109} INFO - [2022-08-13 19:05:50,948] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:05:51,545] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:05:51,558] {logging_mixin.py:109} INFO - [2022-08-13 19:05:51,557] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:05:51,575] {logging_mixin.py:109} INFO - [2022-08-13 19:05:51,574] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:05:51,585] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.644 seconds
[2022-08-13 19:06:22,459] {processor.py:163} INFO - Started process (PID=56056) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:06:22,462] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:06:22,465] {logging_mixin.py:109} INFO - [2022-08-13 19:06:22,464] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:06:23,236] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:06:23,247] {logging_mixin.py:109} INFO - [2022-08-13 19:06:23,246] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:06:23,263] {logging_mixin.py:109} INFO - [2022-08-13 19:06:23,262] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:06:23,275] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.825 seconds
[2022-08-13 19:06:54,224] {processor.py:163} INFO - Started process (PID=56132) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:06:54,227] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:06:54,229] {logging_mixin.py:109} INFO - [2022-08-13 19:06:54,228] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:06:54,805] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:06:54,815] {logging_mixin.py:109} INFO - [2022-08-13 19:06:54,814] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:06:54,828] {logging_mixin.py:109} INFO - [2022-08-13 19:06:54,827] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:06:54,837] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.618 seconds
[2022-08-13 19:07:25,144] {processor.py:163} INFO - Started process (PID=56199) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:07:25,147] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:07:25,149] {logging_mixin.py:109} INFO - [2022-08-13 19:07:25,149] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:07:25,751] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:07:25,764] {logging_mixin.py:109} INFO - [2022-08-13 19:07:25,763] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:07:25,779] {logging_mixin.py:109} INFO - [2022-08-13 19:07:25,779] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:07:25,791] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.650 seconds
[2022-08-13 19:07:56,642] {processor.py:163} INFO - Started process (PID=56264) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:07:56,646] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:07:56,648] {logging_mixin.py:109} INFO - [2022-08-13 19:07:56,647] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:07:57,169] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:07:57,178] {logging_mixin.py:109} INFO - [2022-08-13 19:07:57,178] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:07:57,193] {logging_mixin.py:109} INFO - [2022-08-13 19:07:57,193] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:07:57,202] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.566 seconds
[2022-08-13 19:08:27,493] {processor.py:163} INFO - Started process (PID=56339) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:08:27,496] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:08:27,497] {logging_mixin.py:109} INFO - [2022-08-13 19:08:27,497] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:08:28,160] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:08:28,178] {logging_mixin.py:109} INFO - [2022-08-13 19:08:28,177] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:08:28,198] {logging_mixin.py:109} INFO - [2022-08-13 19:08:28,198] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:08:28,212] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.726 seconds
[2022-08-13 19:08:59,085] {processor.py:163} INFO - Started process (PID=56404) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:08:59,088] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:08:59,090] {logging_mixin.py:109} INFO - [2022-08-13 19:08:59,090] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:08:59,683] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:08:59,693] {logging_mixin.py:109} INFO - [2022-08-13 19:08:59,692] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:08:59,708] {logging_mixin.py:109} INFO - [2022-08-13 19:08:59,708] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:08:59,721] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.642 seconds
[2022-08-13 19:09:30,612] {processor.py:163} INFO - Started process (PID=56469) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:09:30,616] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:09:30,618] {logging_mixin.py:109} INFO - [2022-08-13 19:09:30,617] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:09:31,209] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:09:31,219] {logging_mixin.py:109} INFO - [2022-08-13 19:09:31,219] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:09:31,234] {logging_mixin.py:109} INFO - [2022-08-13 19:09:31,234] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:09:31,243] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.640 seconds
[2022-08-13 19:10:02,173] {processor.py:163} INFO - Started process (PID=56543) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:10:02,176] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:10:02,178] {logging_mixin.py:109} INFO - [2022-08-13 19:10:02,178] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:10:02,806] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:10:02,817] {logging_mixin.py:109} INFO - [2022-08-13 19:10:02,817] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:10:02,833] {logging_mixin.py:109} INFO - [2022-08-13 19:10:02,833] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:10:02,846] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.681 seconds
[2022-08-13 19:10:33,559] {processor.py:163} INFO - Started process (PID=56611) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:10:33,563] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:10:33,564] {logging_mixin.py:109} INFO - [2022-08-13 19:10:33,564] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:10:34,180] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:10:34,189] {logging_mixin.py:109} INFO - [2022-08-13 19:10:34,188] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:10:34,203] {logging_mixin.py:109} INFO - [2022-08-13 19:10:34,203] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:10:34,216] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.661 seconds
[2022-08-13 19:11:05,196] {processor.py:163} INFO - Started process (PID=56685) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:11:05,200] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:11:05,201] {logging_mixin.py:109} INFO - [2022-08-13 19:11:05,201] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:11:05,717] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:11:05,729] {logging_mixin.py:109} INFO - [2022-08-13 19:11:05,729] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:11:05,753] {logging_mixin.py:109} INFO - [2022-08-13 19:11:05,753] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:11:05,778] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.589 seconds
[2022-08-13 19:11:36,508] {processor.py:163} INFO - Started process (PID=56750) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:11:36,510] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:11:36,511] {logging_mixin.py:109} INFO - [2022-08-13 19:11:36,511] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:11:37,049] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:11:37,059] {logging_mixin.py:109} INFO - [2022-08-13 19:11:37,058] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:11:37,071] {logging_mixin.py:109} INFO - [2022-08-13 19:11:37,071] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:11:37,080] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.577 seconds
[2022-08-13 19:12:07,359] {processor.py:163} INFO - Started process (PID=56825) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:12:07,363] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:12:07,366] {logging_mixin.py:109} INFO - [2022-08-13 19:12:07,365] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:12:07,987] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:12:07,998] {logging_mixin.py:109} INFO - [2022-08-13 19:12:07,997] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:12:08,011] {logging_mixin.py:109} INFO - [2022-08-13 19:12:08,011] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:12:08,023] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.672 seconds
[2022-08-13 19:12:38,684] {processor.py:163} INFO - Started process (PID=56896) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:12:38,687] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:12:38,689] {logging_mixin.py:109} INFO - [2022-08-13 19:12:38,689] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:12:39,276] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:12:39,286] {logging_mixin.py:109} INFO - [2022-08-13 19:12:39,286] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:12:39,299] {logging_mixin.py:109} INFO - [2022-08-13 19:12:39,299] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:12:39,307] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.642 seconds
[2022-08-13 19:13:09,549] {processor.py:163} INFO - Started process (PID=56966) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:13:09,552] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:13:09,555] {logging_mixin.py:109} INFO - [2022-08-13 19:13:09,555] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:13:10,117] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:13:10,128] {logging_mixin.py:109} INFO - [2022-08-13 19:13:10,128] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:13:10,142] {logging_mixin.py:109} INFO - [2022-08-13 19:13:10,142] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:13:10,153] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.612 seconds
[2022-08-13 19:13:40,462] {processor.py:163} INFO - Started process (PID=57032) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:13:40,467] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:13:40,471] {logging_mixin.py:109} INFO - [2022-08-13 19:13:40,470] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:13:41,338] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:13:41,353] {logging_mixin.py:109} INFO - [2022-08-13 19:13:41,353] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:13:41,376] {logging_mixin.py:109} INFO - [2022-08-13 19:13:41,376] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:13:41,392] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.936 seconds
[2022-08-13 19:14:12,020] {processor.py:163} INFO - Started process (PID=57098) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:14:12,026] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:14:12,029] {logging_mixin.py:109} INFO - [2022-08-13 19:14:12,029] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:14:13,115] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:14:13,139] {logging_mixin.py:109} INFO - [2022-08-13 19:14:13,134] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:14:13,179] {logging_mixin.py:109} INFO - [2022-08-13 19:14:13,179] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:14:13,198] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.193 seconds
[2022-08-13 19:14:43,550] {processor.py:163} INFO - Started process (PID=57168) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:14:43,554] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:14:43,556] {logging_mixin.py:109} INFO - [2022-08-13 19:14:43,555] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:14:44,107] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:14:44,125] {logging_mixin.py:109} INFO - [2022-08-13 19:14:44,124] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:14:44,149] {logging_mixin.py:109} INFO - [2022-08-13 19:14:44,149] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:14:44,171] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.627 seconds
[2022-08-13 19:15:14,602] {processor.py:163} INFO - Started process (PID=57245) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:15:14,604] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:15:14,605] {logging_mixin.py:109} INFO - [2022-08-13 19:15:14,605] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:15:15,162] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:15:15,174] {logging_mixin.py:109} INFO - [2022-08-13 19:15:15,173] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:15:15,191] {logging_mixin.py:109} INFO - [2022-08-13 19:15:15,191] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:15:15,204] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.607 seconds
[2022-08-13 19:15:45,634] {processor.py:163} INFO - Started process (PID=57312) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:15:45,636] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:15:45,639] {logging_mixin.py:109} INFO - [2022-08-13 19:15:45,638] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:15:46,191] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:15:46,200] {logging_mixin.py:109} INFO - [2022-08-13 19:15:46,199] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:15:46,219] {logging_mixin.py:109} INFO - [2022-08-13 19:15:46,219] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:15:46,235] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.605 seconds
[2022-08-13 19:16:16,373] {processor.py:163} INFO - Started process (PID=57387) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:16:16,376] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:16:16,379] {logging_mixin.py:109} INFO - [2022-08-13 19:16:16,379] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:16:17,095] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:16:17,117] {logging_mixin.py:109} INFO - [2022-08-13 19:16:17,116] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:16:17,149] {logging_mixin.py:109} INFO - [2022-08-13 19:16:17,149] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:16:17,170] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.802 seconds
[2022-08-13 19:16:47,676] {processor.py:163} INFO - Started process (PID=57454) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:16:47,678] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:16:47,680] {logging_mixin.py:109} INFO - [2022-08-13 19:16:47,680] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:16:48,325] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:16:48,334] {logging_mixin.py:109} INFO - [2022-08-13 19:16:48,333] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:16:48,347] {logging_mixin.py:109} INFO - [2022-08-13 19:16:48,346] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:16:48,357] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.685 seconds
[2022-08-13 19:17:18,450] {processor.py:163} INFO - Started process (PID=57520) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:17:18,453] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:17:18,455] {logging_mixin.py:109} INFO - [2022-08-13 19:17:18,455] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:17:19,078] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:17:19,088] {logging_mixin.py:109} INFO - [2022-08-13 19:17:19,088] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:17:19,106] {logging_mixin.py:109} INFO - [2022-08-13 19:17:19,106] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:17:19,122] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.676 seconds
[2022-08-13 19:17:49,267] {processor.py:163} INFO - Started process (PID=57595) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:17:49,270] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:17:49,271] {logging_mixin.py:109} INFO - [2022-08-13 19:17:49,271] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:17:49,790] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:17:49,808] {logging_mixin.py:109} INFO - [2022-08-13 19:17:49,807] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:17:49,824] {logging_mixin.py:109} INFO - [2022-08-13 19:17:49,824] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:17:49,834] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.572 seconds
[2022-08-13 19:18:20,664] {processor.py:163} INFO - Started process (PID=57662) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:18:20,667] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:18:20,670] {logging_mixin.py:109} INFO - [2022-08-13 19:18:20,670] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:18:21,307] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:18:21,326] {logging_mixin.py:109} INFO - [2022-08-13 19:18:21,325] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:18:21,343] {logging_mixin.py:109} INFO - [2022-08-13 19:18:21,343] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:18:21,353] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.694 seconds
[2022-08-13 19:18:51,761] {processor.py:163} INFO - Started process (PID=57740) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:18:51,764] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:18:51,765] {logging_mixin.py:109} INFO - [2022-08-13 19:18:51,765] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:18:52,277] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:18:52,286] {logging_mixin.py:109} INFO - [2022-08-13 19:18:52,286] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:18:52,299] {logging_mixin.py:109} INFO - [2022-08-13 19:18:52,299] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:18:52,308] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.550 seconds
[2022-08-13 19:19:23,028] {processor.py:163} INFO - Started process (PID=57806) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:19:23,033] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:19:23,039] {logging_mixin.py:109} INFO - [2022-08-13 19:19:23,039] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:19:23,674] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:19:23,698] {logging_mixin.py:109} INFO - [2022-08-13 19:19:23,697] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:19:23,724] {logging_mixin.py:109} INFO - [2022-08-13 19:19:23,724] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:19:23,741] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.719 seconds
[2022-08-13 19:19:54,175] {processor.py:163} INFO - Started process (PID=57879) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:19:54,177] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:19:54,178] {logging_mixin.py:109} INFO - [2022-08-13 19:19:54,178] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:19:54,715] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:19:54,725] {logging_mixin.py:109} INFO - [2022-08-13 19:19:54,725] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:19:54,740] {logging_mixin.py:109} INFO - [2022-08-13 19:19:54,740] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:19:54,749] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.578 seconds
[2022-08-13 19:20:25,600] {processor.py:163} INFO - Started process (PID=57945) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:20:25,604] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:20:25,606] {logging_mixin.py:109} INFO - [2022-08-13 19:20:25,605] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:20:26,167] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:20:26,176] {logging_mixin.py:109} INFO - [2022-08-13 19:20:26,176] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:20:26,190] {logging_mixin.py:109} INFO - [2022-08-13 19:20:26,190] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:20:26,200] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.603 seconds
[2022-08-13 19:20:56,602] {processor.py:163} INFO - Started process (PID=58020) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:20:56,608] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:20:56,612] {logging_mixin.py:109} INFO - [2022-08-13 19:20:56,611] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:20:57,299] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:20:57,325] {logging_mixin.py:109} INFO - [2022-08-13 19:20:57,325] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:20:57,341] {logging_mixin.py:109} INFO - [2022-08-13 19:20:57,341] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:20:57,371] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.775 seconds
[2022-08-13 19:21:28,328] {processor.py:163} INFO - Started process (PID=58087) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:21:28,331] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:21:28,340] {logging_mixin.py:109} INFO - [2022-08-13 19:21:28,340] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:21:28,973] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:21:28,984] {logging_mixin.py:109} INFO - [2022-08-13 19:21:28,984] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:21:29,000] {logging_mixin.py:109} INFO - [2022-08-13 19:21:28,999] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:21:29,010] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.688 seconds
[2022-08-13 19:21:59,739] {processor.py:163} INFO - Started process (PID=58153) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:21:59,742] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:21:59,744] {logging_mixin.py:109} INFO - [2022-08-13 19:21:59,743] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:22:00,277] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:22:00,286] {logging_mixin.py:109} INFO - [2022-08-13 19:22:00,286] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:22:00,300] {logging_mixin.py:109} INFO - [2022-08-13 19:22:00,300] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:22:00,311] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.579 seconds
[2022-08-13 19:22:30,383] {processor.py:163} INFO - Started process (PID=58229) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:22:30,386] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:22:30,387] {logging_mixin.py:109} INFO - [2022-08-13 19:22:30,387] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:22:30,995] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:22:31,006] {logging_mixin.py:109} INFO - [2022-08-13 19:22:31,005] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:22:31,027] {logging_mixin.py:109} INFO - [2022-08-13 19:22:31,027] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:22:31,041] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.662 seconds
[2022-08-13 19:23:01,344] {processor.py:163} INFO - Started process (PID=58293) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:23:01,347] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:23:01,348] {logging_mixin.py:109} INFO - [2022-08-13 19:23:01,348] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:23:01,911] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:23:01,921] {logging_mixin.py:109} INFO - [2022-08-13 19:23:01,921] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:23:01,945] {logging_mixin.py:109} INFO - [2022-08-13 19:23:01,945] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:23:01,955] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.616 seconds
[2022-08-13 19:23:32,284] {processor.py:163} INFO - Started process (PID=58363) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:23:32,288] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:23:32,293] {logging_mixin.py:109} INFO - [2022-08-13 19:23:32,292] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:23:32,963] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:23:32,977] {logging_mixin.py:109} INFO - [2022-08-13 19:23:32,976] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:23:32,996] {logging_mixin.py:109} INFO - [2022-08-13 19:23:32,996] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:23:33,013] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.737 seconds
[2022-08-13 19:24:03,415] {processor.py:163} INFO - Started process (PID=58428) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:24:03,418] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:24:03,421] {logging_mixin.py:109} INFO - [2022-08-13 19:24:03,421] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:24:04,036] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:24:04,048] {logging_mixin.py:109} INFO - [2022-08-13 19:24:04,048] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:24:04,066] {logging_mixin.py:109} INFO - [2022-08-13 19:24:04,066] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:24:04,077] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.671 seconds
[2022-08-13 19:24:34,753] {processor.py:163} INFO - Started process (PID=58494) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:24:34,756] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:24:34,758] {logging_mixin.py:109} INFO - [2022-08-13 19:24:34,758] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:24:35,267] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:24:35,280] {logging_mixin.py:109} INFO - [2022-08-13 19:24:35,279] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:24:35,294] {logging_mixin.py:109} INFO - [2022-08-13 19:24:35,293] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:24:35,304] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.558 seconds
[2022-08-13 19:25:05,832] {processor.py:163} INFO - Started process (PID=58568) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:25:05,835] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:25:05,836] {logging_mixin.py:109} INFO - [2022-08-13 19:25:05,836] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:25:06,386] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:25:06,397] {logging_mixin.py:109} INFO - [2022-08-13 19:25:06,397] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:25:06,414] {logging_mixin.py:109} INFO - [2022-08-13 19:25:06,414] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:25:06,427] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.600 seconds
[2022-08-13 19:25:36,753] {processor.py:163} INFO - Started process (PID=58636) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:25:36,756] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:25:36,757] {logging_mixin.py:109} INFO - [2022-08-13 19:25:36,757] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:25:37,336] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:25:37,348] {logging_mixin.py:109} INFO - [2022-08-13 19:25:37,347] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:25:37,366] {logging_mixin.py:109} INFO - [2022-08-13 19:25:37,366] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:25:37,380] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.632 seconds
[2022-08-13 19:26:07,441] {processor.py:163} INFO - Started process (PID=58713) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:26:07,443] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:26:07,445] {logging_mixin.py:109} INFO - [2022-08-13 19:26:07,444] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:26:07,998] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:26:08,010] {logging_mixin.py:109} INFO - [2022-08-13 19:26:08,009] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:26:08,028] {logging_mixin.py:109} INFO - [2022-08-13 19:26:08,028] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:26:08,040] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.602 seconds
[2022-08-13 19:26:38,532] {processor.py:163} INFO - Started process (PID=58778) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:26:38,537] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:26:38,539] {logging_mixin.py:109} INFO - [2022-08-13 19:26:38,539] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:26:39,088] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:26:39,098] {logging_mixin.py:109} INFO - [2022-08-13 19:26:39,098] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:26:39,112] {logging_mixin.py:109} INFO - [2022-08-13 19:26:39,112] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:26:39,124] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.595 seconds
[2022-08-13 19:27:09,622] {processor.py:163} INFO - Started process (PID=58851) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:27:09,626] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:27:09,627] {logging_mixin.py:109} INFO - [2022-08-13 19:27:09,627] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:27:10,220] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:27:10,236] {logging_mixin.py:109} INFO - [2022-08-13 19:27:10,235] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:27:10,265] {logging_mixin.py:109} INFO - [2022-08-13 19:27:10,264] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:27:10,280] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.662 seconds
[2022-08-13 19:27:40,547] {processor.py:163} INFO - Started process (PID=58919) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:27:40,549] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:27:40,550] {logging_mixin.py:109} INFO - [2022-08-13 19:27:40,550] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:27:41,098] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:27:41,108] {logging_mixin.py:109} INFO - [2022-08-13 19:27:41,107] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:27:41,128] {logging_mixin.py:109} INFO - [2022-08-13 19:27:41,128] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:27:41,144] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.601 seconds
[2022-08-13 19:28:11,943] {processor.py:163} INFO - Started process (PID=58994) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:28:11,945] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:28:11,947] {logging_mixin.py:109} INFO - [2022-08-13 19:28:11,947] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:28:12,713] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:28:12,729] {logging_mixin.py:109} INFO - [2022-08-13 19:28:12,728] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:28:12,754] {logging_mixin.py:109} INFO - [2022-08-13 19:28:12,754] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:28:12,783] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.846 seconds
[2022-08-13 19:28:42,955] {processor.py:163} INFO - Started process (PID=59059) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:28:42,957] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:28:42,959] {logging_mixin.py:109} INFO - [2022-08-13 19:28:42,958] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:28:43,574] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:28:43,598] {logging_mixin.py:109} INFO - [2022-08-13 19:28:43,593] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:28:43,616] {logging_mixin.py:109} INFO - [2022-08-13 19:28:43,616] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:28:43,630] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.679 seconds
[2022-08-13 19:29:14,020] {processor.py:163} INFO - Started process (PID=59124) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:29:14,023] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:29:14,025] {logging_mixin.py:109} INFO - [2022-08-13 19:29:14,024] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:29:14,569] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:29:14,582] {logging_mixin.py:109} INFO - [2022-08-13 19:29:14,581] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:29:14,595] {logging_mixin.py:109} INFO - [2022-08-13 19:29:14,595] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:29:14,607] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.591 seconds
[2022-08-13 19:29:44,975] {processor.py:163} INFO - Started process (PID=59199) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:29:44,978] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:29:44,979] {logging_mixin.py:109} INFO - [2022-08-13 19:29:44,979] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:29:45,671] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:29:45,683] {logging_mixin.py:109} INFO - [2022-08-13 19:29:45,682] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:29:45,696] {logging_mixin.py:109} INFO - [2022-08-13 19:29:45,696] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:29:45,708] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.737 seconds
[2022-08-13 19:30:15,778] {processor.py:163} INFO - Started process (PID=59266) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:30:15,781] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:30:15,782] {logging_mixin.py:109} INFO - [2022-08-13 19:30:15,782] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:30:16,540] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:30:16,552] {logging_mixin.py:109} INFO - [2022-08-13 19:30:16,552] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:30:16,572] {logging_mixin.py:109} INFO - [2022-08-13 19:30:16,572] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:30:16,585] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.811 seconds
[2022-08-13 19:30:46,719] {processor.py:163} INFO - Started process (PID=59338) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:30:46,721] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:30:46,722] {logging_mixin.py:109} INFO - [2022-08-13 19:30:46,722] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:30:47,286] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:30:47,295] {logging_mixin.py:109} INFO - [2022-08-13 19:30:47,295] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:30:47,311] {logging_mixin.py:109} INFO - [2022-08-13 19:30:47,311] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:30:47,319] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.605 seconds
[2022-08-13 19:31:17,609] {processor.py:163} INFO - Started process (PID=59403) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:31:17,611] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:31:17,613] {logging_mixin.py:109} INFO - [2022-08-13 19:31:17,613] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:31:18,191] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:31:18,202] {logging_mixin.py:109} INFO - [2022-08-13 19:31:18,202] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:31:18,225] {logging_mixin.py:109} INFO - [2022-08-13 19:31:18,225] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:31:18,241] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.636 seconds
[2022-08-13 19:31:48,359] {processor.py:163} INFO - Started process (PID=59472) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:31:48,361] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:31:48,363] {logging_mixin.py:109} INFO - [2022-08-13 19:31:48,363] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:31:48,950] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:31:48,960] {logging_mixin.py:109} INFO - [2022-08-13 19:31:48,959] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:31:48,974] {logging_mixin.py:109} INFO - [2022-08-13 19:31:48,974] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:31:48,985] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.632 seconds
[2022-08-13 19:32:19,607] {processor.py:163} INFO - Started process (PID=59547) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:32:19,610] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:32:19,612] {logging_mixin.py:109} INFO - [2022-08-13 19:32:19,612] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:32:20,214] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:32:20,224] {logging_mixin.py:109} INFO - [2022-08-13 19:32:20,224] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:32:20,239] {logging_mixin.py:109} INFO - [2022-08-13 19:32:20,238] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:32:20,250] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.648 seconds
[2022-08-13 19:32:50,445] {processor.py:163} INFO - Started process (PID=59611) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:32:50,448] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:32:50,450] {logging_mixin.py:109} INFO - [2022-08-13 19:32:50,450] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:32:51,180] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:32:51,190] {logging_mixin.py:109} INFO - [2022-08-13 19:32:51,190] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:32:51,209] {logging_mixin.py:109} INFO - [2022-08-13 19:32:51,209] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:32:51,219] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.781 seconds
[2022-08-13 19:33:21,984] {processor.py:163} INFO - Started process (PID=59686) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:33:21,986] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:33:21,987] {logging_mixin.py:109} INFO - [2022-08-13 19:33:21,987] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:33:22,609] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:33:22,619] {logging_mixin.py:109} INFO - [2022-08-13 19:33:22,619] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:33:22,641] {logging_mixin.py:109} INFO - [2022-08-13 19:33:22,641] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:33:22,655] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.675 seconds
[2022-08-13 19:33:53,269] {processor.py:163} INFO - Started process (PID=59753) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:33:53,272] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:33:53,274] {logging_mixin.py:109} INFO - [2022-08-13 19:33:53,273] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:33:53,975] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:33:53,994] {logging_mixin.py:109} INFO - [2022-08-13 19:33:53,987] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:33:54,019] {logging_mixin.py:109} INFO - [2022-08-13 19:33:54,019] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:33:54,033] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.772 seconds
[2022-08-13 19:34:24,452] {processor.py:163} INFO - Started process (PID=59820) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:34:24,456] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:34:24,459] {logging_mixin.py:109} INFO - [2022-08-13 19:34:24,458] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:34:25,121] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:34:25,134] {logging_mixin.py:109} INFO - [2022-08-13 19:34:25,134] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:34:25,156] {logging_mixin.py:109} INFO - [2022-08-13 19:34:25,156] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:34:25,180] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.732 seconds
[2022-08-13 19:34:55,288] {processor.py:163} INFO - Started process (PID=59893) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:34:55,291] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:34:55,293] {logging_mixin.py:109} INFO - [2022-08-13 19:34:55,293] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:34:55,869] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:34:55,880] {logging_mixin.py:109} INFO - [2022-08-13 19:34:55,879] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:34:55,899] {logging_mixin.py:109} INFO - [2022-08-13 19:34:55,898] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:34:55,912] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.632 seconds
[2022-08-13 19:35:26,476] {processor.py:163} INFO - Started process (PID=59959) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:35:26,481] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:35:26,483] {logging_mixin.py:109} INFO - [2022-08-13 19:35:26,483] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:35:27,066] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:35:27,080] {logging_mixin.py:109} INFO - [2022-08-13 19:35:27,080] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:35:27,097] {logging_mixin.py:109} INFO - [2022-08-13 19:35:27,097] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:35:27,113] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.643 seconds
[2022-08-13 19:35:57,432] {processor.py:163} INFO - Started process (PID=60033) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:35:57,436] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:35:57,438] {logging_mixin.py:109} INFO - [2022-08-13 19:35:57,438] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:35:58,111] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:35:58,124] {logging_mixin.py:109} INFO - [2022-08-13 19:35:58,123] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:35:58,140] {logging_mixin.py:109} INFO - [2022-08-13 19:35:58,140] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:35:58,152] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.726 seconds
[2022-08-13 19:36:28,728] {processor.py:163} INFO - Started process (PID=60099) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:36:28,731] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:36:28,733] {logging_mixin.py:109} INFO - [2022-08-13 19:36:28,733] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:36:29,397] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:36:29,410] {logging_mixin.py:109} INFO - [2022-08-13 19:36:29,409] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:36:29,427] {logging_mixin.py:109} INFO - [2022-08-13 19:36:29,427] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:36:29,440] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.717 seconds
[2022-08-13 19:37:00,202] {processor.py:163} INFO - Started process (PID=60173) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:37:00,204] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:37:00,208] {logging_mixin.py:109} INFO - [2022-08-13 19:37:00,208] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:37:00,840] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:37:00,852] {logging_mixin.py:109} INFO - [2022-08-13 19:37:00,851] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:37:00,872] {logging_mixin.py:109} INFO - [2022-08-13 19:37:00,871] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:37:00,882] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.683 seconds
[2022-08-13 19:37:31,219] {processor.py:163} INFO - Started process (PID=60239) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:37:31,222] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:37:31,223] {logging_mixin.py:109} INFO - [2022-08-13 19:37:31,223] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:37:31,815] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:37:31,826] {logging_mixin.py:109} INFO - [2022-08-13 19:37:31,825] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:37:31,845] {logging_mixin.py:109} INFO - [2022-08-13 19:37:31,845] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:37:31,857] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.642 seconds
[2022-08-13 19:38:01,950] {processor.py:163} INFO - Started process (PID=60304) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:38:01,953] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:38:01,954] {logging_mixin.py:109} INFO - [2022-08-13 19:38:01,954] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:38:02,527] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:38:02,538] {logging_mixin.py:109} INFO - [2022-08-13 19:38:02,538] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:38:02,553] {logging_mixin.py:109} INFO - [2022-08-13 19:38:02,553] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:38:02,567] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.621 seconds
[2022-08-13 19:38:33,017] {processor.py:163} INFO - Started process (PID=60377) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:38:33,020] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:38:33,022] {logging_mixin.py:109} INFO - [2022-08-13 19:38:33,021] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:38:33,625] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:38:33,638] {logging_mixin.py:109} INFO - [2022-08-13 19:38:33,637] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:38:33,656] {logging_mixin.py:109} INFO - [2022-08-13 19:38:33,656] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:38:33,671] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.659 seconds
[2022-08-13 19:39:04,005] {processor.py:163} INFO - Started process (PID=60444) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:39:04,008] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:39:04,010] {logging_mixin.py:109} INFO - [2022-08-13 19:39:04,010] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:39:04,616] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:39:04,631] {logging_mixin.py:109} INFO - [2022-08-13 19:39:04,631] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:39:04,651] {logging_mixin.py:109} INFO - [2022-08-13 19:39:04,651] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:39:04,663] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.662 seconds
[2022-08-13 19:39:35,071] {processor.py:163} INFO - Started process (PID=60520) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:39:35,074] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:39:35,077] {logging_mixin.py:109} INFO - [2022-08-13 19:39:35,076] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:39:35,681] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:39:35,696] {logging_mixin.py:109} INFO - [2022-08-13 19:39:35,695] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:39:35,745] {logging_mixin.py:109} INFO - [2022-08-13 19:39:35,745] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:39:35,802] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.740 seconds
[2022-08-13 19:40:06,743] {processor.py:163} INFO - Started process (PID=60588) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:40:06,745] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:40:06,747] {logging_mixin.py:109} INFO - [2022-08-13 19:40:06,746] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:40:07,286] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:40:07,299] {logging_mixin.py:109} INFO - [2022-08-13 19:40:07,299] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:40:07,322] {logging_mixin.py:109} INFO - [2022-08-13 19:40:07,322] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:40:07,334] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.595 seconds
[2022-08-13 19:40:37,725] {processor.py:163} INFO - Started process (PID=60662) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:40:37,728] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:40:37,730] {logging_mixin.py:109} INFO - [2022-08-13 19:40:37,730] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:40:38,269] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:40:38,281] {logging_mixin.py:109} INFO - [2022-08-13 19:40:38,280] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:40:38,295] {logging_mixin.py:109} INFO - [2022-08-13 19:40:38,295] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:40:38,309] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.587 seconds
[2022-08-13 19:41:08,615] {processor.py:163} INFO - Started process (PID=60727) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:41:08,618] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:41:08,620] {logging_mixin.py:109} INFO - [2022-08-13 19:41:08,619] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:41:09,243] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:41:09,257] {logging_mixin.py:109} INFO - [2022-08-13 19:41:09,256] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:41:09,276] {logging_mixin.py:109} INFO - [2022-08-13 19:41:09,275] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:41:09,290] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.682 seconds
[2022-08-13 19:41:39,566] {processor.py:163} INFO - Started process (PID=60793) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:41:39,568] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:41:39,570] {logging_mixin.py:109} INFO - [2022-08-13 19:41:39,569] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:41:40,389] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:41:40,434] {logging_mixin.py:109} INFO - [2022-08-13 19:41:40,434] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:41:40,478] {logging_mixin.py:109} INFO - [2022-08-13 19:41:40,478] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:41:40,491] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.929 seconds
[2022-08-13 19:42:10,694] {processor.py:163} INFO - Started process (PID=60870) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:42:10,696] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:42:10,698] {logging_mixin.py:109} INFO - [2022-08-13 19:42:10,698] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:42:11,311] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:42:11,320] {logging_mixin.py:109} INFO - [2022-08-13 19:42:11,320] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:42:11,334] {logging_mixin.py:109} INFO - [2022-08-13 19:42:11,334] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:42:11,344] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.656 seconds
[2022-08-13 19:42:41,444] {processor.py:163} INFO - Started process (PID=60935) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:42:41,447] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:42:41,449] {logging_mixin.py:109} INFO - [2022-08-13 19:42:41,449] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:42:42,099] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:42:42,112] {logging_mixin.py:109} INFO - [2022-08-13 19:42:42,112] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:42:42,129] {logging_mixin.py:109} INFO - [2022-08-13 19:42:42,129] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:42:42,139] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.703 seconds
[2022-08-13 19:43:12,350] {processor.py:163} INFO - Started process (PID=61001) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:43:12,354] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:43:12,356] {logging_mixin.py:109} INFO - [2022-08-13 19:43:12,356] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:43:13,098] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:43:13,113] {logging_mixin.py:109} INFO - [2022-08-13 19:43:13,113] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:43:13,137] {logging_mixin.py:109} INFO - [2022-08-13 19:43:13,137] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:43:13,162] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.819 seconds
[2022-08-13 19:43:43,359] {processor.py:163} INFO - Started process (PID=61075) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:43:43,362] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:43:43,365] {logging_mixin.py:109} INFO - [2022-08-13 19:43:43,364] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:43:43,939] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:43:43,950] {logging_mixin.py:109} INFO - [2022-08-13 19:43:43,950] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:43:43,966] {logging_mixin.py:109} INFO - [2022-08-13 19:43:43,966] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:43:43,983] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.632 seconds
[2022-08-13 19:44:14,357] {processor.py:163} INFO - Started process (PID=61142) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:44:14,360] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:44:14,362] {logging_mixin.py:109} INFO - [2022-08-13 19:44:14,362] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:44:15,106] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:44:15,123] {logging_mixin.py:109} INFO - [2022-08-13 19:44:15,123] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:44:15,143] {logging_mixin.py:109} INFO - [2022-08-13 19:44:15,142] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:44:15,158] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.806 seconds
[2022-08-13 19:44:45,321] {processor.py:163} INFO - Started process (PID=61220) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:44:45,325] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:44:45,329] {logging_mixin.py:109} INFO - [2022-08-13 19:44:45,328] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:44:46,215] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:44:46,229] {logging_mixin.py:109} INFO - [2022-08-13 19:44:46,228] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:44:46,254] {logging_mixin.py:109} INFO - [2022-08-13 19:44:46,254] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:44:46,274] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.980 seconds
[2022-08-13 19:45:16,512] {processor.py:163} INFO - Started process (PID=61285) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:45:16,515] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:45:16,518] {logging_mixin.py:109} INFO - [2022-08-13 19:45:16,518] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:45:17,130] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:45:17,142] {logging_mixin.py:109} INFO - [2022-08-13 19:45:17,142] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:45:17,158] {logging_mixin.py:109} INFO - [2022-08-13 19:45:17,158] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:45:17,167] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.662 seconds
[2022-08-13 19:45:47,468] {processor.py:163} INFO - Started process (PID=61351) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:45:47,471] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:45:47,473] {logging_mixin.py:109} INFO - [2022-08-13 19:45:47,473] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:45:48,092] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:45:48,101] {logging_mixin.py:109} INFO - [2022-08-13 19:45:48,100] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:45:48,117] {logging_mixin.py:109} INFO - [2022-08-13 19:45:48,117] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:45:48,128] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.663 seconds
[2022-08-13 19:46:18,309] {processor.py:163} INFO - Started process (PID=61428) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:46:18,312] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:46:18,313] {logging_mixin.py:109} INFO - [2022-08-13 19:46:18,313] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:46:18,823] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:46:18,833] {logging_mixin.py:109} INFO - [2022-08-13 19:46:18,832] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:46:18,846] {logging_mixin.py:109} INFO - [2022-08-13 19:46:18,846] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:46:18,856] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.551 seconds
[2022-08-13 19:46:49,399] {processor.py:163} INFO - Started process (PID=61494) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:46:49,402] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:46:49,403] {logging_mixin.py:109} INFO - [2022-08-13 19:46:49,403] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:46:50,028] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:46:50,040] {logging_mixin.py:109} INFO - [2022-08-13 19:46:50,040] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:46:50,059] {logging_mixin.py:109} INFO - [2022-08-13 19:46:50,059] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:46:50,073] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.678 seconds
[2022-08-13 19:47:20,322] {processor.py:163} INFO - Started process (PID=61559) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:47:20,324] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:47:20,325] {logging_mixin.py:109} INFO - [2022-08-13 19:47:20,325] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:47:20,805] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:47:20,814] {logging_mixin.py:109} INFO - [2022-08-13 19:47:20,814] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:47:20,827] {logging_mixin.py:109} INFO - [2022-08-13 19:47:20,827] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:47:20,836] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.518 seconds
[2022-08-13 19:47:50,953] {processor.py:163} INFO - Started process (PID=61633) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:47:50,955] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:47:50,957] {logging_mixin.py:109} INFO - [2022-08-13 19:47:50,957] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:47:51,433] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:47:51,442] {logging_mixin.py:109} INFO - [2022-08-13 19:47:51,441] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:47:51,455] {logging_mixin.py:109} INFO - [2022-08-13 19:47:51,455] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:47:51,463] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.516 seconds
[2022-08-13 19:48:22,420] {processor.py:163} INFO - Started process (PID=61698) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:48:22,422] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:48:22,423] {logging_mixin.py:109} INFO - [2022-08-13 19:48:22,423] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:48:22,964] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:48:22,973] {logging_mixin.py:109} INFO - [2022-08-13 19:48:22,973] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:48:22,986] {logging_mixin.py:109} INFO - [2022-08-13 19:48:22,986] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:48:22,996] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.580 seconds
[2022-08-13 19:48:53,284] {processor.py:163} INFO - Started process (PID=61772) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:48:53,286] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:48:53,288] {logging_mixin.py:109} INFO - [2022-08-13 19:48:53,288] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:48:53,769] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:48:53,777] {logging_mixin.py:109} INFO - [2022-08-13 19:48:53,777] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:48:53,790] {logging_mixin.py:109} INFO - [2022-08-13 19:48:53,789] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:48:53,798] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.519 seconds
[2022-08-13 19:49:24,551] {processor.py:163} INFO - Started process (PID=61839) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:49:24,554] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:49:24,556] {logging_mixin.py:109} INFO - [2022-08-13 19:49:24,556] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:49:25,098] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:49:25,108] {logging_mixin.py:109} INFO - [2022-08-13 19:49:25,108] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:49:25,124] {logging_mixin.py:109} INFO - [2022-08-13 19:49:25,124] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:49:25,134] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.588 seconds
[2022-08-13 19:49:55,568] {processor.py:163} INFO - Started process (PID=61913) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:49:55,570] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:49:55,572] {logging_mixin.py:109} INFO - [2022-08-13 19:49:55,572] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:49:56,034] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:49:56,042] {logging_mixin.py:109} INFO - [2022-08-13 19:49:56,041] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:49:56,055] {logging_mixin.py:109} INFO - [2022-08-13 19:49:56,055] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:49:56,064] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.500 seconds
[2022-08-13 19:50:26,251] {processor.py:163} INFO - Started process (PID=61978) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:50:26,253] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:50:26,255] {logging_mixin.py:109} INFO - [2022-08-13 19:50:26,255] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:50:26,779] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:50:26,787] {logging_mixin.py:109} INFO - [2022-08-13 19:50:26,787] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:50:26,800] {logging_mixin.py:109} INFO - [2022-08-13 19:50:26,800] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:50:26,811] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.564 seconds
[2022-08-13 19:50:57,237] {processor.py:163} INFO - Started process (PID=62051) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:50:57,239] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:50:57,240] {logging_mixin.py:109} INFO - [2022-08-13 19:50:57,240] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:50:57,760] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:50:57,769] {logging_mixin.py:109} INFO - [2022-08-13 19:50:57,768] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:50:57,782] {logging_mixin.py:109} INFO - [2022-08-13 19:50:57,782] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:50:57,792] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.559 seconds
[2022-08-13 19:51:28,239] {processor.py:163} INFO - Started process (PID=62116) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:51:28,242] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:51:28,243] {logging_mixin.py:109} INFO - [2022-08-13 19:51:28,243] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:51:28,728] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:51:28,737] {logging_mixin.py:109} INFO - [2022-08-13 19:51:28,736] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:51:28,750] {logging_mixin.py:109} INFO - [2022-08-13 19:51:28,749] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:51:28,760] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.526 seconds
[2022-08-13 19:51:58,971] {processor.py:163} INFO - Started process (PID=62182) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:51:58,973] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:51:58,975] {logging_mixin.py:109} INFO - [2022-08-13 19:51:58,975] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:51:59,469] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:51:59,479] {logging_mixin.py:109} INFO - [2022-08-13 19:51:59,478] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:51:59,492] {logging_mixin.py:109} INFO - [2022-08-13 19:51:59,492] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:51:59,504] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.537 seconds
[2022-08-13 19:52:29,965] {processor.py:163} INFO - Started process (PID=62258) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:52:29,967] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:52:29,969] {logging_mixin.py:109} INFO - [2022-08-13 19:52:29,969] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:52:30,524] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:52:30,535] {logging_mixin.py:109} INFO - [2022-08-13 19:52:30,534] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:52:30,557] {logging_mixin.py:109} INFO - [2022-08-13 19:52:30,557] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:52:30,598] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.639 seconds
[2022-08-13 19:53:00,677] {processor.py:163} INFO - Started process (PID=62323) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:53:00,680] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:53:00,682] {logging_mixin.py:109} INFO - [2022-08-13 19:53:00,682] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:53:01,165] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:53:01,175] {logging_mixin.py:109} INFO - [2022-08-13 19:53:01,175] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:53:01,188] {logging_mixin.py:109} INFO - [2022-08-13 19:53:01,188] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:53:01,198] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.525 seconds
[2022-08-13 19:53:31,875] {processor.py:163} INFO - Started process (PID=62397) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:53:31,877] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:53:31,879] {logging_mixin.py:109} INFO - [2022-08-13 19:53:31,879] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:53:32,355] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:53:32,366] {logging_mixin.py:109} INFO - [2022-08-13 19:53:32,366] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:53:32,378] {logging_mixin.py:109} INFO - [2022-08-13 19:53:32,378] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:53:32,387] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.518 seconds
[2022-08-13 19:54:02,585] {processor.py:163} INFO - Started process (PID=62462) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:54:02,587] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:54:02,589] {logging_mixin.py:109} INFO - [2022-08-13 19:54:02,589] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:54:03,137] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:54:03,146] {logging_mixin.py:109} INFO - [2022-08-13 19:54:03,146] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:54:03,162] {logging_mixin.py:109} INFO - [2022-08-13 19:54:03,162] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:54:03,173] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.592 seconds
[2022-08-13 19:54:33,777] {processor.py:163} INFO - Started process (PID=62536) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:54:33,780] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:54:33,782] {logging_mixin.py:109} INFO - [2022-08-13 19:54:33,782] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:54:34,248] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:54:34,260] {logging_mixin.py:109} INFO - [2022-08-13 19:54:34,259] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:54:34,277] {logging_mixin.py:109} INFO - [2022-08-13 19:54:34,277] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:54:34,289] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.517 seconds
[2022-08-13 19:55:04,348] {processor.py:163} INFO - Started process (PID=62601) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:55:04,350] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:55:04,353] {logging_mixin.py:109} INFO - [2022-08-13 19:55:04,352] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:55:04,920] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:55:04,930] {logging_mixin.py:109} INFO - [2022-08-13 19:55:04,929] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:55:04,943] {logging_mixin.py:109} INFO - [2022-08-13 19:55:04,942] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:55:04,954] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.610 seconds
[2022-08-13 19:55:35,400] {processor.py:163} INFO - Started process (PID=62675) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:55:35,403] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:55:35,407] {logging_mixin.py:109} INFO - [2022-08-13 19:55:35,407] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:55:35,897] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:55:35,908] {logging_mixin.py:109} INFO - [2022-08-13 19:55:35,908] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:55:35,925] {logging_mixin.py:109} INFO - [2022-08-13 19:55:35,925] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:55:35,933] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.539 seconds
[2022-08-13 19:56:06,197] {processor.py:163} INFO - Started process (PID=62740) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:56:06,199] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:56:06,200] {logging_mixin.py:109} INFO - [2022-08-13 19:56:06,200] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:56:06,675] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:56:06,686] {logging_mixin.py:109} INFO - [2022-08-13 19:56:06,686] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:56:06,702] {logging_mixin.py:109} INFO - [2022-08-13 19:56:06,702] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:56:06,714] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.521 seconds
[2022-08-13 19:56:36,858] {processor.py:163} INFO - Started process (PID=62808) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:56:36,865] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:56:36,867] {logging_mixin.py:109} INFO - [2022-08-13 19:56:36,866] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:56:37,383] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:56:37,393] {logging_mixin.py:109} INFO - [2022-08-13 19:56:37,393] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:56:37,408] {logging_mixin.py:109} INFO - [2022-08-13 19:56:37,407] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:56:37,420] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.566 seconds
[2022-08-13 19:57:07,997] {processor.py:163} INFO - Started process (PID=62875) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:57:08,000] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:57:08,002] {logging_mixin.py:109} INFO - [2022-08-13 19:57:08,001] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:57:08,530] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:57:08,541] {logging_mixin.py:109} INFO - [2022-08-13 19:57:08,540] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:57:08,554] {logging_mixin.py:109} INFO - [2022-08-13 19:57:08,554] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:57:08,565] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.576 seconds
[2022-08-13 19:57:38,793] {processor.py:163} INFO - Started process (PID=62940) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:57:38,795] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:57:38,797] {logging_mixin.py:109} INFO - [2022-08-13 19:57:38,797] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:57:39,360] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:57:39,374] {logging_mixin.py:109} INFO - [2022-08-13 19:57:39,373] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:57:39,392] {logging_mixin.py:109} INFO - [2022-08-13 19:57:39,391] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:57:39,401] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.615 seconds
[2022-08-13 19:58:09,830] {processor.py:163} INFO - Started process (PID=63014) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:58:09,832] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:58:09,834] {logging_mixin.py:109} INFO - [2022-08-13 19:58:09,834] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:58:10,379] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:58:10,388] {logging_mixin.py:109} INFO - [2022-08-13 19:58:10,388] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:58:10,401] {logging_mixin.py:109} INFO - [2022-08-13 19:58:10,401] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:58:10,415] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.589 seconds
[2022-08-13 19:58:40,590] {processor.py:163} INFO - Started process (PID=63078) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:58:40,592] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:58:40,595] {logging_mixin.py:109} INFO - [2022-08-13 19:58:40,594] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:58:41,065] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:58:41,077] {logging_mixin.py:109} INFO - [2022-08-13 19:58:41,077] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:58:41,094] {logging_mixin.py:109} INFO - [2022-08-13 19:58:41,094] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:58:41,103] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.519 seconds
[2022-08-13 19:59:11,162] {processor.py:163} INFO - Started process (PID=63152) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:59:11,164] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:59:11,166] {logging_mixin.py:109} INFO - [2022-08-13 19:59:11,165] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:59:11,648] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:59:11,659] {logging_mixin.py:109} INFO - [2022-08-13 19:59:11,659] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:59:11,675] {logging_mixin.py:109} INFO - [2022-08-13 19:59:11,675] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:59:11,685] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.529 seconds
[2022-08-13 19:59:41,777] {processor.py:163} INFO - Started process (PID=63217) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:59:41,799] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 19:59:41,801] {logging_mixin.py:109} INFO - [2022-08-13 19:59:41,801] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:59:42,323] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 19:59:42,334] {logging_mixin.py:109} INFO - [2022-08-13 19:59:42,334] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 19:59:42,350] {logging_mixin.py:109} INFO - [2022-08-13 19:59:42,350] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 19:59:42,363] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.590 seconds
[2022-08-13 20:00:12,589] {processor.py:163} INFO - Started process (PID=63291) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:00:12,591] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:00:12,593] {logging_mixin.py:109} INFO - [2022-08-13 20:00:12,593] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:00:13,058] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:00:13,068] {logging_mixin.py:109} INFO - [2022-08-13 20:00:13,068] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:00:13,081] {logging_mixin.py:109} INFO - [2022-08-13 20:00:13,081] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:00:13,088] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.506 seconds
[2022-08-13 20:00:44,019] {processor.py:163} INFO - Started process (PID=63356) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:00:44,022] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:00:44,024] {logging_mixin.py:109} INFO - [2022-08-13 20:00:44,024] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:00:44,507] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:00:44,517] {logging_mixin.py:109} INFO - [2022-08-13 20:00:44,517] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:00:44,531] {logging_mixin.py:109} INFO - [2022-08-13 20:00:44,531] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:00:44,544] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.534 seconds
[2022-08-13 20:01:14,791] {processor.py:163} INFO - Started process (PID=63430) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:01:14,793] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:01:14,794] {logging_mixin.py:109} INFO - [2022-08-13 20:01:14,794] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:01:15,391] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:01:15,399] {logging_mixin.py:109} INFO - [2022-08-13 20:01:15,399] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:01:15,413] {logging_mixin.py:109} INFO - [2022-08-13 20:01:15,413] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:01:15,427] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.639 seconds
[2022-08-13 20:01:45,741] {processor.py:163} INFO - Started process (PID=63495) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:01:45,744] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:01:45,745] {logging_mixin.py:109} INFO - [2022-08-13 20:01:45,745] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:01:46,209] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:01:46,217] {logging_mixin.py:109} INFO - [2022-08-13 20:01:46,217] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:01:46,230] {logging_mixin.py:109} INFO - [2022-08-13 20:01:46,230] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:01:46,239] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.503 seconds
[2022-08-13 20:02:16,457] {processor.py:163} INFO - Started process (PID=63570) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:02:16,459] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:02:16,461] {logging_mixin.py:109} INFO - [2022-08-13 20:02:16,460] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:02:16,970] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:02:16,982] {logging_mixin.py:109} INFO - [2022-08-13 20:02:16,982] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:02:17,002] {logging_mixin.py:109} INFO - [2022-08-13 20:02:17,002] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:02:17,022] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.571 seconds
[2022-08-13 20:02:47,198] {processor.py:163} INFO - Started process (PID=63636) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:02:47,202] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:02:47,204] {logging_mixin.py:109} INFO - [2022-08-13 20:02:47,204] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:02:47,716] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:02:47,725] {logging_mixin.py:109} INFO - [2022-08-13 20:02:47,724] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:02:47,737] {logging_mixin.py:109} INFO - [2022-08-13 20:02:47,737] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:02:47,747] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.554 seconds
[2022-08-13 20:03:18,646] {processor.py:163} INFO - Started process (PID=63701) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:03:18,648] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:03:18,650] {logging_mixin.py:109} INFO - [2022-08-13 20:03:18,650] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:03:19,140] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:03:19,151] {logging_mixin.py:109} INFO - [2022-08-13 20:03:19,151] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:03:19,165] {logging_mixin.py:109} INFO - [2022-08-13 20:03:19,165] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:03:19,176] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.535 seconds
[2022-08-13 20:03:49,723] {processor.py:163} INFO - Started process (PID=63775) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:03:49,726] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:03:49,727] {logging_mixin.py:109} INFO - [2022-08-13 20:03:49,727] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:03:50,293] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:03:50,303] {logging_mixin.py:109} INFO - [2022-08-13 20:03:50,302] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:03:50,316] {logging_mixin.py:109} INFO - [2022-08-13 20:03:50,316] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:03:50,324] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.606 seconds
[2022-08-13 20:04:20,520] {processor.py:163} INFO - Started process (PID=63840) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:04:20,524] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:04:20,526] {logging_mixin.py:109} INFO - [2022-08-13 20:04:20,526] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:04:21,038] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:04:21,049] {logging_mixin.py:109} INFO - [2022-08-13 20:04:21,049] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:04:21,065] {logging_mixin.py:109} INFO - [2022-08-13 20:04:21,065] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:04:21,076] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.561 seconds
[2022-08-13 20:04:51,725] {processor.py:163} INFO - Started process (PID=63914) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:04:51,728] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:04:51,731] {logging_mixin.py:109} INFO - [2022-08-13 20:04:51,731] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:04:52,253] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:04:52,263] {logging_mixin.py:109} INFO - [2022-08-13 20:04:52,262] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:04:52,277] {logging_mixin.py:109} INFO - [2022-08-13 20:04:52,276] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:04:52,287] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.569 seconds
[2022-08-13 20:05:22,399] {processor.py:163} INFO - Started process (PID=63981) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:05:22,401] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:05:22,403] {logging_mixin.py:109} INFO - [2022-08-13 20:05:22,403] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:05:22,937] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:05:22,949] {logging_mixin.py:109} INFO - [2022-08-13 20:05:22,948] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:05:22,965] {logging_mixin.py:109} INFO - [2022-08-13 20:05:22,965] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:05:22,977] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.587 seconds
[2022-08-13 20:05:53,382] {processor.py:163} INFO - Started process (PID=64053) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:05:53,384] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:05:53,386] {logging_mixin.py:109} INFO - [2022-08-13 20:05:53,386] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:05:53,893] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:05:53,902] {logging_mixin.py:109} INFO - [2022-08-13 20:05:53,902] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:05:53,915] {logging_mixin.py:109} INFO - [2022-08-13 20:05:53,914] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:05:53,923] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.546 seconds
[2022-08-13 20:06:24,700] {processor.py:163} INFO - Started process (PID=64120) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:06:24,702] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:06:24,704] {logging_mixin.py:109} INFO - [2022-08-13 20:06:24,704] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:06:25,380] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:06:25,394] {logging_mixin.py:109} INFO - [2022-08-13 20:06:25,393] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:06:25,408] {logging_mixin.py:109} INFO - [2022-08-13 20:06:25,408] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:06:25,418] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.722 seconds
[2022-08-13 20:06:55,910] {processor.py:163} INFO - Started process (PID=64196) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:06:55,913] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:06:55,915] {logging_mixin.py:109} INFO - [2022-08-13 20:06:55,915] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:06:56,423] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:06:56,433] {logging_mixin.py:109} INFO - [2022-08-13 20:06:56,432] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:06:56,445] {logging_mixin.py:109} INFO - [2022-08-13 20:06:56,445] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:06:56,454] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.551 seconds
[2022-08-13 20:07:26,674] {processor.py:163} INFO - Started process (PID=64264) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:07:26,676] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:07:26,678] {logging_mixin.py:109} INFO - [2022-08-13 20:07:26,677] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:07:27,170] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:07:27,179] {logging_mixin.py:109} INFO - [2022-08-13 20:07:27,179] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:07:27,192] {logging_mixin.py:109} INFO - [2022-08-13 20:07:27,192] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:07:27,204] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.533 seconds
[2022-08-13 20:07:57,950] {processor.py:163} INFO - Started process (PID=64340) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:07:57,954] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:07:57,957] {logging_mixin.py:109} INFO - [2022-08-13 20:07:57,956] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:07:58,613] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:07:58,628] {logging_mixin.py:109} INFO - [2022-08-13 20:07:58,627] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:07:58,644] {logging_mixin.py:109} INFO - [2022-08-13 20:07:58,644] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:07:58,658] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.715 seconds
[2022-08-13 20:08:29,568] {processor.py:163} INFO - Started process (PID=64405) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:08:29,571] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:08:29,572] {logging_mixin.py:109} INFO - [2022-08-13 20:08:29,572] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:08:30,149] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:08:30,162] {logging_mixin.py:109} INFO - [2022-08-13 20:08:30,162] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:08:30,182] {logging_mixin.py:109} INFO - [2022-08-13 20:08:30,182] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:08:30,195] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.632 seconds
[2022-08-13 20:09:01,006] {processor.py:163} INFO - Started process (PID=64470) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:09:01,012] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:09:01,013] {logging_mixin.py:109} INFO - [2022-08-13 20:09:01,013] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:09:01,584] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:09:01,595] {logging_mixin.py:109} INFO - [2022-08-13 20:09:01,595] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:09:01,611] {logging_mixin.py:109} INFO - [2022-08-13 20:09:01,611] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:09:01,624] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.623 seconds
[2022-08-13 20:09:32,341] {processor.py:163} INFO - Started process (PID=64544) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:09:32,345] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:09:32,346] {logging_mixin.py:109} INFO - [2022-08-13 20:09:32,346] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:09:32,966] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:09:32,977] {logging_mixin.py:109} INFO - [2022-08-13 20:09:32,977] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:09:32,994] {logging_mixin.py:109} INFO - [2022-08-13 20:09:32,994] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:09:33,005] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.668 seconds
[2022-08-13 20:10:03,166] {processor.py:163} INFO - Started process (PID=64609) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:10:03,169] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:10:03,171] {logging_mixin.py:109} INFO - [2022-08-13 20:10:03,170] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:10:03,736] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:10:03,748] {logging_mixin.py:109} INFO - [2022-08-13 20:10:03,748] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:10:03,764] {logging_mixin.py:109} INFO - [2022-08-13 20:10:03,764] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:10:03,775] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.615 seconds
[2022-08-13 20:10:34,457] {processor.py:163} INFO - Started process (PID=64685) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:10:34,463] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:10:34,464] {logging_mixin.py:109} INFO - [2022-08-13 20:10:34,464] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:10:35,094] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:10:35,105] {logging_mixin.py:109} INFO - [2022-08-13 20:10:35,104] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:10:35,122] {logging_mixin.py:109} INFO - [2022-08-13 20:10:35,121] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:10:35,138] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.687 seconds
[2022-08-13 20:11:05,485] {processor.py:163} INFO - Started process (PID=64751) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:11:05,487] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:11:05,489] {logging_mixin.py:109} INFO - [2022-08-13 20:11:05,489] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:11:06,120] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:11:06,133] {logging_mixin.py:109} INFO - [2022-08-13 20:11:06,132] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:11:06,153] {logging_mixin.py:109} INFO - [2022-08-13 20:11:06,153] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:11:06,168] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.695 seconds
[2022-08-13 20:11:36,772] {processor.py:163} INFO - Started process (PID=64816) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:11:36,775] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:11:36,776] {logging_mixin.py:109} INFO - [2022-08-13 20:11:36,776] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:11:37,405] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:11:37,419] {logging_mixin.py:109} INFO - [2022-08-13 20:11:37,418] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:11:37,436] {logging_mixin.py:109} INFO - [2022-08-13 20:11:37,436] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:11:37,449] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.681 seconds
[2022-08-13 20:12:08,140] {processor.py:163} INFO - Started process (PID=64890) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:12:08,143] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:12:08,144] {logging_mixin.py:109} INFO - [2022-08-13 20:12:08,144] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:12:08,738] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:12:08,749] {logging_mixin.py:109} INFO - [2022-08-13 20:12:08,748] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:12:08,765] {logging_mixin.py:109} INFO - [2022-08-13 20:12:08,765] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:12:08,776] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.641 seconds
[2022-08-13 20:12:39,059] {processor.py:163} INFO - Started process (PID=64955) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:12:39,063] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:12:39,065] {logging_mixin.py:109} INFO - [2022-08-13 20:12:39,065] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:12:39,669] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:12:39,681] {logging_mixin.py:109} INFO - [2022-08-13 20:12:39,679] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:12:39,694] {logging_mixin.py:109} INFO - [2022-08-13 20:12:39,694] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:12:39,706] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.651 seconds
[2022-08-13 20:13:10,305] {processor.py:163} INFO - Started process (PID=65020) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:13:10,309] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:13:10,312] {logging_mixin.py:109} INFO - [2022-08-13 20:13:10,312] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:13:11,026] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:13:11,038] {logging_mixin.py:109} INFO - [2022-08-13 20:13:11,038] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:13:11,055] {logging_mixin.py:109} INFO - [2022-08-13 20:13:11,055] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:13:11,067] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.769 seconds
[2022-08-13 20:13:41,729] {processor.py:163} INFO - Started process (PID=65094) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:13:41,733] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:13:41,734] {logging_mixin.py:109} INFO - [2022-08-13 20:13:41,734] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:13:42,394] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:13:42,405] {logging_mixin.py:109} INFO - [2022-08-13 20:13:42,405] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:13:42,433] {logging_mixin.py:109} INFO - [2022-08-13 20:13:42,433] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:13:42,444] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.720 seconds
[2022-08-13 20:14:13,482] {processor.py:163} INFO - Started process (PID=65160) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:14:13,485] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:14:13,487] {logging_mixin.py:109} INFO - [2022-08-13 20:14:13,487] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:14:14,119] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:14:14,134] {logging_mixin.py:109} INFO - [2022-08-13 20:14:14,133] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:14:14,153] {logging_mixin.py:109} INFO - [2022-08-13 20:14:14,152] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:14:14,168] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.691 seconds
[2022-08-13 20:14:44,895] {processor.py:163} INFO - Started process (PID=65234) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:14:44,900] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:14:44,903] {logging_mixin.py:109} INFO - [2022-08-13 20:14:44,903] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:14:45,489] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:14:45,500] {logging_mixin.py:109} INFO - [2022-08-13 20:14:45,499] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:14:45,516] {logging_mixin.py:109} INFO - [2022-08-13 20:14:45,516] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:14:45,525] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.655 seconds
[2022-08-13 20:15:16,449] {processor.py:163} INFO - Started process (PID=65299) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:15:16,451] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:15:16,453] {logging_mixin.py:109} INFO - [2022-08-13 20:15:16,453] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:15:17,009] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:15:17,021] {logging_mixin.py:109} INFO - [2022-08-13 20:15:17,021] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:15:17,038] {logging_mixin.py:109} INFO - [2022-08-13 20:15:17,038] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:15:17,049] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.607 seconds
[2022-08-13 20:15:47,148] {processor.py:163} INFO - Started process (PID=65365) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:15:47,151] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:15:47,153] {logging_mixin.py:109} INFO - [2022-08-13 20:15:47,153] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:15:47,735] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:15:47,748] {logging_mixin.py:109} INFO - [2022-08-13 20:15:47,748] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:15:47,765] {logging_mixin.py:109} INFO - [2022-08-13 20:15:47,764] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:15:47,777] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.637 seconds
[2022-08-13 20:16:18,718] {processor.py:163} INFO - Started process (PID=65440) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:16:18,721] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:16:18,723] {logging_mixin.py:109} INFO - [2022-08-13 20:16:18,722] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:16:19,284] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:16:19,297] {logging_mixin.py:109} INFO - [2022-08-13 20:16:19,296] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:16:19,313] {logging_mixin.py:109} INFO - [2022-08-13 20:16:19,313] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:16:19,325] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.617 seconds
[2022-08-13 20:16:49,867] {processor.py:163} INFO - Started process (PID=65505) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:16:49,869] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:16:49,871] {logging_mixin.py:109} INFO - [2022-08-13 20:16:49,871] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:16:50,467] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:16:50,477] {logging_mixin.py:109} INFO - [2022-08-13 20:16:50,477] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:16:50,493] {logging_mixin.py:109} INFO - [2022-08-13 20:16:50,493] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:16:50,506] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.645 seconds
[2022-08-13 20:17:20,597] {processor.py:163} INFO - Started process (PID=65580) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:17:20,600] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:17:20,601] {logging_mixin.py:109} INFO - [2022-08-13 20:17:20,601] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:17:21,260] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:17:21,273] {logging_mixin.py:109} INFO - [2022-08-13 20:17:21,273] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:17:21,291] {logging_mixin.py:109} INFO - [2022-08-13 20:17:21,291] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:17:21,303] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.711 seconds
[2022-08-13 20:17:52,232] {processor.py:163} INFO - Started process (PID=65645) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:17:52,235] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:17:52,237] {logging_mixin.py:109} INFO - [2022-08-13 20:17:52,237] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:17:52,859] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:17:52,873] {logging_mixin.py:109} INFO - [2022-08-13 20:17:52,873] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:17:52,891] {logging_mixin.py:109} INFO - [2022-08-13 20:17:52,891] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:17:52,907] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.680 seconds
[2022-08-13 20:18:23,491] {processor.py:163} INFO - Started process (PID=65711) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:18:23,494] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:18:23,495] {logging_mixin.py:109} INFO - [2022-08-13 20:18:23,495] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:18:24,124] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:18:24,136] {logging_mixin.py:109} INFO - [2022-08-13 20:18:24,134] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:18:24,168] {logging_mixin.py:109} INFO - [2022-08-13 20:18:24,168] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:18:24,180] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.694 seconds
[2022-08-13 20:18:54,571] {processor.py:163} INFO - Started process (PID=65785) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:18:54,574] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:18:54,576] {logging_mixin.py:109} INFO - [2022-08-13 20:18:54,576] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:18:55,150] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:18:55,160] {logging_mixin.py:109} INFO - [2022-08-13 20:18:55,160] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:18:55,175] {logging_mixin.py:109} INFO - [2022-08-13 20:18:55,175] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:18:55,186] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.619 seconds
[2022-08-13 20:19:25,385] {processor.py:163} INFO - Started process (PID=65850) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:19:25,388] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:19:25,390] {logging_mixin.py:109} INFO - [2022-08-13 20:19:25,390] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:19:26,028] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:19:26,041] {logging_mixin.py:109} INFO - [2022-08-13 20:19:26,040] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:19:26,061] {logging_mixin.py:109} INFO - [2022-08-13 20:19:26,061] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:19:26,074] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.699 seconds
[2022-08-13 20:19:56,621] {processor.py:163} INFO - Started process (PID=65923) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:19:56,625] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:19:56,626] {logging_mixin.py:109} INFO - [2022-08-13 20:19:56,626] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:19:57,359] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:19:57,376] {logging_mixin.py:109} INFO - [2022-08-13 20:19:57,376] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:19:57,395] {logging_mixin.py:109} INFO - [2022-08-13 20:19:57,395] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:19:57,414] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.797 seconds
[2022-08-13 20:20:27,709] {processor.py:163} INFO - Started process (PID=65988) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:20:27,712] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:20:27,714] {logging_mixin.py:109} INFO - [2022-08-13 20:20:27,714] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:20:28,340] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:20:28,349] {logging_mixin.py:109} INFO - [2022-08-13 20:20:28,349] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:20:28,365] {logging_mixin.py:109} INFO - [2022-08-13 20:20:28,365] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:20:28,377] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.673 seconds
[2022-08-13 20:20:58,684] {processor.py:163} INFO - Started process (PID=66053) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:20:58,688] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:20:58,690] {logging_mixin.py:109} INFO - [2022-08-13 20:20:58,689] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:20:59,318] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:20:59,329] {logging_mixin.py:109} INFO - [2022-08-13 20:20:59,328] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:20:59,344] {logging_mixin.py:109} INFO - [2022-08-13 20:20:59,344] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:20:59,355] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.676 seconds
[2022-08-13 20:21:30,071] {processor.py:163} INFO - Started process (PID=66127) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:21:30,073] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:21:30,075] {logging_mixin.py:109} INFO - [2022-08-13 20:21:30,075] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:21:30,649] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:21:30,662] {logging_mixin.py:109} INFO - [2022-08-13 20:21:30,661] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:21:30,678] {logging_mixin.py:109} INFO - [2022-08-13 20:21:30,678] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:21:30,689] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.625 seconds
[2022-08-13 20:22:00,840] {processor.py:163} INFO - Started process (PID=66192) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:22:00,843] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:22:00,844] {logging_mixin.py:109} INFO - [2022-08-13 20:22:00,844] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:22:01,562] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:22:01,590] {logging_mixin.py:109} INFO - [2022-08-13 20:22:01,590] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:22:01,612] {logging_mixin.py:109} INFO - [2022-08-13 20:22:01,611] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:22:01,631] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.794 seconds
[2022-08-13 20:22:31,729] {processor.py:163} INFO - Started process (PID=66265) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:22:31,731] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:22:31,733] {logging_mixin.py:109} INFO - [2022-08-13 20:22:31,732] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:22:32,387] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:22:32,401] {logging_mixin.py:109} INFO - [2022-08-13 20:22:32,400] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:22:32,425] {logging_mixin.py:109} INFO - [2022-08-13 20:22:32,425] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:22:32,442] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.718 seconds
[2022-08-13 20:23:02,655] {processor.py:163} INFO - Started process (PID=66332) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:23:02,658] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:23:02,662] {logging_mixin.py:109} INFO - [2022-08-13 20:23:02,662] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:23:03,296] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:23:03,307] {logging_mixin.py:109} INFO - [2022-08-13 20:23:03,307] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:23:03,323] {logging_mixin.py:109} INFO - [2022-08-13 20:23:03,323] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:23:03,338] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.691 seconds
[2022-08-13 20:23:34,215] {processor.py:163} INFO - Started process (PID=66399) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:23:34,217] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:23:34,219] {logging_mixin.py:109} INFO - [2022-08-13 20:23:34,218] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:23:34,789] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:23:34,799] {logging_mixin.py:109} INFO - [2022-08-13 20:23:34,799] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:23:34,816] {logging_mixin.py:109} INFO - [2022-08-13 20:23:34,815] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:23:34,827] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.616 seconds
[2022-08-13 20:24:04,998] {processor.py:163} INFO - Started process (PID=66473) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:24:05,002] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:24:05,006] {logging_mixin.py:109} INFO - [2022-08-13 20:24:05,006] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:24:05,714] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:24:05,731] {logging_mixin.py:109} INFO - [2022-08-13 20:24:05,731] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:24:05,748] {logging_mixin.py:109} INFO - [2022-08-13 20:24:05,748] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:24:05,763] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.773 seconds
[2022-08-13 20:24:36,177] {processor.py:163} INFO - Started process (PID=66539) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:24:36,180] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:24:36,182] {logging_mixin.py:109} INFO - [2022-08-13 20:24:36,182] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:24:36,741] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:24:36,750] {logging_mixin.py:109} INFO - [2022-08-13 20:24:36,750] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:24:36,765] {logging_mixin.py:109} INFO - [2022-08-13 20:24:36,765] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:24:36,779] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.606 seconds
[2022-08-13 20:25:07,545] {processor.py:163} INFO - Started process (PID=66604) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:25:07,547] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:25:07,549] {logging_mixin.py:109} INFO - [2022-08-13 20:25:07,549] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:25:08,202] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:25:08,215] {logging_mixin.py:109} INFO - [2022-08-13 20:25:08,214] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:25:08,236] {logging_mixin.py:109} INFO - [2022-08-13 20:25:08,236] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:25:08,250] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.709 seconds
[2022-08-13 20:25:38,448] {processor.py:163} INFO - Started process (PID=66683) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:25:38,450] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:25:38,452] {logging_mixin.py:109} INFO - [2022-08-13 20:25:38,452] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:25:39,068] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:25:39,081] {logging_mixin.py:109} INFO - [2022-08-13 20:25:39,080] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:25:39,097] {logging_mixin.py:109} INFO - [2022-08-13 20:25:39,097] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:25:39,107] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.667 seconds
[2022-08-13 20:26:09,896] {processor.py:163} INFO - Started process (PID=66750) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:26:09,900] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:26:09,901] {logging_mixin.py:109} INFO - [2022-08-13 20:26:09,901] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:26:10,485] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:26:10,497] {logging_mixin.py:109} INFO - [2022-08-13 20:26:10,497] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:26:10,511] {logging_mixin.py:109} INFO - [2022-08-13 20:26:10,511] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:26:10,524] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.639 seconds
[2022-08-13 20:26:41,200] {processor.py:163} INFO - Started process (PID=66823) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:26:41,204] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:26:41,206] {logging_mixin.py:109} INFO - [2022-08-13 20:26:41,206] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:26:41,719] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:26:41,733] {logging_mixin.py:109} INFO - [2022-08-13 20:26:41,732] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:26:41,751] {logging_mixin.py:109} INFO - [2022-08-13 20:26:41,750] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:26:41,763] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.568 seconds
[2022-08-13 20:27:12,479] {processor.py:163} INFO - Started process (PID=66892) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:27:12,481] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:27:12,483] {logging_mixin.py:109} INFO - [2022-08-13 20:27:12,483] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:27:13,072] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:27:13,084] {logging_mixin.py:109} INFO - [2022-08-13 20:27:13,083] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:27:13,099] {logging_mixin.py:109} INFO - [2022-08-13 20:27:13,099] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:27:13,112] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.640 seconds
[2022-08-13 20:27:43,855] {processor.py:163} INFO - Started process (PID=66957) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:27:43,860] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:27:43,862] {logging_mixin.py:109} INFO - [2022-08-13 20:27:43,861] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:27:44,525] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:27:44,537] {logging_mixin.py:109} INFO - [2022-08-13 20:27:44,536] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:27:44,557] {logging_mixin.py:109} INFO - [2022-08-13 20:27:44,557] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:27:44,572] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.723 seconds
[2022-08-13 20:28:15,407] {processor.py:163} INFO - Started process (PID=67032) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:28:15,409] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:28:15,411] {logging_mixin.py:109} INFO - [2022-08-13 20:28:15,411] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:28:15,976] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:28:15,987] {logging_mixin.py:109} INFO - [2022-08-13 20:28:15,986] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:28:16,003] {logging_mixin.py:109} INFO - [2022-08-13 20:28:16,003] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:28:16,014] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.613 seconds
[2022-08-13 20:28:46,292] {processor.py:163} INFO - Started process (PID=67097) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:28:46,296] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:28:46,298] {logging_mixin.py:109} INFO - [2022-08-13 20:28:46,297] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:28:46,881] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:28:46,892] {logging_mixin.py:109} INFO - [2022-08-13 20:28:46,891] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:28:46,909] {logging_mixin.py:109} INFO - [2022-08-13 20:28:46,909] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:28:46,922] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.636 seconds
[2022-08-13 20:29:16,970] {processor.py:163} INFO - Started process (PID=67162) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:29:16,973] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:29:16,975] {logging_mixin.py:109} INFO - [2022-08-13 20:29:16,974] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:29:17,597] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:29:17,615] {logging_mixin.py:109} INFO - [2022-08-13 20:29:17,614] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:29:17,631] {logging_mixin.py:109} INFO - [2022-08-13 20:29:17,631] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:29:17,652] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.686 seconds
[2022-08-13 20:29:48,235] {processor.py:163} INFO - Started process (PID=67235) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:29:48,237] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:29:48,239] {logging_mixin.py:109} INFO - [2022-08-13 20:29:48,239] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:29:48,825] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:29:48,834] {logging_mixin.py:109} INFO - [2022-08-13 20:29:48,834] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:29:48,849] {logging_mixin.py:109} INFO - [2022-08-13 20:29:48,849] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:29:48,860] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.629 seconds
[2022-08-13 20:30:18,949] {processor.py:163} INFO - Started process (PID=67303) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:30:18,951] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:30:18,952] {logging_mixin.py:109} INFO - [2022-08-13 20:30:18,952] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:30:19,518] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:30:19,531] {logging_mixin.py:109} INFO - [2022-08-13 20:30:19,530] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:30:19,547] {logging_mixin.py:109} INFO - [2022-08-13 20:30:19,547] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:30:19,559] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.614 seconds
[2022-08-13 20:30:49,678] {processor.py:163} INFO - Started process (PID=67369) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:30:49,681] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:30:49,683] {logging_mixin.py:109} INFO - [2022-08-13 20:30:49,683] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:30:50,293] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:30:50,306] {logging_mixin.py:109} INFO - [2022-08-13 20:30:50,306] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:30:50,326] {logging_mixin.py:109} INFO - [2022-08-13 20:30:50,326] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:30:50,340] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.678 seconds
[2022-08-13 20:31:20,898] {processor.py:163} INFO - Started process (PID=67443) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:31:20,901] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:31:20,903] {logging_mixin.py:109} INFO - [2022-08-13 20:31:20,902] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:31:21,521] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:31:21,532] {logging_mixin.py:109} INFO - [2022-08-13 20:31:21,531] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:31:21,546] {logging_mixin.py:109} INFO - [2022-08-13 20:31:21,546] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:31:21,560] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.666 seconds
[2022-08-13 20:31:51,670] {processor.py:163} INFO - Started process (PID=67513) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:31:51,674] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:31:51,676] {logging_mixin.py:109} INFO - [2022-08-13 20:31:51,675] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:31:52,258] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:31:52,270] {logging_mixin.py:109} INFO - [2022-08-13 20:31:52,269] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:31:52,285] {logging_mixin.py:109} INFO - [2022-08-13 20:31:52,285] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:31:52,295] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.629 seconds
[2022-08-13 20:32:22,410] {processor.py:163} INFO - Started process (PID=67588) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:32:22,413] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:32:22,415] {logging_mixin.py:109} INFO - [2022-08-13 20:32:22,415] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:32:22,986] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:32:23,001] {logging_mixin.py:109} INFO - [2022-08-13 20:32:23,000] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:32:23,024] {logging_mixin.py:109} INFO - [2022-08-13 20:32:23,024] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:32:23,038] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.634 seconds
[2022-08-13 20:32:53,734] {processor.py:163} INFO - Started process (PID=67653) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:32:53,736] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:32:53,738] {logging_mixin.py:109} INFO - [2022-08-13 20:32:53,738] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:32:54,296] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:32:54,305] {logging_mixin.py:109} INFO - [2022-08-13 20:32:54,305] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:32:54,333] {logging_mixin.py:109} INFO - [2022-08-13 20:32:54,333] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:32:54,349] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.621 seconds
[2022-08-13 20:33:24,503] {processor.py:163} INFO - Started process (PID=67719) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:33:24,505] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:33:24,509] {logging_mixin.py:109} INFO - [2022-08-13 20:33:24,509] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:33:25,238] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:33:25,252] {logging_mixin.py:109} INFO - [2022-08-13 20:33:25,252] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:33:25,281] {logging_mixin.py:109} INFO - [2022-08-13 20:33:25,281] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:33:25,297] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.800 seconds
[2022-08-13 20:33:55,828] {processor.py:163} INFO - Started process (PID=67793) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:33:55,830] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:33:55,834] {logging_mixin.py:109} INFO - [2022-08-13 20:33:55,834] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:33:56,452] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:33:56,462] {logging_mixin.py:109} INFO - [2022-08-13 20:33:56,461] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:33:56,477] {logging_mixin.py:109} INFO - [2022-08-13 20:33:56,477] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:33:56,487] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.664 seconds
[2022-08-13 20:34:27,064] {processor.py:163} INFO - Started process (PID=67859) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:34:27,069] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:34:27,071] {logging_mixin.py:109} INFO - [2022-08-13 20:34:27,071] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:34:27,639] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:34:27,650] {logging_mixin.py:109} INFO - [2022-08-13 20:34:27,649] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:34:27,669] {logging_mixin.py:109} INFO - [2022-08-13 20:34:27,669] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:34:27,679] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.621 seconds
[2022-08-13 20:34:58,231] {processor.py:163} INFO - Started process (PID=67922) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:34:58,235] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:34:58,238] {logging_mixin.py:109} INFO - [2022-08-13 20:34:58,237] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:34:58,897] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:34:58,911] {logging_mixin.py:109} INFO - [2022-08-13 20:34:58,911] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:34:58,928] {logging_mixin.py:109} INFO - [2022-08-13 20:34:58,928] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:34:58,940] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.715 seconds
[2022-08-13 20:35:29,486] {processor.py:163} INFO - Started process (PID=67997) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:35:29,489] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:35:29,490] {logging_mixin.py:109} INFO - [2022-08-13 20:35:29,490] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:35:30,053] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:35:30,064] {logging_mixin.py:109} INFO - [2022-08-13 20:35:30,063] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:35:30,080] {logging_mixin.py:109} INFO - [2022-08-13 20:35:30,080] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:35:30,090] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.610 seconds
[2022-08-13 20:36:00,851] {processor.py:163} INFO - Started process (PID=68062) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:36:00,854] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:36:00,855] {logging_mixin.py:109} INFO - [2022-08-13 20:36:00,855] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:36:01,466] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:36:01,481] {logging_mixin.py:109} INFO - [2022-08-13 20:36:01,481] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:36:01,497] {logging_mixin.py:109} INFO - [2022-08-13 20:36:01,496] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:36:01,508] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.661 seconds
[2022-08-13 20:36:31,689] {processor.py:163} INFO - Started process (PID=68137) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:36:31,690] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:36:31,692] {logging_mixin.py:109} INFO - [2022-08-13 20:36:31,692] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:36:32,337] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:36:32,350] {logging_mixin.py:109} INFO - [2022-08-13 20:36:32,350] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:36:32,371] {logging_mixin.py:109} INFO - [2022-08-13 20:36:32,370] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:36:32,383] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.700 seconds
[2022-08-13 20:37:02,990] {processor.py:163} INFO - Started process (PID=68202) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:37:02,993] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:37:02,994] {logging_mixin.py:109} INFO - [2022-08-13 20:37:02,994] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:37:03,668] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:37:03,679] {logging_mixin.py:109} INFO - [2022-08-13 20:37:03,679] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:37:03,695] {logging_mixin.py:109} INFO - [2022-08-13 20:37:03,695] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:37:03,707] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.721 seconds
[2022-08-13 20:37:34,556] {processor.py:163} INFO - Started process (PID=68267) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:37:34,558] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:37:34,621] {logging_mixin.py:109} INFO - [2022-08-13 20:37:34,621] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:37:35,345] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:37:35,360] {logging_mixin.py:109} INFO - [2022-08-13 20:37:35,359] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:37:35,379] {logging_mixin.py:109} INFO - [2022-08-13 20:37:35,379] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:37:35,391] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.842 seconds
[2022-08-13 20:38:06,062] {processor.py:163} INFO - Started process (PID=68341) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:38:06,069] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:38:06,072] {logging_mixin.py:109} INFO - [2022-08-13 20:38:06,072] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:38:06,678] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:38:06,691] {logging_mixin.py:109} INFO - [2022-08-13 20:38:06,690] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:38:06,706] {logging_mixin.py:109} INFO - [2022-08-13 20:38:06,706] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:38:06,719] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.661 seconds
[2022-08-13 20:38:37,702] {processor.py:163} INFO - Started process (PID=68408) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:38:37,703] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:38:37,705] {logging_mixin.py:109} INFO - [2022-08-13 20:38:37,705] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:38:38,334] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:38:38,345] {logging_mixin.py:109} INFO - [2022-08-13 20:38:38,344] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:38:38,363] {logging_mixin.py:109} INFO - [2022-08-13 20:38:38,363] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:38:38,378] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.680 seconds
[2022-08-13 20:39:09,385] {processor.py:163} INFO - Started process (PID=68482) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:39:09,387] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:39:09,389] {logging_mixin.py:109} INFO - [2022-08-13 20:39:09,389] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:39:10,001] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:39:10,013] {logging_mixin.py:109} INFO - [2022-08-13 20:39:10,012] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:39:10,035] {logging_mixin.py:109} INFO - [2022-08-13 20:39:10,035] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:39:10,050] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.669 seconds
[2022-08-13 20:39:40,698] {processor.py:163} INFO - Started process (PID=68547) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:39:40,702] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:39:40,704] {logging_mixin.py:109} INFO - [2022-08-13 20:39:40,704] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:39:41,256] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:39:41,267] {logging_mixin.py:109} INFO - [2022-08-13 20:39:41,266] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:39:41,283] {logging_mixin.py:109} INFO - [2022-08-13 20:39:41,283] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:39:41,294] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.599 seconds
[2022-08-13 20:40:12,339] {processor.py:163} INFO - Started process (PID=68611) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:40:12,343] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:40:12,345] {logging_mixin.py:109} INFO - [2022-08-13 20:40:12,345] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:40:12,966] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:40:12,978] {logging_mixin.py:109} INFO - [2022-08-13 20:40:12,977] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:40:12,995] {logging_mixin.py:109} INFO - [2022-08-13 20:40:12,995] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:40:13,008] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.673 seconds
[2022-08-13 20:40:43,622] {processor.py:163} INFO - Started process (PID=68686) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:40:43,626] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:40:43,628] {logging_mixin.py:109} INFO - [2022-08-13 20:40:43,628] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:40:44,169] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:40:44,179] {logging_mixin.py:109} INFO - [2022-08-13 20:40:44,179] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:40:44,196] {logging_mixin.py:109} INFO - [2022-08-13 20:40:44,195] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:40:44,187] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.592 seconds
[2022-08-13 20:41:14,736] {processor.py:163} INFO - Started process (PID=68751) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:41:14,740] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:41:14,742] {logging_mixin.py:109} INFO - [2022-08-13 20:41:14,742] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:41:15,316] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:41:15,325] {logging_mixin.py:109} INFO - [2022-08-13 20:41:15,325] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:41:15,343] {logging_mixin.py:109} INFO - [2022-08-13 20:41:15,342] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:41:15,358] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.626 seconds
[2022-08-13 20:41:45,970] {processor.py:163} INFO - Started process (PID=68825) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:41:45,972] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:41:45,974] {logging_mixin.py:109} INFO - [2022-08-13 20:41:45,974] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:41:46,483] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:41:46,499] {logging_mixin.py:109} INFO - [2022-08-13 20:41:46,498] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:41:46,527] {logging_mixin.py:109} INFO - [2022-08-13 20:41:46,526] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:41:46,541] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.574 seconds
[2022-08-13 20:42:17,524] {processor.py:163} INFO - Started process (PID=68890) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:42:17,526] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:42:17,528] {logging_mixin.py:109} INFO - [2022-08-13 20:42:17,527] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:42:18,090] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:42:18,100] {logging_mixin.py:109} INFO - [2022-08-13 20:42:18,099] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:42:18,115] {logging_mixin.py:109} INFO - [2022-08-13 20:42:18,114] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:42:18,126] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.608 seconds
[2022-08-13 20:42:48,776] {processor.py:163} INFO - Started process (PID=68956) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:42:48,778] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:42:48,780] {logging_mixin.py:109} INFO - [2022-08-13 20:42:48,779] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:42:49,426] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:42:49,437] {logging_mixin.py:109} INFO - [2022-08-13 20:42:49,436] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:42:49,452] {logging_mixin.py:109} INFO - [2022-08-13 20:42:49,452] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:42:49,464] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.695 seconds
[2022-08-13 20:43:20,054] {processor.py:163} INFO - Started process (PID=69030) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:43:20,057] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:43:20,059] {logging_mixin.py:109} INFO - [2022-08-13 20:43:20,059] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:43:20,632] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:43:20,645] {logging_mixin.py:109} INFO - [2022-08-13 20:43:20,645] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:43:20,664] {logging_mixin.py:109} INFO - [2022-08-13 20:43:20,664] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:43:20,679] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.632 seconds
[2022-08-13 20:43:51,278] {processor.py:163} INFO - Started process (PID=69096) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:43:51,280] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:43:51,282] {logging_mixin.py:109} INFO - [2022-08-13 20:43:51,281] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:43:51,898] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:43:51,913] {logging_mixin.py:109} INFO - [2022-08-13 20:43:51,912] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:43:51,936] {logging_mixin.py:109} INFO - [2022-08-13 20:43:51,936] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:43:51,953] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.678 seconds
[2022-08-13 20:44:22,763] {processor.py:163} INFO - Started process (PID=69170) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:44:22,765] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:44:22,768] {logging_mixin.py:109} INFO - [2022-08-13 20:44:22,768] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:44:23,379] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:44:23,390] {logging_mixin.py:109} INFO - [2022-08-13 20:44:23,390] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:44:23,407] {logging_mixin.py:109} INFO - [2022-08-13 20:44:23,407] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:44:23,421] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.661 seconds
[2022-08-13 20:44:54,316] {processor.py:163} INFO - Started process (PID=69235) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:44:54,322] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:44:54,324] {logging_mixin.py:109} INFO - [2022-08-13 20:44:54,323] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:44:55,030] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:44:55,042] {logging_mixin.py:109} INFO - [2022-08-13 20:44:55,041] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:44:55,058] {logging_mixin.py:109} INFO - [2022-08-13 20:44:55,057] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:44:55,077] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.768 seconds
[2022-08-13 20:45:25,390] {processor.py:163} INFO - Started process (PID=69305) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:45:25,394] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:45:25,398] {logging_mixin.py:109} INFO - [2022-08-13 20:45:25,397] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:45:26,252] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:45:26,273] {logging_mixin.py:109} INFO - [2022-08-13 20:45:26,272] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:45:26,310] {logging_mixin.py:109} INFO - [2022-08-13 20:45:26,309] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:45:26,325] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.941 seconds
[2022-08-13 20:45:56,388] {processor.py:163} INFO - Started process (PID=69382) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:45:56,390] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:45:56,391] {logging_mixin.py:109} INFO - [2022-08-13 20:45:56,391] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:45:57,033] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:45:57,046] {logging_mixin.py:109} INFO - [2022-08-13 20:45:57,046] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:45:57,064] {logging_mixin.py:109} INFO - [2022-08-13 20:45:57,064] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:45:57,080] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.697 seconds
[2022-08-13 20:46:27,608] {processor.py:163} INFO - Started process (PID=69448) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:46:27,611] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:46:27,614] {logging_mixin.py:109} INFO - [2022-08-13 20:46:27,614] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:46:28,286] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:46:28,299] {logging_mixin.py:109} INFO - [2022-08-13 20:46:28,298] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:46:28,317] {logging_mixin.py:109} INFO - [2022-08-13 20:46:28,317] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:46:28,332] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.735 seconds
[2022-08-13 20:46:58,758] {processor.py:163} INFO - Started process (PID=69522) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:46:58,763] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:46:58,766] {logging_mixin.py:109} INFO - [2022-08-13 20:46:58,765] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:46:59,421] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:46:59,434] {logging_mixin.py:109} INFO - [2022-08-13 20:46:59,433] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:46:59,451] {logging_mixin.py:109} INFO - [2022-08-13 20:46:59,451] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:46:59,465] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.717 seconds
[2022-08-13 20:47:29,810] {processor.py:163} INFO - Started process (PID=69591) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:47:29,815] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:47:29,816] {logging_mixin.py:109} INFO - [2022-08-13 20:47:29,816] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:47:30,485] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:47:30,509] {logging_mixin.py:109} INFO - [2022-08-13 20:47:30,508] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:47:30,536] {logging_mixin.py:109} INFO - [2022-08-13 20:47:30,536] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:47:30,561] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.757 seconds
[2022-08-13 20:48:00,916] {processor.py:163} INFO - Started process (PID=69657) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:48:00,919] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:48:00,922] {logging_mixin.py:109} INFO - [2022-08-13 20:48:00,922] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:48:01,619] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:48:01,633] {logging_mixin.py:109} INFO - [2022-08-13 20:48:01,632] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:48:01,660] {logging_mixin.py:109} INFO - [2022-08-13 20:48:01,659] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:48:01,674] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.764 seconds
[2022-08-13 20:48:32,379] {processor.py:163} INFO - Started process (PID=69735) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:48:32,387] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:48:32,390] {logging_mixin.py:109} INFO - [2022-08-13 20:48:32,390] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:48:33,060] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:48:33,074] {logging_mixin.py:109} INFO - [2022-08-13 20:48:33,074] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:48:33,092] {logging_mixin.py:109} INFO - [2022-08-13 20:48:33,092] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:48:33,105] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.730 seconds
[2022-08-13 20:49:03,453] {processor.py:163} INFO - Started process (PID=69799) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:49:03,455] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:49:03,459] {logging_mixin.py:109} INFO - [2022-08-13 20:49:03,459] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:49:04,102] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:49:04,121] {logging_mixin.py:109} INFO - [2022-08-13 20:49:04,120] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:49:04,151] {logging_mixin.py:109} INFO - [2022-08-13 20:49:04,151] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:49:04,173] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.724 seconds
[2022-08-13 20:49:34,470] {processor.py:163} INFO - Started process (PID=69866) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:49:34,476] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:49:34,477] {logging_mixin.py:109} INFO - [2022-08-13 20:49:34,477] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:49:35,138] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:49:35,150] {logging_mixin.py:109} INFO - [2022-08-13 20:49:35,149] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:49:35,168] {logging_mixin.py:109} INFO - [2022-08-13 20:49:35,168] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:49:35,183] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.720 seconds
[2022-08-13 20:50:05,561] {processor.py:163} INFO - Started process (PID=69941) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:50:05,565] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:50:05,568] {logging_mixin.py:109} INFO - [2022-08-13 20:50:05,568] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:50:06,277] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:50:06,288] {logging_mixin.py:109} INFO - [2022-08-13 20:50:06,288] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:50:06,311] {logging_mixin.py:109} INFO - [2022-08-13 20:50:06,310] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:50:06,322] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.768 seconds
[2022-08-13 20:50:36,668] {processor.py:163} INFO - Started process (PID=70011) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:50:36,670] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:50:36,673] {logging_mixin.py:109} INFO - [2022-08-13 20:50:36,672] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:50:37,249] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:50:37,258] {logging_mixin.py:109} INFO - [2022-08-13 20:50:37,258] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:50:37,273] {logging_mixin.py:109} INFO - [2022-08-13 20:50:37,273] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:50:37,286] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.621 seconds
[2022-08-13 20:51:07,558] {processor.py:163} INFO - Started process (PID=70084) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:51:07,562] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:51:07,564] {logging_mixin.py:109} INFO - [2022-08-13 20:51:07,564] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:51:08,216] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:51:08,229] {logging_mixin.py:109} INFO - [2022-08-13 20:51:08,229] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:51:08,247] {logging_mixin.py:109} INFO - [2022-08-13 20:51:08,247] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:51:08,258] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.714 seconds
[2022-08-13 20:51:39,100] {processor.py:163} INFO - Started process (PID=70152) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:51:39,103] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:51:39,104] {logging_mixin.py:109} INFO - [2022-08-13 20:51:39,104] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:51:39,773] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:51:39,791] {logging_mixin.py:109} INFO - [2022-08-13 20:51:39,790] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:51:39,814] {logging_mixin.py:109} INFO - [2022-08-13 20:51:39,814] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:51:39,826] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.731 seconds
[2022-08-13 20:52:10,118] {processor.py:163} INFO - Started process (PID=70219) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:52:10,121] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:52:10,122] {logging_mixin.py:109} INFO - [2022-08-13 20:52:10,122] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:52:10,837] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:52:10,855] {logging_mixin.py:109} INFO - [2022-08-13 20:52:10,854] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:52:10,876] {logging_mixin.py:109} INFO - [2022-08-13 20:52:10,876] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:52:10,889] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.778 seconds
[2022-08-13 20:52:41,005] {processor.py:163} INFO - Started process (PID=70295) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:52:41,008] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:52:41,014] {logging_mixin.py:109} INFO - [2022-08-13 20:52:41,014] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:52:41,799] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:52:41,812] {logging_mixin.py:109} INFO - [2022-08-13 20:52:41,811] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:52:41,838] {logging_mixin.py:109} INFO - [2022-08-13 20:52:41,838] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:52:41,870] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.870 seconds
[2022-08-13 20:53:11,928] {processor.py:163} INFO - Started process (PID=70360) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:53:11,930] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:53:11,932] {logging_mixin.py:109} INFO - [2022-08-13 20:53:11,932] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:53:12,556] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:53:12,566] {logging_mixin.py:109} INFO - [2022-08-13 20:53:12,565] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:53:12,582] {logging_mixin.py:109} INFO - [2022-08-13 20:53:12,582] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:53:12,592] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.669 seconds
[2022-08-13 20:53:42,770] {processor.py:163} INFO - Started process (PID=70425) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:53:42,773] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:53:42,775] {logging_mixin.py:109} INFO - [2022-08-13 20:53:42,775] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:53:43,475] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:53:43,489] {logging_mixin.py:109} INFO - [2022-08-13 20:53:43,489] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:53:43,506] {logging_mixin.py:109} INFO - [2022-08-13 20:53:43,506] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:53:43,521] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.756 seconds
[2022-08-13 20:54:13,714] {processor.py:163} INFO - Started process (PID=70502) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:54:13,716] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:54:13,719] {logging_mixin.py:109} INFO - [2022-08-13 20:54:13,719] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:54:14,377] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:54:14,388] {logging_mixin.py:109} INFO - [2022-08-13 20:54:14,387] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:54:14,406] {logging_mixin.py:109} INFO - [2022-08-13 20:54:14,406] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:54:14,419] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.732 seconds
[2022-08-13 20:54:44,545] {processor.py:163} INFO - Started process (PID=70568) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:54:44,548] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:54:44,549] {logging_mixin.py:109} INFO - [2022-08-13 20:54:44,549] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:54:45,300] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:54:45,317] {logging_mixin.py:109} INFO - [2022-08-13 20:54:45,316] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:54:45,333] {logging_mixin.py:109} INFO - [2022-08-13 20:54:45,333] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:54:45,345] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.805 seconds
[2022-08-13 20:55:15,484] {processor.py:163} INFO - Started process (PID=70632) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:55:15,487] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:55:15,491] {logging_mixin.py:109} INFO - [2022-08-13 20:55:15,491] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:55:16,232] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:55:16,244] {logging_mixin.py:109} INFO - [2022-08-13 20:55:16,243] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:55:16,264] {logging_mixin.py:109} INFO - [2022-08-13 20:55:16,263] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:55:16,280] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.803 seconds
[2022-08-13 20:55:47,155] {processor.py:163} INFO - Started process (PID=70708) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:55:47,158] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:55:47,160] {logging_mixin.py:109} INFO - [2022-08-13 20:55:47,160] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:55:47,760] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:55:47,771] {logging_mixin.py:109} INFO - [2022-08-13 20:55:47,771] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:55:47,786] {logging_mixin.py:109} INFO - [2022-08-13 20:55:47,786] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:55:47,796] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.645 seconds
[2022-08-13 20:56:18,477] {processor.py:163} INFO - Started process (PID=70774) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:56:18,479] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:56:18,483] {logging_mixin.py:109} INFO - [2022-08-13 20:56:18,482] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:56:19,195] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:56:19,207] {logging_mixin.py:109} INFO - [2022-08-13 20:56:19,206] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:56:19,225] {logging_mixin.py:109} INFO - [2022-08-13 20:56:19,225] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:56:19,239] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.767 seconds
[2022-08-13 20:56:49,395] {processor.py:163} INFO - Started process (PID=70854) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:56:49,397] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:56:49,399] {logging_mixin.py:109} INFO - [2022-08-13 20:56:49,398] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:56:49,998] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:56:50,010] {logging_mixin.py:109} INFO - [2022-08-13 20:56:50,009] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:56:50,029] {logging_mixin.py:109} INFO - [2022-08-13 20:56:50,029] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:56:50,040] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.650 seconds
[2022-08-13 20:57:20,933] {processor.py:163} INFO - Started process (PID=70920) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:57:20,936] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:57:20,938] {logging_mixin.py:109} INFO - [2022-08-13 20:57:20,938] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:57:21,511] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:57:21,521] {logging_mixin.py:109} INFO - [2022-08-13 20:57:21,521] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:57:21,536] {logging_mixin.py:109} INFO - [2022-08-13 20:57:21,535] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:57:21,544] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.617 seconds
[2022-08-13 20:57:52,103] {processor.py:163} INFO - Started process (PID=70985) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:57:52,106] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:57:52,107] {logging_mixin.py:109} INFO - [2022-08-13 20:57:52,107] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:57:52,749] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:57:52,763] {logging_mixin.py:109} INFO - [2022-08-13 20:57:52,762] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:57:52,779] {logging_mixin.py:109} INFO - [2022-08-13 20:57:52,779] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:57:52,790] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.692 seconds
[2022-08-13 20:58:22,927] {processor.py:163} INFO - Started process (PID=71059) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:58:22,931] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:58:22,932] {logging_mixin.py:109} INFO - [2022-08-13 20:58:22,932] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:58:23,567] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:58:23,582] {logging_mixin.py:109} INFO - [2022-08-13 20:58:23,582] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:58:23,600] {logging_mixin.py:109} INFO - [2022-08-13 20:58:23,600] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:58:23,614] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.692 seconds
[2022-08-13 20:58:54,498] {processor.py:163} INFO - Started process (PID=71124) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:58:54,502] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:58:54,504] {logging_mixin.py:109} INFO - [2022-08-13 20:58:54,504] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:58:55,139] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:58:55,152] {logging_mixin.py:109} INFO - [2022-08-13 20:58:55,152] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:58:55,171] {logging_mixin.py:109} INFO - [2022-08-13 20:58:55,171] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:58:55,183] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.695 seconds
[2022-08-13 20:59:25,518] {processor.py:163} INFO - Started process (PID=71191) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:59:25,521] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:59:25,523] {logging_mixin.py:109} INFO - [2022-08-13 20:59:25,523] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:59:26,113] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:59:26,124] {logging_mixin.py:109} INFO - [2022-08-13 20:59:26,123] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:59:26,139] {logging_mixin.py:109} INFO - [2022-08-13 20:59:26,139] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:59:26,152] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.637 seconds
[2022-08-13 20:59:56,430] {processor.py:163} INFO - Started process (PID=71265) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:59:56,432] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 20:59:56,434] {logging_mixin.py:109} INFO - [2022-08-13 20:59:56,434] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:59:57,067] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 20:59:57,078] {logging_mixin.py:109} INFO - [2022-08-13 20:59:57,077] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 20:59:57,094] {logging_mixin.py:109} INFO - [2022-08-13 20:59:57,094] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 20:59:57,106] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.682 seconds
[2022-08-13 21:00:27,491] {processor.py:163} INFO - Started process (PID=71333) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:00:27,493] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:00:27,495] {logging_mixin.py:109} INFO - [2022-08-13 21:00:27,495] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:00:28,124] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:00:28,135] {logging_mixin.py:109} INFO - [2022-08-13 21:00:28,134] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:00:28,151] {logging_mixin.py:109} INFO - [2022-08-13 21:00:28,151] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:00:28,163] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.675 seconds
[2022-08-13 21:00:58,521] {processor.py:163} INFO - Started process (PID=71408) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:00:58,524] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:00:58,525] {logging_mixin.py:109} INFO - [2022-08-13 21:00:58,525] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:00:59,134] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:00:59,144] {logging_mixin.py:109} INFO - [2022-08-13 21:00:59,144] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:00:59,163] {logging_mixin.py:109} INFO - [2022-08-13 21:00:59,163] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:00:59,178] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.661 seconds
[2022-08-13 21:01:29,378] {processor.py:163} INFO - Started process (PID=71474) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:01:29,381] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:01:29,383] {logging_mixin.py:109} INFO - [2022-08-13 21:01:29,383] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:01:29,945] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:01:29,958] {logging_mixin.py:109} INFO - [2022-08-13 21:01:29,957] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:01:29,975] {logging_mixin.py:109} INFO - [2022-08-13 21:01:29,975] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:01:29,993] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.618 seconds
[2022-08-13 21:02:00,477] {processor.py:163} INFO - Started process (PID=71539) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:02:00,479] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:02:00,482] {logging_mixin.py:109} INFO - [2022-08-13 21:02:00,482] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:02:01,096] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:02:01,108] {logging_mixin.py:109} INFO - [2022-08-13 21:02:01,107] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:02:01,135] {logging_mixin.py:109} INFO - [2022-08-13 21:02:01,135] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:02:01,149] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.676 seconds
[2022-08-13 21:02:31,587] {processor.py:163} INFO - Started process (PID=71614) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:02:31,591] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:02:31,594] {logging_mixin.py:109} INFO - [2022-08-13 21:02:31,594] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:02:32,227] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:02:32,241] {logging_mixin.py:109} INFO - [2022-08-13 21:02:32,241] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:02:32,257] {logging_mixin.py:109} INFO - [2022-08-13 21:02:32,257] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:02:32,268] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.695 seconds
[2022-08-13 21:03:02,507] {processor.py:163} INFO - Started process (PID=71680) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:03:02,510] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:03:02,513] {logging_mixin.py:109} INFO - [2022-08-13 21:03:02,512] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:03:03,093] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:03:03,104] {logging_mixin.py:109} INFO - [2022-08-13 21:03:03,104] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:03:03,120] {logging_mixin.py:109} INFO - [2022-08-13 21:03:03,120] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:03:03,131] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.631 seconds
[2022-08-13 21:03:33,830] {processor.py:163} INFO - Started process (PID=71746) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:03:33,834] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:03:33,836] {logging_mixin.py:109} INFO - [2022-08-13 21:03:33,836] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:03:34,399] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:03:34,410] {logging_mixin.py:109} INFO - [2022-08-13 21:03:34,409] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:03:34,430] {logging_mixin.py:109} INFO - [2022-08-13 21:03:34,429] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:03:34,442] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.617 seconds
[2022-08-13 21:04:04,678] {processor.py:163} INFO - Started process (PID=71821) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:04:04,680] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:04:04,682] {logging_mixin.py:109} INFO - [2022-08-13 21:04:04,682] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:04:05,301] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:04:05,312] {logging_mixin.py:109} INFO - [2022-08-13 21:04:05,311] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:04:05,330] {logging_mixin.py:109} INFO - [2022-08-13 21:04:05,330] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:04:05,344] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.671 seconds
[2022-08-13 21:04:35,652] {processor.py:163} INFO - Started process (PID=71886) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:04:35,655] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:04:35,658] {logging_mixin.py:109} INFO - [2022-08-13 21:04:35,658] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:04:36,374] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:04:36,393] {logging_mixin.py:109} INFO - [2022-08-13 21:04:36,392] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:04:36,410] {logging_mixin.py:109} INFO - [2022-08-13 21:04:36,410] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:04:36,432] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.788 seconds
[2022-08-13 21:05:06,588] {processor.py:163} INFO - Started process (PID=71952) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:05:06,591] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:05:06,593] {logging_mixin.py:109} INFO - [2022-08-13 21:05:06,593] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:05:07,162] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:05:07,174] {logging_mixin.py:109} INFO - [2022-08-13 21:05:07,173] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:05:07,192] {logging_mixin.py:109} INFO - [2022-08-13 21:05:07,192] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:05:07,204] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.624 seconds
[2022-08-13 21:05:37,375] {processor.py:163} INFO - Started process (PID=72027) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:05:37,377] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:05:37,379] {logging_mixin.py:109} INFO - [2022-08-13 21:05:37,378] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:05:37,995] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:05:38,006] {logging_mixin.py:109} INFO - [2022-08-13 21:05:38,005] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:05:38,022] {logging_mixin.py:109} INFO - [2022-08-13 21:05:38,022] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:05:38,037] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.669 seconds
[2022-08-13 21:06:08,116] {processor.py:163} INFO - Started process (PID=72093) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:06:08,120] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:06:08,122] {logging_mixin.py:109} INFO - [2022-08-13 21:06:08,122] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:06:08,759] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:06:08,770] {logging_mixin.py:109} INFO - [2022-08-13 21:06:08,769] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:06:08,787] {logging_mixin.py:109} INFO - [2022-08-13 21:06:08,787] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:06:08,798] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.688 seconds
[2022-08-13 21:06:39,009] {processor.py:163} INFO - Started process (PID=72168) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:06:39,011] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:06:39,013] {logging_mixin.py:109} INFO - [2022-08-13 21:06:39,013] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:06:39,615] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:06:39,628] {logging_mixin.py:109} INFO - [2022-08-13 21:06:39,628] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:06:39,646] {logging_mixin.py:109} INFO - [2022-08-13 21:06:39,645] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:06:39,661] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.659 seconds
[2022-08-13 21:07:10,115] {processor.py:163} INFO - Started process (PID=72234) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:07:10,119] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:07:10,120] {logging_mixin.py:109} INFO - [2022-08-13 21:07:10,120] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:07:10,748] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:07:10,764] {logging_mixin.py:109} INFO - [2022-08-13 21:07:10,763] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:07:10,781] {logging_mixin.py:109} INFO - [2022-08-13 21:07:10,781] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:07:10,799] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.693 seconds
[2022-08-13 21:07:41,296] {processor.py:163} INFO - Started process (PID=72299) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:07:41,298] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:07:41,300] {logging_mixin.py:109} INFO - [2022-08-13 21:07:41,299] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:07:41,949] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:07:41,961] {logging_mixin.py:109} INFO - [2022-08-13 21:07:41,961] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:07:41,978] {logging_mixin.py:109} INFO - [2022-08-13 21:07:41,977] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:07:41,994] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.703 seconds
[2022-08-13 21:08:12,117] {processor.py:163} INFO - Started process (PID=72373) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:08:12,119] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:08:12,121] {logging_mixin.py:109} INFO - [2022-08-13 21:08:12,121] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:08:12,812] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:08:12,822] {logging_mixin.py:109} INFO - [2022-08-13 21:08:12,821] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:08:12,837] {logging_mixin.py:109} INFO - [2022-08-13 21:08:12,837] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:08:12,849] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.735 seconds
[2022-08-13 21:08:43,268] {processor.py:163} INFO - Started process (PID=72439) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:08:43,271] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:08:43,274] {logging_mixin.py:109} INFO - [2022-08-13 21:08:43,274] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:08:43,865] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:08:43,877] {logging_mixin.py:109} INFO - [2022-08-13 21:08:43,876] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:08:43,892] {logging_mixin.py:109} INFO - [2022-08-13 21:08:43,892] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:08:43,903] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.641 seconds
[2022-08-13 21:09:14,734] {processor.py:163} INFO - Started process (PID=72503) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:09:14,736] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:09:14,738] {logging_mixin.py:109} INFO - [2022-08-13 21:09:14,738] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:09:15,342] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:09:15,352] {logging_mixin.py:109} INFO - [2022-08-13 21:09:15,351] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:09:15,367] {logging_mixin.py:109} INFO - [2022-08-13 21:09:15,367] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:09:15,379] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.652 seconds
[2022-08-13 21:09:45,527] {processor.py:163} INFO - Started process (PID=72578) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:09:45,529] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:09:45,531] {logging_mixin.py:109} INFO - [2022-08-13 21:09:45,531] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:09:46,191] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:09:46,203] {logging_mixin.py:109} INFO - [2022-08-13 21:09:46,202] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:09:46,219] {logging_mixin.py:109} INFO - [2022-08-13 21:09:46,219] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:09:46,234] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.711 seconds
[2022-08-13 21:10:16,605] {processor.py:163} INFO - Started process (PID=72643) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:10:16,608] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:10:16,610] {logging_mixin.py:109} INFO - [2022-08-13 21:10:16,609] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:10:17,280] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:10:17,292] {logging_mixin.py:109} INFO - [2022-08-13 21:10:17,291] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:10:17,309] {logging_mixin.py:109} INFO - [2022-08-13 21:10:17,309] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:10:17,328] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.731 seconds
[2022-08-13 21:10:47,932] {processor.py:163} INFO - Started process (PID=72717) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:10:47,935] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:10:47,937] {logging_mixin.py:109} INFO - [2022-08-13 21:10:47,937] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:10:48,551] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:10:48,563] {logging_mixin.py:109} INFO - [2022-08-13 21:10:48,563] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:10:48,580] {logging_mixin.py:109} INFO - [2022-08-13 21:10:48,580] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:10:48,594] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.667 seconds
[2022-08-13 21:11:18,871] {processor.py:163} INFO - Started process (PID=72783) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:11:18,873] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:11:18,876] {logging_mixin.py:109} INFO - [2022-08-13 21:11:18,875] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:11:19,481] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:11:19,493] {logging_mixin.py:109} INFO - [2022-08-13 21:11:19,492] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:11:19,508] {logging_mixin.py:109} INFO - [2022-08-13 21:11:19,508] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:11:19,529] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.666 seconds
[2022-08-13 21:11:49,660] {processor.py:163} INFO - Started process (PID=72848) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:11:49,662] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:11:49,664] {logging_mixin.py:109} INFO - [2022-08-13 21:11:49,664] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:11:50,294] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:11:50,305] {logging_mixin.py:109} INFO - [2022-08-13 21:11:50,305] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:11:50,322] {logging_mixin.py:109} INFO - [2022-08-13 21:11:50,322] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:11:50,334] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.679 seconds
[2022-08-13 21:12:20,698] {processor.py:163} INFO - Started process (PID=72926) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:12:20,702] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:12:20,704] {logging_mixin.py:109} INFO - [2022-08-13 21:12:20,703] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:12:21,315] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:12:21,327] {logging_mixin.py:109} INFO - [2022-08-13 21:12:21,327] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:12:21,344] {logging_mixin.py:109} INFO - [2022-08-13 21:12:21,344] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:12:21,356] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.662 seconds
[2022-08-13 21:12:51,555] {processor.py:163} INFO - Started process (PID=72991) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:12:51,558] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:12:51,560] {logging_mixin.py:109} INFO - [2022-08-13 21:12:51,560] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:12:52,228] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:12:52,248] {logging_mixin.py:109} INFO - [2022-08-13 21:12:52,247] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:12:52,269] {logging_mixin.py:109} INFO - [2022-08-13 21:12:52,269] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:12:52,289] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.740 seconds
[2022-08-13 21:13:23,022] {processor.py:163} INFO - Started process (PID=73052) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:13:23,025] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:13:23,028] {logging_mixin.py:109} INFO - [2022-08-13 21:13:23,027] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:13:23,680] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:13:23,692] {logging_mixin.py:109} INFO - [2022-08-13 21:13:23,691] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:13:23,709] {logging_mixin.py:109} INFO - [2022-08-13 21:13:23,708] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:13:23,722] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.707 seconds
[2022-08-13 21:13:54,684] {processor.py:163} INFO - Started process (PID=73126) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:13:54,688] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:13:54,690] {logging_mixin.py:109} INFO - [2022-08-13 21:13:54,690] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:13:55,298] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:13:55,310] {logging_mixin.py:109} INFO - [2022-08-13 21:13:55,309] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:13:55,329] {logging_mixin.py:109} INFO - [2022-08-13 21:13:55,328] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:13:55,344] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.665 seconds
[2022-08-13 21:14:25,701] {processor.py:163} INFO - Started process (PID=73191) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:14:25,705] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:14:25,707] {logging_mixin.py:109} INFO - [2022-08-13 21:14:25,707] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:14:26,356] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:14:26,369] {logging_mixin.py:109} INFO - [2022-08-13 21:14:26,369] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:14:26,390] {logging_mixin.py:109} INFO - [2022-08-13 21:14:26,390] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:14:26,406] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.709 seconds
[2022-08-13 21:14:57,365] {processor.py:163} INFO - Started process (PID=73265) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:14:57,367] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:14:57,370] {logging_mixin.py:109} INFO - [2022-08-13 21:14:57,369] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:14:58,117] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:14:58,130] {logging_mixin.py:109} INFO - [2022-08-13 21:14:58,129] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:14:58,149] {logging_mixin.py:109} INFO - [2022-08-13 21:14:58,149] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:14:58,169] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.808 seconds
[2022-08-13 21:15:29,052] {processor.py:163} INFO - Started process (PID=73330) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:15:29,055] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:15:29,057] {logging_mixin.py:109} INFO - [2022-08-13 21:15:29,057] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:15:29,692] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:15:29,704] {logging_mixin.py:109} INFO - [2022-08-13 21:15:29,703] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:15:29,723] {logging_mixin.py:109} INFO - [2022-08-13 21:15:29,722] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:15:29,743] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.697 seconds
[2022-08-13 21:15:59,837] {processor.py:163} INFO - Started process (PID=73395) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:15:59,844] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:15:59,847] {logging_mixin.py:109} INFO - [2022-08-13 21:15:59,847] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:16:00,476] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:16:00,487] {logging_mixin.py:109} INFO - [2022-08-13 21:16:00,486] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:16:00,503] {logging_mixin.py:109} INFO - [2022-08-13 21:16:00,503] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:16:00,516] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.687 seconds
[2022-08-13 21:16:31,372] {processor.py:163} INFO - Started process (PID=73469) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:16:31,377] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:16:31,379] {logging_mixin.py:109} INFO - [2022-08-13 21:16:31,379] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:16:32,002] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:16:32,018] {logging_mixin.py:109} INFO - [2022-08-13 21:16:32,018] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:16:32,054] {logging_mixin.py:109} INFO - [2022-08-13 21:16:32,054] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:16:32,069] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.702 seconds
[2022-08-13 21:17:02,135] {processor.py:163} INFO - Started process (PID=73536) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:17:02,138] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:17:02,140] {logging_mixin.py:109} INFO - [2022-08-13 21:17:02,139] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:17:02,778] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:17:02,789] {logging_mixin.py:109} INFO - [2022-08-13 21:17:02,788] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:17:02,806] {logging_mixin.py:109} INFO - [2022-08-13 21:17:02,806] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:17:02,819] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.695 seconds
[2022-08-13 21:17:33,336] {processor.py:163} INFO - Started process (PID=73601) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:17:33,339] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:17:33,340] {logging_mixin.py:109} INFO - [2022-08-13 21:17:33,340] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:17:33,945] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:17:33,965] {logging_mixin.py:109} INFO - [2022-08-13 21:17:33,964] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:17:33,986] {logging_mixin.py:109} INFO - [2022-08-13 21:17:33,986] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:17:34,001] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.669 seconds
[2022-08-13 21:18:04,080] {processor.py:163} INFO - Started process (PID=73675) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:18:04,083] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:18:04,085] {logging_mixin.py:109} INFO - [2022-08-13 21:18:04,085] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:18:04,657] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:18:04,668] {logging_mixin.py:109} INFO - [2022-08-13 21:18:04,668] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:18:04,684] {logging_mixin.py:109} INFO - [2022-08-13 21:18:04,684] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:18:04,695] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.624 seconds
[2022-08-13 21:18:34,999] {processor.py:163} INFO - Started process (PID=73741) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:18:35,002] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:18:35,004] {logging_mixin.py:109} INFO - [2022-08-13 21:18:35,004] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:18:35,636] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:18:35,646] {logging_mixin.py:109} INFO - [2022-08-13 21:18:35,646] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:18:35,662] {logging_mixin.py:109} INFO - [2022-08-13 21:18:35,662] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:18:35,673] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.681 seconds
[2022-08-13 21:19:05,923] {processor.py:163} INFO - Started process (PID=73815) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:19:05,925] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:19:05,927] {logging_mixin.py:109} INFO - [2022-08-13 21:19:05,927] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:19:06,609] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:19:06,624] {logging_mixin.py:109} INFO - [2022-08-13 21:19:06,623] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:19:06,648] {logging_mixin.py:109} INFO - [2022-08-13 21:19:06,648] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:19:06,664] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.747 seconds
[2022-08-13 21:19:37,605] {processor.py:163} INFO - Started process (PID=73881) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:19:37,607] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:19:37,608] {logging_mixin.py:109} INFO - [2022-08-13 21:19:37,608] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:19:38,213] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:19:38,225] {logging_mixin.py:109} INFO - [2022-08-13 21:19:38,225] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:19:38,247] {logging_mixin.py:109} INFO - [2022-08-13 21:19:38,247] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:19:38,263] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.664 seconds
[2022-08-13 21:20:08,410] {processor.py:163} INFO - Started process (PID=73948) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:20:08,412] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:20:08,414] {logging_mixin.py:109} INFO - [2022-08-13 21:20:08,414] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:20:09,031] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:20:09,043] {logging_mixin.py:109} INFO - [2022-08-13 21:20:09,042] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:20:09,063] {logging_mixin.py:109} INFO - [2022-08-13 21:20:09,062] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:20:09,073] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.667 seconds
[2022-08-13 21:20:39,157] {processor.py:163} INFO - Started process (PID=74026) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:20:39,160] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:20:39,162] {logging_mixin.py:109} INFO - [2022-08-13 21:20:39,162] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:20:39,765] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:20:39,776] {logging_mixin.py:109} INFO - [2022-08-13 21:20:39,776] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:20:39,795] {logging_mixin.py:109} INFO - [2022-08-13 21:20:39,795] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:20:39,808] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.654 seconds
[2022-08-13 21:21:10,516] {processor.py:163} INFO - Started process (PID=74092) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:21:10,518] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:21:10,520] {logging_mixin.py:109} INFO - [2022-08-13 21:21:10,520] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:21:11,118] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:21:11,131] {logging_mixin.py:109} INFO - [2022-08-13 21:21:11,130] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:21:11,148] {logging_mixin.py:109} INFO - [2022-08-13 21:21:11,148] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:21:11,160] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.651 seconds
[2022-08-13 21:21:41,225] {processor.py:163} INFO - Started process (PID=74157) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:21:41,228] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:21:41,230] {logging_mixin.py:109} INFO - [2022-08-13 21:21:41,230] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:21:41,818] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:21:41,830] {logging_mixin.py:109} INFO - [2022-08-13 21:21:41,828] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:21:41,848] {logging_mixin.py:109} INFO - [2022-08-13 21:21:41,847] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:21:41,859] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.641 seconds
[2022-08-13 21:22:12,007] {processor.py:163} INFO - Started process (PID=74234) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:22:12,011] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:22:12,013] {logging_mixin.py:109} INFO - [2022-08-13 21:22:12,013] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:22:12,599] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:22:12,609] {logging_mixin.py:109} INFO - [2022-08-13 21:22:12,608] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:22:12,624] {logging_mixin.py:109} INFO - [2022-08-13 21:22:12,624] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:22:12,637] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.636 seconds
[2022-08-13 21:22:43,284] {processor.py:163} INFO - Started process (PID=74299) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:22:43,285] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:22:43,287] {logging_mixin.py:109} INFO - [2022-08-13 21:22:43,287] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:22:43,939] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:22:43,953] {logging_mixin.py:109} INFO - [2022-08-13 21:22:43,952] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:22:43,971] {logging_mixin.py:109} INFO - [2022-08-13 21:22:43,970] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:22:43,985] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.706 seconds
[2022-08-13 21:23:14,880] {processor.py:163} INFO - Started process (PID=74374) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:23:14,883] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:23:14,884] {logging_mixin.py:109} INFO - [2022-08-13 21:23:14,884] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:23:15,488] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:23:15,499] {logging_mixin.py:109} INFO - [2022-08-13 21:23:15,499] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:23:15,515] {logging_mixin.py:109} INFO - [2022-08-13 21:23:15,515] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:23:15,529] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.653 seconds
[2022-08-13 21:23:46,097] {processor.py:163} INFO - Started process (PID=74439) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:23:46,099] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:23:46,101] {logging_mixin.py:109} INFO - [2022-08-13 21:23:46,101] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:23:46,706] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:23:46,720] {logging_mixin.py:109} INFO - [2022-08-13 21:23:46,719] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:23:46,738] {logging_mixin.py:109} INFO - [2022-08-13 21:23:46,738] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:23:46,751] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.660 seconds
[2022-08-13 21:24:17,449] {processor.py:163} INFO - Started process (PID=74504) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:24:17,452] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:24:17,454] {logging_mixin.py:109} INFO - [2022-08-13 21:24:17,454] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:24:18,116] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:24:18,128] {logging_mixin.py:109} INFO - [2022-08-13 21:24:18,127] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:24:18,143] {logging_mixin.py:109} INFO - [2022-08-13 21:24:18,142] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:24:18,154] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.711 seconds
[2022-08-13 21:24:48,781] {processor.py:163} INFO - Started process (PID=74578) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:24:48,784] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:24:48,786] {logging_mixin.py:109} INFO - [2022-08-13 21:24:48,785] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:24:49,383] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:24:49,392] {logging_mixin.py:109} INFO - [2022-08-13 21:24:49,392] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:24:49,407] {logging_mixin.py:109} INFO - [2022-08-13 21:24:49,407] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:24:49,420] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.644 seconds
[2022-08-13 21:25:20,420] {processor.py:163} INFO - Started process (PID=74644) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:25:20,422] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:25:20,425] {logging_mixin.py:109} INFO - [2022-08-13 21:25:20,424] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:25:21,086] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:25:21,097] {logging_mixin.py:109} INFO - [2022-08-13 21:25:21,096] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:25:21,110] {logging_mixin.py:109} INFO - [2022-08-13 21:25:21,110] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:25:21,123] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.708 seconds
[2022-08-13 21:25:51,907] {processor.py:163} INFO - Started process (PID=74709) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:25:51,912] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:25:51,914] {logging_mixin.py:109} INFO - [2022-08-13 21:25:51,914] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:25:52,535] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:25:52,546] {logging_mixin.py:109} INFO - [2022-08-13 21:25:52,546] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:25:52,563] {logging_mixin.py:109} INFO - [2022-08-13 21:25:52,563] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:25:52,575] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.674 seconds
[2022-08-13 21:26:22,661] {processor.py:163} INFO - Started process (PID=74785) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:26:22,664] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:26:22,666] {logging_mixin.py:109} INFO - [2022-08-13 21:26:22,666] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:26:23,278] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:26:23,290] {logging_mixin.py:109} INFO - [2022-08-13 21:26:23,290] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:26:23,307] {logging_mixin.py:109} INFO - [2022-08-13 21:26:23,306] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:26:23,317] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.660 seconds
[2022-08-13 21:26:54,043] {processor.py:163} INFO - Started process (PID=74851) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:26:54,046] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:26:54,048] {logging_mixin.py:109} INFO - [2022-08-13 21:26:54,048] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:26:54,686] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:26:54,701] {logging_mixin.py:109} INFO - [2022-08-13 21:26:54,701] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:26:54,719] {logging_mixin.py:109} INFO - [2022-08-13 21:26:54,719] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:26:54,731] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.693 seconds
[2022-08-13 21:27:25,569] {processor.py:163} INFO - Started process (PID=74927) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:27:25,572] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:27:25,574] {logging_mixin.py:109} INFO - [2022-08-13 21:27:25,574] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:27:26,201] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:27:26,215] {logging_mixin.py:109} INFO - [2022-08-13 21:27:26,214] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:27:26,231] {logging_mixin.py:109} INFO - [2022-08-13 21:27:26,231] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:27:26,244] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.680 seconds
[2022-08-13 21:27:57,190] {processor.py:163} INFO - Started process (PID=74992) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:27:57,194] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:27:57,196] {logging_mixin.py:109} INFO - [2022-08-13 21:27:57,196] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:27:57,824] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:27:57,843] {logging_mixin.py:109} INFO - [2022-08-13 21:27:57,842] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:27:57,864] {logging_mixin.py:109} INFO - [2022-08-13 21:27:57,864] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:27:57,878] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.695 seconds
[2022-08-13 21:28:28,552] {processor.py:163} INFO - Started process (PID=75058) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:28:28,554] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:28:28,556] {logging_mixin.py:109} INFO - [2022-08-13 21:28:28,556] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:28:29,205] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:28:29,218] {logging_mixin.py:109} INFO - [2022-08-13 21:28:29,218] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:28:29,237] {logging_mixin.py:109} INFO - [2022-08-13 21:28:29,236] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:28:29,256] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.710 seconds
[2022-08-13 21:29:00,125] {processor.py:163} INFO - Started process (PID=75132) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:29:00,128] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:29:00,130] {logging_mixin.py:109} INFO - [2022-08-13 21:29:00,130] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:29:00,738] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:29:00,749] {logging_mixin.py:109} INFO - [2022-08-13 21:29:00,748] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:29:00,765] {logging_mixin.py:109} INFO - [2022-08-13 21:29:00,765] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:29:00,778] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.658 seconds
[2022-08-13 21:29:31,360] {processor.py:163} INFO - Started process (PID=75197) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:29:31,362] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:29:31,363] {logging_mixin.py:109} INFO - [2022-08-13 21:29:31,363] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:29:31,961] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:29:31,978] {logging_mixin.py:109} INFO - [2022-08-13 21:29:31,977] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:29:31,994] {logging_mixin.py:109} INFO - [2022-08-13 21:29:31,994] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:29:32,006] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.651 seconds
[2022-08-13 21:30:02,106] {processor.py:163} INFO - Started process (PID=75273) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:30:02,108] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:30:02,109] {logging_mixin.py:109} INFO - [2022-08-13 21:30:02,109] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:30:02,766] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:30:02,778] {logging_mixin.py:109} INFO - [2022-08-13 21:30:02,777] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:30:02,797] {logging_mixin.py:109} INFO - [2022-08-13 21:30:02,797] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:30:02,809] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.707 seconds
[2022-08-13 21:30:33,566] {processor.py:163} INFO - Started process (PID=75338) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:30:33,570] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:30:33,572] {logging_mixin.py:109} INFO - [2022-08-13 21:30:33,572] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:30:34,172] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:30:34,181] {logging_mixin.py:109} INFO - [2022-08-13 21:30:34,181] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:30:34,198] {logging_mixin.py:109} INFO - [2022-08-13 21:30:34,198] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:30:34,211] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.650 seconds
[2022-08-13 21:31:05,103] {processor.py:163} INFO - Started process (PID=75401) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:31:05,106] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:31:05,108] {logging_mixin.py:109} INFO - [2022-08-13 21:31:05,108] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:31:05,717] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:31:05,727] {logging_mixin.py:109} INFO - [2022-08-13 21:31:05,727] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:31:05,743] {logging_mixin.py:109} INFO - [2022-08-13 21:31:05,743] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:31:05,755] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.659 seconds
[2022-08-13 21:31:36,356] {processor.py:163} INFO - Started process (PID=75476) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:31:36,359] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:31:36,361] {logging_mixin.py:109} INFO - [2022-08-13 21:31:36,360] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:31:36,975] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:31:36,985] {logging_mixin.py:109} INFO - [2022-08-13 21:31:36,984] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:31:37,001] {logging_mixin.py:109} INFO - [2022-08-13 21:31:37,001] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:31:37,013] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.662 seconds
[2022-08-13 21:32:07,880] {processor.py:163} INFO - Started process (PID=75541) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:32:07,883] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:32:07,885] {logging_mixin.py:109} INFO - [2022-08-13 21:32:07,885] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:32:08,522] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:32:08,534] {logging_mixin.py:109} INFO - [2022-08-13 21:32:08,534] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:32:08,554] {logging_mixin.py:109} INFO - [2022-08-13 21:32:08,553] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:32:08,567] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.695 seconds
[2022-08-13 21:32:39,139] {processor.py:163} INFO - Started process (PID=75615) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:32:39,142] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:32:39,144] {logging_mixin.py:109} INFO - [2022-08-13 21:32:39,144] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:32:39,771] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:32:39,783] {logging_mixin.py:109} INFO - [2022-08-13 21:32:39,782] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:32:39,801] {logging_mixin.py:109} INFO - [2022-08-13 21:32:39,800] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:32:39,824] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.690 seconds
[2022-08-13 21:33:09,923] {processor.py:163} INFO - Started process (PID=75679) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:33:09,926] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:33:09,928] {logging_mixin.py:109} INFO - [2022-08-13 21:33:09,928] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:33:10,515] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:33:10,528] {logging_mixin.py:109} INFO - [2022-08-13 21:33:10,527] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:33:10,544] {logging_mixin.py:109} INFO - [2022-08-13 21:33:10,543] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:33:10,556] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.640 seconds
[2022-08-13 21:33:41,145] {processor.py:163} INFO - Started process (PID=75744) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:33:41,148] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:33:41,150] {logging_mixin.py:109} INFO - [2022-08-13 21:33:41,150] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:33:41,739] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:33:41,749] {logging_mixin.py:109} INFO - [2022-08-13 21:33:41,749] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:33:41,765] {logging_mixin.py:109} INFO - [2022-08-13 21:33:41,765] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:33:41,775] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.635 seconds
[2022-08-13 21:34:12,391] {processor.py:163} INFO - Started process (PID=75818) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:34:12,395] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:34:12,397] {logging_mixin.py:109} INFO - [2022-08-13 21:34:12,397] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:34:13,021] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:34:13,037] {logging_mixin.py:109} INFO - [2022-08-13 21:34:13,037] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:34:13,056] {logging_mixin.py:109} INFO - [2022-08-13 21:34:13,056] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:34:13,066] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.682 seconds
[2022-08-13 21:34:43,638] {processor.py:163} INFO - Started process (PID=75883) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:34:43,643] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:34:43,645] {logging_mixin.py:109} INFO - [2022-08-13 21:34:43,645] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:34:44,239] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:34:44,251] {logging_mixin.py:109} INFO - [2022-08-13 21:34:44,250] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:34:44,266] {logging_mixin.py:109} INFO - [2022-08-13 21:34:44,266] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:34:44,281] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.652 seconds
[2022-08-13 21:35:14,548] {processor.py:163} INFO - Started process (PID=75948) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:35:14,550] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:35:14,552] {logging_mixin.py:109} INFO - [2022-08-13 21:35:14,552] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:35:15,201] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:35:15,216] {logging_mixin.py:109} INFO - [2022-08-13 21:35:15,215] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:35:15,239] {logging_mixin.py:109} INFO - [2022-08-13 21:35:15,238] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:35:15,255] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.712 seconds
[2022-08-13 21:35:45,800] {processor.py:163} INFO - Started process (PID=76021) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:35:45,804] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:35:45,806] {logging_mixin.py:109} INFO - [2022-08-13 21:35:45,806] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:35:46,384] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:35:46,397] {logging_mixin.py:109} INFO - [2022-08-13 21:35:46,396] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:35:46,413] {logging_mixin.py:109} INFO - [2022-08-13 21:35:46,413] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:35:46,424] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.629 seconds
[2022-08-13 21:36:17,216] {processor.py:163} INFO - Started process (PID=76088) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:36:17,220] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:36:17,223] {logging_mixin.py:109} INFO - [2022-08-13 21:36:17,222] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:36:18,918] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:36:18,931] {logging_mixin.py:109} INFO - [2022-08-13 21:36:18,929] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:36:18,948] {logging_mixin.py:109} INFO - [2022-08-13 21:36:18,948] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:36:18,960] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.747 seconds
[2022-08-13 21:36:49,756] {processor.py:163} INFO - Started process (PID=76165) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:36:49,758] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:36:49,759] {logging_mixin.py:109} INFO - [2022-08-13 21:36:49,759] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:36:50,495] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:36:50,507] {logging_mixin.py:109} INFO - [2022-08-13 21:36:50,506] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:36:50,536] {logging_mixin.py:109} INFO - [2022-08-13 21:36:50,535] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:36:50,549] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.800 seconds
[2022-08-13 21:37:21,546] {processor.py:163} INFO - Started process (PID=76230) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:37:21,548] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:37:21,550] {logging_mixin.py:109} INFO - [2022-08-13 21:37:21,550] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:37:22,181] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:37:22,192] {logging_mixin.py:109} INFO - [2022-08-13 21:37:22,191] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:37:22,209] {logging_mixin.py:109} INFO - [2022-08-13 21:37:22,209] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:37:22,220] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.679 seconds
[2022-08-13 21:37:53,052] {processor.py:163} INFO - Started process (PID=76304) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:37:53,055] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:37:53,058] {logging_mixin.py:109} INFO - [2022-08-13 21:37:53,058] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:37:53,671] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:37:53,685] {logging_mixin.py:109} INFO - [2022-08-13 21:37:53,685] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:37:53,701] {logging_mixin.py:109} INFO - [2022-08-13 21:37:53,701] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:37:53,714] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.665 seconds
[2022-08-13 21:38:23,787] {processor.py:163} INFO - Started process (PID=76369) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:38:23,793] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:38:23,795] {logging_mixin.py:109} INFO - [2022-08-13 21:38:23,795] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:38:24,462] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:38:24,472] {logging_mixin.py:109} INFO - [2022-08-13 21:38:24,472] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:38:24,490] {logging_mixin.py:109} INFO - [2022-08-13 21:38:24,490] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:38:24,503] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.722 seconds
[2022-08-13 21:38:54,955] {processor.py:163} INFO - Started process (PID=76434) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:38:54,961] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:38:54,963] {logging_mixin.py:109} INFO - [2022-08-13 21:38:54,963] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:38:55,621] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:38:55,636] {logging_mixin.py:109} INFO - [2022-08-13 21:38:55,635] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:38:55,657] {logging_mixin.py:109} INFO - [2022-08-13 21:38:55,657] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:38:55,672] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.724 seconds
[2022-08-13 21:39:26,489] {processor.py:163} INFO - Started process (PID=76510) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:39:26,492] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:39:26,495] {logging_mixin.py:109} INFO - [2022-08-13 21:39:26,495] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:39:27,078] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:39:27,089] {logging_mixin.py:109} INFO - [2022-08-13 21:39:27,088] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:39:27,104] {logging_mixin.py:109} INFO - [2022-08-13 21:39:27,104] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:39:27,115] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.631 seconds
[2022-08-13 21:39:57,314] {processor.py:163} INFO - Started process (PID=76575) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:39:57,318] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:39:57,320] {logging_mixin.py:109} INFO - [2022-08-13 21:39:57,320] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:39:57,912] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:39:57,921] {logging_mixin.py:109} INFO - [2022-08-13 21:39:57,921] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:39:57,937] {logging_mixin.py:109} INFO - [2022-08-13 21:39:57,937] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:39:57,948] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.641 seconds
[2022-08-13 21:40:28,890] {processor.py:163} INFO - Started process (PID=76642) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:40:28,893] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:40:28,896] {logging_mixin.py:109} INFO - [2022-08-13 21:40:28,896] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:40:29,541] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:40:29,555] {logging_mixin.py:109} INFO - [2022-08-13 21:40:29,554] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:40:29,572] {logging_mixin.py:109} INFO - [2022-08-13 21:40:29,572] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:40:29,587] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.701 seconds
[2022-08-13 21:41:00,501] {processor.py:163} INFO - Started process (PID=76716) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:41:00,504] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:41:00,505] {logging_mixin.py:109} INFO - [2022-08-13 21:41:00,505] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:41:01,130] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:41:01,146] {logging_mixin.py:109} INFO - [2022-08-13 21:41:01,143] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:41:01,164] {logging_mixin.py:109} INFO - [2022-08-13 21:41:01,164] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:41:01,174] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.677 seconds
[2022-08-13 21:41:31,495] {processor.py:163} INFO - Started process (PID=76780) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:41:31,498] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:41:31,499] {logging_mixin.py:109} INFO - [2022-08-13 21:41:31,499] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:41:32,150] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:41:32,160] {logging_mixin.py:109} INFO - [2022-08-13 21:41:32,159] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:41:32,175] {logging_mixin.py:109} INFO - [2022-08-13 21:41:32,175] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:41:32,189] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.699 seconds
[2022-08-13 21:42:02,958] {processor.py:163} INFO - Started process (PID=76855) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:42:02,960] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:42:02,962] {logging_mixin.py:109} INFO - [2022-08-13 21:42:02,962] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:42:03,600] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:42:03,614] {logging_mixin.py:109} INFO - [2022-08-13 21:42:03,612] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:42:03,636] {logging_mixin.py:109} INFO - [2022-08-13 21:42:03,636] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:42:03,652] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.699 seconds
[2022-08-13 21:42:33,803] {processor.py:163} INFO - Started process (PID=76920) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:42:33,806] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:42:33,807] {logging_mixin.py:109} INFO - [2022-08-13 21:42:33,807] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:42:34,387] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:42:34,399] {logging_mixin.py:109} INFO - [2022-08-13 21:42:34,398] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:42:34,414] {logging_mixin.py:109} INFO - [2022-08-13 21:42:34,414] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:42:34,425] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.627 seconds
[2022-08-13 21:43:05,143] {processor.py:163} INFO - Started process (PID=76985) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:43:05,148] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:43:05,151] {logging_mixin.py:109} INFO - [2022-08-13 21:43:05,151] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:43:05,773] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:43:05,783] {logging_mixin.py:109} INFO - [2022-08-13 21:43:05,782] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:43:05,801] {logging_mixin.py:109} INFO - [2022-08-13 21:43:05,801] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:43:05,816] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.682 seconds
[2022-08-13 21:43:36,559] {processor.py:163} INFO - Started process (PID=77059) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:43:36,560] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:43:36,562] {logging_mixin.py:109} INFO - [2022-08-13 21:43:36,562] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:43:37,183] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:43:37,194] {logging_mixin.py:109} INFO - [2022-08-13 21:43:37,193] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:43:37,210] {logging_mixin.py:109} INFO - [2022-08-13 21:43:37,210] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:43:37,222] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.668 seconds
[2022-08-13 21:44:07,837] {processor.py:163} INFO - Started process (PID=77125) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:44:07,841] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:44:07,843] {logging_mixin.py:109} INFO - [2022-08-13 21:44:07,843] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:44:08,476] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:44:08,492] {logging_mixin.py:109} INFO - [2022-08-13 21:44:08,491] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:44:08,511] {logging_mixin.py:109} INFO - [2022-08-13 21:44:08,511] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:44:08,526] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.695 seconds
[2022-08-13 21:44:39,479] {processor.py:163} INFO - Started process (PID=77201) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:44:39,484] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:44:39,486] {logging_mixin.py:109} INFO - [2022-08-13 21:44:39,486] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:44:40,125] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:44:40,135] {logging_mixin.py:109} INFO - [2022-08-13 21:44:40,135] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:44:40,154] {logging_mixin.py:109} INFO - [2022-08-13 21:44:40,154] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:44:40,166] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.690 seconds
[2022-08-13 21:45:10,734] {processor.py:163} INFO - Started process (PID=77267) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:45:10,737] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:45:10,739] {logging_mixin.py:109} INFO - [2022-08-13 21:45:10,739] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:45:11,374] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:45:11,385] {logging_mixin.py:109} INFO - [2022-08-13 21:45:11,385] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:45:11,400] {logging_mixin.py:109} INFO - [2022-08-13 21:45:11,399] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:45:11,420] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.694 seconds
[2022-08-13 21:45:41,477] {processor.py:163} INFO - Started process (PID=77334) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:45:41,479] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:45:41,481] {logging_mixin.py:109} INFO - [2022-08-13 21:45:41,481] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:45:42,106] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:45:42,156] {logging_mixin.py:109} INFO - [2022-08-13 21:45:42,156] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:45:42,173] {logging_mixin.py:109} INFO - [2022-08-13 21:45:42,172] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:45:42,184] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.733 seconds
[2022-08-13 21:46:12,768] {processor.py:163} INFO - Started process (PID=77408) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:46:12,772] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:46:12,774] {logging_mixin.py:109} INFO - [2022-08-13 21:46:12,774] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:46:13,393] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:46:13,405] {logging_mixin.py:109} INFO - [2022-08-13 21:46:13,404] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:46:13,424] {logging_mixin.py:109} INFO - [2022-08-13 21:46:13,424] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:46:13,440] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.676 seconds
[2022-08-13 21:46:44,024] {processor.py:163} INFO - Started process (PID=77474) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:46:44,027] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:46:44,030] {logging_mixin.py:109} INFO - [2022-08-13 21:46:44,030] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:46:44,664] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:46:44,675] {logging_mixin.py:109} INFO - [2022-08-13 21:46:44,675] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:46:44,693] {logging_mixin.py:109} INFO - [2022-08-13 21:46:44,693] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:46:44,707] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.691 seconds
[2022-08-13 21:47:14,767] {processor.py:163} INFO - Started process (PID=77539) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:47:14,769] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:47:14,772] {logging_mixin.py:109} INFO - [2022-08-13 21:47:14,772] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:47:15,435] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:47:15,446] {logging_mixin.py:109} INFO - [2022-08-13 21:47:15,445] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:47:15,462] {logging_mixin.py:109} INFO - [2022-08-13 21:47:15,462] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:47:15,476] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.713 seconds
[2022-08-13 21:47:46,133] {processor.py:163} INFO - Started process (PID=77614) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:47:46,136] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:47:46,138] {logging_mixin.py:109} INFO - [2022-08-13 21:47:46,138] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:47:46,789] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:47:46,800] {logging_mixin.py:109} INFO - [2022-08-13 21:47:46,800] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:47:46,821] {logging_mixin.py:109} INFO - [2022-08-13 21:47:46,821] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:47:46,836] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.714 seconds
[2022-08-13 21:48:17,335] {processor.py:163} INFO - Started process (PID=77680) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:48:17,339] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:48:17,341] {logging_mixin.py:109} INFO - [2022-08-13 21:48:17,341] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:48:18,050] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:48:18,061] {logging_mixin.py:109} INFO - [2022-08-13 21:48:18,060] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:48:18,079] {logging_mixin.py:109} INFO - [2022-08-13 21:48:18,078] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:48:18,093] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.764 seconds
[2022-08-13 21:48:48,305] {processor.py:163} INFO - Started process (PID=77754) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:48:48,309] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:48:48,311] {logging_mixin.py:109} INFO - [2022-08-13 21:48:48,310] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:48:48,951] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:48:48,961] {logging_mixin.py:109} INFO - [2022-08-13 21:48:48,961] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:48:48,978] {logging_mixin.py:109} INFO - [2022-08-13 21:48:48,978] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:48:48,992] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.692 seconds
[2022-08-13 21:49:19,209] {processor.py:163} INFO - Started process (PID=77819) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:49:19,211] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:49:19,213] {logging_mixin.py:109} INFO - [2022-08-13 21:49:19,213] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:49:19,867] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:49:19,879] {logging_mixin.py:109} INFO - [2022-08-13 21:49:19,879] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:49:19,896] {logging_mixin.py:109} INFO - [2022-08-13 21:49:19,896] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:49:19,910] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.706 seconds
[2022-08-13 21:49:50,012] {processor.py:163} INFO - Started process (PID=77884) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:49:50,014] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:49:50,016] {logging_mixin.py:109} INFO - [2022-08-13 21:49:50,016] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:49:50,688] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:49:50,706] {logging_mixin.py:109} INFO - [2022-08-13 21:49:50,705] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:49:50,723] {logging_mixin.py:109} INFO - [2022-08-13 21:49:50,723] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:49:50,736] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.728 seconds
[2022-08-13 21:50:21,093] {processor.py:163} INFO - Started process (PID=77963) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:50:21,095] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:50:21,096] {logging_mixin.py:109} INFO - [2022-08-13 21:50:21,096] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:50:21,869] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:50:21,887] {logging_mixin.py:109} INFO - [2022-08-13 21:50:21,886] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:50:21,908] {logging_mixin.py:109} INFO - [2022-08-13 21:50:21,907] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:50:21,921] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.832 seconds
[2022-08-13 21:50:52,826] {processor.py:163} INFO - Started process (PID=78031) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:50:52,830] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:50:52,833] {logging_mixin.py:109} INFO - [2022-08-13 21:50:52,832] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:50:53,515] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:50:53,528] {logging_mixin.py:109} INFO - [2022-08-13 21:50:53,528] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:50:53,555] {logging_mixin.py:109} INFO - [2022-08-13 21:50:53,554] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:50:53,569] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.751 seconds
[2022-08-13 21:51:23,734] {processor.py:163} INFO - Started process (PID=78098) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:51:23,738] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:51:23,741] {logging_mixin.py:109} INFO - [2022-08-13 21:51:23,740] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:51:24,411] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:51:24,424] {logging_mixin.py:109} INFO - [2022-08-13 21:51:24,423] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:51:24,444] {logging_mixin.py:109} INFO - [2022-08-13 21:51:24,444] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:51:24,454] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.729 seconds
[2022-08-13 21:51:54,507] {processor.py:163} INFO - Started process (PID=78173) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:51:54,511] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:51:54,513] {logging_mixin.py:109} INFO - [2022-08-13 21:51:54,512] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:51:55,156] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:51:55,166] {logging_mixin.py:109} INFO - [2022-08-13 21:51:55,166] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:51:55,182] {logging_mixin.py:109} INFO - [2022-08-13 21:51:55,182] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:51:55,196] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.693 seconds
[2022-08-13 21:52:25,329] {processor.py:163} INFO - Started process (PID=78237) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:52:25,331] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:52:25,333] {logging_mixin.py:109} INFO - [2022-08-13 21:52:25,333] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:52:26,006] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:52:26,020] {logging_mixin.py:109} INFO - [2022-08-13 21:52:26,019] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:52:26,040] {logging_mixin.py:109} INFO - [2022-08-13 21:52:26,039] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:52:26,055] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.733 seconds
[2022-08-13 21:52:56,466] {processor.py:163} INFO - Started process (PID=78303) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:52:56,469] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:52:56,470] {logging_mixin.py:109} INFO - [2022-08-13 21:52:56,470] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:52:57,130] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:52:57,145] {logging_mixin.py:109} INFO - [2022-08-13 21:52:57,144] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:52:57,163] {logging_mixin.py:109} INFO - [2022-08-13 21:52:57,163] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:52:57,176] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.715 seconds
[2022-08-13 21:53:28,143] {processor.py:163} INFO - Started process (PID=78381) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:53:28,147] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:53:28,148] {logging_mixin.py:109} INFO - [2022-08-13 21:53:28,148] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:53:28,730] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:53:28,742] {logging_mixin.py:109} INFO - [2022-08-13 21:53:28,741] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:53:28,759] {logging_mixin.py:109} INFO - [2022-08-13 21:53:28,759] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:53:28,770] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.632 seconds
[2022-08-13 21:53:59,715] {processor.py:163} INFO - Started process (PID=78446) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:53:59,718] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:53:59,721] {logging_mixin.py:109} INFO - [2022-08-13 21:53:59,721] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:54:00,321] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:54:00,331] {logging_mixin.py:109} INFO - [2022-08-13 21:54:00,331] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:54:00,348] {logging_mixin.py:109} INFO - [2022-08-13 21:54:00,348] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:54:00,361] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.651 seconds
[2022-08-13 21:54:31,217] {processor.py:163} INFO - Started process (PID=78521) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:54:31,221] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:54:31,225] {logging_mixin.py:109} INFO - [2022-08-13 21:54:31,224] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:54:31,892] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:54:31,904] {logging_mixin.py:109} INFO - [2022-08-13 21:54:31,903] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:54:31,923] {logging_mixin.py:109} INFO - [2022-08-13 21:54:31,923] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:54:31,938] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.728 seconds
[2022-08-13 21:55:02,321] {processor.py:163} INFO - Started process (PID=78588) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:55:02,325] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:55:02,326] {logging_mixin.py:109} INFO - [2022-08-13 21:55:02,326] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:55:03,031] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:55:03,043] {logging_mixin.py:109} INFO - [2022-08-13 21:55:03,042] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:55:03,060] {logging_mixin.py:109} INFO - [2022-08-13 21:55:03,060] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:55:03,073] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.756 seconds
[2022-08-13 21:55:33,459] {processor.py:163} INFO - Started process (PID=78653) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:55:33,462] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:55:33,464] {logging_mixin.py:109} INFO - [2022-08-13 21:55:33,464] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:55:34,076] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:55:34,089] {logging_mixin.py:109} INFO - [2022-08-13 21:55:34,088] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:55:34,111] {logging_mixin.py:109} INFO - [2022-08-13 21:55:34,111] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:55:34,126] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.674 seconds
[2022-08-13 21:56:04,184] {processor.py:163} INFO - Started process (PID=78726) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:56:04,186] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:56:04,188] {logging_mixin.py:109} INFO - [2022-08-13 21:56:04,188] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:56:04,815] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:56:04,828] {logging_mixin.py:109} INFO - [2022-08-13 21:56:04,827] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:56:04,848] {logging_mixin.py:109} INFO - [2022-08-13 21:56:04,847] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:56:04,862] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.683 seconds
[2022-08-13 21:56:35,176] {processor.py:163} INFO - Started process (PID=78792) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:56:35,179] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:56:35,180] {logging_mixin.py:109} INFO - [2022-08-13 21:56:35,180] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:56:35,951] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:56:35,972] {logging_mixin.py:109} INFO - [2022-08-13 21:56:35,972] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:56:35,997] {logging_mixin.py:109} INFO - [2022-08-13 21:56:35,997] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:56:36,014] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.844 seconds
[2022-08-13 21:57:06,336] {processor.py:163} INFO - Started process (PID=78868) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:57:06,340] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:57:06,343] {logging_mixin.py:109} INFO - [2022-08-13 21:57:06,343] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:57:06,969] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:57:06,982] {logging_mixin.py:109} INFO - [2022-08-13 21:57:06,982] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:57:06,999] {logging_mixin.py:109} INFO - [2022-08-13 21:57:06,999] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:57:07,010] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.679 seconds
[2022-08-13 21:57:37,636] {processor.py:163} INFO - Started process (PID=78932) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:57:37,638] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:57:37,641] {logging_mixin.py:109} INFO - [2022-08-13 21:57:37,640] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:57:38,289] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:57:38,306] {logging_mixin.py:109} INFO - [2022-08-13 21:57:38,305] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:57:38,322] {logging_mixin.py:109} INFO - [2022-08-13 21:57:38,322] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:57:38,333] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.701 seconds
[2022-08-13 21:58:08,735] {processor.py:163} INFO - Started process (PID=78998) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:58:08,738] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:58:08,739] {logging_mixin.py:109} INFO - [2022-08-13 21:58:08,739] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:58:09,402] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:58:09,413] {logging_mixin.py:109} INFO - [2022-08-13 21:58:09,413] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:58:09,429] {logging_mixin.py:109} INFO - [2022-08-13 21:58:09,429] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:58:09,440] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.713 seconds
[2022-08-13 21:58:39,615] {processor.py:163} INFO - Started process (PID=79075) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:58:39,618] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:58:39,620] {logging_mixin.py:109} INFO - [2022-08-13 21:58:39,620] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:58:40,249] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:58:40,264] {logging_mixin.py:109} INFO - [2022-08-13 21:58:40,264] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:58:40,285] {logging_mixin.py:109} INFO - [2022-08-13 21:58:40,285] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:58:40,307] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.696 seconds
[2022-08-13 21:59:11,210] {processor.py:163} INFO - Started process (PID=79140) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:59:11,213] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:59:11,214] {logging_mixin.py:109} INFO - [2022-08-13 21:59:11,214] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:59:11,777] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:59:11,790] {logging_mixin.py:109} INFO - [2022-08-13 21:59:11,790] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:59:11,810] {logging_mixin.py:109} INFO - [2022-08-13 21:59:11,810] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:59:11,823] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.640 seconds
[2022-08-13 21:59:42,328] {processor.py:163} INFO - Started process (PID=79205) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:59:42,331] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 21:59:42,333] {logging_mixin.py:109} INFO - [2022-08-13 21:59:42,333] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:59:42,962] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 21:59:42,973] {logging_mixin.py:109} INFO - [2022-08-13 21:59:42,972] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 21:59:42,993] {logging_mixin.py:109} INFO - [2022-08-13 21:59:42,993] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 21:59:43,005] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.684 seconds
[2022-08-13 22:00:13,327] {processor.py:163} INFO - Started process (PID=79279) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:00:13,333] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:00:13,336] {logging_mixin.py:109} INFO - [2022-08-13 22:00:13,335] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:00:13,995] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:00:14,005] {logging_mixin.py:109} INFO - [2022-08-13 22:00:14,004] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:00:14,022] {logging_mixin.py:109} INFO - [2022-08-13 22:00:14,022] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:00:14,035] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.719 seconds
[2022-08-13 22:00:44,369] {processor.py:163} INFO - Started process (PID=79344) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:00:44,372] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:00:44,374] {logging_mixin.py:109} INFO - [2022-08-13 22:00:44,374] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:00:45,042] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:00:45,052] {logging_mixin.py:109} INFO - [2022-08-13 22:00:45,051] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:00:45,069] {logging_mixin.py:109} INFO - [2022-08-13 22:00:45,069] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:00:45,085] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.720 seconds
[2022-08-13 22:01:15,381] {processor.py:163} INFO - Started process (PID=79417) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:01:15,383] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:01:15,386] {logging_mixin.py:109} INFO - [2022-08-13 22:01:15,386] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:01:16,019] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:01:16,033] {logging_mixin.py:109} INFO - [2022-08-13 22:01:16,032] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:01:16,051] {logging_mixin.py:109} INFO - [2022-08-13 22:01:16,051] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:01:16,063] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.692 seconds
[2022-08-13 22:01:46,244] {processor.py:163} INFO - Started process (PID=79483) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:01:46,247] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:01:46,249] {logging_mixin.py:109} INFO - [2022-08-13 22:01:46,249] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:01:46,863] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:01:46,873] {logging_mixin.py:109} INFO - [2022-08-13 22:01:46,872] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:01:46,890] {logging_mixin.py:109} INFO - [2022-08-13 22:01:46,890] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:01:46,904] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.668 seconds
[2022-08-13 22:02:17,011] {processor.py:163} INFO - Started process (PID=79548) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:02:17,015] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:02:17,017] {logging_mixin.py:109} INFO - [2022-08-13 22:02:17,017] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:02:17,883] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:02:17,896] {logging_mixin.py:109} INFO - [2022-08-13 22:02:17,895] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:02:17,917] {logging_mixin.py:109} INFO - [2022-08-13 22:02:17,917] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:02:17,932] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.925 seconds
[2022-08-13 22:02:48,237] {processor.py:163} INFO - Started process (PID=79622) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:02:48,243] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:02:48,245] {logging_mixin.py:109} INFO - [2022-08-13 22:02:48,245] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:02:48,951] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:02:48,963] {logging_mixin.py:109} INFO - [2022-08-13 22:02:48,962] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:02:48,979] {logging_mixin.py:109} INFO - [2022-08-13 22:02:48,979] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:02:48,995] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.770 seconds
[2022-08-13 22:03:19,087] {processor.py:163} INFO - Started process (PID=79689) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:03:19,089] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:03:19,092] {logging_mixin.py:109} INFO - [2022-08-13 22:03:19,092] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:03:19,690] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:03:19,702] {logging_mixin.py:109} INFO - [2022-08-13 22:03:19,702] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:03:19,718] {logging_mixin.py:109} INFO - [2022-08-13 22:03:19,718] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:03:19,728] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.644 seconds
[2022-08-13 22:03:50,520] {processor.py:163} INFO - Started process (PID=79756) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:03:50,524] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:03:50,527] {logging_mixin.py:109} INFO - [2022-08-13 22:03:50,526] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:03:51,156] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:03:51,171] {logging_mixin.py:109} INFO - [2022-08-13 22:03:51,171] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:03:51,193] {logging_mixin.py:109} INFO - [2022-08-13 22:03:51,193] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:03:51,205] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.699 seconds
[2022-08-13 22:04:21,379] {processor.py:163} INFO - Started process (PID=79830) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:04:21,383] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:04:21,385] {logging_mixin.py:109} INFO - [2022-08-13 22:04:21,385] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:04:22,115] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:04:22,130] {logging_mixin.py:109} INFO - [2022-08-13 22:04:22,130] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:04:22,161] {logging_mixin.py:109} INFO - [2022-08-13 22:04:22,161] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:04:22,175] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.800 seconds
[2022-08-13 22:04:52,349] {processor.py:163} INFO - Started process (PID=79896) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:04:52,359] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:04:52,361] {logging_mixin.py:109} INFO - [2022-08-13 22:04:52,361] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:04:53,021] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:04:53,037] {logging_mixin.py:109} INFO - [2022-08-13 22:04:53,036] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:04:53,056] {logging_mixin.py:109} INFO - [2022-08-13 22:04:53,056] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:04:53,071] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.727 seconds
[2022-08-13 22:05:23,561] {processor.py:163} INFO - Started process (PID=79964) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:05:23,563] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:05:23,565] {logging_mixin.py:109} INFO - [2022-08-13 22:05:23,565] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:05:24,225] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:05:24,237] {logging_mixin.py:109} INFO - [2022-08-13 22:05:24,236] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:05:24,255] {logging_mixin.py:109} INFO - [2022-08-13 22:05:24,255] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:05:24,269] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.712 seconds
[2022-08-13 22:05:54,383] {processor.py:163} INFO - Started process (PID=80035) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:05:54,387] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:05:54,390] {logging_mixin.py:109} INFO - [2022-08-13 22:05:54,389] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:05:55,043] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:05:55,056] {logging_mixin.py:109} INFO - [2022-08-13 22:05:55,056] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:05:55,074] {logging_mixin.py:109} INFO - [2022-08-13 22:05:55,074] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:05:55,089] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.716 seconds
[2022-08-13 22:06:25,431] {processor.py:163} INFO - Started process (PID=80101) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:06:25,439] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:06:25,444] {logging_mixin.py:109} INFO - [2022-08-13 22:06:25,444] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:06:26,144] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:06:26,157] {logging_mixin.py:109} INFO - [2022-08-13 22:06:26,156] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:06:26,174] {logging_mixin.py:109} INFO - [2022-08-13 22:06:26,174] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:06:26,189] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.774 seconds
[2022-08-13 22:06:56,399] {processor.py:163} INFO - Started process (PID=80176) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:06:56,404] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:06:56,406] {logging_mixin.py:109} INFO - [2022-08-13 22:06:56,405] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:06:57,109] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:06:57,124] {logging_mixin.py:109} INFO - [2022-08-13 22:06:57,124] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:06:57,145] {logging_mixin.py:109} INFO - [2022-08-13 22:06:57,145] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:06:57,164] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.774 seconds
[2022-08-13 22:07:27,291] {processor.py:163} INFO - Started process (PID=80243) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:07:27,294] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:07:27,297] {logging_mixin.py:109} INFO - [2022-08-13 22:07:27,297] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:07:27,935] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:07:27,950] {logging_mixin.py:109} INFO - [2022-08-13 22:07:27,949] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:07:27,967] {logging_mixin.py:109} INFO - [2022-08-13 22:07:27,967] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:07:27,979] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.692 seconds
[2022-08-13 22:07:58,172] {processor.py:163} INFO - Started process (PID=80305) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:07:58,175] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:07:58,177] {logging_mixin.py:109} INFO - [2022-08-13 22:07:58,177] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:07:58,997] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:07:59,007] {logging_mixin.py:109} INFO - [2022-08-13 22:07:59,006] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:07:59,024] {logging_mixin.py:109} INFO - [2022-08-13 22:07:59,024] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:07:59,034] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.866 seconds
[2022-08-13 22:08:29,877] {processor.py:163} INFO - Started process (PID=80384) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:08:29,882] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:08:29,884] {logging_mixin.py:109} INFO - [2022-08-13 22:08:29,884] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:08:30,507] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:08:30,518] {logging_mixin.py:109} INFO - [2022-08-13 22:08:30,518] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:08:30,535] {logging_mixin.py:109} INFO - [2022-08-13 22:08:30,534] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:08:30,549] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.679 seconds
[2022-08-13 22:09:00,907] {processor.py:163} INFO - Started process (PID=80449) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:09:00,909] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:09:00,912] {logging_mixin.py:109} INFO - [2022-08-13 22:09:00,911] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:09:01,541] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:09:01,554] {logging_mixin.py:109} INFO - [2022-08-13 22:09:01,553] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:09:01,572] {logging_mixin.py:109} INFO - [2022-08-13 22:09:01,572] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:09:01,584] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.685 seconds
[2022-08-13 22:09:31,756] {processor.py:163} INFO - Started process (PID=80515) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:09:31,759] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:09:31,761] {logging_mixin.py:109} INFO - [2022-08-13 22:09:31,761] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:09:32,362] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:09:32,381] {logging_mixin.py:109} INFO - [2022-08-13 22:09:32,380] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:09:32,402] {logging_mixin.py:109} INFO - [2022-08-13 22:09:32,402] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:09:32,421] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.671 seconds
[2022-08-13 22:10:02,554] {processor.py:163} INFO - Started process (PID=80591) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:10:02,557] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:10:02,559] {logging_mixin.py:109} INFO - [2022-08-13 22:10:02,558] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:10:03,278] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:10:03,292] {logging_mixin.py:109} INFO - [2022-08-13 22:10:03,291] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:10:03,309] {logging_mixin.py:109} INFO - [2022-08-13 22:10:03,309] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:10:03,320] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.770 seconds
[2022-08-13 22:10:33,810] {processor.py:163} INFO - Started process (PID=80656) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:10:33,813] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:10:33,816] {logging_mixin.py:109} INFO - [2022-08-13 22:10:33,816] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:10:34,447] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:10:34,458] {logging_mixin.py:109} INFO - [2022-08-13 22:10:34,458] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:10:34,474] {logging_mixin.py:109} INFO - [2022-08-13 22:10:34,474] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:10:34,485] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.680 seconds
[2022-08-13 22:11:04,888] {processor.py:163} INFO - Started process (PID=80731) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:11:04,891] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:11:04,893] {logging_mixin.py:109} INFO - [2022-08-13 22:11:04,892] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:11:05,521] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:11:05,530] {logging_mixin.py:109} INFO - [2022-08-13 22:11:05,530] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:11:05,547] {logging_mixin.py:109} INFO - [2022-08-13 22:11:05,547] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:11:05,559] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.675 seconds
[2022-08-13 22:11:35,744] {processor.py:163} INFO - Started process (PID=80796) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:11:35,748] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:11:35,752] {logging_mixin.py:109} INFO - [2022-08-13 22:11:35,752] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:11:36,469] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:11:36,480] {logging_mixin.py:109} INFO - [2022-08-13 22:11:36,479] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:11:36,501] {logging_mixin.py:109} INFO - [2022-08-13 22:11:36,500] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:11:36,516] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.778 seconds
[2022-08-13 22:12:06,673] {processor.py:163} INFO - Started process (PID=80863) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:12:06,676] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:12:06,678] {logging_mixin.py:109} INFO - [2022-08-13 22:12:06,678] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:12:07,339] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:12:07,352] {logging_mixin.py:109} INFO - [2022-08-13 22:12:07,351] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:12:07,371] {logging_mixin.py:109} INFO - [2022-08-13 22:12:07,371] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:12:07,380] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.712 seconds
[2022-08-13 22:12:37,791] {processor.py:163} INFO - Started process (PID=80937) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:12:37,794] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:12:37,796] {logging_mixin.py:109} INFO - [2022-08-13 22:12:37,796] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:12:38,531] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:12:38,549] {logging_mixin.py:109} INFO - [2022-08-13 22:12:38,549] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:12:38,585] {logging_mixin.py:109} INFO - [2022-08-13 22:12:38,585] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:12:38,597] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.813 seconds
[2022-08-13 22:13:09,210] {processor.py:163} INFO - Started process (PID=81002) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:13:09,212] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:13:09,214] {logging_mixin.py:109} INFO - [2022-08-13 22:13:09,213] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:13:09,858] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:13:09,870] {logging_mixin.py:109} INFO - [2022-08-13 22:13:09,869] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:13:09,888] {logging_mixin.py:109} INFO - [2022-08-13 22:13:09,888] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:13:09,905] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.702 seconds
[2022-08-13 22:13:40,244] {processor.py:163} INFO - Started process (PID=81067) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:13:40,248] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:13:40,250] {logging_mixin.py:109} INFO - [2022-08-13 22:13:40,249] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:13:40,906] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:13:40,917] {logging_mixin.py:109} INFO - [2022-08-13 22:13:40,917] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:13:40,940] {logging_mixin.py:109} INFO - [2022-08-13 22:13:40,940] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:13:40,952] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.739 seconds
[2022-08-13 22:14:11,482] {processor.py:163} INFO - Started process (PID=81141) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:14:11,485] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:14:11,488] {logging_mixin.py:109} INFO - [2022-08-13 22:14:11,487] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:14:12,154] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:14:12,166] {logging_mixin.py:109} INFO - [2022-08-13 22:14:12,166] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:14:12,186] {logging_mixin.py:109} INFO - [2022-08-13 22:14:12,186] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:14:12,201] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.728 seconds
[2022-08-13 22:14:42,306] {processor.py:163} INFO - Started process (PID=81207) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:14:42,308] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:14:42,310] {logging_mixin.py:109} INFO - [2022-08-13 22:14:42,310] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:14:42,953] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:14:42,964] {logging_mixin.py:109} INFO - [2022-08-13 22:14:42,963] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:14:42,978] {logging_mixin.py:109} INFO - [2022-08-13 22:14:42,978] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:14:42,991] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.689 seconds
[2022-08-13 22:15:13,178] {processor.py:163} INFO - Started process (PID=81272) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:15:13,182] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:15:13,184] {logging_mixin.py:109} INFO - [2022-08-13 22:15:13,184] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:15:13,843] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:15:13,858] {logging_mixin.py:109} INFO - [2022-08-13 22:15:13,857] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:15:13,881] {logging_mixin.py:109} INFO - [2022-08-13 22:15:13,880] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:15:13,896] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.723 seconds
[2022-08-13 22:15:44,723] {processor.py:163} INFO - Started process (PID=81348) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:15:44,726] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:15:44,727] {logging_mixin.py:109} INFO - [2022-08-13 22:15:44,727] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:15:45,372] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:15:45,386] {logging_mixin.py:109} INFO - [2022-08-13 22:15:45,386] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:15:45,416] {logging_mixin.py:109} INFO - [2022-08-13 22:15:45,416] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:15:45,434] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.716 seconds
[2022-08-13 22:16:15,514] {processor.py:163} INFO - Started process (PID=81414) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:16:15,517] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:16:15,519] {logging_mixin.py:109} INFO - [2022-08-13 22:16:15,519] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:16:16,193] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:16:16,204] {logging_mixin.py:109} INFO - [2022-08-13 22:16:16,204] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:16:16,231] {logging_mixin.py:109} INFO - [2022-08-13 22:16:16,230] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:16:16,253] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.743 seconds
[2022-08-13 22:16:46,602] {processor.py:163} INFO - Started process (PID=81488) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:16:46,604] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:16:46,607] {logging_mixin.py:109} INFO - [2022-08-13 22:16:46,607] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:16:47,265] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:16:47,274] {logging_mixin.py:109} INFO - [2022-08-13 22:16:47,274] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:16:47,291] {logging_mixin.py:109} INFO - [2022-08-13 22:16:47,291] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:16:47,302] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.705 seconds
[2022-08-13 22:17:17,587] {processor.py:163} INFO - Started process (PID=81552) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:17:17,592] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:17:17,594] {logging_mixin.py:109} INFO - [2022-08-13 22:17:17,594] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:17:18,523] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:17:18,540] {logging_mixin.py:109} INFO - [2022-08-13 22:17:18,539] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:17:18,565] {logging_mixin.py:109} INFO - [2022-08-13 22:17:18,565] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:17:18,583] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 1.001 seconds
[2022-08-13 22:17:48,739] {processor.py:163} INFO - Started process (PID=81617) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:17:48,743] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:17:48,746] {logging_mixin.py:109} INFO - [2022-08-13 22:17:48,745] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:17:49,413] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:17:49,424] {logging_mixin.py:109} INFO - [2022-08-13 22:17:49,424] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:17:49,443] {logging_mixin.py:109} INFO - [2022-08-13 22:17:49,443] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:17:49,456] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.723 seconds
[2022-08-13 22:18:19,805] {processor.py:163} INFO - Started process (PID=81694) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:18:19,808] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:18:19,810] {logging_mixin.py:109} INFO - [2022-08-13 22:18:19,810] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:18:20,529] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:18:20,542] {logging_mixin.py:109} INFO - [2022-08-13 22:18:20,541] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:18:20,565] {logging_mixin.py:109} INFO - [2022-08-13 22:18:20,564] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:18:20,589] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.792 seconds
[2022-08-13 22:18:50,864] {processor.py:163} INFO - Started process (PID=81761) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:18:50,867] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:18:50,871] {logging_mixin.py:109} INFO - [2022-08-13 22:18:50,870] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:18:51,553] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:18:51,564] {logging_mixin.py:109} INFO - [2022-08-13 22:18:51,564] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:18:51,582] {logging_mixin.py:109} INFO - [2022-08-13 22:18:51,582] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:18:51,598] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.737 seconds
[2022-08-13 22:19:21,669] {processor.py:163} INFO - Started process (PID=81828) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:19:21,671] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:19:21,673] {logging_mixin.py:109} INFO - [2022-08-13 22:19:21,673] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:19:22,433] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:19:22,448] {logging_mixin.py:109} INFO - [2022-08-13 22:19:22,447] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:19:22,466] {logging_mixin.py:109} INFO - [2022-08-13 22:19:22,466] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:19:22,479] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.814 seconds
[2022-08-13 22:19:52,747] {processor.py:163} INFO - Started process (PID=81902) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:19:52,749] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:19:52,752] {logging_mixin.py:109} INFO - [2022-08-13 22:19:52,751] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:19:53,386] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:19:53,399] {logging_mixin.py:109} INFO - [2022-08-13 22:19:53,398] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:19:53,415] {logging_mixin.py:109} INFO - [2022-08-13 22:19:53,415] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:19:53,429] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.690 seconds
[2022-08-13 22:20:23,751] {processor.py:163} INFO - Started process (PID=81968) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:20:23,756] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:20:23,758] {logging_mixin.py:109} INFO - [2022-08-13 22:20:23,758] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:20:24,438] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:20:24,449] {logging_mixin.py:109} INFO - [2022-08-13 22:20:24,449] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:20:24,467] {logging_mixin.py:109} INFO - [2022-08-13 22:20:24,467] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:20:24,481] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.742 seconds
[2022-08-13 22:20:54,567] {processor.py:163} INFO - Started process (PID=82042) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:20:54,570] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:20:54,572] {logging_mixin.py:109} INFO - [2022-08-13 22:20:54,572] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:20:55,141] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:20:55,155] {logging_mixin.py:109} INFO - [2022-08-13 22:20:55,154] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:20:55,174] {logging_mixin.py:109} INFO - [2022-08-13 22:20:55,174] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:20:55,190] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.628 seconds
[2022-08-13 22:21:26,050] {processor.py:163} INFO - Started process (PID=82110) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:21:26,053] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:21:26,055] {logging_mixin.py:109} INFO - [2022-08-13 22:21:26,054] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:21:26,603] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:21:26,615] {logging_mixin.py:109} INFO - [2022-08-13 22:21:26,614] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:21:26,631] {logging_mixin.py:109} INFO - [2022-08-13 22:21:26,631] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:21:26,643] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.600 seconds
[2022-08-13 22:21:57,332] {processor.py:163} INFO - Started process (PID=82175) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:21:57,334] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:21:57,335] {logging_mixin.py:109} INFO - [2022-08-13 22:21:57,335] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:21:57,913] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:21:57,925] {logging_mixin.py:109} INFO - [2022-08-13 22:21:57,924] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:21:57,941] {logging_mixin.py:109} INFO - [2022-08-13 22:21:57,941] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:21:57,954] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.630 seconds
[2022-08-13 22:22:28,826] {processor.py:163} INFO - Started process (PID=82251) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:22:28,829] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:22:28,831] {logging_mixin.py:109} INFO - [2022-08-13 22:22:28,831] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:22:29,384] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:22:29,396] {logging_mixin.py:109} INFO - [2022-08-13 22:22:29,394] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:22:29,414] {logging_mixin.py:109} INFO - [2022-08-13 22:22:29,414] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:22:29,426] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.604 seconds
[2022-08-13 22:22:59,615] {processor.py:163} INFO - Started process (PID=82320) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:22:59,618] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:22:59,619] {logging_mixin.py:109} INFO - [2022-08-13 22:22:59,619] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:23:00,183] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:23:00,197] {logging_mixin.py:109} INFO - [2022-08-13 22:23:00,195] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:23:00,218] {logging_mixin.py:109} INFO - [2022-08-13 22:23:00,217] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:23:00,232] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.621 seconds
[2022-08-13 22:23:30,879] {processor.py:163} INFO - Started process (PID=82386) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:23:30,882] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:23:30,884] {logging_mixin.py:109} INFO - [2022-08-13 22:23:30,884] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:23:31,381] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:23:31,393] {logging_mixin.py:109} INFO - [2022-08-13 22:23:31,392] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:23:31,413] {logging_mixin.py:109} INFO - [2022-08-13 22:23:31,413] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:23:31,427] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.553 seconds
[2022-08-13 22:24:02,324] {processor.py:163} INFO - Started process (PID=82463) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:24:02,327] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:24:02,329] {logging_mixin.py:109} INFO - [2022-08-13 22:24:02,329] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:24:02,796] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:24:02,808] {logging_mixin.py:109} INFO - [2022-08-13 22:24:02,807] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:24:02,824] {logging_mixin.py:109} INFO - [2022-08-13 22:24:02,824] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:24:02,834] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.516 seconds
[2022-08-13 22:24:33,460] {processor.py:163} INFO - Started process (PID=82529) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:24:33,463] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:24:33,465] {logging_mixin.py:109} INFO - [2022-08-13 22:24:33,465] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:24:33,997] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:24:34,011] {logging_mixin.py:109} INFO - [2022-08-13 22:24:34,010] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:24:34,032] {logging_mixin.py:109} INFO - [2022-08-13 22:24:34,032] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:24:34,043] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.589 seconds
[2022-08-13 22:25:04,377] {processor.py:163} INFO - Started process (PID=82603) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:25:04,380] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:25:04,382] {logging_mixin.py:109} INFO - [2022-08-13 22:25:04,382] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:25:04,883] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:25:04,893] {logging_mixin.py:109} INFO - [2022-08-13 22:25:04,892] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:25:04,909] {logging_mixin.py:109} INFO - [2022-08-13 22:25:04,909] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:25:04,920] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.558 seconds
[2022-08-13 22:25:34,995] {processor.py:163} INFO - Started process (PID=82668) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:25:34,998] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:25:35,000] {logging_mixin.py:109} INFO - [2022-08-13 22:25:35,000] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:25:35,452] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:25:35,468] {logging_mixin.py:109} INFO - [2022-08-13 22:25:35,466] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:25:35,488] {logging_mixin.py:109} INFO - [2022-08-13 22:25:35,488] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:25:35,502] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.514 seconds
[2022-08-13 22:26:06,185] {processor.py:163} INFO - Started process (PID=82733) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:26:06,188] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:26:06,189] {logging_mixin.py:109} INFO - [2022-08-13 22:26:06,189] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:26:06,639] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:26:06,652] {logging_mixin.py:109} INFO - [2022-08-13 22:26:06,651] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:26:06,675] {logging_mixin.py:109} INFO - [2022-08-13 22:26:06,675] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:26:06,687] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.507 seconds
[2022-08-13 22:26:36,831] {processor.py:163} INFO - Started process (PID=82809) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:26:36,835] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:26:36,837] {logging_mixin.py:109} INFO - [2022-08-13 22:26:36,837] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:26:37,415] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:26:37,429] {logging_mixin.py:109} INFO - [2022-08-13 22:26:37,428] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:26:37,453] {logging_mixin.py:109} INFO - [2022-08-13 22:26:37,453] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:26:37,470] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.645 seconds
[2022-08-13 22:27:07,639] {processor.py:163} INFO - Started process (PID=82874) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:27:07,641] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:27:07,642] {logging_mixin.py:109} INFO - [2022-08-13 22:27:07,642] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:27:08,171] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:27:08,190] {logging_mixin.py:109} INFO - [2022-08-13 22:27:08,188] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:27:08,220] {logging_mixin.py:109} INFO - [2022-08-13 22:27:08,220] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:27:08,237] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.602 seconds
[2022-08-13 22:27:38,358] {processor.py:163} INFO - Started process (PID=82940) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:27:38,362] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:27:38,364] {logging_mixin.py:109} INFO - [2022-08-13 22:27:38,364] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:27:38,836] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:27:38,847] {logging_mixin.py:109} INFO - [2022-08-13 22:27:38,846] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:27:38,865] {logging_mixin.py:109} INFO - [2022-08-13 22:27:38,865] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:27:38,876] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.523 seconds
[2022-08-13 22:28:09,377] {processor.py:163} INFO - Started process (PID=83014) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:28:09,381] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:28:09,385] {logging_mixin.py:109} INFO - [2022-08-13 22:28:09,385] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:28:09,871] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:28:09,883] {logging_mixin.py:109} INFO - [2022-08-13 22:28:09,882] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:28:09,900] {logging_mixin.py:109} INFO - [2022-08-13 22:28:09,900] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:28:09,912] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.541 seconds
[2022-08-13 22:28:40,329] {processor.py:163} INFO - Started process (PID=83079) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:28:40,332] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:28:40,334] {logging_mixin.py:109} INFO - [2022-08-13 22:28:40,334] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:28:40,857] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:28:40,873] {logging_mixin.py:109} INFO - [2022-08-13 22:28:40,872] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:28:40,904] {logging_mixin.py:109} INFO - [2022-08-13 22:28:40,903] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:28:40,928] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.626 seconds
[2022-08-13 22:29:11,692] {processor.py:163} INFO - Started process (PID=83145) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:29:11,694] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:29:11,696] {logging_mixin.py:109} INFO - [2022-08-13 22:29:11,696] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:29:12,172] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:29:12,187] {logging_mixin.py:109} INFO - [2022-08-13 22:29:12,186] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:29:12,209] {logging_mixin.py:109} INFO - [2022-08-13 22:29:12,209] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:29:12,221] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.535 seconds
[2022-08-13 22:29:42,349] {processor.py:163} INFO - Started process (PID=83220) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:29:42,351] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:29:42,353] {logging_mixin.py:109} INFO - [2022-08-13 22:29:42,353] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:29:42,810] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:29:42,821] {logging_mixin.py:109} INFO - [2022-08-13 22:29:42,821] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:29:42,840] {logging_mixin.py:109} INFO - [2022-08-13 22:29:42,840] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:29:42,852] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.508 seconds
[2022-08-13 22:30:13,035] {processor.py:163} INFO - Started process (PID=83286) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:30:13,038] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:30:13,041] {logging_mixin.py:109} INFO - [2022-08-13 22:30:13,041] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:30:13,530] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:30:13,546] {logging_mixin.py:109} INFO - [2022-08-13 22:30:13,545] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:30:13,565] {logging_mixin.py:109} INFO - [2022-08-13 22:30:13,564] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:30:13,580] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.549 seconds
[2022-08-13 22:30:44,218] {processor.py:163} INFO - Started process (PID=83361) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:30:44,221] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:30:44,222] {logging_mixin.py:109} INFO - [2022-08-13 22:30:44,222] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:30:44,740] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:30:44,755] {logging_mixin.py:109} INFO - [2022-08-13 22:30:44,754] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:30:44,780] {logging_mixin.py:109} INFO - [2022-08-13 22:30:44,779] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:30:44,798] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.583 seconds
[2022-08-13 22:31:15,278] {processor.py:163} INFO - Started process (PID=83427) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:31:15,281] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:31:15,283] {logging_mixin.py:109} INFO - [2022-08-13 22:31:15,282] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:31:15,851] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:31:15,874] {logging_mixin.py:109} INFO - [2022-08-13 22:31:15,872] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:31:15,897] {logging_mixin.py:109} INFO - [2022-08-13 22:31:15,897] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:31:15,907] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.632 seconds
[2022-08-13 22:31:46,749] {processor.py:163} INFO - Started process (PID=83501) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:31:46,751] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:31:46,752] {logging_mixin.py:109} INFO - [2022-08-13 22:31:46,752] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:31:47,182] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:31:47,195] {logging_mixin.py:109} INFO - [2022-08-13 22:31:47,194] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:31:47,212] {logging_mixin.py:109} INFO - [2022-08-13 22:31:47,212] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:31:47,223] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.478 seconds
[2022-08-13 22:32:17,714] {processor.py:163} INFO - Started process (PID=83566) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:32:17,718] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:32:17,720] {logging_mixin.py:109} INFO - [2022-08-13 22:32:17,720] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:32:18,176] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:32:18,187] {logging_mixin.py:109} INFO - [2022-08-13 22:32:18,186] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:32:18,203] {logging_mixin.py:109} INFO - [2022-08-13 22:32:18,202] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:32:18,213] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.503 seconds
[2022-08-13 22:32:49,261] {processor.py:163} INFO - Started process (PID=83631) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:32:49,265] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:32:49,267] {logging_mixin.py:109} INFO - [2022-08-13 22:32:49,267] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:32:49,669] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:32:49,680] {logging_mixin.py:109} INFO - [2022-08-13 22:32:49,679] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:32:49,694] {logging_mixin.py:109} INFO - [2022-08-13 22:32:49,694] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:32:49,705] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.454 seconds
[2022-08-13 22:33:19,869] {processor.py:163} INFO - Started process (PID=83705) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:33:19,872] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:33:19,874] {logging_mixin.py:109} INFO - [2022-08-13 22:33:19,873] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:33:20,357] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:33:20,375] {logging_mixin.py:109} INFO - [2022-08-13 22:33:20,373] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:33:20,391] {logging_mixin.py:109} INFO - [2022-08-13 22:33:20,390] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:33:20,402] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.537 seconds
[2022-08-13 22:33:50,740] {processor.py:163} INFO - Started process (PID=83770) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:33:50,742] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:33:50,744] {logging_mixin.py:109} INFO - [2022-08-13 22:33:50,744] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:33:51,135] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:33:51,146] {logging_mixin.py:109} INFO - [2022-08-13 22:33:51,145] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:33:51,160] {logging_mixin.py:109} INFO - [2022-08-13 22:33:51,159] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:33:51,169] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.435 seconds
[2022-08-13 22:34:21,222] {processor.py:163} INFO - Started process (PID=83845) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:34:21,225] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:34:21,228] {logging_mixin.py:109} INFO - [2022-08-13 22:34:21,227] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:34:21,873] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:34:21,885] {logging_mixin.py:109} INFO - [2022-08-13 22:34:21,884] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:34:21,902] {logging_mixin.py:109} INFO - [2022-08-13 22:34:21,902] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:34:21,914] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.698 seconds
[2022-08-13 22:34:52,903] {processor.py:163} INFO - Started process (PID=83910) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:34:52,906] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:34:52,908] {logging_mixin.py:109} INFO - [2022-08-13 22:34:52,908] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:34:53,335] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:34:53,345] {logging_mixin.py:109} INFO - [2022-08-13 22:34:53,344] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:34:53,359] {logging_mixin.py:109} INFO - [2022-08-13 22:34:53,359] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:34:53,368] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.469 seconds
[2022-08-13 22:35:23,451] {processor.py:163} INFO - Started process (PID=83985) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:35:23,453] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:35:23,454] {logging_mixin.py:109} INFO - [2022-08-13 22:35:23,454] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:35:23,941] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:35:23,954] {logging_mixin.py:109} INFO - [2022-08-13 22:35:23,953] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:35:23,972] {logging_mixin.py:109} INFO - [2022-08-13 22:35:23,972] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:35:23,987] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.542 seconds
[2022-08-13 22:35:54,641] {processor.py:163} INFO - Started process (PID=84051) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:35:54,644] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:35:54,646] {logging_mixin.py:109} INFO - [2022-08-13 22:35:54,646] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:35:55,095] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:35:55,106] {logging_mixin.py:109} INFO - [2022-08-13 22:35:55,105] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:35:55,122] {logging_mixin.py:109} INFO - [2022-08-13 22:35:55,122] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:35:55,131] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.494 seconds
[2022-08-13 22:36:25,453] {processor.py:163} INFO - Started process (PID=84127) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:36:25,455] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:36:25,457] {logging_mixin.py:109} INFO - [2022-08-13 22:36:25,457] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:36:25,913] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:36:25,924] {logging_mixin.py:109} INFO - [2022-08-13 22:36:25,923] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:36:25,938] {logging_mixin.py:109} INFO - [2022-08-13 22:36:25,938] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:36:25,949] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.500 seconds
[2022-08-13 22:36:56,512] {processor.py:163} INFO - Started process (PID=84192) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:36:56,514] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:36:56,516] {logging_mixin.py:109} INFO - [2022-08-13 22:36:56,516] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:36:56,967] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:36:56,979] {logging_mixin.py:109} INFO - [2022-08-13 22:36:56,978] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:36:56,994] {logging_mixin.py:109} INFO - [2022-08-13 22:36:56,994] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:36:57,004] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.497 seconds
[2022-08-13 22:37:27,211] {processor.py:163} INFO - Started process (PID=84264) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:37:27,213] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:37:27,214] {logging_mixin.py:109} INFO - [2022-08-13 22:37:27,214] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:37:27,663] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:37:27,675] {logging_mixin.py:109} INFO - [2022-08-13 22:37:27,674] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:37:27,690] {logging_mixin.py:109} INFO - [2022-08-13 22:37:27,690] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:37:27,700] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.493 seconds
[2022-08-13 22:37:58,214] {processor.py:163} INFO - Started process (PID=84333) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:37:58,217] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:37:58,219] {logging_mixin.py:109} INFO - [2022-08-13 22:37:58,219] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:37:58,731] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:37:58,750] {logging_mixin.py:109} INFO - [2022-08-13 22:37:58,748] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:37:58,767] {logging_mixin.py:109} INFO - [2022-08-13 22:37:58,767] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:37:58,778] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.572 seconds
[2022-08-13 22:38:29,020] {processor.py:163} INFO - Started process (PID=84398) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:38:29,024] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:38:29,027] {logging_mixin.py:109} INFO - [2022-08-13 22:38:29,027] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:38:29,481] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:38:29,492] {logging_mixin.py:109} INFO - [2022-08-13 22:38:29,491] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:38:29,509] {logging_mixin.py:109} INFO - [2022-08-13 22:38:29,509] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:38:29,519] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.507 seconds
[2022-08-13 22:38:59,676] {processor.py:163} INFO - Started process (PID=84473) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:38:59,680] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:38:59,682] {logging_mixin.py:109} INFO - [2022-08-13 22:38:59,681] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:39:00,120] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:39:00,144] {logging_mixin.py:109} INFO - [2022-08-13 22:39:00,143] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:39:00,159] {logging_mixin.py:109} INFO - [2022-08-13 22:39:00,159] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:39:00,171] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.500 seconds
[2022-08-13 22:39:30,356] {processor.py:163} INFO - Started process (PID=84540) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:39:30,359] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:39:30,360] {logging_mixin.py:109} INFO - [2022-08-13 22:39:30,360] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:39:30,787] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:39:30,805] {logging_mixin.py:109} INFO - [2022-08-13 22:39:30,803] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:39:30,822] {logging_mixin.py:109} INFO - [2022-08-13 22:39:30,822] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:39:30,832] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.482 seconds
[2022-08-13 22:40:01,034] {processor.py:163} INFO - Started process (PID=84614) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:40:01,037] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:40:01,038] {logging_mixin.py:109} INFO - [2022-08-13 22:40:01,038] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:40:01,496] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:40:01,507] {logging_mixin.py:109} INFO - [2022-08-13 22:40:01,506] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:40:01,524] {logging_mixin.py:109} INFO - [2022-08-13 22:40:01,523] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:40:01,534] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.504 seconds
[2022-08-13 22:40:31,648] {processor.py:163} INFO - Started process (PID=84680) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:40:31,651] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:40:31,653] {logging_mixin.py:109} INFO - [2022-08-13 22:40:31,652] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:40:32,094] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:40:32,107] {logging_mixin.py:109} INFO - [2022-08-13 22:40:32,106] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:40:32,128] {logging_mixin.py:109} INFO - [2022-08-13 22:40:32,128] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:40:32,140] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.496 seconds
[2022-08-13 22:41:02,303] {processor.py:163} INFO - Started process (PID=84755) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:41:02,305] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:41:02,307] {logging_mixin.py:109} INFO - [2022-08-13 22:41:02,306] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:41:02,833] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:41:02,844] {logging_mixin.py:109} INFO - [2022-08-13 22:41:02,844] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:41:02,862] {logging_mixin.py:109} INFO - [2022-08-13 22:41:02,862] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:41:02,874] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.576 seconds
[2022-08-13 22:41:33,391] {processor.py:163} INFO - Started process (PID=84822) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:41:33,394] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:41:33,396] {logging_mixin.py:109} INFO - [2022-08-13 22:41:33,396] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:41:34,001] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:41:34,017] {logging_mixin.py:109} INFO - [2022-08-13 22:41:34,016] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:41:34,037] {logging_mixin.py:109} INFO - [2022-08-13 22:41:34,037] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:41:34,051] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.666 seconds
[2022-08-13 22:42:04,771] {processor.py:163} INFO - Started process (PID=84896) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:42:04,773] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:42:04,774] {logging_mixin.py:109} INFO - [2022-08-13 22:42:04,774] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:42:05,264] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:42:05,277] {logging_mixin.py:109} INFO - [2022-08-13 22:42:05,276] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:42:05,293] {logging_mixin.py:109} INFO - [2022-08-13 22:42:05,293] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:42:05,304] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.537 seconds
[2022-08-13 22:42:35,747] {processor.py:163} INFO - Started process (PID=84961) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:42:35,749] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:42:35,750] {logging_mixin.py:109} INFO - [2022-08-13 22:42:35,750] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:42:36,417] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:42:36,430] {logging_mixin.py:109} INFO - [2022-08-13 22:42:36,429] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:42:36,445] {logging_mixin.py:109} INFO - [2022-08-13 22:42:36,445] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:42:36,458] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.715 seconds
[2022-08-13 22:43:06,544] {processor.py:163} INFO - Started process (PID=85029) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:43:06,547] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:43:06,548] {logging_mixin.py:109} INFO - [2022-08-13 22:43:06,548] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:43:07,027] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:43:07,040] {logging_mixin.py:109} INFO - [2022-08-13 22:43:07,039] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:43:07,059] {logging_mixin.py:109} INFO - [2022-08-13 22:43:07,059] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:43:07,074] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.533 seconds
[2022-08-13 22:43:37,324] {processor.py:163} INFO - Started process (PID=85103) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:43:37,326] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:43:37,327] {logging_mixin.py:109} INFO - [2022-08-13 22:43:37,327] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:43:37,709] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:43:37,720] {logging_mixin.py:109} INFO - [2022-08-13 22:43:37,719] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:43:37,735] {logging_mixin.py:109} INFO - [2022-08-13 22:43:37,734] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:43:37,744] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.424 seconds
[2022-08-13 22:44:08,064] {processor.py:163} INFO - Started process (PID=85168) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:44:08,066] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:44:08,068] {logging_mixin.py:109} INFO - [2022-08-13 22:44:08,068] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:44:08,616] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:44:08,641] {logging_mixin.py:109} INFO - [2022-08-13 22:44:08,639] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:44:08,658] {logging_mixin.py:109} INFO - [2022-08-13 22:44:08,658] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:44:08,668] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.611 seconds
[2022-08-13 22:44:39,122] {processor.py:163} INFO - Started process (PID=85243) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:44:39,125] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:44:39,126] {logging_mixin.py:109} INFO - [2022-08-13 22:44:39,126] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:44:39,619] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:44:39,644] {logging_mixin.py:109} INFO - [2022-08-13 22:44:39,642] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:44:39,670] {logging_mixin.py:109} INFO - [2022-08-13 22:44:39,670] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:44:39,690] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.595 seconds
[2022-08-13 22:45:10,429] {processor.py:163} INFO - Started process (PID=85304) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:45:10,432] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:45:10,434] {logging_mixin.py:109} INFO - [2022-08-13 22:45:10,433] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:45:10,904] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:45:10,916] {logging_mixin.py:109} INFO - [2022-08-13 22:45:10,915] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:45:10,932] {logging_mixin.py:109} INFO - [2022-08-13 22:45:10,932] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:45:10,944] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.521 seconds
[2022-08-13 22:45:41,028] {processor.py:163} INFO - Started process (PID=85378) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:45:41,030] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:45:41,032] {logging_mixin.py:109} INFO - [2022-08-13 22:45:41,031] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:45:41,526] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:45:41,539] {logging_mixin.py:109} INFO - [2022-08-13 22:45:41,538] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:45:41,558] {logging_mixin.py:109} INFO - [2022-08-13 22:45:41,558] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:45:41,568] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.544 seconds
[2022-08-13 22:46:12,436] {processor.py:163} INFO - Started process (PID=85444) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:46:12,440] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:46:12,441] {logging_mixin.py:109} INFO - [2022-08-13 22:46:12,441] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:46:12,919] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:46:12,933] {logging_mixin.py:109} INFO - [2022-08-13 22:46:12,932] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:46:12,953] {logging_mixin.py:109} INFO - [2022-08-13 22:46:12,953] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:46:12,966] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.535 seconds
[2022-08-13 22:46:43,769] {processor.py:163} INFO - Started process (PID=85518) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:46:43,773] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:46:43,776] {logging_mixin.py:109} INFO - [2022-08-13 22:46:43,775] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:46:44,241] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:46:44,252] {logging_mixin.py:109} INFO - [2022-08-13 22:46:44,251] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:46:44,267] {logging_mixin.py:109} INFO - [2022-08-13 22:46:44,267] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:46:44,277] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.512 seconds
[2022-08-13 22:47:15,137] {processor.py:163} INFO - Started process (PID=85582) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:47:15,140] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:47:15,141] {logging_mixin.py:109} INFO - [2022-08-13 22:47:15,141] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:47:15,577] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:47:15,587] {logging_mixin.py:109} INFO - [2022-08-13 22:47:15,587] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:47:15,604] {logging_mixin.py:109} INFO - [2022-08-13 22:47:15,603] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:47:15,614] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.482 seconds
[2022-08-13 22:47:46,589] {processor.py:163} INFO - Started process (PID=85657) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:47:46,591] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:47:46,593] {logging_mixin.py:109} INFO - [2022-08-13 22:47:46,593] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:47:47,024] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:47:47,034] {logging_mixin.py:109} INFO - [2022-08-13 22:47:47,033] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:47:47,050] {logging_mixin.py:109} INFO - [2022-08-13 22:47:47,049] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:47:47,060] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.476 seconds
[2022-08-13 22:48:17,954] {processor.py:163} INFO - Started process (PID=85722) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:48:17,956] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:48:17,957] {logging_mixin.py:109} INFO - [2022-08-13 22:48:17,957] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:48:18,381] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:48:18,395] {logging_mixin.py:109} INFO - [2022-08-13 22:48:18,393] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:48:18,410] {logging_mixin.py:109} INFO - [2022-08-13 22:48:18,410] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:48:18,420] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.472 seconds
[2022-08-13 22:48:49,390] {processor.py:163} INFO - Started process (PID=85796) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:48:49,392] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:48:49,393] {logging_mixin.py:109} INFO - [2022-08-13 22:48:49,393] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:48:49,878] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:48:49,892] {logging_mixin.py:109} INFO - [2022-08-13 22:48:49,891] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:48:49,912] {logging_mixin.py:109} INFO - [2022-08-13 22:48:49,912] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:48:49,925] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.540 seconds
[2022-08-13 22:49:19,994] {processor.py:163} INFO - Started process (PID=85860) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:49:19,996] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:49:19,998] {logging_mixin.py:109} INFO - [2022-08-13 22:49:19,998] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:49:20,414] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:49:20,426] {logging_mixin.py:109} INFO - [2022-08-13 22:49:20,425] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:49:20,441] {logging_mixin.py:109} INFO - [2022-08-13 22:49:20,441] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:49:20,452] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.463 seconds
[2022-08-13 22:49:50,539] {processor.py:163} INFO - Started process (PID=85934) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:49:50,541] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:49:50,543] {logging_mixin.py:109} INFO - [2022-08-13 22:49:50,543] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:49:51,026] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:49:51,037] {logging_mixin.py:109} INFO - [2022-08-13 22:49:51,035] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:49:51,052] {logging_mixin.py:109} INFO - [2022-08-13 22:49:51,052] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:49:51,062] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.527 seconds
[2022-08-13 22:50:21,778] {processor.py:163} INFO - Started process (PID=85999) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:50:21,781] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:50:21,782] {logging_mixin.py:109} INFO - [2022-08-13 22:50:21,782] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:50:22,249] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:50:22,259] {logging_mixin.py:109} INFO - [2022-08-13 22:50:22,258] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:50:22,273] {logging_mixin.py:109} INFO - [2022-08-13 22:50:22,273] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:50:22,283] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.510 seconds
[2022-08-13 22:50:53,150] {processor.py:163} INFO - Started process (PID=86067) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:50:53,152] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:50:53,155] {logging_mixin.py:109} INFO - [2022-08-13 22:50:53,155] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:50:53,744] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:50:53,760] {logging_mixin.py:109} INFO - [2022-08-13 22:50:53,759] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:50:53,785] {logging_mixin.py:109} INFO - [2022-08-13 22:50:53,785] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:50:53,802] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.658 seconds
[2022-08-13 22:51:24,502] {processor.py:163} INFO - Started process (PID=86142) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:51:24,505] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:51:24,506] {logging_mixin.py:109} INFO - [2022-08-13 22:51:24,506] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:51:25,006] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:51:25,017] {logging_mixin.py:109} INFO - [2022-08-13 22:51:25,016] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:51:25,032] {logging_mixin.py:109} INFO - [2022-08-13 22:51:25,032] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:51:25,042] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.544 seconds
[2022-08-13 22:51:55,217] {processor.py:163} INFO - Started process (PID=86207) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:51:55,220] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:51:55,221] {logging_mixin.py:109} INFO - [2022-08-13 22:51:55,221] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:51:55,607] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:51:55,617] {logging_mixin.py:109} INFO - [2022-08-13 22:51:55,616] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:51:55,630] {logging_mixin.py:109} INFO - [2022-08-13 22:51:55,630] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:51:55,640] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.428 seconds
[2022-08-13 22:52:26,520] {processor.py:163} INFO - Started process (PID=86281) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:52:26,523] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:52:26,525] {logging_mixin.py:109} INFO - [2022-08-13 22:52:26,525] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:52:26,962] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:52:26,973] {logging_mixin.py:109} INFO - [2022-08-13 22:52:26,972] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:52:26,989] {logging_mixin.py:109} INFO - [2022-08-13 22:52:26,989] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:52:27,001] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.485 seconds
[2022-08-13 22:52:57,991] {processor.py:163} INFO - Started process (PID=86347) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:52:57,994] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:52:57,996] {logging_mixin.py:109} INFO - [2022-08-13 22:52:57,996] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:52:58,451] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:52:58,461] {logging_mixin.py:109} INFO - [2022-08-13 22:52:58,460] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:52:58,476] {logging_mixin.py:109} INFO - [2022-08-13 22:52:58,476] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:52:58,487] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.501 seconds
[2022-08-13 22:53:29,351] {processor.py:163} INFO - Started process (PID=86421) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:53:29,354] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:53:29,356] {logging_mixin.py:109} INFO - [2022-08-13 22:53:29,356] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:53:29,864] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:53:29,877] {logging_mixin.py:109} INFO - [2022-08-13 22:53:29,876] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:53:29,893] {logging_mixin.py:109} INFO - [2022-08-13 22:53:29,893] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:53:29,907] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.560 seconds
[2022-08-13 22:54:00,668] {processor.py:163} INFO - Started process (PID=86486) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:54:00,672] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:54:00,674] {logging_mixin.py:109} INFO - [2022-08-13 22:54:00,673] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:54:01,195] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:54:01,207] {logging_mixin.py:109} INFO - [2022-08-13 22:54:01,206] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:54:01,224] {logging_mixin.py:109} INFO - [2022-08-13 22:54:01,224] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:54:01,239] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.577 seconds
[2022-08-13 22:54:31,427] {processor.py:163} INFO - Started process (PID=86559) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:54:31,430] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:54:31,432] {logging_mixin.py:109} INFO - [2022-08-13 22:54:31,431] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:54:31,969] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:54:31,987] {logging_mixin.py:109} INFO - [2022-08-13 22:54:31,986] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:54:32,005] {logging_mixin.py:109} INFO - [2022-08-13 22:54:32,005] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:54:32,023] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.602 seconds
[2022-08-13 22:55:02,094] {processor.py:163} INFO - Started process (PID=86624) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:55:02,098] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:55:02,100] {logging_mixin.py:109} INFO - [2022-08-13 22:55:02,100] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:55:02,616] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:55:02,629] {logging_mixin.py:109} INFO - [2022-08-13 22:55:02,628] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:55:02,646] {logging_mixin.py:109} INFO - [2022-08-13 22:55:02,645] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:55:02,660] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.576 seconds
[2022-08-13 22:55:32,781] {processor.py:163} INFO - Started process (PID=86698) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:55:32,783] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:55:32,785] {logging_mixin.py:109} INFO - [2022-08-13 22:55:32,785] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:55:33,259] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:55:33,274] {logging_mixin.py:109} INFO - [2022-08-13 22:55:33,273] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:55:33,293] {logging_mixin.py:109} INFO - [2022-08-13 22:55:33,292] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:55:33,304] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.529 seconds
[2022-08-13 22:56:03,384] {processor.py:163} INFO - Started process (PID=86766) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:56:03,386] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:56:03,388] {logging_mixin.py:109} INFO - [2022-08-13 22:56:03,387] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:56:03,924] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:56:03,934] {logging_mixin.py:109} INFO - [2022-08-13 22:56:03,933] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:56:03,950] {logging_mixin.py:109} INFO - [2022-08-13 22:56:03,949] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:56:03,960] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.580 seconds
[2022-08-13 22:56:34,798] {processor.py:163} INFO - Started process (PID=86842) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:56:34,800] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:56:34,801] {logging_mixin.py:109} INFO - [2022-08-13 22:56:34,801] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:56:35,268] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:56:35,279] {logging_mixin.py:109} INFO - [2022-08-13 22:56:35,278] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:56:35,297] {logging_mixin.py:109} INFO - [2022-08-13 22:56:35,297] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:56:35,313] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.519 seconds
[2022-08-13 22:57:05,467] {processor.py:163} INFO - Started process (PID=86910) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:57:05,469] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:57:05,471] {logging_mixin.py:109} INFO - [2022-08-13 22:57:05,470] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:57:05,880] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:57:05,895] {logging_mixin.py:109} INFO - [2022-08-13 22:57:05,894] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:57:05,915] {logging_mixin.py:109} INFO - [2022-08-13 22:57:05,915] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:57:05,939] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.475 seconds
[2022-08-13 22:57:36,684] {processor.py:163} INFO - Started process (PID=86975) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:57:36,686] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:57:36,688] {logging_mixin.py:109} INFO - [2022-08-13 22:57:36,688] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:57:37,088] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:57:37,099] {logging_mixin.py:109} INFO - [2022-08-13 22:57:37,098] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:57:37,117] {logging_mixin.py:109} INFO - [2022-08-13 22:57:37,117] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:57:37,128] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.449 seconds
[2022-08-13 22:58:07,569] {processor.py:163} INFO - Started process (PID=87051) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:58:07,572] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:58:07,574] {logging_mixin.py:109} INFO - [2022-08-13 22:58:07,574] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:58:07,967] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:58:07,978] {logging_mixin.py:109} INFO - [2022-08-13 22:58:07,977] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:58:07,992] {logging_mixin.py:109} INFO - [2022-08-13 22:58:07,992] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:58:08,001] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.438 seconds
[2022-08-13 22:58:38,810] {processor.py:163} INFO - Started process (PID=87122) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:58:38,816] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:58:38,819] {logging_mixin.py:109} INFO - [2022-08-13 22:58:38,819] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:58:39,261] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:58:39,274] {logging_mixin.py:109} INFO - [2022-08-13 22:58:39,273] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:58:39,290] {logging_mixin.py:109} INFO - [2022-08-13 22:58:39,290] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:58:39,302] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.517 seconds
[2022-08-13 22:59:09,603] {processor.py:163} INFO - Started process (PID=87195) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:59:09,606] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:59:09,608] {logging_mixin.py:109} INFO - [2022-08-13 22:59:09,608] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:59:10,061] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:59:10,072] {logging_mixin.py:109} INFO - [2022-08-13 22:59:10,071] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:59:10,088] {logging_mixin.py:109} INFO - [2022-08-13 22:59:10,088] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:59:10,101] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.502 seconds
[2022-08-13 22:59:40,596] {processor.py:163} INFO - Started process (PID=87256) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:59:40,599] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 22:59:40,601] {logging_mixin.py:109} INFO - [2022-08-13 22:59:40,601] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:59:41,068] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 22:59:41,081] {logging_mixin.py:109} INFO - [2022-08-13 22:59:41,080] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 22:59:41,098] {logging_mixin.py:109} INFO - [2022-08-13 22:59:41,098] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 22:59:41,111] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.522 seconds
[2022-08-13 23:00:11,519] {processor.py:163} INFO - Started process (PID=87335) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:00:11,522] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:00:11,523] {logging_mixin.py:109} INFO - [2022-08-13 23:00:11,523] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:00:12,059] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:00:12,071] {logging_mixin.py:109} INFO - [2022-08-13 23:00:12,070] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:00:12,088] {logging_mixin.py:109} INFO - [2022-08-13 23:00:12,088] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:00:12,102] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.587 seconds
[2022-08-13 23:00:42,326] {processor.py:163} INFO - Started process (PID=87401) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:00:42,329] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:00:42,331] {logging_mixin.py:109} INFO - [2022-08-13 23:00:42,331] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:00:42,861] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:00:42,874] {logging_mixin.py:109} INFO - [2022-08-13 23:00:42,873] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:00:42,895] {logging_mixin.py:109} INFO - [2022-08-13 23:00:42,895] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:00:42,911] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.589 seconds
[2022-08-13 23:01:13,361] {processor.py:163} INFO - Started process (PID=87479) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:01:13,364] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:01:13,365] {logging_mixin.py:109} INFO - [2022-08-13 23:01:13,365] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:01:13,863] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:01:13,881] {logging_mixin.py:109} INFO - [2022-08-13 23:01:13,879] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:01:13,903] {logging_mixin.py:109} INFO - [2022-08-13 23:01:13,903] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:01:13,916] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.558 seconds
[2022-08-13 23:01:43,964] {processor.py:163} INFO - Started process (PID=87548) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:01:43,966] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:01:43,968] {logging_mixin.py:109} INFO - [2022-08-13 23:01:43,967] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:01:44,388] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:01:44,399] {logging_mixin.py:109} INFO - [2022-08-13 23:01:44,398] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:01:44,415] {logging_mixin.py:109} INFO - [2022-08-13 23:01:44,415] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:01:44,428] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.467 seconds
[2022-08-13 23:02:14,730] {processor.py:163} INFO - Started process (PID=87624) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:02:14,732] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:02:14,733] {logging_mixin.py:109} INFO - [2022-08-13 23:02:14,733] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:02:15,189] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:02:15,201] {logging_mixin.py:109} INFO - [2022-08-13 23:02:15,200] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:02:15,215] {logging_mixin.py:109} INFO - [2022-08-13 23:02:15,215] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:02:15,225] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.499 seconds
[2022-08-13 23:02:46,045] {processor.py:163} INFO - Started process (PID=87689) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:02:46,047] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:02:46,049] {logging_mixin.py:109} INFO - [2022-08-13 23:02:46,049] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:02:46,505] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:02:46,516] {logging_mixin.py:109} INFO - [2022-08-13 23:02:46,515] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:02:46,531] {logging_mixin.py:109} INFO - [2022-08-13 23:02:46,531] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:02:46,540] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.501 seconds
[2022-08-13 23:03:17,180] {processor.py:163} INFO - Started process (PID=87765) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:03:17,183] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:03:17,185] {logging_mixin.py:109} INFO - [2022-08-13 23:03:17,184] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:03:17,671] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:03:17,685] {logging_mixin.py:109} INFO - [2022-08-13 23:03:17,684] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:03:17,704] {logging_mixin.py:109} INFO - [2022-08-13 23:03:17,704] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:03:17,714] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.541 seconds
[2022-08-13 23:03:47,914] {processor.py:163} INFO - Started process (PID=87831) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:03:47,916] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:03:47,917] {logging_mixin.py:109} INFO - [2022-08-13 23:03:47,917] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:03:48,336] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:03:48,348] {logging_mixin.py:109} INFO - [2022-08-13 23:03:48,347] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:03:48,363] {logging_mixin.py:109} INFO - [2022-08-13 23:03:48,363] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:03:48,376] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.466 seconds
[2022-08-13 23:04:18,634] {processor.py:163} INFO - Started process (PID=87908) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:04:18,636] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:04:18,638] {logging_mixin.py:109} INFO - [2022-08-13 23:04:18,637] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:04:19,116] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:04:19,127] {logging_mixin.py:109} INFO - [2022-08-13 23:04:19,126] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:04:19,144] {logging_mixin.py:109} INFO - [2022-08-13 23:04:19,144] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:04:19,163] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.533 seconds
[2022-08-13 23:04:49,290] {processor.py:163} INFO - Started process (PID=87974) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:04:49,297] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:04:49,299] {logging_mixin.py:109} INFO - [2022-08-13 23:04:49,298] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:04:49,754] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:04:49,766] {logging_mixin.py:109} INFO - [2022-08-13 23:04:49,765] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:04:49,780] {logging_mixin.py:109} INFO - [2022-08-13 23:04:49,779] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:04:49,789] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.505 seconds
[2022-08-13 23:05:20,030] {processor.py:163} INFO - Started process (PID=88049) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:05:20,033] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:05:20,036] {logging_mixin.py:109} INFO - [2022-08-13 23:05:20,035] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:05:20,547] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:05:20,565] {logging_mixin.py:109} INFO - [2022-08-13 23:05:20,564] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:05:20,589] {logging_mixin.py:109} INFO - [2022-08-13 23:05:20,588] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:05:20,608] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.584 seconds
[2022-08-13 23:05:51,297] {processor.py:163} INFO - Started process (PID=88116) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:05:51,301] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:05:51,303] {logging_mixin.py:109} INFO - [2022-08-13 23:05:51,302] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:05:51,758] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:05:51,769] {logging_mixin.py:109} INFO - [2022-08-13 23:05:51,768] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:05:51,784] {logging_mixin.py:109} INFO - [2022-08-13 23:05:51,784] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:05:51,796] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.505 seconds
[2022-08-13 23:06:22,685] {processor.py:163} INFO - Started process (PID=88191) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:06:22,688] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:06:22,690] {logging_mixin.py:109} INFO - [2022-08-13 23:06:22,690] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:06:23,154] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:06:23,166] {logging_mixin.py:109} INFO - [2022-08-13 23:06:23,165] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:06:23,181] {logging_mixin.py:109} INFO - [2022-08-13 23:06:23,181] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:06:23,193] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.511 seconds
[2022-08-13 23:06:54,149] {processor.py:163} INFO - Started process (PID=88257) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:06:54,153] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:06:54,155] {logging_mixin.py:109} INFO - [2022-08-13 23:06:54,155] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:06:54,538] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:06:54,549] {logging_mixin.py:109} INFO - [2022-08-13 23:06:54,548] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:06:54,563] {logging_mixin.py:109} INFO - [2022-08-13 23:06:54,563] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:06:54,572] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.429 seconds
[2022-08-13 23:07:25,329] {processor.py:163} INFO - Started process (PID=88331) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:07:25,331] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:07:25,332] {logging_mixin.py:109} INFO - [2022-08-13 23:07:25,332] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:07:25,786] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:07:25,798] {logging_mixin.py:109} INFO - [2022-08-13 23:07:25,797] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:07:25,817] {logging_mixin.py:109} INFO - [2022-08-13 23:07:25,816] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:07:25,830] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.505 seconds
[2022-08-13 23:07:55,911] {processor.py:163} INFO - Started process (PID=88397) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:07:55,913] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:07:55,915] {logging_mixin.py:109} INFO - [2022-08-13 23:07:55,915] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:07:56,311] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:07:56,325] {logging_mixin.py:109} INFO - [2022-08-13 23:07:56,324] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:07:56,343] {logging_mixin.py:109} INFO - [2022-08-13 23:07:56,343] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:07:56,356] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.450 seconds
[2022-08-13 23:08:27,149] {processor.py:163} INFO - Started process (PID=88473) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:08:27,151] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:08:27,153] {logging_mixin.py:109} INFO - [2022-08-13 23:08:27,153] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:08:27,636] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:08:27,651] {logging_mixin.py:109} INFO - [2022-08-13 23:08:27,650] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:08:27,669] {logging_mixin.py:109} INFO - [2022-08-13 23:08:27,668] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:08:27,685] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.540 seconds
[2022-08-13 23:08:57,965] {processor.py:163} INFO - Started process (PID=88539) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:08:57,976] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:08:57,979] {logging_mixin.py:109} INFO - [2022-08-13 23:08:57,978] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:08:58,381] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:08:58,394] {logging_mixin.py:109} INFO - [2022-08-13 23:08:58,393] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:08:58,411] {logging_mixin.py:109} INFO - [2022-08-13 23:08:58,411] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:08:58,423] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.462 seconds
[2022-08-13 23:09:28,573] {processor.py:163} INFO - Started process (PID=88604) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:09:28,576] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:09:28,577] {logging_mixin.py:109} INFO - [2022-08-13 23:09:28,577] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:09:28,979] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:09:28,991] {logging_mixin.py:109} INFO - [2022-08-13 23:09:28,990] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:09:29,007] {logging_mixin.py:109} INFO - [2022-08-13 23:09:29,007] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:09:29,018] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.450 seconds
[2022-08-13 23:09:59,203] {processor.py:163} INFO - Started process (PID=88680) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:09:59,206] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:09:59,208] {logging_mixin.py:109} INFO - [2022-08-13 23:09:59,208] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:09:59,590] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:09:59,603] {logging_mixin.py:109} INFO - [2022-08-13 23:09:59,602] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:09:59,618] {logging_mixin.py:109} INFO - [2022-08-13 23:09:59,618] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:09:59,627] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.430 seconds
[2022-08-13 23:10:30,220] {processor.py:163} INFO - Started process (PID=88746) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:10:30,222] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:10:30,224] {logging_mixin.py:109} INFO - [2022-08-13 23:10:30,224] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:10:30,615] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:10:30,626] {logging_mixin.py:109} INFO - [2022-08-13 23:10:30,625] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:10:30,641] {logging_mixin.py:109} INFO - [2022-08-13 23:10:30,641] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:10:30,651] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.436 seconds
[2022-08-13 23:11:01,560] {processor.py:163} INFO - Started process (PID=88821) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:11:01,563] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:11:01,564] {logging_mixin.py:109} INFO - [2022-08-13 23:11:01,564] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:11:02,034] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:11:02,048] {logging_mixin.py:109} INFO - [2022-08-13 23:11:02,047] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:11:02,068] {logging_mixin.py:109} INFO - [2022-08-13 23:11:02,068] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:11:02,084] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.531 seconds
[2022-08-13 23:11:32,186] {processor.py:163} INFO - Started process (PID=88887) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:11:32,188] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:11:32,190] {logging_mixin.py:109} INFO - [2022-08-13 23:11:32,189] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:11:32,596] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:11:32,608] {logging_mixin.py:109} INFO - [2022-08-13 23:11:32,608] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:11:32,623] {logging_mixin.py:109} INFO - [2022-08-13 23:11:32,623] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:11:32,632] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.452 seconds
[2022-08-13 23:12:02,827] {processor.py:163} INFO - Started process (PID=88963) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:12:02,829] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:12:02,833] {logging_mixin.py:109} INFO - [2022-08-13 23:12:02,833] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:12:03,242] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:12:03,254] {logging_mixin.py:109} INFO - [2022-08-13 23:12:03,253] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:12:03,269] {logging_mixin.py:109} INFO - [2022-08-13 23:12:03,269] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:12:03,279] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.456 seconds
[2022-08-13 23:12:33,490] {processor.py:163} INFO - Started process (PID=89027) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:12:33,492] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:12:33,494] {logging_mixin.py:109} INFO - [2022-08-13 23:12:33,494] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:12:33,922] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:12:33,933] {logging_mixin.py:109} INFO - [2022-08-13 23:12:33,932] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:12:33,948] {logging_mixin.py:109} INFO - [2022-08-13 23:12:33,948] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:12:33,959] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.474 seconds
[2022-08-13 23:13:04,043] {processor.py:163} INFO - Started process (PID=89103) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:13:04,046] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:13:04,049] {logging_mixin.py:109} INFO - [2022-08-13 23:13:04,049] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:13:04,528] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:13:04,538] {logging_mixin.py:109} INFO - [2022-08-13 23:13:04,537] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:13:04,553] {logging_mixin.py:109} INFO - [2022-08-13 23:13:04,553] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:13:04,563] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.529 seconds
[2022-08-13 23:13:34,838] {processor.py:163} INFO - Started process (PID=89168) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:13:34,840] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:13:34,841] {logging_mixin.py:109} INFO - [2022-08-13 23:13:34,841] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:13:35,308] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:13:35,338] {logging_mixin.py:109} INFO - [2022-08-13 23:13:35,337] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:13:35,359] {logging_mixin.py:109} INFO - [2022-08-13 23:13:35,359] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:13:35,375] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.544 seconds
[2022-08-13 23:14:05,681] {processor.py:163} INFO - Started process (PID=89243) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:14:05,683] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:14:05,685] {logging_mixin.py:109} INFO - [2022-08-13 23:14:05,685] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:14:06,139] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:14:06,152] {logging_mixin.py:109} INFO - [2022-08-13 23:14:06,151] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:14:06,170] {logging_mixin.py:109} INFO - [2022-08-13 23:14:06,170] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:14:06,179] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.502 seconds
[2022-08-13 23:14:36,890] {processor.py:163} INFO - Started process (PID=89308) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:14:36,893] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:14:36,895] {logging_mixin.py:109} INFO - [2022-08-13 23:14:36,894] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:14:37,382] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:14:37,393] {logging_mixin.py:109} INFO - [2022-08-13 23:14:37,392] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:14:37,409] {logging_mixin.py:109} INFO - [2022-08-13 23:14:37,409] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:14:37,420] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.536 seconds
[2022-08-13 23:15:07,974] {processor.py:163} INFO - Started process (PID=89382) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:15:07,976] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:15:07,978] {logging_mixin.py:109} INFO - [2022-08-13 23:15:07,977] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:15:08,446] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:15:08,456] {logging_mixin.py:109} INFO - [2022-08-13 23:15:08,455] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:15:08,470] {logging_mixin.py:109} INFO - [2022-08-13 23:15:08,470] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:15:08,481] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.534 seconds
[2022-08-13 23:15:38,630] {processor.py:163} INFO - Started process (PID=89448) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:15:38,633] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:15:38,636] {logging_mixin.py:109} INFO - [2022-08-13 23:15:38,636] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:15:39,065] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:15:39,080] {logging_mixin.py:109} INFO - [2022-08-13 23:15:39,079] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:15:39,096] {logging_mixin.py:109} INFO - [2022-08-13 23:15:39,096] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:15:39,106] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.483 seconds
[2022-08-13 23:16:09,157] {processor.py:163} INFO - Started process (PID=89516) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:16:09,159] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:16:09,160] {logging_mixin.py:109} INFO - [2022-08-13 23:16:09,160] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:16:09,610] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:16:09,620] {logging_mixin.py:109} INFO - [2022-08-13 23:16:09,619] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:16:09,636] {logging_mixin.py:109} INFO - [2022-08-13 23:16:09,636] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:16:09,647] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.493 seconds
[2022-08-13 23:16:39,782] {processor.py:163} INFO - Started process (PID=89586) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:16:39,785] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:16:39,787] {logging_mixin.py:109} INFO - [2022-08-13 23:16:39,787] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:16:40,235] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:16:40,248] {logging_mixin.py:109} INFO - [2022-08-13 23:16:40,247] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:16:40,267] {logging_mixin.py:109} INFO - [2022-08-13 23:16:40,267] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:16:40,284] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.508 seconds
[2022-08-13 23:17:11,068] {processor.py:163} INFO - Started process (PID=89653) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:17:11,071] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:17:11,073] {logging_mixin.py:109} INFO - [2022-08-13 23:17:11,073] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:17:11,549] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:17:11,563] {logging_mixin.py:109} INFO - [2022-08-13 23:17:11,561] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:17:11,584] {logging_mixin.py:109} INFO - [2022-08-13 23:17:11,584] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:17:11,605] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.546 seconds
[2022-08-13 23:17:42,091] {processor.py:163} INFO - Started process (PID=89727) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:17:42,093] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:17:42,095] {logging_mixin.py:109} INFO - [2022-08-13 23:17:42,095] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:17:42,510] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:17:42,522] {logging_mixin.py:109} INFO - [2022-08-13 23:17:42,520] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:17:42,538] {logging_mixin.py:109} INFO - [2022-08-13 23:17:42,538] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:17:42,549] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.465 seconds
[2022-08-13 23:18:13,397] {processor.py:163} INFO - Started process (PID=89793) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:18:13,400] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:18:13,402] {logging_mixin.py:109} INFO - [2022-08-13 23:18:13,402] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:18:13,856] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:18:13,867] {logging_mixin.py:109} INFO - [2022-08-13 23:18:13,867] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:18:13,884] {logging_mixin.py:109} INFO - [2022-08-13 23:18:13,883] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:18:13,895] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.505 seconds
[2022-08-13 23:18:44,068] {processor.py:163} INFO - Started process (PID=89870) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:18:44,071] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:18:44,073] {logging_mixin.py:109} INFO - [2022-08-13 23:18:44,073] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:18:44,470] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:18:44,480] {logging_mixin.py:109} INFO - [2022-08-13 23:18:44,479] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:18:44,496] {logging_mixin.py:109} INFO - [2022-08-13 23:18:44,496] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:18:44,506] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.442 seconds
[2022-08-13 23:19:15,012] {processor.py:163} INFO - Started process (PID=89935) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:19:15,015] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:19:15,017] {logging_mixin.py:109} INFO - [2022-08-13 23:19:15,017] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:19:15,477] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:19:15,488] {logging_mixin.py:109} INFO - [2022-08-13 23:19:15,487] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:19:15,503] {logging_mixin.py:109} INFO - [2022-08-13 23:19:15,503] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:19:15,513] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.506 seconds
[2022-08-13 23:19:45,574] {processor.py:163} INFO - Started process (PID=90010) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:19:45,579] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:19:45,582] {logging_mixin.py:109} INFO - [2022-08-13 23:19:45,582] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:19:46,030] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:19:46,042] {logging_mixin.py:109} INFO - [2022-08-13 23:19:46,041] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:19:46,057] {logging_mixin.py:109} INFO - [2022-08-13 23:19:46,057] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:19:46,067] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.497 seconds
[2022-08-13 23:20:16,306] {processor.py:163} INFO - Started process (PID=90075) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:20:16,308] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:20:16,309] {logging_mixin.py:109} INFO - [2022-08-13 23:20:16,309] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:20:16,741] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:20:16,753] {logging_mixin.py:109} INFO - [2022-08-13 23:20:16,752] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:20:16,768] {logging_mixin.py:109} INFO - [2022-08-13 23:20:16,768] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:20:16,778] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.477 seconds
[2022-08-13 23:20:47,016] {processor.py:163} INFO - Started process (PID=90149) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:20:47,019] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:20:47,021] {logging_mixin.py:109} INFO - [2022-08-13 23:20:47,021] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:20:47,481] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:20:47,493] {logging_mixin.py:109} INFO - [2022-08-13 23:20:47,492] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:20:47,507] {logging_mixin.py:109} INFO - [2022-08-13 23:20:47,507] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:20:47,518] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.508 seconds
[2022-08-13 23:21:17,595] {processor.py:163} INFO - Started process (PID=90214) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:21:17,597] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:21:17,601] {logging_mixin.py:109} INFO - [2022-08-13 23:21:17,600] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:21:18,047] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:21:18,058] {logging_mixin.py:109} INFO - [2022-08-13 23:21:18,057] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:21:18,073] {logging_mixin.py:109} INFO - [2022-08-13 23:21:18,072] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:21:18,085] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.494 seconds
[2022-08-13 23:21:48,294] {processor.py:163} INFO - Started process (PID=90289) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:21:48,297] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:21:48,299] {logging_mixin.py:109} INFO - [2022-08-13 23:21:48,299] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:21:48,750] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:21:48,761] {logging_mixin.py:109} INFO - [2022-08-13 23:21:48,760] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:21:48,777] {logging_mixin.py:109} INFO - [2022-08-13 23:21:48,777] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:21:48,790] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.504 seconds
[2022-08-13 23:22:18,909] {processor.py:163} INFO - Started process (PID=90355) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:22:18,912] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:22:18,913] {logging_mixin.py:109} INFO - [2022-08-13 23:22:18,913] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:22:19,333] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:22:19,352] {logging_mixin.py:109} INFO - [2022-08-13 23:22:19,351] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:22:19,368] {logging_mixin.py:109} INFO - [2022-08-13 23:22:19,368] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:22:19,378] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.474 seconds
[2022-08-13 23:22:49,610] {processor.py:163} INFO - Started process (PID=90430) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:22:49,612] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:22:49,614] {logging_mixin.py:109} INFO - [2022-08-13 23:22:49,613] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:22:50,102] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:22:50,113] {logging_mixin.py:109} INFO - [2022-08-13 23:22:50,112] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:22:50,129] {logging_mixin.py:109} INFO - [2022-08-13 23:22:50,129] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:22:50,142] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.537 seconds
[2022-08-13 23:23:20,230] {processor.py:163} INFO - Started process (PID=90496) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:23:20,232] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:23:20,234] {logging_mixin.py:109} INFO - [2022-08-13 23:23:20,234] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:23:20,664] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:23:20,675] {logging_mixin.py:109} INFO - [2022-08-13 23:23:20,674] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:23:20,692] {logging_mixin.py:109} INFO - [2022-08-13 23:23:20,692] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:23:20,702] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.478 seconds
[2022-08-13 23:23:51,634] {processor.py:163} INFO - Started process (PID=90570) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:23:51,637] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:23:51,639] {logging_mixin.py:109} INFO - [2022-08-13 23:23:51,639] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:23:52,115] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:23:52,126] {logging_mixin.py:109} INFO - [2022-08-13 23:23:52,125] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:23:52,140] {logging_mixin.py:109} INFO - [2022-08-13 23:23:52,140] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:23:52,151] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.521 seconds
[2022-08-13 23:24:22,383] {processor.py:163} INFO - Started process (PID=90637) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:24:22,385] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:24:22,386] {logging_mixin.py:109} INFO - [2022-08-13 23:24:22,386] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:24:22,849] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:24:22,859] {logging_mixin.py:109} INFO - [2022-08-13 23:24:22,858] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:24:22,873] {logging_mixin.py:109} INFO - [2022-08-13 23:24:22,873] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:24:22,882] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.503 seconds
[2022-08-13 23:24:53,487] {processor.py:163} INFO - Started process (PID=90711) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:24:53,490] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:24:53,491] {logging_mixin.py:109} INFO - [2022-08-13 23:24:53,491] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:24:53,958] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:24:53,972] {logging_mixin.py:109} INFO - [2022-08-13 23:24:53,971] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:24:53,990] {logging_mixin.py:109} INFO - [2022-08-13 23:24:53,990] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:24:54,003] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.522 seconds
[2022-08-13 23:25:24,170] {processor.py:163} INFO - Started process (PID=90776) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:25:24,173] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:25:24,174] {logging_mixin.py:109} INFO - [2022-08-13 23:25:24,174] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:25:24,566] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:25:24,581] {logging_mixin.py:109} INFO - [2022-08-13 23:25:24,580] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:25:24,602] {logging_mixin.py:109} INFO - [2022-08-13 23:25:24,602] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:25:24,614] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.450 seconds
[2022-08-13 23:25:55,460] {processor.py:163} INFO - Started process (PID=90849) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:25:55,462] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:25:55,464] {logging_mixin.py:109} INFO - [2022-08-13 23:25:55,463] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:25:55,925] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:25:55,935] {logging_mixin.py:109} INFO - [2022-08-13 23:25:55,935] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:25:55,951] {logging_mixin.py:109} INFO - [2022-08-13 23:25:55,951] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:25:55,960] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.504 seconds
[2022-08-13 23:26:26,147] {processor.py:163} INFO - Started process (PID=90916) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:26:26,150] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:26:26,151] {logging_mixin.py:109} INFO - [2022-08-13 23:26:26,151] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:26:26,589] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:26:26,600] {logging_mixin.py:109} INFO - [2022-08-13 23:26:26,600] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:26:26,619] {logging_mixin.py:109} INFO - [2022-08-13 23:26:26,619] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:26:26,641] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.498 seconds
[2022-08-13 23:26:57,309] {processor.py:163} INFO - Started process (PID=90989) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:26:57,311] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:26:57,312] {logging_mixin.py:109} INFO - [2022-08-13 23:26:57,312] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:26:57,804] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:26:57,823] {logging_mixin.py:109} INFO - [2022-08-13 23:26:57,821] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:26:57,845] {logging_mixin.py:109} INFO - [2022-08-13 23:26:57,845] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:26:57,857] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.552 seconds
[2022-08-13 23:27:27,957] {processor.py:163} INFO - Started process (PID=91057) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:27:27,959] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:27:27,963] {logging_mixin.py:109} INFO - [2022-08-13 23:27:27,963] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:27:28,412] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:27:28,424] {logging_mixin.py:109} INFO - [2022-08-13 23:27:28,423] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:27:28,439] {logging_mixin.py:109} INFO - [2022-08-13 23:27:28,439] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:27:28,450] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.496 seconds
[2022-08-13 23:27:59,056] {processor.py:163} INFO - Started process (PID=91122) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:27:59,058] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:27:59,060] {logging_mixin.py:109} INFO - [2022-08-13 23:27:59,060] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:27:59,559] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:27:59,570] {logging_mixin.py:109} INFO - [2022-08-13 23:27:59,569] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:27:59,588] {logging_mixin.py:109} INFO - [2022-08-13 23:27:59,588] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:27:59,598] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.545 seconds
[2022-08-13 23:28:29,739] {processor.py:163} INFO - Started process (PID=91198) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:28:29,741] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:28:29,742] {logging_mixin.py:109} INFO - [2022-08-13 23:28:29,742] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:28:30,131] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:28:30,142] {logging_mixin.py:109} INFO - [2022-08-13 23:28:30,141] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:28:30,156] {logging_mixin.py:109} INFO - [2022-08-13 23:28:30,156] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:28:30,165] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.429 seconds
[2022-08-13 23:29:00,450] {processor.py:163} INFO - Started process (PID=91262) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:29:00,452] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:29:00,455] {logging_mixin.py:109} INFO - [2022-08-13 23:29:00,454] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:29:00,903] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:29:00,914] {logging_mixin.py:109} INFO - [2022-08-13 23:29:00,913] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:29:00,929] {logging_mixin.py:109} INFO - [2022-08-13 23:29:00,929] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:29:00,940] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.494 seconds
[2022-08-13 23:29:31,105] {processor.py:163} INFO - Started process (PID=91337) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:29:31,109] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:29:31,111] {logging_mixin.py:109} INFO - [2022-08-13 23:29:31,111] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:29:31,617] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:29:31,629] {logging_mixin.py:109} INFO - [2022-08-13 23:29:31,628] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:29:31,646] {logging_mixin.py:109} INFO - [2022-08-13 23:29:31,646] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:29:31,678] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.580 seconds
[2022-08-13 23:30:01,825] {processor.py:163} INFO - Started process (PID=91402) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:30:01,828] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:30:01,830] {logging_mixin.py:109} INFO - [2022-08-13 23:30:01,830] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:30:02,333] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:30:02,349] {logging_mixin.py:109} INFO - [2022-08-13 23:30:02,348] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:30:02,371] {logging_mixin.py:109} INFO - [2022-08-13 23:30:02,371] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:30:02,387] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.569 seconds
[2022-08-13 23:30:32,447] {processor.py:163} INFO - Started process (PID=91479) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:30:32,450] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:30:32,452] {logging_mixin.py:109} INFO - [2022-08-13 23:30:32,452] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:30:32,974] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:30:32,988] {logging_mixin.py:109} INFO - [2022-08-13 23:30:32,987] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:30:33,007] {logging_mixin.py:109} INFO - [2022-08-13 23:30:33,006] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:30:33,021] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.577 seconds
[2022-08-13 23:31:03,694] {processor.py:163} INFO - Started process (PID=91544) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:31:03,696] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:31:03,698] {logging_mixin.py:109} INFO - [2022-08-13 23:31:03,698] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:31:04,173] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:31:04,186] {logging_mixin.py:109} INFO - [2022-08-13 23:31:04,185] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:31:04,205] {logging_mixin.py:109} INFO - [2022-08-13 23:31:04,205] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:31:04,217] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.528 seconds
[2022-08-13 23:31:34,869] {processor.py:163} INFO - Started process (PID=91609) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:31:34,873] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:31:34,875] {logging_mixin.py:109} INFO - [2022-08-13 23:31:34,875] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:31:35,409] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:31:35,422] {logging_mixin.py:109} INFO - [2022-08-13 23:31:35,422] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:31:35,442] {logging_mixin.py:109} INFO - [2022-08-13 23:31:35,442] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:31:35,455] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.591 seconds
[2022-08-13 23:32:06,166] {processor.py:163} INFO - Started process (PID=91684) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:32:06,170] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:32:06,171] {logging_mixin.py:109} INFO - [2022-08-13 23:32:06,171] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:32:06,715] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:32:06,731] {logging_mixin.py:109} INFO - [2022-08-13 23:32:06,730] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:32:06,749] {logging_mixin.py:109} INFO - [2022-08-13 23:32:06,749] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:32:06,762] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.599 seconds
[2022-08-13 23:32:37,478] {processor.py:163} INFO - Started process (PID=91749) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:32:37,481] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:32:37,482] {logging_mixin.py:109} INFO - [2022-08-13 23:32:37,482] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:32:37,943] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:32:37,956] {logging_mixin.py:109} INFO - [2022-08-13 23:32:37,955] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:32:37,973] {logging_mixin.py:109} INFO - [2022-08-13 23:32:37,972] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:32:37,984] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.533 seconds
[2022-08-13 23:33:08,667] {processor.py:163} INFO - Started process (PID=91823) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:33:08,670] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:33:08,671] {logging_mixin.py:109} INFO - [2022-08-13 23:33:08,671] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:33:09,209] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:33:09,223] {logging_mixin.py:109} INFO - [2022-08-13 23:33:09,222] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:33:09,244] {logging_mixin.py:109} INFO - [2022-08-13 23:33:09,244] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:33:09,257] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.598 seconds
[2022-08-13 23:33:39,380] {processor.py:163} INFO - Started process (PID=91891) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:33:39,383] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:33:39,385] {logging_mixin.py:109} INFO - [2022-08-13 23:33:39,385] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:33:39,940] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:33:39,953] {logging_mixin.py:109} INFO - [2022-08-13 23:33:39,952] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:33:39,973] {logging_mixin.py:109} INFO - [2022-08-13 23:33:39,972] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:33:39,985] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.609 seconds
[2022-08-13 23:34:10,427] {processor.py:163} INFO - Started process (PID=91955) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:34:10,430] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:34:10,433] {logging_mixin.py:109} INFO - [2022-08-13 23:34:10,433] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:34:10,881] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:34:10,891] {logging_mixin.py:109} INFO - [2022-08-13 23:34:10,890] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:34:10,906] {logging_mixin.py:109} INFO - [2022-08-13 23:34:10,906] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:34:10,919] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.498 seconds
[2022-08-13 23:34:41,957] {processor.py:163} INFO - Started process (PID=92032) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:34:41,961] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:34:41,963] {logging_mixin.py:109} INFO - [2022-08-13 23:34:41,962] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:34:42,512] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:34:42,527] {logging_mixin.py:109} INFO - [2022-08-13 23:34:42,525] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:34:42,544] {logging_mixin.py:109} INFO - [2022-08-13 23:34:42,544] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:34:42,555] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.609 seconds
[2022-08-13 23:35:12,602] {processor.py:163} INFO - Started process (PID=92101) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:35:12,604] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:35:12,605] {logging_mixin.py:109} INFO - [2022-08-13 23:35:12,605] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:35:13,130] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:35:13,146] {logging_mixin.py:109} INFO - [2022-08-13 23:35:13,145] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:35:13,171] {logging_mixin.py:109} INFO - [2022-08-13 23:35:13,171] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:35:13,189] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.592 seconds
[2022-08-13 23:35:44,037] {processor.py:163} INFO - Started process (PID=92175) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:35:44,041] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:35:44,043] {logging_mixin.py:109} INFO - [2022-08-13 23:35:44,043] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:35:44,585] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:35:44,597] {logging_mixin.py:109} INFO - [2022-08-13 23:35:44,597] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:35:44,615] {logging_mixin.py:109} INFO - [2022-08-13 23:35:44,615] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:35:44,628] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.596 seconds
[2022-08-13 23:36:15,414] {processor.py:163} INFO - Started process (PID=92240) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:36:15,417] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:36:15,420] {logging_mixin.py:109} INFO - [2022-08-13 23:36:15,420] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:36:15,916] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:36:15,930] {logging_mixin.py:109} INFO - [2022-08-13 23:36:15,929] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:36:15,946] {logging_mixin.py:109} INFO - [2022-08-13 23:36:15,946] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:36:15,958] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.550 seconds
[2022-08-13 23:36:46,609] {processor.py:163} INFO - Started process (PID=92315) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:36:46,613] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:36:46,615] {logging_mixin.py:109} INFO - [2022-08-13 23:36:46,614] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:36:47,173] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:36:47,187] {logging_mixin.py:109} INFO - [2022-08-13 23:36:47,186] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:36:47,206] {logging_mixin.py:109} INFO - [2022-08-13 23:36:47,206] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:36:47,223] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.618 seconds
[2022-08-13 23:37:17,584] {processor.py:163} INFO - Started process (PID=92382) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:37:17,587] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:37:17,588] {logging_mixin.py:109} INFO - [2022-08-13 23:37:17,588] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:37:18,066] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:37:18,082] {logging_mixin.py:109} INFO - [2022-08-13 23:37:18,081] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:37:18,100] {logging_mixin.py:109} INFO - [2022-08-13 23:37:18,100] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:37:18,113] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.534 seconds
[2022-08-13 23:37:48,831] {processor.py:163} INFO - Started process (PID=92448) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:37:48,833] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:37:48,835] {logging_mixin.py:109} INFO - [2022-08-13 23:37:48,835] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:37:49,382] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:37:49,398] {logging_mixin.py:109} INFO - [2022-08-13 23:37:49,398] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:37:49,417] {logging_mixin.py:109} INFO - [2022-08-13 23:37:49,417] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:37:49,432] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.604 seconds
[2022-08-13 23:38:19,989] {processor.py:163} INFO - Started process (PID=92523) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:38:19,991] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:38:19,995] {logging_mixin.py:109} INFO - [2022-08-13 23:38:19,994] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:38:20,482] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:38:20,498] {logging_mixin.py:109} INFO - [2022-08-13 23:38:20,497] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:38:20,517] {logging_mixin.py:109} INFO - [2022-08-13 23:38:20,516] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:38:20,532] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.548 seconds
[2022-08-13 23:38:51,230] {processor.py:163} INFO - Started process (PID=92588) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:38:51,233] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:38:51,234] {logging_mixin.py:109} INFO - [2022-08-13 23:38:51,234] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:38:51,722] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:38:51,737] {logging_mixin.py:109} INFO - [2022-08-13 23:38:51,735] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:38:51,757] {logging_mixin.py:109} INFO - [2022-08-13 23:38:51,757] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:38:51,769] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.545 seconds
[2022-08-13 23:39:22,502] {processor.py:163} INFO - Started process (PID=92663) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:39:22,505] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:39:22,507] {logging_mixin.py:109} INFO - [2022-08-13 23:39:22,507] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:39:23,023] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:39:23,036] {logging_mixin.py:109} INFO - [2022-08-13 23:39:23,035] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:39:23,054] {logging_mixin.py:109} INFO - [2022-08-13 23:39:23,054] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:39:23,066] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.578 seconds
[2022-08-13 23:39:53,241] {processor.py:163} INFO - Started process (PID=92729) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:39:53,245] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:39:53,246] {logging_mixin.py:109} INFO - [2022-08-13 23:39:53,246] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:39:53,723] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:39:53,737] {logging_mixin.py:109} INFO - [2022-08-13 23:39:53,736] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:39:53,755] {logging_mixin.py:109} INFO - [2022-08-13 23:39:53,754] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:39:53,767] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.531 seconds
[2022-08-13 23:40:24,673] {processor.py:163} INFO - Started process (PID=92794) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:40:24,677] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:40:24,679] {logging_mixin.py:109} INFO - [2022-08-13 23:40:24,679] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:40:25,283] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:40:25,298] {logging_mixin.py:109} INFO - [2022-08-13 23:40:25,297] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:40:25,317] {logging_mixin.py:109} INFO - [2022-08-13 23:40:25,317] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:40:25,330] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.660 seconds
[2022-08-13 23:40:56,060] {processor.py:163} INFO - Started process (PID=92870) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:40:56,064] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:40:56,067] {logging_mixin.py:109} INFO - [2022-08-13 23:40:56,066] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:40:56,550] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:40:56,562] {logging_mixin.py:109} INFO - [2022-08-13 23:40:56,561] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:40:56,581] {logging_mixin.py:109} INFO - [2022-08-13 23:40:56,581] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:40:56,592] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.536 seconds
[2022-08-13 23:41:26,916] {processor.py:163} INFO - Started process (PID=92934) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:41:26,919] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:41:26,922] {logging_mixin.py:109} INFO - [2022-08-13 23:41:26,921] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:41:27,458] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:41:27,472] {logging_mixin.py:109} INFO - [2022-08-13 23:41:27,471] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:41:27,493] {logging_mixin.py:109} INFO - [2022-08-13 23:41:27,493] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:41:27,505] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.597 seconds
[2022-08-13 23:41:57,719] {processor.py:163} INFO - Started process (PID=93008) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:41:57,723] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:41:57,726] {logging_mixin.py:109} INFO - [2022-08-13 23:41:57,726] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:41:58,228] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:41:58,239] {logging_mixin.py:109} INFO - [2022-08-13 23:41:58,238] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:41:58,355] {logging_mixin.py:109} INFO - [2022-08-13 23:41:58,355] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:41:58,370] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.655 seconds
[2022-08-13 23:42:28,925] {processor.py:163} INFO - Started process (PID=93074) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:42:28,927] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:42:28,929] {logging_mixin.py:109} INFO - [2022-08-13 23:42:28,929] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:42:29,421] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:42:29,435] {logging_mixin.py:109} INFO - [2022-08-13 23:42:29,434] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:42:29,561] {logging_mixin.py:109} INFO - [2022-08-13 23:42:29,561] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:42:29,576] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.656 seconds
[2022-08-13 23:42:59,769] {processor.py:163} INFO - Started process (PID=93139) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:42:59,772] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:42:59,774] {logging_mixin.py:109} INFO - [2022-08-13 23:42:59,774] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:43:00,434] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:43:00,447] {logging_mixin.py:109} INFO - [2022-08-13 23:43:00,446] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:43:00,466] {logging_mixin.py:109} INFO - [2022-08-13 23:43:00,466] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:43:00,486] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.723 seconds
[2022-08-13 23:43:30,985] {processor.py:163} INFO - Started process (PID=93214) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:43:30,987] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:43:30,989] {logging_mixin.py:109} INFO - [2022-08-13 23:43:30,989] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:43:31,627] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:43:31,641] {logging_mixin.py:109} INFO - [2022-08-13 23:43:31,641] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:43:31,661] {logging_mixin.py:109} INFO - [2022-08-13 23:43:31,660] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:43:31,677] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.698 seconds
[2022-08-13 23:44:02,342] {processor.py:163} INFO - Started process (PID=93280) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:44:02,345] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:44:02,347] {logging_mixin.py:109} INFO - [2022-08-13 23:44:02,346] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:44:02,986] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:44:02,997] {logging_mixin.py:109} INFO - [2022-08-13 23:44:02,996] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:44:03,013] {logging_mixin.py:109} INFO - [2022-08-13 23:44:03,013] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:44:03,028] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.694 seconds
[2022-08-13 23:44:33,531] {processor.py:163} INFO - Started process (PID=93356) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:44:33,534] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:44:33,536] {logging_mixin.py:109} INFO - [2022-08-13 23:44:33,536] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:44:34,017] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:44:34,033] {logging_mixin.py:109} INFO - [2022-08-13 23:44:34,032] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:44:34,057] {logging_mixin.py:109} INFO - [2022-08-13 23:44:34,057] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:44:34,067] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.540 seconds
[2022-08-13 23:45:04,830] {processor.py:163} INFO - Started process (PID=93421) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:45:04,832] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:45:04,833] {logging_mixin.py:109} INFO - [2022-08-13 23:45:04,833] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:45:05,496] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:45:05,508] {logging_mixin.py:109} INFO - [2022-08-13 23:45:05,507] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:45:05,527] {logging_mixin.py:109} INFO - [2022-08-13 23:45:05,526] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:45:05,539] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.714 seconds
[2022-08-13 23:45:36,280] {processor.py:163} INFO - Started process (PID=93498) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:45:36,283] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:45:36,285] {logging_mixin.py:109} INFO - [2022-08-13 23:45:36,284] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:45:36,963] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:45:36,974] {logging_mixin.py:109} INFO - [2022-08-13 23:45:36,973] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:45:36,992] {logging_mixin.py:109} INFO - [2022-08-13 23:45:36,992] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:45:37,006] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.730 seconds
[2022-08-13 23:46:07,079] {processor.py:163} INFO - Started process (PID=93564) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:46:07,087] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:46:07,089] {logging_mixin.py:109} INFO - [2022-08-13 23:46:07,089] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:46:07,672] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:46:07,685] {logging_mixin.py:109} INFO - [2022-08-13 23:46:07,685] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:46:07,700] {logging_mixin.py:109} INFO - [2022-08-13 23:46:07,700] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:46:07,711] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.659 seconds
[2022-08-13 23:46:38,169] {processor.py:163} INFO - Started process (PID=93627) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:46:38,172] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:46:38,175] {logging_mixin.py:109} INFO - [2022-08-13 23:46:38,174] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:46:39,026] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:46:39,037] {logging_mixin.py:109} INFO - [2022-08-13 23:46:39,036] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:46:39,060] {logging_mixin.py:109} INFO - [2022-08-13 23:46:39,060] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:46:39,076] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.916 seconds
[2022-08-13 23:47:10,050] {processor.py:163} INFO - Started process (PID=93700) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:47:10,054] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:47:10,056] {logging_mixin.py:109} INFO - [2022-08-13 23:47:10,055] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:47:10,595] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:47:10,611] {logging_mixin.py:109} INFO - [2022-08-13 23:47:10,610] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:47:10,630] {logging_mixin.py:109} INFO - [2022-08-13 23:47:10,630] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:47:10,645] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.600 seconds
[2022-08-13 23:47:41,376] {processor.py:163} INFO - Started process (PID=93765) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:47:41,378] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:47:41,380] {logging_mixin.py:109} INFO - [2022-08-13 23:47:41,380] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:47:41,930] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:47:41,943] {logging_mixin.py:109} INFO - [2022-08-13 23:47:41,941] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:47:41,962] {logging_mixin.py:109} INFO - [2022-08-13 23:47:41,962] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:47:41,973] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.607 seconds
[2022-08-13 23:48:12,577] {processor.py:163} INFO - Started process (PID=93839) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:48:12,579] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:48:12,581] {logging_mixin.py:109} INFO - [2022-08-13 23:48:12,581] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:48:13,147] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:48:13,163] {logging_mixin.py:109} INFO - [2022-08-13 23:48:13,162] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:48:13,182] {logging_mixin.py:109} INFO - [2022-08-13 23:48:13,181] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:48:13,199] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.627 seconds
[2022-08-13 23:48:44,044] {processor.py:163} INFO - Started process (PID=93904) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:48:44,046] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:48:44,047] {logging_mixin.py:109} INFO - [2022-08-13 23:48:44,047] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:48:44,691] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:48:44,706] {logging_mixin.py:109} INFO - [2022-08-13 23:48:44,705] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:48:44,728] {logging_mixin.py:109} INFO - [2022-08-13 23:48:44,728] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:48:44,741] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.702 seconds
[2022-08-13 23:49:15,477] {processor.py:163} INFO - Started process (PID=93979) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:49:15,480] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:49:15,481] {logging_mixin.py:109} INFO - [2022-08-13 23:49:15,481] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:49:16,114] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:49:16,129] {logging_mixin.py:109} INFO - [2022-08-13 23:49:16,128] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:49:16,146] {logging_mixin.py:109} INFO - [2022-08-13 23:49:16,146] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:49:16,162] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.689 seconds
[2022-08-13 23:49:46,335] {processor.py:163} INFO - Started process (PID=94044) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:49:46,338] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:49:46,340] {logging_mixin.py:109} INFO - [2022-08-13 23:49:46,340] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:49:47,118] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:49:47,134] {logging_mixin.py:109} INFO - [2022-08-13 23:49:47,133] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:49:47,154] {logging_mixin.py:109} INFO - [2022-08-13 23:49:47,154] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:49:47,173] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.843 seconds
[2022-08-13 23:50:17,747] {processor.py:163} INFO - Started process (PID=94110) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:50:17,750] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:50:17,752] {logging_mixin.py:109} INFO - [2022-08-13 23:50:17,752] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:50:18,453] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:50:18,469] {logging_mixin.py:109} INFO - [2022-08-13 23:50:18,468] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:50:18,489] {logging_mixin.py:109} INFO - [2022-08-13 23:50:18,489] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:50:18,501] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.760 seconds
[2022-08-13 23:50:49,376] {processor.py:163} INFO - Started process (PID=94185) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:50:49,379] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:50:49,381] {logging_mixin.py:109} INFO - [2022-08-13 23:50:49,381] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:50:50,004] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:50:50,017] {logging_mixin.py:109} INFO - [2022-08-13 23:50:50,017] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:50:50,034] {logging_mixin.py:109} INFO - [2022-08-13 23:50:50,034] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:50:50,046] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.676 seconds
[2022-08-13 23:51:20,123] {processor.py:163} INFO - Started process (PID=94249) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:51:20,125] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:51:20,127] {logging_mixin.py:109} INFO - [2022-08-13 23:51:20,127] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:51:20,782] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:51:20,794] {logging_mixin.py:109} INFO - [2022-08-13 23:51:20,794] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:51:20,811] {logging_mixin.py:109} INFO - [2022-08-13 23:51:20,811] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:51:20,826] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.708 seconds
[2022-08-13 23:51:51,081] {processor.py:163} INFO - Started process (PID=94324) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:51:51,083] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:51:51,084] {logging_mixin.py:109} INFO - [2022-08-13 23:51:51,084] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:51:51,600] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:51:51,613] {logging_mixin.py:109} INFO - [2022-08-13 23:51:51,611] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:51:51,634] {logging_mixin.py:109} INFO - [2022-08-13 23:51:51,633] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:51:51,650] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.573 seconds
[2022-08-13 23:52:22,582] {processor.py:163} INFO - Started process (PID=94389) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:52:22,584] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:52:22,585] {logging_mixin.py:109} INFO - [2022-08-13 23:52:22,585] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:52:23,050] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:52:23,066] {logging_mixin.py:109} INFO - [2022-08-13 23:52:23,064] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:52:23,084] {logging_mixin.py:109} INFO - [2022-08-13 23:52:23,084] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:52:23,095] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.518 seconds
[2022-08-13 23:52:54,029] {processor.py:163} INFO - Started process (PID=94463) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:52:54,032] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:52:54,033] {logging_mixin.py:109} INFO - [2022-08-13 23:52:54,033] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:52:54,662] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:52:54,680] {logging_mixin.py:109} INFO - [2022-08-13 23:52:54,679] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:52:54,700] {logging_mixin.py:109} INFO - [2022-08-13 23:52:54,700] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:52:54,712] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.690 seconds
[2022-08-13 23:53:24,906] {processor.py:163} INFO - Started process (PID=94530) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:53:24,911] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:53:24,913] {logging_mixin.py:109} INFO - [2022-08-13 23:53:24,913] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:53:25,409] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:53:25,426] {logging_mixin.py:109} INFO - [2022-08-13 23:53:25,425] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:53:25,443] {logging_mixin.py:109} INFO - [2022-08-13 23:53:25,443] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:53:25,455] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.554 seconds
[2022-08-13 23:53:55,936] {processor.py:163} INFO - Started process (PID=94597) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:53:55,939] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:53:55,941] {logging_mixin.py:109} INFO - [2022-08-13 23:53:55,941] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:53:56,449] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:53:56,461] {logging_mixin.py:109} INFO - [2022-08-13 23:53:56,459] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:53:56,478] {logging_mixin.py:109} INFO - [2022-08-13 23:53:56,478] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:53:56,489] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.559 seconds
[2022-08-13 23:54:27,130] {processor.py:163} INFO - Started process (PID=94672) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:54:27,134] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:54:27,136] {logging_mixin.py:109} INFO - [2022-08-13 23:54:27,136] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:54:27,892] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:54:27,908] {logging_mixin.py:109} INFO - [2022-08-13 23:54:27,907] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:54:27,938] {logging_mixin.py:109} INFO - [2022-08-13 23:54:27,938] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:54:27,957] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.836 seconds
[2022-08-13 23:54:58,626] {processor.py:163} INFO - Started process (PID=94739) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:54:58,630] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:54:58,632] {logging_mixin.py:109} INFO - [2022-08-13 23:54:58,632] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:54:59,176] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:54:59,190] {logging_mixin.py:109} INFO - [2022-08-13 23:54:59,189] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:54:59,208] {logging_mixin.py:109} INFO - [2022-08-13 23:54:59,208] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:54:59,222] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.599 seconds
[2022-08-13 23:55:30,135] {processor.py:163} INFO - Started process (PID=94816) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:55:30,137] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:55:30,139] {logging_mixin.py:109} INFO - [2022-08-13 23:55:30,139] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:55:30,704] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:55:30,717] {logging_mixin.py:109} INFO - [2022-08-13 23:55:30,716] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:55:30,734] {logging_mixin.py:109} INFO - [2022-08-13 23:55:30,734] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:55:30,749] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.618 seconds
[2022-08-13 23:56:01,568] {processor.py:163} INFO - Started process (PID=94882) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:56:01,571] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:56:01,573] {logging_mixin.py:109} INFO - [2022-08-13 23:56:01,573] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:56:02,101] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:56:02,123] {logging_mixin.py:109} INFO - [2022-08-13 23:56:02,122] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:56:02,143] {logging_mixin.py:109} INFO - [2022-08-13 23:56:02,143] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:56:02,160] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.599 seconds
[2022-08-13 23:56:32,504] {processor.py:163} INFO - Started process (PID=94947) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:56:32,508] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:56:32,509] {logging_mixin.py:109} INFO - [2022-08-13 23:56:32,509] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:56:32,937] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:56:32,948] {logging_mixin.py:109} INFO - [2022-08-13 23:56:32,947] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:56:33,050] {logging_mixin.py:109} INFO - [2022-08-13 23:56:33,050] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:56:33,060] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.561 seconds
[2022-08-13 23:57:03,401] {processor.py:163} INFO - Started process (PID=95023) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:57:03,405] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:57:03,407] {logging_mixin.py:109} INFO - [2022-08-13 23:57:03,407] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:57:03,878] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:57:03,894] {logging_mixin.py:109} INFO - [2022-08-13 23:57:03,893] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:57:04,022] {logging_mixin.py:109} INFO - [2022-08-13 23:57:04,022] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:57:04,037] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.642 seconds
[2022-08-13 23:57:34,949] {processor.py:163} INFO - Started process (PID=95088) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:57:34,951] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:57:34,952] {logging_mixin.py:109} INFO - [2022-08-13 23:57:34,952] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:57:35,439] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:57:35,452] {logging_mixin.py:109} INFO - [2022-08-13 23:57:35,451] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:57:35,586] {logging_mixin.py:109} INFO - [2022-08-13 23:57:35,586] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:57:35,598] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.654 seconds
[2022-08-13 23:58:05,935] {processor.py:163} INFO - Started process (PID=95163) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:58:05,937] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:58:05,940] {logging_mixin.py:109} INFO - [2022-08-13 23:58:05,939] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:58:06,585] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:58:06,595] {logging_mixin.py:109} INFO - [2022-08-13 23:58:06,595] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:58:06,611] {logging_mixin.py:109} INFO - [2022-08-13 23:58:06,611] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:58:06,623] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.693 seconds
[2022-08-13 23:58:37,277] {processor.py:163} INFO - Started process (PID=95228) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:58:37,280] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:58:37,282] {logging_mixin.py:109} INFO - [2022-08-13 23:58:37,282] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:58:37,910] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:58:37,922] {logging_mixin.py:109} INFO - [2022-08-13 23:58:37,921] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:58:37,950] {logging_mixin.py:109} INFO - [2022-08-13 23:58:37,949] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:58:37,965] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.692 seconds
[2022-08-13 23:59:08,704] {processor.py:163} INFO - Started process (PID=95303) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:59:08,706] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:59:08,707] {logging_mixin.py:109} INFO - [2022-08-13 23:59:08,707] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:59:09,331] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:59:09,340] {logging_mixin.py:109} INFO - [2022-08-13 23:59:09,340] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:59:09,357] {logging_mixin.py:109} INFO - [2022-08-13 23:59:09,356] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:59:09,368] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.669 seconds
[2022-08-13 23:59:40,160] {processor.py:163} INFO - Started process (PID=95368) to work on /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:59:40,163] {processor.py:642} INFO - Processing file /opt/airflow/dags/postgres_ingestion.py for tasks to queue
[2022-08-13 23:59:40,166] {logging_mixin.py:109} INFO - [2022-08-13 23:59:40,165] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:59:40,754] {processor.py:654} INFO - DAG(s) dict_keys(['load_data']) retrieved from /opt/airflow/dags/postgres_ingestion.py
[2022-08-13 23:59:40,763] {logging_mixin.py:109} INFO - [2022-08-13 23:59:40,762] {dag.py:2396} INFO - Sync 1 DAGs
[2022-08-13 23:59:40,778] {logging_mixin.py:109} INFO - [2022-08-13 23:59:40,778] {dag.py:2935} INFO - Setting next_dagrun for load_data to None
[2022-08-13 23:59:40,790] {processor.py:171} INFO - Processing /opt/airflow/dags/postgres_ingestion.py took 0.634 seconds
